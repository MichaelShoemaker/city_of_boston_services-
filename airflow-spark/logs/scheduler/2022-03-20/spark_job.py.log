[2022-03-20 01:18:04,145] {scheduler_job.py:182} INFO - Started process (PID=9063) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 01:18:04,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 01:18:04,155] {logging_mixin.py:104} INFO - [2022-03-20 01:18:04,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 01:18:04,208] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 01:18:04,297] {logging_mixin.py:104} INFO - [2022-03-20 01:18:04,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 01:18:04,363] {logging_mixin.py:104} INFO - [2022-03-20 01:18:04,362] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 01:18:04,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.279 seconds
[2022-03-20 02:38:52,185] {scheduler_job.py:182} INFO - Started process (PID=9095) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 02:38:52,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 02:38:52,197] {logging_mixin.py:104} INFO - [2022-03-20 02:38:52,196] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 02:38:52,270] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 02:38:52,361] {logging_mixin.py:104} INFO - [2022-03-20 02:38:52,361] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 02:38:52,450] {logging_mixin.py:104} INFO - [2022-03-20 02:38:52,449] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 02:38:52,488] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.316 seconds
[2022-03-20 04:01:47,658] {scheduler_job.py:182} INFO - Started process (PID=9127) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:01:47,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:01:47,681] {logging_mixin.py:104} INFO - [2022-03-20 04:01:47,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:01:47,746] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:01:47,807] {logging_mixin.py:104} INFO - [2022-03-20 04:01:47,807] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:01:47,909] {logging_mixin.py:104} INFO - [2022-03-20 04:01:47,909] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:01:47,949] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.304 seconds
[2022-03-20 04:21:48,768] {scheduler_job.py:182} INFO - Started process (PID=9159) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:21:48,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:21:48,780] {logging_mixin.py:104} INFO - [2022-03-20 04:21:48,780] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:21:48,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:21:48,931] {logging_mixin.py:104} INFO - [2022-03-20 04:21:48,930] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:21:48,986] {logging_mixin.py:104} INFO - [2022-03-20 04:21:48,986] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:21:49,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.264 seconds
[2022-03-20 04:22:23,386] {scheduler_job.py:182} INFO - Started process (PID=9191) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:23,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:22:23,393] {logging_mixin.py:104} INFO - [2022-03-20 04:22:23,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:23,428] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:23,473] {logging_mixin.py:104} INFO - [2022-03-20 04:22:23,472] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:22:23,511] {logging_mixin.py:104} INFO - [2022-03-20 04:22:23,511] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:22:23,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 04:22:58,070] {scheduler_job.py:182} INFO - Started process (PID=9223) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:58,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:22:58,076] {logging_mixin.py:104} INFO - [2022-03-20 04:22:58,076] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:58,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:22:58,157] {logging_mixin.py:104} INFO - [2022-03-20 04:22:58,156] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:22:58,192] {logging_mixin.py:104} INFO - [2022-03-20 04:22:58,191] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:22:58,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 04:23:32,805] {scheduler_job.py:182} INFO - Started process (PID=9255) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:23:32,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:23:32,811] {logging_mixin.py:104} INFO - [2022-03-20 04:23:32,811] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:23:32,847] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:23:32,890] {logging_mixin.py:104} INFO - [2022-03-20 04:23:32,890] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:23:32,929] {logging_mixin.py:104} INFO - [2022-03-20 04:23:32,928] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:23:32,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 04:24:07,788] {scheduler_job.py:182} INFO - Started process (PID=9287) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:07,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:24:07,794] {logging_mixin.py:104} INFO - [2022-03-20 04:24:07,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:07,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:07,874] {logging_mixin.py:104} INFO - [2022-03-20 04:24:07,873] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:24:07,919] {logging_mixin.py:104} INFO - [2022-03-20 04:24:07,918] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:24:07,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 04:24:42,761] {scheduler_job.py:182} INFO - Started process (PID=9319) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:42,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:24:42,767] {logging_mixin.py:104} INFO - [2022-03-20 04:24:42,767] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:42,801] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:24:42,844] {logging_mixin.py:104} INFO - [2022-03-20 04:24:42,844] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:24:42,878] {logging_mixin.py:104} INFO - [2022-03-20 04:24:42,878] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:24:42,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 04:25:17,416] {scheduler_job.py:182} INFO - Started process (PID=9351) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:17,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:25:17,422] {logging_mixin.py:104} INFO - [2022-03-20 04:25:17,421] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:17,455] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:17,499] {logging_mixin.py:104} INFO - [2022-03-20 04:25:17,499] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:25:17,538] {logging_mixin.py:104} INFO - [2022-03-20 04:25:17,537] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:25:17,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 04:25:52,376] {scheduler_job.py:182} INFO - Started process (PID=9383) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:52,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:25:52,382] {logging_mixin.py:104} INFO - [2022-03-20 04:25:52,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:52,416] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:25:52,463] {logging_mixin.py:104} INFO - [2022-03-20 04:25:52,462] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:25:52,501] {logging_mixin.py:104} INFO - [2022-03-20 04:25:52,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:25:52,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 04:26:27,490] {scheduler_job.py:182} INFO - Started process (PID=9427) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:26:27,494] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:26:27,497] {logging_mixin.py:104} INFO - [2022-03-20 04:26:27,497] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:26:27,534] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:26:27,580] {logging_mixin.py:104} INFO - [2022-03-20 04:26:27,579] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:26:27,615] {logging_mixin.py:104} INFO - [2022-03-20 04:26:27,615] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:26:27,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 04:27:02,581] {scheduler_job.py:182} INFO - Started process (PID=9459) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:02,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:27:02,588] {logging_mixin.py:104} INFO - [2022-03-20 04:27:02,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:02,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:02,664] {logging_mixin.py:104} INFO - [2022-03-20 04:27:02,664] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:27:02,700] {logging_mixin.py:104} INFO - [2022-03-20 04:27:02,700] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:27:02,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 04:27:37,462] {scheduler_job.py:182} INFO - Started process (PID=9491) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:37,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:27:37,469] {logging_mixin.py:104} INFO - [2022-03-20 04:27:37,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:37,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:27:37,549] {logging_mixin.py:104} INFO - [2022-03-20 04:27:37,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:27:37,579] {logging_mixin.py:104} INFO - [2022-03-20 04:27:37,579] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:27:37,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 04:28:12,595] {scheduler_job.py:182} INFO - Started process (PID=9523) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:12,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:28:12,603] {logging_mixin.py:104} INFO - [2022-03-20 04:28:12,602] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:12,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:12,688] {logging_mixin.py:104} INFO - [2022-03-20 04:28:12,688] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:28:12,724] {logging_mixin.py:104} INFO - [2022-03-20 04:28:12,724] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:28:12,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 04:28:47,864] {scheduler_job.py:182} INFO - Started process (PID=9555) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:47,868] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:28:47,871] {logging_mixin.py:104} INFO - [2022-03-20 04:28:47,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:47,905] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:28:47,950] {logging_mixin.py:104} INFO - [2022-03-20 04:28:47,949] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:28:47,983] {logging_mixin.py:104} INFO - [2022-03-20 04:28:47,983] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:28:48,004] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 04:29:22,970] {scheduler_job.py:182} INFO - Started process (PID=9587) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:22,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:29:22,977] {logging_mixin.py:104} INFO - [2022-03-20 04:29:22,976] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:23,015] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:23,061] {logging_mixin.py:104} INFO - [2022-03-20 04:29:23,060] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:29:23,100] {logging_mixin.py:104} INFO - [2022-03-20 04:29:23,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:29:23,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 04:29:57,976] {scheduler_job.py:182} INFO - Started process (PID=9619) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:57,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:29:57,982] {logging_mixin.py:104} INFO - [2022-03-20 04:29:57,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:58,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:29:58,062] {logging_mixin.py:104} INFO - [2022-03-20 04:29:58,062] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:29:58,097] {logging_mixin.py:104} INFO - [2022-03-20 04:29:58,096] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:29:58,116] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 04:30:32,986] {scheduler_job.py:182} INFO - Started process (PID=9651) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:30:32,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:30:32,992] {logging_mixin.py:104} INFO - [2022-03-20 04:30:32,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:30:33,027] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:30:33,072] {logging_mixin.py:104} INFO - [2022-03-20 04:30:33,072] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:30:33,109] {logging_mixin.py:104} INFO - [2022-03-20 04:30:33,108] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:30:33,131] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 04:31:08,177] {scheduler_job.py:182} INFO - Started process (PID=9695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:08,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:31:08,185] {logging_mixin.py:104} INFO - [2022-03-20 04:31:08,184] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:08,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:08,260] {logging_mixin.py:104} INFO - [2022-03-20 04:31:08,259] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:31:08,293] {logging_mixin.py:104} INFO - [2022-03-20 04:31:08,292] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:31:08,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 04:31:42,347] {scheduler_job.py:182} INFO - Started process (PID=9727) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:42,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:31:42,354] {logging_mixin.py:104} INFO - [2022-03-20 04:31:42,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:42,388] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:31:42,429] {logging_mixin.py:104} INFO - [2022-03-20 04:31:42,429] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:31:42,462] {logging_mixin.py:104} INFO - [2022-03-20 04:31:42,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:31:42,479] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 04:32:12,990] {scheduler_job.py:182} INFO - Started process (PID=9750) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:12,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:32:13,001] {logging_mixin.py:104} INFO - [2022-03-20 04:32:13,000] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:13,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:13,081] {logging_mixin.py:104} INFO - [2022-03-20 04:32:13,081] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:32:13,113] {logging_mixin.py:104} INFO - [2022-03-20 04:32:13,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:32:13,133] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 04:32:43,963] {scheduler_job.py:182} INFO - Started process (PID=9779) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:43,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:32:43,971] {logging_mixin.py:104} INFO - [2022-03-20 04:32:43,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:44,005] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:32:44,047] {logging_mixin.py:104} INFO - [2022-03-20 04:32:44,046] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:32:44,079] {logging_mixin.py:104} INFO - [2022-03-20 04:32:44,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:32:44,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 04:33:14,800] {scheduler_job.py:182} INFO - Started process (PID=9811) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:14,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:33:14,810] {logging_mixin.py:104} INFO - [2022-03-20 04:33:14,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:14,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:14,903] {logging_mixin.py:104} INFO - [2022-03-20 04:33:14,903] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:33:14,939] {logging_mixin.py:104} INFO - [2022-03-20 04:33:14,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:33:14,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 04:33:45,696] {scheduler_job.py:182} INFO - Started process (PID=9843) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:45,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:33:45,705] {logging_mixin.py:104} INFO - [2022-03-20 04:33:45,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:45,736] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:33:45,774] {logging_mixin.py:104} INFO - [2022-03-20 04:33:45,774] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:33:45,804] {logging_mixin.py:104} INFO - [2022-03-20 04:33:45,803] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:33:45,823] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 04:34:16,410] {scheduler_job.py:182} INFO - Started process (PID=9875) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:16,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:34:16,417] {logging_mixin.py:104} INFO - [2022-03-20 04:34:16,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:16,450] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:16,494] {logging_mixin.py:104} INFO - [2022-03-20 04:34:16,493] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:34:16,525] {logging_mixin.py:104} INFO - [2022-03-20 04:34:16,524] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:34:16,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 04:34:47,126] {scheduler_job.py:182} INFO - Started process (PID=9907) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:47,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:34:47,134] {logging_mixin.py:104} INFO - [2022-03-20 04:34:47,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:47,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:34:47,208] {logging_mixin.py:104} INFO - [2022-03-20 04:34:47,208] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:34:47,241] {logging_mixin.py:104} INFO - [2022-03-20 04:34:47,240] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:34:47,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 04:35:17,687] {scheduler_job.py:182} INFO - Started process (PID=9939) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:17,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:35:17,694] {logging_mixin.py:104} INFO - [2022-03-20 04:35:17,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:17,726] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:17,767] {logging_mixin.py:104} INFO - [2022-03-20 04:35:17,767] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:35:17,799] {logging_mixin.py:104} INFO - [2022-03-20 04:35:17,799] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:35:17,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 04:35:48,349] {scheduler_job.py:182} INFO - Started process (PID=9971) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:48,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:35:48,355] {logging_mixin.py:104} INFO - [2022-03-20 04:35:48,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:48,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:35:48,428] {logging_mixin.py:104} INFO - [2022-03-20 04:35:48,428] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:35:48,458] {logging_mixin.py:104} INFO - [2022-03-20 04:35:48,457] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:35:48,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.132 seconds
[2022-03-20 04:36:21,436] {scheduler_job.py:182} INFO - Started process (PID=10001) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:21,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:36:21,442] {logging_mixin.py:104} INFO - [2022-03-20 04:36:21,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:21,476] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:21,523] {logging_mixin.py:104} INFO - [2022-03-20 04:36:21,522] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:36:21,555] {logging_mixin.py:104} INFO - [2022-03-20 04:36:21,554] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:36:21,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 04:36:52,186] {scheduler_job.py:182} INFO - Started process (PID=10024) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:52,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:36:52,194] {logging_mixin.py:104} INFO - [2022-03-20 04:36:52,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:52,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:36:52,276] {logging_mixin.py:104} INFO - [2022-03-20 04:36:52,276] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:36:52,310] {logging_mixin.py:104} INFO - [2022-03-20 04:36:52,309] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:36:52,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 04:37:23,185] {scheduler_job.py:182} INFO - Started process (PID=10053) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:23,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:37:23,192] {logging_mixin.py:104} INFO - [2022-03-20 04:37:23,192] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:23,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:23,262] {logging_mixin.py:104} INFO - [2022-03-20 04:37:23,262] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:37:23,292] {logging_mixin.py:104} INFO - [2022-03-20 04:37:23,292] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:37:23,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.130 seconds
[2022-03-20 04:37:54,070] {scheduler_job.py:182} INFO - Started process (PID=10085) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:54,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:37:54,078] {logging_mixin.py:104} INFO - [2022-03-20 04:37:54,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:54,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:37:54,151] {logging_mixin.py:104} INFO - [2022-03-20 04:37:54,151] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:37:54,183] {logging_mixin.py:104} INFO - [2022-03-20 04:37:54,183] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:37:54,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 04:38:25,064] {scheduler_job.py:182} INFO - Started process (PID=10117) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:38:25,068] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:38:25,070] {logging_mixin.py:104} INFO - [2022-03-20 04:38:25,070] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:38:25,104] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:38:25,146] {logging_mixin.py:104} INFO - [2022-03-20 04:38:25,146] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:38:25,182] {logging_mixin.py:104} INFO - [2022-03-20 04:38:25,181] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:38:25,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 04:39:01,841] {scheduler_job.py:182} INFO - Started process (PID=221) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:01,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:39:01,848] {logging_mixin.py:104} INFO - [2022-03-20 04:39:01,847] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:01,920] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:01,970] {logging_mixin.py:104} INFO - [2022-03-20 04:39:01,969] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:39:02,018] {logging_mixin.py:104} INFO - [2022-03-20 04:39:02,018] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:39:02,037] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.203 seconds
[2022-03-20 04:39:32,174] {scheduler_job.py:182} INFO - Started process (PID=249) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:32,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:39:32,180] {logging_mixin.py:104} INFO - [2022-03-20 04:39:32,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:32,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:39:32,276] {logging_mixin.py:104} INFO - [2022-03-20 04:39:32,276] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:39:32,317] {logging_mixin.py:104} INFO - [2022-03-20 04:39:32,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:39:32,334] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 04:40:02,825] {scheduler_job.py:182} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:02,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:40:02,831] {logging_mixin.py:104} INFO - [2022-03-20 04:40:02,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:02,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:02,940] {logging_mixin.py:104} INFO - [2022-03-20 04:40:02,939] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:40:02,986] {logging_mixin.py:104} INFO - [2022-03-20 04:40:02,986] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:40:03,004] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 04:40:33,821] {scheduler_job.py:182} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:33,831] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:40:33,834] {logging_mixin.py:104} INFO - [2022-03-20 04:40:33,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:33,935] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:40:33,988] {logging_mixin.py:104} INFO - [2022-03-20 04:40:33,987] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:40:34,084] {logging_mixin.py:104} INFO - [2022-03-20 04:40:34,084] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:40:34,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.312 seconds
[2022-03-20 04:41:04,893] {scheduler_job.py:182} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:04,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:41:04,900] {logging_mixin.py:104} INFO - [2022-03-20 04:41:04,900] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:04,986] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:05,045] {logging_mixin.py:104} INFO - [2022-03-20 04:41:05,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:41:05,111] {logging_mixin.py:104} INFO - [2022-03-20 04:41:05,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:41:05,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.256 seconds
[2022-03-20 04:41:24,366] {scheduler_job.py:182} INFO - Started process (PID=357) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:24,370] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:41:24,373] {logging_mixin.py:104} INFO - [2022-03-20 04:41:24,373] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:24,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:24,489] {logging_mixin.py:104} INFO - [2022-03-20 04:41:24,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:41:24,526] {logging_mixin.py:104} INFO - [2022-03-20 04:41:24,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:41:24,541] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 04:41:53,497] {scheduler_job.py:182} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:53,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:41:53,528] {logging_mixin.py:104} INFO - [2022-03-20 04:41:53,526] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:53,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:41:53,710] {logging_mixin.py:104} INFO - [2022-03-20 04:41:53,709] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:41:53,750] {logging_mixin.py:104} INFO - [2022-03-20 04:41:53,750] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:41:53,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.282 seconds
[2022-03-20 04:42:24,678] {scheduler_job.py:182} INFO - Started process (PID=421) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:24,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:42:24,686] {logging_mixin.py:104} INFO - [2022-03-20 04:42:24,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:24,736] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:24,776] {logging_mixin.py:104} INFO - [2022-03-20 04:42:24,776] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:42:24,813] {logging_mixin.py:104} INFO - [2022-03-20 04:42:24,813] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:42:24,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 04:42:55,455] {scheduler_job.py:182} INFO - Started process (PID=453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:55,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:42:55,462] {logging_mixin.py:104} INFO - [2022-03-20 04:42:55,462] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:55,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:42:55,551] {logging_mixin.py:104} INFO - [2022-03-20 04:42:55,551] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:42:55,589] {logging_mixin.py:104} INFO - [2022-03-20 04:42:55,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:42:55,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 04:43:26,350] {scheduler_job.py:182} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:26,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:43:26,358] {logging_mixin.py:104} INFO - [2022-03-20 04:43:26,357] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:26,404] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:26,448] {logging_mixin.py:104} INFO - [2022-03-20 04:43:26,447] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:43:26,487] {logging_mixin.py:104} INFO - [2022-03-20 04:43:26,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:43:26,503] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 04:43:49,117] {scheduler_job.py:182} INFO - Started process (PID=513) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:49,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:43:49,122] {logging_mixin.py:104} INFO - [2022-03-20 04:43:49,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:49,174] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:43:49,240] {logging_mixin.py:104} INFO - [2022-03-20 04:43:49,239] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:43:49,286] {logging_mixin.py:104} INFO - [2022-03-20 04:43:49,285] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:43:49,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-20 04:44:20,125] {scheduler_job.py:182} INFO - Started process (PID=659) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:20,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:44:20,134] {logging_mixin.py:104} INFO - [2022-03-20 04:44:20,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:20,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:20,281] {logging_mixin.py:104} INFO - [2022-03-20 04:44:20,280] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:44:20,405] {logging_mixin.py:104} INFO - [2022-03-20 04:44:20,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:44:20,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.332 seconds
[2022-03-20 04:44:50,762] {scheduler_job.py:182} INFO - Started process (PID=807) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:50,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:44:50,783] {logging_mixin.py:104} INFO - [2022-03-20 04:44:50,782] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:50,860] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:44:50,959] {logging_mixin.py:104} INFO - [2022-03-20 04:44:50,958] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:44:51,106] {logging_mixin.py:104} INFO - [2022-03-20 04:44:51,106] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:44:51,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.378 seconds
[2022-03-20 04:45:21,322] {scheduler_job.py:182} INFO - Started process (PID=997) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:21,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:45:21,330] {logging_mixin.py:104} INFO - [2022-03-20 04:45:21,330] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:21,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:21,435] {logging_mixin.py:104} INFO - [2022-03-20 04:45:21,434] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:45:21,480] {logging_mixin.py:104} INFO - [2022-03-20 04:45:21,480] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:45:21,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 04:45:51,961] {scheduler_job.py:182} INFO - Started process (PID=1029) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:51,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:45:51,971] {logging_mixin.py:104} INFO - [2022-03-20 04:45:51,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:52,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:45:52,078] {logging_mixin.py:104} INFO - [2022-03-20 04:45:52,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:45:52,122] {logging_mixin.py:104} INFO - [2022-03-20 04:45:52,121] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:45:52,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-20 04:46:22,311] {scheduler_job.py:182} INFO - Started process (PID=1064) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:22,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:46:22,319] {logging_mixin.py:104} INFO - [2022-03-20 04:46:22,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:22,374] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:22,421] {logging_mixin.py:104} INFO - [2022-03-20 04:46:22,421] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:46:22,472] {logging_mixin.py:104} INFO - [2022-03-20 04:46:22,471] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:46:22,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.190 seconds
[2022-03-20 04:46:52,885] {scheduler_job.py:182} INFO - Started process (PID=1096) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:52,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:46:52,893] {logging_mixin.py:104} INFO - [2022-03-20 04:46:52,892] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:52,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:46:52,991] {logging_mixin.py:104} INFO - [2022-03-20 04:46:52,990] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:46:53,033] {logging_mixin.py:104} INFO - [2022-03-20 04:46:53,033] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:46:53,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 04:47:23,136] {scheduler_job.py:182} INFO - Started process (PID=1127) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:23,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:47:23,142] {logging_mixin.py:104} INFO - [2022-03-20 04:47:23,141] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:23,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:23,234] {logging_mixin.py:104} INFO - [2022-03-20 04:47:23,234] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:47:23,274] {logging_mixin.py:104} INFO - [2022-03-20 04:47:23,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:47:23,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 04:47:53,887] {scheduler_job.py:182} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:53,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:47:53,896] {logging_mixin.py:104} INFO - [2022-03-20 04:47:53,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:53,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:47:53,993] {logging_mixin.py:104} INFO - [2022-03-20 04:47:53,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:47:54,037] {logging_mixin.py:104} INFO - [2022-03-20 04:47:54,037] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:47:54,056] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 04:48:24,755] {scheduler_job.py:182} INFO - Started process (PID=1186) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:24,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:48:24,761] {logging_mixin.py:104} INFO - [2022-03-20 04:48:24,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:24,812] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:24,857] {logging_mixin.py:104} INFO - [2022-03-20 04:48:24,857] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:48:24,900] {logging_mixin.py:104} INFO - [2022-03-20 04:48:24,899] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:48:24,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 04:48:55,578] {scheduler_job.py:182} INFO - Started process (PID=1210) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:55,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:48:55,585] {logging_mixin.py:104} INFO - [2022-03-20 04:48:55,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:55,635] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:48:55,682] {logging_mixin.py:104} INFO - [2022-03-20 04:48:55,682] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:48:55,724] {logging_mixin.py:104} INFO - [2022-03-20 04:48:55,723] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:48:55,741] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 04:49:26,284] {scheduler_job.py:182} INFO - Started process (PID=1242) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:26,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:49:26,292] {logging_mixin.py:104} INFO - [2022-03-20 04:49:26,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:26,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:26,386] {logging_mixin.py:104} INFO - [2022-03-20 04:49:26,386] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:49:26,425] {logging_mixin.py:104} INFO - [2022-03-20 04:49:26,425] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:49:26,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 04:49:56,648] {scheduler_job.py:182} INFO - Started process (PID=1274) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:56,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:49:56,655] {logging_mixin.py:104} INFO - [2022-03-20 04:49:56,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:56,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:49:56,751] {logging_mixin.py:104} INFO - [2022-03-20 04:49:56,751] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:49:56,793] {logging_mixin.py:104} INFO - [2022-03-20 04:49:56,792] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:49:56,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 04:50:27,083] {scheduler_job.py:182} INFO - Started process (PID=1305) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:27,087] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:50:27,090] {logging_mixin.py:104} INFO - [2022-03-20 04:50:27,090] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:27,142] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:27,191] {logging_mixin.py:104} INFO - [2022-03-20 04:50:27,191] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:50:27,237] {logging_mixin.py:104} INFO - [2022-03-20 04:50:27,236] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:50:27,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 04:50:57,527] {scheduler_job.py:182} INFO - Started process (PID=1338) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:57,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:50:57,535] {logging_mixin.py:104} INFO - [2022-03-20 04:50:57,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:57,588] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:50:57,632] {logging_mixin.py:104} INFO - [2022-03-20 04:50:57,632] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:50:57,674] {logging_mixin.py:104} INFO - [2022-03-20 04:50:57,673] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:50:57,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 04:51:27,956] {scheduler_job.py:182} INFO - Started process (PID=1370) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:27,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:51:27,963] {logging_mixin.py:104} INFO - [2022-03-20 04:51:27,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:28,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:28,067] {logging_mixin.py:104} INFO - [2022-03-20 04:51:28,067] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:51:28,111] {logging_mixin.py:104} INFO - [2022-03-20 04:51:28,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:51:28,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 04:51:58,225] {scheduler_job.py:182} INFO - Started process (PID=1402) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:58,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:51:58,232] {logging_mixin.py:104} INFO - [2022-03-20 04:51:58,232] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:58,281] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:51:58,322] {logging_mixin.py:104} INFO - [2022-03-20 04:51:58,322] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:51:58,363] {logging_mixin.py:104} INFO - [2022-03-20 04:51:58,363] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:51:58,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 04:52:28,786] {scheduler_job.py:182} INFO - Started process (PID=1435) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:28,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:52:28,793] {logging_mixin.py:104} INFO - [2022-03-20 04:52:28,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:28,842] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:28,888] {logging_mixin.py:104} INFO - [2022-03-20 04:52:28,887] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:52:28,934] {logging_mixin.py:104} INFO - [2022-03-20 04:52:28,934] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:52:28,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 04:52:59,689] {scheduler_job.py:182} INFO - Started process (PID=1460) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:59,694] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:52:59,696] {logging_mixin.py:104} INFO - [2022-03-20 04:52:59,696] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:59,745] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:52:59,790] {logging_mixin.py:104} INFO - [2022-03-20 04:52:59,790] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:52:59,833] {logging_mixin.py:104} INFO - [2022-03-20 04:52:59,833] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:52:59,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 04:53:30,027] {scheduler_job.py:182} INFO - Started process (PID=1484) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:53:30,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:53:30,034] {logging_mixin.py:104} INFO - [2022-03-20 04:53:30,034] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:53:30,087] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:53:30,132] {logging_mixin.py:104} INFO - [2022-03-20 04:53:30,132] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:53:30,173] {logging_mixin.py:104} INFO - [2022-03-20 04:53:30,173] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:53:30,192] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 04:54:00,317] {scheduler_job.py:182} INFO - Started process (PID=1516) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:00,322] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:54:00,325] {logging_mixin.py:104} INFO - [2022-03-20 04:54:00,325] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:00,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:00,418] {logging_mixin.py:104} INFO - [2022-03-20 04:54:00,418] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:54:00,458] {logging_mixin.py:104} INFO - [2022-03-20 04:54:00,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:54:00,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 04:54:30,624] {scheduler_job.py:182} INFO - Started process (PID=1548) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:30,627] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:54:30,631] {logging_mixin.py:104} INFO - [2022-03-20 04:54:30,630] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:30,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:54:30,728] {logging_mixin.py:104} INFO - [2022-03-20 04:54:30,728] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:54:30,769] {logging_mixin.py:104} INFO - [2022-03-20 04:54:30,769] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:54:30,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 04:55:01,242] {scheduler_job.py:182} INFO - Started process (PID=1580) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:01,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:55:01,250] {logging_mixin.py:104} INFO - [2022-03-20 04:55:01,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:01,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:01,345] {logging_mixin.py:104} INFO - [2022-03-20 04:55:01,345] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:55:01,386] {logging_mixin.py:104} INFO - [2022-03-20 04:55:01,386] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:55:01,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 04:55:32,040] {scheduler_job.py:182} INFO - Started process (PID=1612) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:32,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:55:32,047] {logging_mixin.py:104} INFO - [2022-03-20 04:55:32,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:32,102] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:55:32,147] {logging_mixin.py:104} INFO - [2022-03-20 04:55:32,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:55:32,189] {logging_mixin.py:104} INFO - [2022-03-20 04:55:32,188] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:55:32,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 04:56:02,285] {scheduler_job.py:182} INFO - Started process (PID=1643) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:02,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:56:02,291] {logging_mixin.py:104} INFO - [2022-03-20 04:56:02,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:02,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:02,384] {logging_mixin.py:104} INFO - [2022-03-20 04:56:02,384] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:56:02,426] {logging_mixin.py:104} INFO - [2022-03-20 04:56:02,426] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:56:02,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 04:56:32,942] {scheduler_job.py:182} INFO - Started process (PID=1675) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:32,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:56:32,951] {logging_mixin.py:104} INFO - [2022-03-20 04:56:32,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:33,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:56:33,049] {logging_mixin.py:104} INFO - [2022-03-20 04:56:33,049] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:56:33,094] {logging_mixin.py:104} INFO - [2022-03-20 04:56:33,094] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:56:33,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 04:57:03,687] {scheduler_job.py:182} INFO - Started process (PID=1709) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:03,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:57:03,695] {logging_mixin.py:104} INFO - [2022-03-20 04:57:03,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:03,744] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:03,789] {logging_mixin.py:104} INFO - [2022-03-20 04:57:03,788] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:57:03,832] {logging_mixin.py:104} INFO - [2022-03-20 04:57:03,832] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:57:03,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 04:57:33,943] {scheduler_job.py:182} INFO - Started process (PID=1734) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:33,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:57:33,949] {logging_mixin.py:104} INFO - [2022-03-20 04:57:33,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:33,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:57:34,045] {logging_mixin.py:104} INFO - [2022-03-20 04:57:34,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:57:34,088] {logging_mixin.py:104} INFO - [2022-03-20 04:57:34,088] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:57:34,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 04:58:04,206] {scheduler_job.py:182} INFO - Started process (PID=1759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:04,211] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:58:04,214] {logging_mixin.py:104} INFO - [2022-03-20 04:58:04,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:04,273] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:04,322] {logging_mixin.py:104} INFO - [2022-03-20 04:58:04,322] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:58:04,366] {logging_mixin.py:104} INFO - [2022-03-20 04:58:04,366] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:58:04,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 04:58:34,859] {scheduler_job.py:182} INFO - Started process (PID=1789) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:34,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:58:34,867] {logging_mixin.py:104} INFO - [2022-03-20 04:58:34,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:34,924] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:58:34,973] {logging_mixin.py:104} INFO - [2022-03-20 04:58:34,972] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:58:35,017] {logging_mixin.py:104} INFO - [2022-03-20 04:58:35,017] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:58:35,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 04:59:05,293] {scheduler_job.py:182} INFO - Started process (PID=1822) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:05,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:59:05,300] {logging_mixin.py:104} INFO - [2022-03-20 04:59:05,300] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:05,350] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:05,392] {logging_mixin.py:104} INFO - [2022-03-20 04:59:05,392] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:59:05,432] {logging_mixin.py:104} INFO - [2022-03-20 04:59:05,432] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:59:05,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 04:59:35,675] {scheduler_job.py:182} INFO - Started process (PID=1854) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:35,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 04:59:35,683] {logging_mixin.py:104} INFO - [2022-03-20 04:59:35,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:35,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 04:59:35,789] {logging_mixin.py:104} INFO - [2022-03-20 04:59:35,788] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 04:59:35,835] {logging_mixin.py:104} INFO - [2022-03-20 04:59:35,835] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 04:59:35,855] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-20 05:00:06,071] {scheduler_job.py:182} INFO - Started process (PID=1886) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:06,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:00:06,078] {logging_mixin.py:104} INFO - [2022-03-20 05:00:06,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:06,127] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:06,171] {logging_mixin.py:104} INFO - [2022-03-20 05:00:06,170] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:00:06,211] {logging_mixin.py:104} INFO - [2022-03-20 05:00:06,211] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:00:06,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 05:00:36,535] {scheduler_job.py:182} INFO - Started process (PID=1918) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:36,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:00:36,542] {logging_mixin.py:104} INFO - [2022-03-20 05:00:36,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:36,592] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:00:36,637] {logging_mixin.py:104} INFO - [2022-03-20 05:00:36,637] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:00:36,682] {logging_mixin.py:104} INFO - [2022-03-20 05:00:36,682] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:00:36,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 05:01:07,126] {scheduler_job.py:182} INFO - Started process (PID=1950) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:07,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:01:07,134] {logging_mixin.py:104} INFO - [2022-03-20 05:01:07,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:07,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:07,232] {logging_mixin.py:104} INFO - [2022-03-20 05:01:07,232] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:01:07,276] {logging_mixin.py:104} INFO - [2022-03-20 05:01:07,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:01:07,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 05:01:37,634] {scheduler_job.py:182} INFO - Started process (PID=1983) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:37,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:01:37,640] {logging_mixin.py:104} INFO - [2022-03-20 05:01:37,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:37,687] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:01:37,732] {logging_mixin.py:104} INFO - [2022-03-20 05:01:37,732] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:01:37,775] {logging_mixin.py:104} INFO - [2022-03-20 05:01:37,774] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:01:37,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 05:02:08,265] {scheduler_job.py:182} INFO - Started process (PID=2008) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:08,268] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:02:08,271] {logging_mixin.py:104} INFO - [2022-03-20 05:02:08,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:08,321] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:08,366] {logging_mixin.py:104} INFO - [2022-03-20 05:02:08,365] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:02:08,408] {logging_mixin.py:104} INFO - [2022-03-20 05:02:08,407] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:02:08,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 05:02:39,019] {scheduler_job.py:182} INFO - Started process (PID=2032) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:39,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:02:39,030] {logging_mixin.py:104} INFO - [2022-03-20 05:02:39,029] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:39,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:02:39,127] {logging_mixin.py:104} INFO - [2022-03-20 05:02:39,126] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:02:39,169] {logging_mixin.py:104} INFO - [2022-03-20 05:02:39,169] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:02:39,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 05:03:09,367] {scheduler_job.py:182} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:09,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:03:09,378] {logging_mixin.py:104} INFO - [2022-03-20 05:03:09,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:09,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:09,488] {logging_mixin.py:104} INFO - [2022-03-20 05:03:09,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:03:09,537] {logging_mixin.py:104} INFO - [2022-03-20 05:03:09,537] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:03:09,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.206 seconds
[2022-03-20 05:03:40,030] {scheduler_job.py:182} INFO - Started process (PID=2096) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:40,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:03:40,037] {logging_mixin.py:104} INFO - [2022-03-20 05:03:40,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:40,085] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:03:40,127] {logging_mixin.py:104} INFO - [2022-03-20 05:03:40,127] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:03:40,168] {logging_mixin.py:104} INFO - [2022-03-20 05:03:40,168] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:03:40,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 05:04:10,498] {scheduler_job.py:182} INFO - Started process (PID=2128) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:10,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:04:10,506] {logging_mixin.py:104} INFO - [2022-03-20 05:04:10,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:10,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:10,601] {logging_mixin.py:104} INFO - [2022-03-20 05:04:10,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:04:10,643] {logging_mixin.py:104} INFO - [2022-03-20 05:04:10,643] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:04:10,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 05:04:41,098] {scheduler_job.py:182} INFO - Started process (PID=2160) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:41,102] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:04:41,105] {logging_mixin.py:104} INFO - [2022-03-20 05:04:41,105] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:41,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:04:41,198] {logging_mixin.py:104} INFO - [2022-03-20 05:04:41,198] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:04:41,239] {logging_mixin.py:104} INFO - [2022-03-20 05:04:41,238] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:04:41,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 05:05:11,920] {scheduler_job.py:182} INFO - Started process (PID=2192) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:11,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:05:11,926] {logging_mixin.py:104} INFO - [2022-03-20 05:05:11,926] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:11,980] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:12,027] {logging_mixin.py:104} INFO - [2022-03-20 05:05:12,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:05:12,069] {logging_mixin.py:104} INFO - [2022-03-20 05:05:12,069] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:05:12,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 05:05:42,375] {scheduler_job.py:182} INFO - Started process (PID=2224) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:42,380] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 05:05:42,384] {logging_mixin.py:104} INFO - [2022-03-20 05:05:42,384] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:42,437] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 05:05:42,482] {logging_mixin.py:104} INFO - [2022-03-20 05:05:42,481] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 05:05:42,522] {logging_mixin.py:104} INFO - [2022-03-20 05:05:42,522] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 05:05:42,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 06:09:15,253] {scheduler_job.py:182} INFO - Started process (PID=2273) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 06:09:15,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 06:09:15,263] {logging_mixin.py:104} INFO - [2022-03-20 06:09:15,263] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 06:09:15,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 06:09:15,388] {logging_mixin.py:104} INFO - [2022-03-20 06:09:15,388] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 06:09:15,463] {logging_mixin.py:104} INFO - [2022-03-20 06:09:15,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 06:09:15,856] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.616 seconds
[2022-03-20 07:31:22,455] {scheduler_job.py:182} INFO - Started process (PID=2305) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 07:31:22,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 07:31:22,465] {logging_mixin.py:104} INFO - [2022-03-20 07:31:22,465] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 07:31:22,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 07:31:22,624] {logging_mixin.py:104} INFO - [2022-03-20 07:31:22,623] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 07:31:22,662] {logging_mixin.py:104} INFO - [2022-03-20 07:31:22,662] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 07:31:22,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.247 seconds
[2022-03-20 08:37:31,360] {scheduler_job.py:182} INFO - Started process (PID=2337) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 08:37:31,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 08:37:31,373] {logging_mixin.py:104} INFO - [2022-03-20 08:37:31,373] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 08:37:31,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 08:37:31,549] {logging_mixin.py:104} INFO - [2022-03-20 08:37:31,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 08:37:31,613] {logging_mixin.py:104} INFO - [2022-03-20 08:37:31,612] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 08:37:31,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.296 seconds
[2022-03-20 09:27:58,383] {scheduler_job.py:182} INFO - Started process (PID=2369) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:27:58,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:27:58,396] {logging_mixin.py:104} INFO - [2022-03-20 09:27:58,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:27:58,458] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:27:58,515] {logging_mixin.py:104} INFO - [2022-03-20 09:27:58,514] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:27:58,562] {logging_mixin.py:104} INFO - [2022-03-20 09:27:58,561] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:27:58,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.220 seconds
[2022-03-20 09:28:28,781] {scheduler_job.py:182} INFO - Started process (PID=2397) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:28,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:28:28,790] {logging_mixin.py:104} INFO - [2022-03-20 09:28:28,790] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:28,833] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:28,887] {logging_mixin.py:104} INFO - [2022-03-20 09:28:28,886] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:28:28,932] {logging_mixin.py:104} INFO - [2022-03-20 09:28:28,932] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:28:28,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 09:28:59,279] {scheduler_job.py:182} INFO - Started process (PID=2425) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:59,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:28:59,284] {logging_mixin.py:104} INFO - [2022-03-20 09:28:59,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:59,319] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:28:59,362] {logging_mixin.py:104} INFO - [2022-03-20 09:28:59,362] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:28:59,398] {logging_mixin.py:104} INFO - [2022-03-20 09:28:59,398] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:28:59,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 09:29:30,038] {scheduler_job.py:182} INFO - Started process (PID=2458) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:29:30,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:29:30,046] {logging_mixin.py:104} INFO - [2022-03-20 09:29:30,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:29:30,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:29:30,127] {logging_mixin.py:104} INFO - [2022-03-20 09:29:30,127] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:29:30,160] {logging_mixin.py:104} INFO - [2022-03-20 09:29:30,160] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:29:30,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:30:00,719] {scheduler_job.py:182} INFO - Started process (PID=2490) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:00,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:30:00,725] {logging_mixin.py:104} INFO - [2022-03-20 09:30:00,725] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:00,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:00,807] {logging_mixin.py:104} INFO - [2022-03-20 09:30:00,806] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:30:00,840] {logging_mixin.py:104} INFO - [2022-03-20 09:30:00,840] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:30:00,855] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 09:30:31,410] {scheduler_job.py:182} INFO - Started process (PID=2522) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:31,414] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:30:31,417] {logging_mixin.py:104} INFO - [2022-03-20 09:30:31,416] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:31,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:30:31,493] {logging_mixin.py:104} INFO - [2022-03-20 09:30:31,492] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:30:31,531] {logging_mixin.py:104} INFO - [2022-03-20 09:30:31,530] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:30:31,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:31:02,128] {scheduler_job.py:182} INFO - Started process (PID=2553) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:02,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:31:02,135] {logging_mixin.py:104} INFO - [2022-03-20 09:31:02,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:02,167] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:02,210] {logging_mixin.py:104} INFO - [2022-03-20 09:31:02,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:31:02,244] {logging_mixin.py:104} INFO - [2022-03-20 09:31:02,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:31:02,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 09:31:32,962] {scheduler_job.py:182} INFO - Started process (PID=2587) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:32,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:31:32,968] {logging_mixin.py:104} INFO - [2022-03-20 09:31:32,968] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:33,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:31:33,044] {logging_mixin.py:104} INFO - [2022-03-20 09:31:33,044] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:31:33,080] {logging_mixin.py:104} INFO - [2022-03-20 09:31:33,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:31:33,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 09:32:03,930] {scheduler_job.py:182} INFO - Started process (PID=2611) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:03,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:32:03,937] {logging_mixin.py:104} INFO - [2022-03-20 09:32:03,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:03,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:04,013] {logging_mixin.py:104} INFO - [2022-03-20 09:32:04,013] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:32:04,045] {logging_mixin.py:104} INFO - [2022-03-20 09:32:04,045] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:32:04,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 09:32:34,690] {scheduler_job.py:182} INFO - Started process (PID=2636) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:34,694] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:32:34,696] {logging_mixin.py:104} INFO - [2022-03-20 09:32:34,696] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:34,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:32:34,777] {logging_mixin.py:104} INFO - [2022-03-20 09:32:34,776] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:32:34,810] {logging_mixin.py:104} INFO - [2022-03-20 09:32:34,810] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:32:34,827] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 09:33:05,498] {scheduler_job.py:182} INFO - Started process (PID=2668) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:05,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:33:05,504] {logging_mixin.py:104} INFO - [2022-03-20 09:33:05,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:05,540] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:05,587] {logging_mixin.py:104} INFO - [2022-03-20 09:33:05,587] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:33:05,622] {logging_mixin.py:104} INFO - [2022-03-20 09:33:05,621] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:33:05,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 09:33:36,141] {scheduler_job.py:182} INFO - Started process (PID=2700) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:36,145] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:33:36,148] {logging_mixin.py:104} INFO - [2022-03-20 09:33:36,147] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:36,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:33:36,224] {logging_mixin.py:104} INFO - [2022-03-20 09:33:36,224] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:33:36,257] {logging_mixin.py:104} INFO - [2022-03-20 09:33:36,256] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:33:36,272] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 09:34:06,818] {scheduler_job.py:182} INFO - Started process (PID=2732) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:06,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:34:06,824] {logging_mixin.py:104} INFO - [2022-03-20 09:34:06,824] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:06,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:06,904] {logging_mixin.py:104} INFO - [2022-03-20 09:34:06,903] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:34:06,938] {logging_mixin.py:104} INFO - [2022-03-20 09:34:06,937] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:34:06,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:34:37,564] {scheduler_job.py:182} INFO - Started process (PID=2763) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:37,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:34:37,571] {logging_mixin.py:104} INFO - [2022-03-20 09:34:37,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:37,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:34:37,648] {logging_mixin.py:104} INFO - [2022-03-20 09:34:37,648] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:34:37,682] {logging_mixin.py:104} INFO - [2022-03-20 09:34:37,681] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:34:37,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 09:35:08,245] {scheduler_job.py:182} INFO - Started process (PID=2795) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:08,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:35:08,253] {logging_mixin.py:104} INFO - [2022-03-20 09:35:08,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:08,289] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:08,336] {logging_mixin.py:104} INFO - [2022-03-20 09:35:08,336] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:35:08,370] {logging_mixin.py:104} INFO - [2022-03-20 09:35:08,370] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:35:08,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 09:35:39,026] {scheduler_job.py:182} INFO - Started process (PID=2827) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:39,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:35:39,033] {logging_mixin.py:104} INFO - [2022-03-20 09:35:39,032] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:39,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:35:39,115] {logging_mixin.py:104} INFO - [2022-03-20 09:35:39,115] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:35:39,149] {logging_mixin.py:104} INFO - [2022-03-20 09:35:39,148] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:35:39,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:36:09,880] {scheduler_job.py:182} INFO - Started process (PID=2861) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:09,884] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:36:09,887] {logging_mixin.py:104} INFO - [2022-03-20 09:36:09,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:09,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:09,966] {logging_mixin.py:104} INFO - [2022-03-20 09:36:09,966] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:36:09,998] {logging_mixin.py:104} INFO - [2022-03-20 09:36:09,998] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:36:10,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 09:36:40,347] {scheduler_job.py:182} INFO - Started process (PID=2878) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:40,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:36:40,354] {logging_mixin.py:104} INFO - [2022-03-20 09:36:40,354] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:40,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:36:40,432] {logging_mixin.py:104} INFO - [2022-03-20 09:36:40,432] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:36:40,465] {logging_mixin.py:104} INFO - [2022-03-20 09:36:40,465] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:36:40,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 09:37:11,065] {scheduler_job.py:182} INFO - Started process (PID=2909) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:11,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:37:11,072] {logging_mixin.py:104} INFO - [2022-03-20 09:37:11,072] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:11,104] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:11,148] {logging_mixin.py:104} INFO - [2022-03-20 09:37:11,148] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:37:11,182] {logging_mixin.py:104} INFO - [2022-03-20 09:37:11,182] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:37:11,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 09:37:41,996] {scheduler_job.py:182} INFO - Started process (PID=2942) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:41,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:37:42,002] {logging_mixin.py:104} INFO - [2022-03-20 09:37:42,002] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:42,035] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:37:42,078] {logging_mixin.py:104} INFO - [2022-03-20 09:37:42,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:37:42,113] {logging_mixin.py:104} INFO - [2022-03-20 09:37:42,112] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:37:42,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 09:38:12,705] {scheduler_job.py:182} INFO - Started process (PID=2973) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:12,708] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:38:12,711] {logging_mixin.py:104} INFO - [2022-03-20 09:38:12,711] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:12,747] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:12,789] {logging_mixin.py:104} INFO - [2022-03-20 09:38:12,788] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:38:12,822] {logging_mixin.py:104} INFO - [2022-03-20 09:38:12,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:38:12,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 09:38:43,249] {scheduler_job.py:182} INFO - Started process (PID=3006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:43,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:38:43,255] {logging_mixin.py:104} INFO - [2022-03-20 09:38:43,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:43,290] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:38:43,334] {logging_mixin.py:104} INFO - [2022-03-20 09:38:43,334] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:38:43,367] {logging_mixin.py:104} INFO - [2022-03-20 09:38:43,367] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:38:43,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 09:39:13,800] {scheduler_job.py:182} INFO - Started process (PID=3038) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:13,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:39:13,808] {logging_mixin.py:104} INFO - [2022-03-20 09:39:13,808] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:13,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:13,891] {logging_mixin.py:104} INFO - [2022-03-20 09:39:13,891] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:39:13,924] {logging_mixin.py:104} INFO - [2022-03-20 09:39:13,923] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:39:13,939] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 09:39:44,378] {scheduler_job.py:182} INFO - Started process (PID=3069) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:44,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:39:44,385] {logging_mixin.py:104} INFO - [2022-03-20 09:39:44,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:44,419] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:39:44,463] {logging_mixin.py:104} INFO - [2022-03-20 09:39:44,463] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:39:44,496] {logging_mixin.py:104} INFO - [2022-03-20 09:39:44,496] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:39:44,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 09:40:14,925] {scheduler_job.py:182} INFO - Started process (PID=3103) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:14,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:40:14,931] {logging_mixin.py:104} INFO - [2022-03-20 09:40:14,930] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:14,963] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:15,010] {logging_mixin.py:104} INFO - [2022-03-20 09:40:15,009] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:40:15,041] {logging_mixin.py:104} INFO - [2022-03-20 09:40:15,041] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:40:15,056] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 09:40:45,787] {scheduler_job.py:182} INFO - Started process (PID=3128) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:45,791] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:40:45,793] {logging_mixin.py:104} INFO - [2022-03-20 09:40:45,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:45,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:40:45,871] {logging_mixin.py:104} INFO - [2022-03-20 09:40:45,871] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:40:45,904] {logging_mixin.py:104} INFO - [2022-03-20 09:40:45,904] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:40:45,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 09:41:16,112] {scheduler_job.py:182} INFO - Started process (PID=3153) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:16,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:41:16,118] {logging_mixin.py:104} INFO - [2022-03-20 09:41:16,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:16,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:16,188] {logging_mixin.py:104} INFO - [2022-03-20 09:41:16,188] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:41:16,219] {logging_mixin.py:104} INFO - [2022-03-20 09:41:16,219] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:41:16,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.131 seconds
[2022-03-20 09:41:46,447] {scheduler_job.py:182} INFO - Started process (PID=3184) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:46,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:41:46,453] {logging_mixin.py:104} INFO - [2022-03-20 09:41:46,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:46,489] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:41:46,534] {logging_mixin.py:104} INFO - [2022-03-20 09:41:46,534] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:41:46,569] {logging_mixin.py:104} INFO - [2022-03-20 09:41:46,569] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:41:46,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 09:42:16,989] {scheduler_job.py:182} INFO - Started process (PID=3215) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:16,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:42:16,996] {logging_mixin.py:104} INFO - [2022-03-20 09:42:16,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:17,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:17,074] {logging_mixin.py:104} INFO - [2022-03-20 09:42:17,074] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:42:17,106] {logging_mixin.py:104} INFO - [2022-03-20 09:42:17,106] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:42:17,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 09:42:47,430] {scheduler_job.py:182} INFO - Started process (PID=3248) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:47,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:42:47,439] {logging_mixin.py:104} INFO - [2022-03-20 09:42:47,439] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:47,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:42:47,522] {logging_mixin.py:104} INFO - [2022-03-20 09:42:47,522] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:42:47,557] {logging_mixin.py:104} INFO - [2022-03-20 09:42:47,556] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:42:47,572] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 09:43:17,956] {scheduler_job.py:182} INFO - Started process (PID=3280) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:17,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:43:17,964] {logging_mixin.py:104} INFO - [2022-03-20 09:43:17,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:17,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:18,045] {logging_mixin.py:104} INFO - [2022-03-20 09:43:18,044] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:43:18,077] {logging_mixin.py:104} INFO - [2022-03-20 09:43:18,077] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:43:18,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 09:43:48,437] {scheduler_job.py:182} INFO - Started process (PID=3312) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:48,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:43:48,447] {logging_mixin.py:104} INFO - [2022-03-20 09:43:48,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:48,487] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:43:48,533] {logging_mixin.py:104} INFO - [2022-03-20 09:43:48,532] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:43:48,566] {logging_mixin.py:104} INFO - [2022-03-20 09:43:48,565] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:43:48,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 09:44:18,964] {scheduler_job.py:182} INFO - Started process (PID=3343) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:18,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:44:18,973] {logging_mixin.py:104} INFO - [2022-03-20 09:44:18,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:19,008] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:19,057] {logging_mixin.py:104} INFO - [2022-03-20 09:44:19,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:44:19,091] {logging_mixin.py:104} INFO - [2022-03-20 09:44:19,091] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:44:19,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 09:44:49,783] {scheduler_job.py:182} INFO - Started process (PID=3377) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:49,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:44:49,790] {logging_mixin.py:104} INFO - [2022-03-20 09:44:49,789] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:49,826] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:44:49,871] {logging_mixin.py:104} INFO - [2022-03-20 09:44:49,871] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:44:49,904] {logging_mixin.py:104} INFO - [2022-03-20 09:44:49,903] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:44:49,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:45:20,432] {scheduler_job.py:182} INFO - Started process (PID=3401) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:20,437] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:45:20,439] {logging_mixin.py:104} INFO - [2022-03-20 09:45:20,439] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:20,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:20,515] {logging_mixin.py:104} INFO - [2022-03-20 09:45:20,514] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:45:20,547] {logging_mixin.py:104} INFO - [2022-03-20 09:45:20,546] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:45:20,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 09:45:50,723] {scheduler_job.py:182} INFO - Started process (PID=3426) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:50,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:45:50,730] {logging_mixin.py:104} INFO - [2022-03-20 09:45:50,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:50,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:45:50,818] {logging_mixin.py:104} INFO - [2022-03-20 09:45:50,817] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:45:50,854] {logging_mixin.py:104} INFO - [2022-03-20 09:45:50,854] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:45:50,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 09:46:21,554] {scheduler_job.py:182} INFO - Started process (PID=3458) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:21,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:46:21,562] {logging_mixin.py:104} INFO - [2022-03-20 09:46:21,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:21,599] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:21,643] {logging_mixin.py:104} INFO - [2022-03-20 09:46:21,642] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:46:21,676] {logging_mixin.py:104} INFO - [2022-03-20 09:46:21,676] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:46:21,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 09:46:51,903] {scheduler_job.py:182} INFO - Started process (PID=3490) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:51,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:46:51,910] {logging_mixin.py:104} INFO - [2022-03-20 09:46:51,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:51,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:46:51,990] {logging_mixin.py:104} INFO - [2022-03-20 09:46:51,989] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:46:52,022] {logging_mixin.py:104} INFO - [2022-03-20 09:46:52,022] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:46:52,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 09:47:22,266] {scheduler_job.py:182} INFO - Started process (PID=3522) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:22,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:47:22,273] {logging_mixin.py:104} INFO - [2022-03-20 09:47:22,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:22,308] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:22,353] {logging_mixin.py:104} INFO - [2022-03-20 09:47:22,353] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:47:22,387] {logging_mixin.py:104} INFO - [2022-03-20 09:47:22,387] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:47:22,402] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 09:47:52,607] {scheduler_job.py:182} INFO - Started process (PID=3554) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:52,611] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:47:52,614] {logging_mixin.py:104} INFO - [2022-03-20 09:47:52,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:52,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:47:52,695] {logging_mixin.py:104} INFO - [2022-03-20 09:47:52,695] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:47:52,729] {logging_mixin.py:104} INFO - [2022-03-20 09:47:52,728] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:47:52,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 09:48:23,045] {scheduler_job.py:182} INFO - Started process (PID=3586) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:23,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:48:23,053] {logging_mixin.py:104} INFO - [2022-03-20 09:48:23,053] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:23,087] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:23,133] {logging_mixin.py:104} INFO - [2022-03-20 09:48:23,132] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:48:23,170] {logging_mixin.py:104} INFO - [2022-03-20 09:48:23,170] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:48:23,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 09:48:53,395] {scheduler_job.py:182} INFO - Started process (PID=3617) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:53,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:48:53,401] {logging_mixin.py:104} INFO - [2022-03-20 09:48:53,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:53,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:48:53,481] {logging_mixin.py:104} INFO - [2022-03-20 09:48:53,481] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:48:53,518] {logging_mixin.py:104} INFO - [2022-03-20 09:48:53,518] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:48:53,534] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 09:49:23,736] {scheduler_job.py:182} INFO - Started process (PID=3642) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:23,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:49:23,742] {logging_mixin.py:104} INFO - [2022-03-20 09:49:23,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:23,777] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:23,821] {logging_mixin.py:104} INFO - [2022-03-20 09:49:23,820] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:49:23,857] {logging_mixin.py:104} INFO - [2022-03-20 09:49:23,856] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:49:23,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 09:49:54,479] {scheduler_job.py:182} INFO - Started process (PID=3667) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:54,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:49:54,486] {logging_mixin.py:104} INFO - [2022-03-20 09:49:54,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:54,524] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:49:54,568] {logging_mixin.py:104} INFO - [2022-03-20 09:49:54,567] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:49:54,604] {logging_mixin.py:104} INFO - [2022-03-20 09:49:54,603] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:49:54,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 09:50:25,077] {scheduler_job.py:182} INFO - Started process (PID=3700) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:25,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:50:25,089] {logging_mixin.py:104} INFO - [2022-03-20 09:50:25,089] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:25,125] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:25,171] {logging_mixin.py:104} INFO - [2022-03-20 09:50:25,171] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:50:25,209] {logging_mixin.py:104} INFO - [2022-03-20 09:50:25,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:50:25,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 09:50:55,654] {scheduler_job.py:182} INFO - Started process (PID=3731) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:55,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:50:55,661] {logging_mixin.py:104} INFO - [2022-03-20 09:50:55,660] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:55,695] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:50:55,742] {logging_mixin.py:104} INFO - [2022-03-20 09:50:55,741] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:50:55,775] {logging_mixin.py:104} INFO - [2022-03-20 09:50:55,774] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:50:55,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 09:51:26,151] {scheduler_job.py:182} INFO - Started process (PID=3764) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:26,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:51:26,161] {logging_mixin.py:104} INFO - [2022-03-20 09:51:26,160] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:26,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:26,243] {logging_mixin.py:104} INFO - [2022-03-20 09:51:26,242] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:51:26,276] {logging_mixin.py:104} INFO - [2022-03-20 09:51:26,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:51:26,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 09:51:56,831] {scheduler_job.py:182} INFO - Started process (PID=3796) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:56,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:51:56,840] {logging_mixin.py:104} INFO - [2022-03-20 09:51:56,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:56,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:51:56,924] {logging_mixin.py:104} INFO - [2022-03-20 09:51:56,924] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:51:56,959] {logging_mixin.py:104} INFO - [2022-03-20 09:51:56,959] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:51:56,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 09:52:27,384] {scheduler_job.py:182} INFO - Started process (PID=3828) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:27,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:52:27,392] {logging_mixin.py:104} INFO - [2022-03-20 09:52:27,392] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:27,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:27,480] {logging_mixin.py:104} INFO - [2022-03-20 09:52:27,480] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:52:27,516] {logging_mixin.py:104} INFO - [2022-03-20 09:52:27,516] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:52:27,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 09:52:57,904] {scheduler_job.py:182} INFO - Started process (PID=3860) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:57,908] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:52:57,911] {logging_mixin.py:104} INFO - [2022-03-20 09:52:57,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:57,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:52:57,994] {logging_mixin.py:104} INFO - [2022-03-20 09:52:57,994] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:52:58,031] {logging_mixin.py:104} INFO - [2022-03-20 09:52:58,031] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:52:58,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 09:53:28,694] {scheduler_job.py:182} INFO - Started process (PID=3893) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:28,697] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:53:28,700] {logging_mixin.py:104} INFO - [2022-03-20 09:53:28,699] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:28,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:28,780] {logging_mixin.py:104} INFO - [2022-03-20 09:53:28,780] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:53:28,813] {logging_mixin.py:104} INFO - [2022-03-20 09:53:28,813] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:53:28,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 09:53:59,469] {scheduler_job.py:182} INFO - Started process (PID=3918) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:59,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:53:59,475] {logging_mixin.py:104} INFO - [2022-03-20 09:53:59,475] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:59,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:53:59,557] {logging_mixin.py:104} INFO - [2022-03-20 09:53:59,557] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:53:59,589] {logging_mixin.py:104} INFO - [2022-03-20 09:53:59,589] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:53:59,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 09:54:29,766] {scheduler_job.py:182} INFO - Started process (PID=3943) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:54:29,773] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:54:29,776] {logging_mixin.py:104} INFO - [2022-03-20 09:54:29,776] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:54:29,808] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:54:29,850] {logging_mixin.py:104} INFO - [2022-03-20 09:54:29,850] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:54:29,881] {logging_mixin.py:104} INFO - [2022-03-20 09:54:29,881] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:54:29,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 09:55:00,303] {scheduler_job.py:182} INFO - Started process (PID=3974) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:00,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:55:00,310] {logging_mixin.py:104} INFO - [2022-03-20 09:55:00,310] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:00,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:00,396] {logging_mixin.py:104} INFO - [2022-03-20 09:55:00,396] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:55:00,431] {logging_mixin.py:104} INFO - [2022-03-20 09:55:00,430] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:55:00,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 09:55:30,924] {scheduler_job.py:182} INFO - Started process (PID=4006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:30,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:55:30,931] {logging_mixin.py:104} INFO - [2022-03-20 09:55:30,930] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:30,969] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:55:31,015] {logging_mixin.py:104} INFO - [2022-03-20 09:55:31,015] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:55:31,050] {logging_mixin.py:104} INFO - [2022-03-20 09:55:31,050] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:55:31,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 09:56:01,373] {scheduler_job.py:182} INFO - Started process (PID=4038) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:01,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:56:01,383] {logging_mixin.py:104} INFO - [2022-03-20 09:56:01,382] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:01,421] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:01,468] {logging_mixin.py:104} INFO - [2022-03-20 09:56:01,467] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:56:01,503] {logging_mixin.py:104} INFO - [2022-03-20 09:56:01,503] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:56:01,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 09:56:31,984] {scheduler_job.py:182} INFO - Started process (PID=4070) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:31,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:56:31,994] {logging_mixin.py:104} INFO - [2022-03-20 09:56:31,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:32,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:56:32,078] {logging_mixin.py:104} INFO - [2022-03-20 09:56:32,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:56:32,112] {logging_mixin.py:104} INFO - [2022-03-20 09:56:32,112] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:56:32,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 09:57:02,604] {scheduler_job.py:182} INFO - Started process (PID=4102) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:02,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:57:02,611] {logging_mixin.py:104} INFO - [2022-03-20 09:57:02,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:02,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:02,695] {logging_mixin.py:104} INFO - [2022-03-20 09:57:02,695] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:57:02,732] {logging_mixin.py:104} INFO - [2022-03-20 09:57:02,732] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:57:02,748] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 09:57:33,192] {scheduler_job.py:182} INFO - Started process (PID=4134) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:33,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:57:33,201] {logging_mixin.py:104} INFO - [2022-03-20 09:57:33,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:33,232] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:57:33,278] {logging_mixin.py:104} INFO - [2022-03-20 09:57:33,278] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:57:33,313] {logging_mixin.py:104} INFO - [2022-03-20 09:57:33,313] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:57:33,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 09:58:04,155] {scheduler_job.py:182} INFO - Started process (PID=4167) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:04,158] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:58:04,161] {logging_mixin.py:104} INFO - [2022-03-20 09:58:04,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:04,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:04,248] {logging_mixin.py:104} INFO - [2022-03-20 09:58:04,248] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:58:04,285] {logging_mixin.py:104} INFO - [2022-03-20 09:58:04,284] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:58:04,302] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 09:58:34,540] {scheduler_job.py:182} INFO - Started process (PID=4183) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:34,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:58:34,549] {logging_mixin.py:104} INFO - [2022-03-20 09:58:34,548] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:34,591] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:58:34,639] {logging_mixin.py:104} INFO - [2022-03-20 09:58:34,639] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:58:34,673] {logging_mixin.py:104} INFO - [2022-03-20 09:58:34,673] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:58:34,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 09:59:05,239] {scheduler_job.py:182} INFO - Started process (PID=4215) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:05,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:59:05,246] {logging_mixin.py:104} INFO - [2022-03-20 09:59:05,245] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:05,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:05,329] {logging_mixin.py:104} INFO - [2022-03-20 09:59:05,328] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:59:05,363] {logging_mixin.py:104} INFO - [2022-03-20 09:59:05,363] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:59:05,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 09:59:35,648] {scheduler_job.py:182} INFO - Started process (PID=4247) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:35,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 09:59:35,656] {logging_mixin.py:104} INFO - [2022-03-20 09:59:35,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:35,695] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 09:59:35,741] {logging_mixin.py:104} INFO - [2022-03-20 09:59:35,740] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 09:59:35,774] {logging_mixin.py:104} INFO - [2022-03-20 09:59:35,773] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 09:59:35,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:00:06,102] {scheduler_job.py:182} INFO - Started process (PID=4279) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:06,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:00:06,109] {logging_mixin.py:104} INFO - [2022-03-20 10:00:06,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:06,143] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:06,195] {logging_mixin.py:104} INFO - [2022-03-20 10:00:06,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:00:06,231] {logging_mixin.py:104} INFO - [2022-03-20 10:00:06,231] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:00:06,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 10:00:36,711] {scheduler_job.py:182} INFO - Started process (PID=4312) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:36,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:00:36,718] {logging_mixin.py:104} INFO - [2022-03-20 10:00:36,718] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:36,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:00:36,801] {logging_mixin.py:104} INFO - [2022-03-20 10:00:36,800] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:00:36,836] {logging_mixin.py:104} INFO - [2022-03-20 10:00:36,836] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:00:36,853] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:01:07,270] {scheduler_job.py:182} INFO - Started process (PID=4344) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:07,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:01:07,276] {logging_mixin.py:104} INFO - [2022-03-20 10:01:07,276] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:07,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:07,359] {logging_mixin.py:104} INFO - [2022-03-20 10:01:07,358] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:01:07,393] {logging_mixin.py:104} INFO - [2022-03-20 10:01:07,392] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:01:07,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:01:37,792] {scheduler_job.py:182} INFO - Started process (PID=4376) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:37,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:01:37,801] {logging_mixin.py:104} INFO - [2022-03-20 10:01:37,800] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:37,838] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:01:37,883] {logging_mixin.py:104} INFO - [2022-03-20 10:01:37,882] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:01:37,915] {logging_mixin.py:104} INFO - [2022-03-20 10:01:37,915] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:01:37,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:02:08,464] {scheduler_job.py:182} INFO - Started process (PID=4409) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:08,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:02:08,472] {logging_mixin.py:104} INFO - [2022-03-20 10:02:08,472] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:08,506] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:08,549] {logging_mixin.py:104} INFO - [2022-03-20 10:02:08,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:02:08,584] {logging_mixin.py:104} INFO - [2022-03-20 10:02:08,583] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:02:08,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:02:39,372] {scheduler_job.py:182} INFO - Started process (PID=4434) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:39,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:02:39,378] {logging_mixin.py:104} INFO - [2022-03-20 10:02:39,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:39,412] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:02:39,457] {logging_mixin.py:104} INFO - [2022-03-20 10:02:39,456] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:02:39,488] {logging_mixin.py:104} INFO - [2022-03-20 10:02:39,488] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:02:39,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 10:03:09,765] {scheduler_job.py:182} INFO - Started process (PID=4458) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:09,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:03:09,772] {logging_mixin.py:104} INFO - [2022-03-20 10:03:09,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:09,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:09,855] {logging_mixin.py:104} INFO - [2022-03-20 10:03:09,854] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:03:09,887] {logging_mixin.py:104} INFO - [2022-03-20 10:03:09,886] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:03:09,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:03:40,379] {scheduler_job.py:182} INFO - Started process (PID=4489) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:40,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:03:40,385] {logging_mixin.py:104} INFO - [2022-03-20 10:03:40,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:40,421] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:03:40,464] {logging_mixin.py:104} INFO - [2022-03-20 10:03:40,464] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:03:40,498] {logging_mixin.py:104} INFO - [2022-03-20 10:03:40,497] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:03:40,514] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:04:10,940] {scheduler_job.py:182} INFO - Started process (PID=4522) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:10,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:04:10,948] {logging_mixin.py:104} INFO - [2022-03-20 10:04:10,947] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:10,982] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:11,027] {logging_mixin.py:104} INFO - [2022-03-20 10:04:11,026] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:04:11,060] {logging_mixin.py:104} INFO - [2022-03-20 10:04:11,060] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:04:11,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:04:41,432] {scheduler_job.py:182} INFO - Started process (PID=4554) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:41,435] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:04:41,439] {logging_mixin.py:104} INFO - [2022-03-20 10:04:41,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:41,479] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:04:41,524] {logging_mixin.py:104} INFO - [2022-03-20 10:04:41,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:04:41,561] {logging_mixin.py:104} INFO - [2022-03-20 10:04:41,560] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:04:41,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 10:05:12,022] {scheduler_job.py:182} INFO - Started process (PID=4586) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:12,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:05:12,030] {logging_mixin.py:104} INFO - [2022-03-20 10:05:12,029] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:12,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:12,113] {logging_mixin.py:104} INFO - [2022-03-20 10:05:12,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:05:12,150] {logging_mixin.py:104} INFO - [2022-03-20 10:05:12,150] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:05:12,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 10:05:42,728] {scheduler_job.py:182} INFO - Started process (PID=4618) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:42,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:05:42,734] {logging_mixin.py:104} INFO - [2022-03-20 10:05:42,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:42,772] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:05:42,817] {logging_mixin.py:104} INFO - [2022-03-20 10:05:42,816] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:05:42,849] {logging_mixin.py:104} INFO - [2022-03-20 10:05:42,848] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:05:42,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:06:13,316] {scheduler_job.py:182} INFO - Started process (PID=4649) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:13,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:06:13,323] {logging_mixin.py:104} INFO - [2022-03-20 10:06:13,323] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:13,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:13,403] {logging_mixin.py:104} INFO - [2022-03-20 10:06:13,403] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:06:13,436] {logging_mixin.py:104} INFO - [2022-03-20 10:06:13,436] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:06:13,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:06:44,087] {scheduler_job.py:182} INFO - Started process (PID=4683) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:44,090] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:06:44,093] {logging_mixin.py:104} INFO - [2022-03-20 10:06:44,093] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:44,125] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:06:44,169] {logging_mixin.py:104} INFO - [2022-03-20 10:06:44,168] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:06:44,201] {logging_mixin.py:104} INFO - [2022-03-20 10:06:44,200] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:06:44,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 10:07:14,664] {scheduler_job.py:182} INFO - Started process (PID=4699) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:14,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:07:14,669] {logging_mixin.py:104} INFO - [2022-03-20 10:07:14,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:14,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:14,750] {logging_mixin.py:104} INFO - [2022-03-20 10:07:14,750] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:07:14,784] {logging_mixin.py:104} INFO - [2022-03-20 10:07:14,784] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:07:14,800] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:07:45,341] {scheduler_job.py:182} INFO - Started process (PID=4731) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:45,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:07:45,348] {logging_mixin.py:104} INFO - [2022-03-20 10:07:45,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:45,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:07:45,430] {logging_mixin.py:104} INFO - [2022-03-20 10:07:45,430] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:07:45,465] {logging_mixin.py:104} INFO - [2022-03-20 10:07:45,464] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:07:45,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:08:16,298] {scheduler_job.py:182} INFO - Started process (PID=4764) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:16,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:08:16,305] {logging_mixin.py:104} INFO - [2022-03-20 10:08:16,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:16,337] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:16,383] {logging_mixin.py:104} INFO - [2022-03-20 10:08:16,383] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:08:16,417] {logging_mixin.py:104} INFO - [2022-03-20 10:08:16,417] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:08:16,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:08:46,889] {scheduler_job.py:182} INFO - Started process (PID=4795) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:46,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:08:46,896] {logging_mixin.py:104} INFO - [2022-03-20 10:08:46,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:46,929] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:08:46,976] {logging_mixin.py:104} INFO - [2022-03-20 10:08:46,975] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:08:47,010] {logging_mixin.py:104} INFO - [2022-03-20 10:08:47,010] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:08:47,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:09:17,496] {scheduler_job.py:182} INFO - Started process (PID=4827) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:17,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:09:17,502] {logging_mixin.py:104} INFO - [2022-03-20 10:09:17,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:17,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:17,580] {logging_mixin.py:104} INFO - [2022-03-20 10:09:17,580] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:09:17,614] {logging_mixin.py:104} INFO - [2022-03-20 10:09:17,613] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:09:17,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 10:09:48,147] {scheduler_job.py:182} INFO - Started process (PID=4860) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:48,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:09:48,153] {logging_mixin.py:104} INFO - [2022-03-20 10:09:48,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:48,190] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:09:48,236] {logging_mixin.py:104} INFO - [2022-03-20 10:09:48,236] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:09:48,269] {logging_mixin.py:104} INFO - [2022-03-20 10:09:48,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:09:48,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:10:18,705] {scheduler_job.py:182} INFO - Started process (PID=4892) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:18,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:10:18,711] {logging_mixin.py:104} INFO - [2022-03-20 10:10:18,711] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:18,751] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:18,798] {logging_mixin.py:104} INFO - [2022-03-20 10:10:18,797] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:10:18,832] {logging_mixin.py:104} INFO - [2022-03-20 10:10:18,832] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:10:18,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:10:49,409] {scheduler_job.py:182} INFO - Started process (PID=4925) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:49,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:10:49,415] {logging_mixin.py:104} INFO - [2022-03-20 10:10:49,414] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:49,447] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:10:49,492] {logging_mixin.py:104} INFO - [2022-03-20 10:10:49,491] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:10:49,521] {logging_mixin.py:104} INFO - [2022-03-20 10:10:49,521] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:10:49,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.134 seconds
[2022-03-20 10:11:20,327] {scheduler_job.py:182} INFO - Started process (PID=4950) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:20,331] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:11:20,334] {logging_mixin.py:104} INFO - [2022-03-20 10:11:20,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:20,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:20,412] {logging_mixin.py:104} INFO - [2022-03-20 10:11:20,411] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:11:20,444] {logging_mixin.py:104} INFO - [2022-03-20 10:11:20,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:11:20,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 10:11:50,661] {scheduler_job.py:182} INFO - Started process (PID=4974) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:50,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:11:50,669] {logging_mixin.py:104} INFO - [2022-03-20 10:11:50,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:50,703] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:11:50,749] {logging_mixin.py:104} INFO - [2022-03-20 10:11:50,749] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:11:50,784] {logging_mixin.py:104} INFO - [2022-03-20 10:11:50,784] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:11:50,800] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:12:21,340] {scheduler_job.py:182} INFO - Started process (PID=5006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:21,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:12:21,345] {logging_mixin.py:104} INFO - [2022-03-20 10:12:21,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:21,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:21,421] {logging_mixin.py:104} INFO - [2022-03-20 10:12:21,421] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:12:21,457] {logging_mixin.py:104} INFO - [2022-03-20 10:12:21,457] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:12:21,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:12:51,928] {scheduler_job.py:182} INFO - Started process (PID=5038) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:51,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:12:51,934] {logging_mixin.py:104} INFO - [2022-03-20 10:12:51,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:51,969] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:12:52,014] {logging_mixin.py:104} INFO - [2022-03-20 10:12:52,014] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:12:52,049] {logging_mixin.py:104} INFO - [2022-03-20 10:12:52,049] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:12:52,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:13:22,480] {scheduler_job.py:182} INFO - Started process (PID=5070) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:22,484] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:13:22,487] {logging_mixin.py:104} INFO - [2022-03-20 10:13:22,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:22,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:22,568] {logging_mixin.py:104} INFO - [2022-03-20 10:13:22,568] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:13:22,604] {logging_mixin.py:104} INFO - [2022-03-20 10:13:22,603] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:13:22,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:13:52,978] {scheduler_job.py:182} INFO - Started process (PID=5101) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:52,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:13:52,984] {logging_mixin.py:104} INFO - [2022-03-20 10:13:52,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:53,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:13:53,066] {logging_mixin.py:104} INFO - [2022-03-20 10:13:53,066] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:13:53,102] {logging_mixin.py:104} INFO - [2022-03-20 10:13:53,102] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:13:53,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:14:23,518] {scheduler_job.py:182} INFO - Started process (PID=5133) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:23,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:14:23,525] {logging_mixin.py:104} INFO - [2022-03-20 10:14:23,524] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:23,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:23,604] {logging_mixin.py:104} INFO - [2022-03-20 10:14:23,603] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:14:23,638] {logging_mixin.py:104} INFO - [2022-03-20 10:14:23,637] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:14:23,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:14:54,169] {scheduler_job.py:182} INFO - Started process (PID=5166) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:54,175] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:14:54,181] {logging_mixin.py:104} INFO - [2022-03-20 10:14:54,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:54,214] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:14:54,262] {logging_mixin.py:104} INFO - [2022-03-20 10:14:54,262] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:14:54,298] {logging_mixin.py:104} INFO - [2022-03-20 10:14:54,297] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:14:54,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 10:15:24,975] {scheduler_job.py:182} INFO - Started process (PID=5199) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:24,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:15:24,983] {logging_mixin.py:104} INFO - [2022-03-20 10:15:24,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:25,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:25,059] {logging_mixin.py:104} INFO - [2022-03-20 10:15:25,059] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:15:25,093] {logging_mixin.py:104} INFO - [2022-03-20 10:15:25,093] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:15:25,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:15:55,661] {scheduler_job.py:182} INFO - Started process (PID=5223) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:55,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:15:55,667] {logging_mixin.py:104} INFO - [2022-03-20 10:15:55,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:55,700] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:15:55,743] {logging_mixin.py:104} INFO - [2022-03-20 10:15:55,742] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:15:55,775] {logging_mixin.py:104} INFO - [2022-03-20 10:15:55,775] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:15:55,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 10:16:25,948] {scheduler_job.py:182} INFO - Started process (PID=5248) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:25,955] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:16:25,959] {logging_mixin.py:104} INFO - [2022-03-20 10:16:25,959] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:25,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:26,041] {logging_mixin.py:104} INFO - [2022-03-20 10:16:26,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:16:26,074] {logging_mixin.py:104} INFO - [2022-03-20 10:16:26,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:16:26,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 10:16:56,446] {scheduler_job.py:182} INFO - Started process (PID=5280) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:56,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:16:56,456] {logging_mixin.py:104} INFO - [2022-03-20 10:16:56,455] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:56,490] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:16:56,533] {logging_mixin.py:104} INFO - [2022-03-20 10:16:56,533] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:16:56,566] {logging_mixin.py:104} INFO - [2022-03-20 10:16:56,565] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:16:56,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:17:27,052] {scheduler_job.py:182} INFO - Started process (PID=5311) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:27,056] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:17:27,059] {logging_mixin.py:104} INFO - [2022-03-20 10:17:27,059] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:27,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:27,139] {logging_mixin.py:104} INFO - [2022-03-20 10:17:27,138] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:17:27,172] {logging_mixin.py:104} INFO - [2022-03-20 10:17:27,172] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:17:27,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:17:57,726] {scheduler_job.py:182} INFO - Started process (PID=5344) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:57,732] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:17:57,735] {logging_mixin.py:104} INFO - [2022-03-20 10:17:57,735] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:57,770] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:17:57,816] {logging_mixin.py:104} INFO - [2022-03-20 10:17:57,816] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:17:57,849] {logging_mixin.py:104} INFO - [2022-03-20 10:17:57,848] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:17:57,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:18:28,424] {scheduler_job.py:182} INFO - Started process (PID=5376) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:28,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:18:28,432] {logging_mixin.py:104} INFO - [2022-03-20 10:18:28,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:28,468] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:28,517] {logging_mixin.py:104} INFO - [2022-03-20 10:18:28,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:18:28,551] {logging_mixin.py:104} INFO - [2022-03-20 10:18:28,550] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:18:28,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:18:58,778] {scheduler_job.py:182} INFO - Started process (PID=5407) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:58,781] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:18:58,784] {logging_mixin.py:104} INFO - [2022-03-20 10:18:58,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:58,819] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:18:58,863] {logging_mixin.py:104} INFO - [2022-03-20 10:18:58,863] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:18:58,897] {logging_mixin.py:104} INFO - [2022-03-20 10:18:58,897] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:18:58,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:19:29,292] {scheduler_job.py:182} INFO - Started process (PID=5439) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:29,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:19:29,298] {logging_mixin.py:104} INFO - [2022-03-20 10:19:29,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:29,335] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:29,381] {logging_mixin.py:104} INFO - [2022-03-20 10:19:29,380] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:19:29,413] {logging_mixin.py:104} INFO - [2022-03-20 10:19:29,413] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:19:29,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:19:59,827] {scheduler_job.py:182} INFO - Started process (PID=5464) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:59,831] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:19:59,835] {logging_mixin.py:104} INFO - [2022-03-20 10:19:59,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:59,869] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:19:59,915] {logging_mixin.py:104} INFO - [2022-03-20 10:19:59,914] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:19:59,947] {logging_mixin.py:104} INFO - [2022-03-20 10:19:59,947] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:19:59,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:20:30,512] {scheduler_job.py:182} INFO - Started process (PID=5489) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:20:30,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:20:30,519] {logging_mixin.py:104} INFO - [2022-03-20 10:20:30,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:20:30,554] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:20:30,600] {logging_mixin.py:104} INFO - [2022-03-20 10:20:30,599] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:20:30,631] {logging_mixin.py:104} INFO - [2022-03-20 10:20:30,631] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:20:30,647] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:21:00,719] {scheduler_job.py:182} INFO - Started process (PID=5519) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:00,725] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:21:00,727] {logging_mixin.py:104} INFO - [2022-03-20 10:21:00,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:00,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:00,800] {logging_mixin.py:104} INFO - [2022-03-20 10:21:00,800] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:21:00,830] {logging_mixin.py:104} INFO - [2022-03-20 10:21:00,829] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:21:00,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.133 seconds
[2022-03-20 10:21:31,091] {scheduler_job.py:182} INFO - Started process (PID=5551) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:31,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:21:31,100] {logging_mixin.py:104} INFO - [2022-03-20 10:21:31,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:31,137] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:21:31,178] {logging_mixin.py:104} INFO - [2022-03-20 10:21:31,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:21:31,208] {logging_mixin.py:104} INFO - [2022-03-20 10:21:31,207] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:21:31,222] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:22:01,473] {scheduler_job.py:182} INFO - Started process (PID=5583) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:01,477] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:22:01,480] {logging_mixin.py:104} INFO - [2022-03-20 10:22:01,480] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:01,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:01,555] {logging_mixin.py:104} INFO - [2022-03-20 10:22:01,555] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:22:01,589] {logging_mixin.py:104} INFO - [2022-03-20 10:22:01,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:22:01,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:22:31,875] {scheduler_job.py:182} INFO - Started process (PID=5615) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:31,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:22:31,881] {logging_mixin.py:104} INFO - [2022-03-20 10:22:31,880] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:31,914] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:22:31,953] {logging_mixin.py:104} INFO - [2022-03-20 10:22:31,953] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:22:31,983] {logging_mixin.py:104} INFO - [2022-03-20 10:22:31,983] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:22:31,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.131 seconds
[2022-03-20 10:23:02,535] {scheduler_job.py:182} INFO - Started process (PID=5649) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:02,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:23:02,541] {logging_mixin.py:104} INFO - [2022-03-20 10:23:02,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:02,575] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:02,618] {logging_mixin.py:104} INFO - [2022-03-20 10:23:02,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:23:02,652] {logging_mixin.py:104} INFO - [2022-03-20 10:23:02,651] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:23:02,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:23:32,938] {scheduler_job.py:182} INFO - Started process (PID=5682) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:32,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:23:32,945] {logging_mixin.py:104} INFO - [2022-03-20 10:23:32,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:32,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:23:33,025] {logging_mixin.py:104} INFO - [2022-03-20 10:23:33,025] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:23:33,058] {logging_mixin.py:104} INFO - [2022-03-20 10:23:33,058] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:23:33,074] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:24:03,638] {scheduler_job.py:182} INFO - Started process (PID=5715) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:03,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:24:03,645] {logging_mixin.py:104} INFO - [2022-03-20 10:24:03,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:03,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:03,721] {logging_mixin.py:104} INFO - [2022-03-20 10:24:03,721] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:24:03,756] {logging_mixin.py:104} INFO - [2022-03-20 10:24:03,755] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:24:03,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:24:34,657] {scheduler_job.py:182} INFO - Started process (PID=5740) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:34,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:24:34,663] {logging_mixin.py:104} INFO - [2022-03-20 10:24:34,662] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:34,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:24:34,739] {logging_mixin.py:104} INFO - [2022-03-20 10:24:34,739] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:24:34,772] {logging_mixin.py:104} INFO - [2022-03-20 10:24:34,772] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:24:34,788] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 10:25:04,940] {scheduler_job.py:182} INFO - Started process (PID=5767) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:04,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:25:04,945] {logging_mixin.py:104} INFO - [2022-03-20 10:25:04,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:04,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:05,016] {logging_mixin.py:104} INFO - [2022-03-20 10:25:05,015] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:25:05,045] {logging_mixin.py:104} INFO - [2022-03-20 10:25:05,045] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:25:05,060] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.126 seconds
[2022-03-20 10:25:35,247] {scheduler_job.py:182} INFO - Started process (PID=5796) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:35,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:25:35,254] {logging_mixin.py:104} INFO - [2022-03-20 10:25:35,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:35,288] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:25:35,334] {logging_mixin.py:104} INFO - [2022-03-20 10:25:35,333] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:25:35,369] {logging_mixin.py:104} INFO - [2022-03-20 10:25:35,369] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:25:35,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:26:05,795] {scheduler_job.py:182} INFO - Started process (PID=5828) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:05,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:26:05,803] {logging_mixin.py:104} INFO - [2022-03-20 10:26:05,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:05,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:05,884] {logging_mixin.py:104} INFO - [2022-03-20 10:26:05,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:26:05,919] {logging_mixin.py:104} INFO - [2022-03-20 10:26:05,918] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:26:05,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:26:36,491] {scheduler_job.py:182} INFO - Started process (PID=5860) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:36,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:26:36,500] {logging_mixin.py:104} INFO - [2022-03-20 10:26:36,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:36,537] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:26:36,582] {logging_mixin.py:104} INFO - [2022-03-20 10:26:36,581] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:26:36,615] {logging_mixin.py:104} INFO - [2022-03-20 10:26:36,615] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:26:36,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:27:07,068] {scheduler_job.py:182} INFO - Started process (PID=5891) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:07,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:27:07,076] {logging_mixin.py:104} INFO - [2022-03-20 10:27:07,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:07,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:07,159] {logging_mixin.py:104} INFO - [2022-03-20 10:27:07,158] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:27:07,193] {logging_mixin.py:104} INFO - [2022-03-20 10:27:07,193] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:27:07,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:27:37,644] {scheduler_job.py:182} INFO - Started process (PID=5924) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:37,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:27:37,650] {logging_mixin.py:104} INFO - [2022-03-20 10:27:37,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:37,685] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:27:37,729] {logging_mixin.py:104} INFO - [2022-03-20 10:27:37,729] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:27:37,762] {logging_mixin.py:104} INFO - [2022-03-20 10:27:37,762] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:27:37,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:28:08,284] {scheduler_job.py:182} INFO - Started process (PID=5955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:08,288] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:28:08,291] {logging_mixin.py:104} INFO - [2022-03-20 10:28:08,290] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:08,326] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:08,374] {logging_mixin.py:104} INFO - [2022-03-20 10:28:08,374] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:28:08,409] {logging_mixin.py:104} INFO - [2022-03-20 10:28:08,408] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:28:08,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:28:39,182] {scheduler_job.py:182} INFO - Started process (PID=5989) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:39,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:28:39,188] {logging_mixin.py:104} INFO - [2022-03-20 10:28:39,188] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:39,222] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:28:39,267] {logging_mixin.py:104} INFO - [2022-03-20 10:28:39,267] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:28:39,300] {logging_mixin.py:104} INFO - [2022-03-20 10:28:39,300] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:28:39,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:29:09,576] {scheduler_job.py:182} INFO - Started process (PID=6006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:09,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:29:09,584] {logging_mixin.py:104} INFO - [2022-03-20 10:29:09,583] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:09,621] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:09,666] {logging_mixin.py:104} INFO - [2022-03-20 10:29:09,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:29:09,698] {logging_mixin.py:104} INFO - [2022-03-20 10:29:09,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:29:09,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:29:40,291] {scheduler_job.py:182} INFO - Started process (PID=6038) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:40,298] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:29:40,301] {logging_mixin.py:104} INFO - [2022-03-20 10:29:40,300] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:40,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:29:40,387] {logging_mixin.py:104} INFO - [2022-03-20 10:29:40,386] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:29:40,420] {logging_mixin.py:104} INFO - [2022-03-20 10:29:40,420] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:29:40,437] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 10:30:10,835] {scheduler_job.py:182} INFO - Started process (PID=6069) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:10,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:30:10,841] {logging_mixin.py:104} INFO - [2022-03-20 10:30:10,841] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:10,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:10,930] {logging_mixin.py:104} INFO - [2022-03-20 10:30:10,929] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:30:10,966] {logging_mixin.py:104} INFO - [2022-03-20 10:30:10,966] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:30:10,985] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 10:30:41,562] {scheduler_job.py:182} INFO - Started process (PID=6102) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:41,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:30:41,569] {logging_mixin.py:104} INFO - [2022-03-20 10:30:41,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:41,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:30:41,652] {logging_mixin.py:104} INFO - [2022-03-20 10:30:41,652] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:30:41,689] {logging_mixin.py:104} INFO - [2022-03-20 10:30:41,688] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:30:41,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 10:31:12,100] {scheduler_job.py:182} INFO - Started process (PID=6134) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:12,104] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:31:12,106] {logging_mixin.py:104} INFO - [2022-03-20 10:31:12,106] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:12,139] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:12,184] {logging_mixin.py:104} INFO - [2022-03-20 10:31:12,184] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:31:12,217] {logging_mixin.py:104} INFO - [2022-03-20 10:31:12,216] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:31:12,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:31:42,709] {scheduler_job.py:182} INFO - Started process (PID=6166) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:42,713] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:31:42,716] {logging_mixin.py:104} INFO - [2022-03-20 10:31:42,715] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:42,751] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:31:42,801] {logging_mixin.py:104} INFO - [2022-03-20 10:31:42,800] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:31:42,833] {logging_mixin.py:104} INFO - [2022-03-20 10:31:42,833] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:31:42,849] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:32:13,557] {scheduler_job.py:182} INFO - Started process (PID=6198) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:13,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:32:13,564] {logging_mixin.py:104} INFO - [2022-03-20 10:32:13,564] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:13,598] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:13,643] {logging_mixin.py:104} INFO - [2022-03-20 10:32:13,643] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:32:13,677] {logging_mixin.py:104} INFO - [2022-03-20 10:32:13,677] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:32:13,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:32:44,335] {scheduler_job.py:182} INFO - Started process (PID=6231) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:44,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:32:44,343] {logging_mixin.py:104} INFO - [2022-03-20 10:32:44,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:44,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:32:44,420] {logging_mixin.py:104} INFO - [2022-03-20 10:32:44,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:32:44,453] {logging_mixin.py:104} INFO - [2022-03-20 10:32:44,453] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:32:44,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:33:15,290] {scheduler_job.py:182} INFO - Started process (PID=6256) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:15,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:33:15,297] {logging_mixin.py:104} INFO - [2022-03-20 10:33:15,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:15,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:15,375] {logging_mixin.py:104} INFO - [2022-03-20 10:33:15,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:33:15,408] {logging_mixin.py:104} INFO - [2022-03-20 10:33:15,407] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:33:15,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:33:45,958] {scheduler_job.py:182} INFO - Started process (PID=6280) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:45,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:33:45,965] {logging_mixin.py:104} INFO - [2022-03-20 10:33:45,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:46,001] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:33:46,044] {logging_mixin.py:104} INFO - [2022-03-20 10:33:46,044] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:33:46,078] {logging_mixin.py:104} INFO - [2022-03-20 10:33:46,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:33:46,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:34:16,696] {scheduler_job.py:182} INFO - Started process (PID=6312) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:16,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:34:16,703] {logging_mixin.py:104} INFO - [2022-03-20 10:34:16,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:16,738] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:16,786] {logging_mixin.py:104} INFO - [2022-03-20 10:34:16,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:34:16,819] {logging_mixin.py:104} INFO - [2022-03-20 10:34:16,819] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:34:16,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:34:47,614] {scheduler_job.py:182} INFO - Started process (PID=6344) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:47,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:34:47,621] {logging_mixin.py:104} INFO - [2022-03-20 10:34:47,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:47,654] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:34:47,703] {logging_mixin.py:104} INFO - [2022-03-20 10:34:47,703] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:34:47,738] {logging_mixin.py:104} INFO - [2022-03-20 10:34:47,737] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:34:47,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:35:18,089] {scheduler_job.py:182} INFO - Started process (PID=6376) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:18,094] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:35:18,097] {logging_mixin.py:104} INFO - [2022-03-20 10:35:18,096] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:18,131] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:18,180] {logging_mixin.py:104} INFO - [2022-03-20 10:35:18,180] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:35:18,213] {logging_mixin.py:104} INFO - [2022-03-20 10:35:18,212] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:35:18,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:35:48,670] {scheduler_job.py:182} INFO - Started process (PID=6408) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:48,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:35:48,679] {logging_mixin.py:104} INFO - [2022-03-20 10:35:48,678] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:48,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:35:48,762] {logging_mixin.py:104} INFO - [2022-03-20 10:35:48,762] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:35:48,798] {logging_mixin.py:104} INFO - [2022-03-20 10:35:48,798] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:35:48,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 10:36:19,359] {scheduler_job.py:182} INFO - Started process (PID=6440) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:19,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:36:19,366] {logging_mixin.py:104} INFO - [2022-03-20 10:36:19,366] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:19,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:19,445] {logging_mixin.py:104} INFO - [2022-03-20 10:36:19,445] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:36:19,479] {logging_mixin.py:104} INFO - [2022-03-20 10:36:19,479] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:36:19,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:36:50,057] {scheduler_job.py:182} INFO - Started process (PID=6471) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:50,060] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:36:50,064] {logging_mixin.py:104} INFO - [2022-03-20 10:36:50,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:50,096] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:36:50,141] {logging_mixin.py:104} INFO - [2022-03-20 10:36:50,141] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:36:50,175] {logging_mixin.py:104} INFO - [2022-03-20 10:36:50,175] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:36:50,193] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:37:20,813] {scheduler_job.py:182} INFO - Started process (PID=6505) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:20,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:37:20,819] {logging_mixin.py:104} INFO - [2022-03-20 10:37:20,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:20,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:20,897] {logging_mixin.py:104} INFO - [2022-03-20 10:37:20,897] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:37:20,931] {logging_mixin.py:104} INFO - [2022-03-20 10:37:20,931] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:37:20,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:37:51,742] {scheduler_job.py:182} INFO - Started process (PID=6530) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:51,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:37:51,748] {logging_mixin.py:104} INFO - [2022-03-20 10:37:51,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:51,782] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:37:51,824] {logging_mixin.py:104} INFO - [2022-03-20 10:37:51,823] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:37:51,859] {logging_mixin.py:104} INFO - [2022-03-20 10:37:51,858] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:37:51,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:38:22,657] {scheduler_job.py:182} INFO - Started process (PID=6554) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:22,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:38:22,666] {logging_mixin.py:104} INFO - [2022-03-20 10:38:22,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:22,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:22,748] {logging_mixin.py:104} INFO - [2022-03-20 10:38:22,747] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:38:22,782] {logging_mixin.py:104} INFO - [2022-03-20 10:38:22,782] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:38:22,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:38:53,372] {scheduler_job.py:182} INFO - Started process (PID=6586) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:53,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:38:53,379] {logging_mixin.py:104} INFO - [2022-03-20 10:38:53,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:53,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:38:53,460] {logging_mixin.py:104} INFO - [2022-03-20 10:38:53,459] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:38:53,492] {logging_mixin.py:104} INFO - [2022-03-20 10:38:53,492] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:38:53,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:39:23,937] {scheduler_job.py:182} INFO - Started process (PID=6617) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:23,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:39:23,945] {logging_mixin.py:104} INFO - [2022-03-20 10:39:23,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:23,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:24,023] {logging_mixin.py:104} INFO - [2022-03-20 10:39:24,022] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:39:24,055] {logging_mixin.py:104} INFO - [2022-03-20 10:39:24,055] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:39:24,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:39:54,560] {scheduler_job.py:182} INFO - Started process (PID=6650) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:54,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:39:54,567] {logging_mixin.py:104} INFO - [2022-03-20 10:39:54,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:54,603] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:39:54,648] {logging_mixin.py:104} INFO - [2022-03-20 10:39:54,648] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:39:54,682] {logging_mixin.py:104} INFO - [2022-03-20 10:39:54,681] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:39:54,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:40:25,074] {scheduler_job.py:182} INFO - Started process (PID=6682) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:25,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:40:25,081] {logging_mixin.py:104} INFO - [2022-03-20 10:40:25,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:25,118] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:25,164] {logging_mixin.py:104} INFO - [2022-03-20 10:40:25,163] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:40:25,196] {logging_mixin.py:104} INFO - [2022-03-20 10:40:25,196] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:40:25,213] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:40:55,570] {scheduler_job.py:182} INFO - Started process (PID=6714) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:55,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:40:55,577] {logging_mixin.py:104} INFO - [2022-03-20 10:40:55,577] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:55,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:40:55,657] {logging_mixin.py:104} INFO - [2022-03-20 10:40:55,656] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:40:55,691] {logging_mixin.py:104} INFO - [2022-03-20 10:40:55,690] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:40:55,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:41:26,285] {scheduler_job.py:182} INFO - Started process (PID=6746) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:26,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:41:26,293] {logging_mixin.py:104} INFO - [2022-03-20 10:41:26,292] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:26,326] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:26,371] {logging_mixin.py:104} INFO - [2022-03-20 10:41:26,370] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:41:26,404] {logging_mixin.py:104} INFO - [2022-03-20 10:41:26,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:41:26,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:41:57,051] {scheduler_job.py:182} INFO - Started process (PID=6779) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:57,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:41:57,057] {logging_mixin.py:104} INFO - [2022-03-20 10:41:57,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:57,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:41:57,138] {logging_mixin.py:104} INFO - [2022-03-20 10:41:57,137] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:41:57,171] {logging_mixin.py:104} INFO - [2022-03-20 10:41:57,170] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:41:57,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:42:27,733] {scheduler_job.py:182} INFO - Started process (PID=6803) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:27,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:42:27,739] {logging_mixin.py:104} INFO - [2022-03-20 10:42:27,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:27,773] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:27,816] {logging_mixin.py:104} INFO - [2022-03-20 10:42:27,815] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:42:27,850] {logging_mixin.py:104} INFO - [2022-03-20 10:42:27,849] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:42:27,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 10:42:58,142] {scheduler_job.py:182} INFO - Started process (PID=6828) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:58,145] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:42:58,148] {logging_mixin.py:104} INFO - [2022-03-20 10:42:58,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:58,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:42:58,226] {logging_mixin.py:104} INFO - [2022-03-20 10:42:58,225] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:42:58,258] {logging_mixin.py:104} INFO - [2022-03-20 10:42:58,258] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:42:58,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:43:28,678] {scheduler_job.py:182} INFO - Started process (PID=6860) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:28,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:43:28,685] {logging_mixin.py:104} INFO - [2022-03-20 10:43:28,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:28,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:28,766] {logging_mixin.py:104} INFO - [2022-03-20 10:43:28,765] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:43:28,797] {logging_mixin.py:104} INFO - [2022-03-20 10:43:28,797] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:43:28,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 10:43:59,332] {scheduler_job.py:182} INFO - Started process (PID=6892) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:59,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:43:59,341] {logging_mixin.py:104} INFO - [2022-03-20 10:43:59,341] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:59,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:43:59,420] {logging_mixin.py:104} INFO - [2022-03-20 10:43:59,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:43:59,454] {logging_mixin.py:104} INFO - [2022-03-20 10:43:59,454] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:43:59,471] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:44:29,782] {scheduler_job.py:182} INFO - Started process (PID=6924) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:44:29,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:44:29,789] {logging_mixin.py:104} INFO - [2022-03-20 10:44:29,788] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:44:29,825] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:44:29,873] {logging_mixin.py:104} INFO - [2022-03-20 10:44:29,872] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:44:29,907] {logging_mixin.py:104} INFO - [2022-03-20 10:44:29,907] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:44:29,923] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:45:00,322] {scheduler_job.py:182} INFO - Started process (PID=6956) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:00,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:45:00,330] {logging_mixin.py:104} INFO - [2022-03-20 10:45:00,330] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:00,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:00,416] {logging_mixin.py:104} INFO - [2022-03-20 10:45:00,416] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:45:00,451] {logging_mixin.py:104} INFO - [2022-03-20 10:45:00,450] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:45:00,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 10:45:30,933] {scheduler_job.py:182} INFO - Started process (PID=6987) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:30,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:45:30,941] {logging_mixin.py:104} INFO - [2022-03-20 10:45:30,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:30,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:45:31,026] {logging_mixin.py:104} INFO - [2022-03-20 10:45:31,026] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:45:31,060] {logging_mixin.py:104} INFO - [2022-03-20 10:45:31,060] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:45:31,075] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:46:01,669] {scheduler_job.py:182} INFO - Started process (PID=7021) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:01,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:46:01,676] {logging_mixin.py:104} INFO - [2022-03-20 10:46:01,675] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:01,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:01,757] {logging_mixin.py:104} INFO - [2022-03-20 10:46:01,756] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:46:01,790] {logging_mixin.py:104} INFO - [2022-03-20 10:46:01,790] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:46:01,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:46:32,575] {scheduler_job.py:182} INFO - Started process (PID=7046) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:32,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:46:32,581] {logging_mixin.py:104} INFO - [2022-03-20 10:46:32,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:32,618] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:46:32,664] {logging_mixin.py:104} INFO - [2022-03-20 10:46:32,663] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:46:32,699] {logging_mixin.py:104} INFO - [2022-03-20 10:46:32,699] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:46:32,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:47:02,939] {scheduler_job.py:182} INFO - Started process (PID=7071) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:02,945] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:47:02,947] {logging_mixin.py:104} INFO - [2022-03-20 10:47:02,947] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:02,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:03,022] {logging_mixin.py:104} INFO - [2022-03-20 10:47:03,022] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:47:03,052] {logging_mixin.py:104} INFO - [2022-03-20 10:47:03,052] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:47:03,067] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 10:47:33,471] {scheduler_job.py:182} INFO - Started process (PID=7102) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:33,475] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:47:33,477] {logging_mixin.py:104} INFO - [2022-03-20 10:47:33,477] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:33,510] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:47:33,555] {logging_mixin.py:104} INFO - [2022-03-20 10:47:33,554] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:47:33,586] {logging_mixin.py:104} INFO - [2022-03-20 10:47:33,586] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:47:33,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:48:04,046] {scheduler_job.py:182} INFO - Started process (PID=7134) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:04,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:48:04,053] {logging_mixin.py:104} INFO - [2022-03-20 10:48:04,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:04,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:04,133] {logging_mixin.py:104} INFO - [2022-03-20 10:48:04,133] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:48:04,171] {logging_mixin.py:104} INFO - [2022-03-20 10:48:04,170] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:48:04,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 10:48:34,681] {scheduler_job.py:182} INFO - Started process (PID=7166) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:34,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:48:34,688] {logging_mixin.py:104} INFO - [2022-03-20 10:48:34,687] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:34,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:48:34,771] {logging_mixin.py:104} INFO - [2022-03-20 10:48:34,771] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:48:34,805] {logging_mixin.py:104} INFO - [2022-03-20 10:48:34,805] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:48:34,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 10:49:05,273] {scheduler_job.py:182} INFO - Started process (PID=7198) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:05,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:49:05,280] {logging_mixin.py:104} INFO - [2022-03-20 10:49:05,279] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:05,314] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:05,361] {logging_mixin.py:104} INFO - [2022-03-20 10:49:05,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:49:05,393] {logging_mixin.py:104} INFO - [2022-03-20 10:49:05,393] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:49:05,409] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 10:49:35,778] {scheduler_job.py:182} INFO - Started process (PID=7230) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:35,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:49:35,784] {logging_mixin.py:104} INFO - [2022-03-20 10:49:35,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:35,819] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:49:35,865] {logging_mixin.py:104} INFO - [2022-03-20 10:49:35,864] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:49:35,897] {logging_mixin.py:104} INFO - [2022-03-20 10:49:35,897] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:49:35,913] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:50:06,320] {scheduler_job.py:182} INFO - Started process (PID=7262) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:06,326] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:50:06,329] {logging_mixin.py:104} INFO - [2022-03-20 10:50:06,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:06,366] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:06,410] {logging_mixin.py:104} INFO - [2022-03-20 10:50:06,410] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:50:06,443] {logging_mixin.py:104} INFO - [2022-03-20 10:50:06,443] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:50:06,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 10:50:37,128] {scheduler_job.py:182} INFO - Started process (PID=7295) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:37,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:50:37,135] {logging_mixin.py:104} INFO - [2022-03-20 10:50:37,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:37,169] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:50:37,211] {logging_mixin.py:104} INFO - [2022-03-20 10:50:37,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:50:37,245] {logging_mixin.py:104} INFO - [2022-03-20 10:50:37,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:50:37,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 10:51:07,978] {scheduler_job.py:182} INFO - Started process (PID=7319) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:07,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:51:07,985] {logging_mixin.py:104} INFO - [2022-03-20 10:51:07,984] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:08,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:08,074] {logging_mixin.py:104} INFO - [2022-03-20 10:51:08,074] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:51:08,118] {logging_mixin.py:104} INFO - [2022-03-20 10:51:08,118] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:51:08,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 10:51:38,633] {scheduler_job.py:182} INFO - Started process (PID=7344) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:38,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:51:38,640] {logging_mixin.py:104} INFO - [2022-03-20 10:51:38,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:38,679] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:51:38,732] {logging_mixin.py:104} INFO - [2022-03-20 10:51:38,731] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:51:38,774] {logging_mixin.py:104} INFO - [2022-03-20 10:51:38,774] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:51:38,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 10:52:09,244] {scheduler_job.py:182} INFO - Started process (PID=7376) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:09,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:52:09,251] {logging_mixin.py:104} INFO - [2022-03-20 10:52:09,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:09,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:09,332] {logging_mixin.py:104} INFO - [2022-03-20 10:52:09,331] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:52:09,367] {logging_mixin.py:104} INFO - [2022-03-20 10:52:09,367] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:52:09,383] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:52:39,795] {scheduler_job.py:182} INFO - Started process (PID=7408) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:39,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:52:39,803] {logging_mixin.py:104} INFO - [2022-03-20 10:52:39,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:39,838] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:52:39,884] {logging_mixin.py:104} INFO - [2022-03-20 10:52:39,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:52:39,917] {logging_mixin.py:104} INFO - [2022-03-20 10:52:39,916] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:52:39,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:53:10,441] {scheduler_job.py:182} INFO - Started process (PID=7440) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:10,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:53:10,448] {logging_mixin.py:104} INFO - [2022-03-20 10:53:10,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:10,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:10,530] {logging_mixin.py:104} INFO - [2022-03-20 10:53:10,530] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:53:10,564] {logging_mixin.py:104} INFO - [2022-03-20 10:53:10,564] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:53:10,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:53:41,025] {scheduler_job.py:182} INFO - Started process (PID=7472) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:41,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:53:41,033] {logging_mixin.py:104} INFO - [2022-03-20 10:53:41,032] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:41,067] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:53:41,111] {logging_mixin.py:104} INFO - [2022-03-20 10:53:41,110] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:53:41,145] {logging_mixin.py:104} INFO - [2022-03-20 10:53:41,145] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:53:41,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:54:11,661] {scheduler_job.py:182} INFO - Started process (PID=7504) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:11,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:54:11,672] {logging_mixin.py:104} INFO - [2022-03-20 10:54:11,671] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:11,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:11,754] {logging_mixin.py:104} INFO - [2022-03-20 10:54:11,754] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:54:11,788] {logging_mixin.py:104} INFO - [2022-03-20 10:54:11,788] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:54:11,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 10:54:42,248] {scheduler_job.py:182} INFO - Started process (PID=7535) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:42,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:54:42,254] {logging_mixin.py:104} INFO - [2022-03-20 10:54:42,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:42,288] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:54:42,332] {logging_mixin.py:104} INFO - [2022-03-20 10:54:42,332] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:54:42,365] {logging_mixin.py:104} INFO - [2022-03-20 10:54:42,365] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:54:42,382] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 10:55:13,053] {scheduler_job.py:182} INFO - Started process (PID=7569) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:13,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:55:13,060] {logging_mixin.py:104} INFO - [2022-03-20 10:55:13,059] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:13,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:13,137] {logging_mixin.py:104} INFO - [2022-03-20 10:55:13,137] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:55:13,171] {logging_mixin.py:104} INFO - [2022-03-20 10:55:13,171] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:55:13,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:55:43,738] {scheduler_job.py:182} INFO - Started process (PID=7586) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:43,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:55:43,748] {logging_mixin.py:104} INFO - [2022-03-20 10:55:43,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:43,781] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:55:43,825] {logging_mixin.py:104} INFO - [2022-03-20 10:55:43,825] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:55:43,859] {logging_mixin.py:104} INFO - [2022-03-20 10:55:43,858] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:55:43,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:56:14,231] {scheduler_job.py:182} INFO - Started process (PID=7617) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:14,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:56:14,238] {logging_mixin.py:104} INFO - [2022-03-20 10:56:14,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:14,272] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:14,316] {logging_mixin.py:104} INFO - [2022-03-20 10:56:14,315] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:56:14,349] {logging_mixin.py:104} INFO - [2022-03-20 10:56:14,349] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:56:14,365] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 10:56:44,785] {scheduler_job.py:182} INFO - Started process (PID=7649) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:44,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:56:44,793] {logging_mixin.py:104} INFO - [2022-03-20 10:56:44,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:44,832] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:56:44,880] {logging_mixin.py:104} INFO - [2022-03-20 10:56:44,879] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:56:44,916] {logging_mixin.py:104} INFO - [2022-03-20 10:56:44,915] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:56:44,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 10:57:15,363] {scheduler_job.py:182} INFO - Started process (PID=7681) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:15,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:57:15,371] {logging_mixin.py:104} INFO - [2022-03-20 10:57:15,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:15,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:15,454] {logging_mixin.py:104} INFO - [2022-03-20 10:57:15,454] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:57:15,487] {logging_mixin.py:104} INFO - [2022-03-20 10:57:15,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:57:15,503] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 10:57:45,908] {scheduler_job.py:182} INFO - Started process (PID=7714) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:45,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:57:45,916] {logging_mixin.py:104} INFO - [2022-03-20 10:57:45,916] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:45,955] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:57:46,004] {logging_mixin.py:104} INFO - [2022-03-20 10:57:46,004] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:57:46,039] {logging_mixin.py:104} INFO - [2022-03-20 10:57:46,039] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:57:46,055] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 10:58:16,591] {scheduler_job.py:182} INFO - Started process (PID=7745) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:16,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:58:16,597] {logging_mixin.py:104} INFO - [2022-03-20 10:58:16,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:16,633] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:16,680] {logging_mixin.py:104} INFO - [2022-03-20 10:58:16,679] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:58:16,713] {logging_mixin.py:104} INFO - [2022-03-20 10:58:16,713] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:58:16,728] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 10:58:47,195] {scheduler_job.py:182} INFO - Started process (PID=7778) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:47,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:58:47,207] {logging_mixin.py:104} INFO - [2022-03-20 10:58:47,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:47,244] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:58:47,294] {logging_mixin.py:104} INFO - [2022-03-20 10:58:47,294] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:58:47,328] {logging_mixin.py:104} INFO - [2022-03-20 10:58:47,328] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:58:47,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 10:59:17,936] {scheduler_job.py:182} INFO - Started process (PID=7811) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:17,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:59:17,942] {logging_mixin.py:104} INFO - [2022-03-20 10:59:17,942] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:17,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:18,020] {logging_mixin.py:104} INFO - [2022-03-20 10:59:18,019] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:59:18,052] {logging_mixin.py:104} INFO - [2022-03-20 10:59:18,052] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:59:18,068] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 10:59:48,583] {scheduler_job.py:182} INFO - Started process (PID=7836) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:48,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 10:59:48,589] {logging_mixin.py:104} INFO - [2022-03-20 10:59:48,589] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:48,624] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 10:59:48,666] {logging_mixin.py:104} INFO - [2022-03-20 10:59:48,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 10:59:48,698] {logging_mixin.py:104} INFO - [2022-03-20 10:59:48,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 10:59:48,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 11:00:18,878] {scheduler_job.py:182} INFO - Started process (PID=7860) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:18,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:00:18,886] {logging_mixin.py:104} INFO - [2022-03-20 11:00:18,886] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:18,924] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:18,973] {logging_mixin.py:104} INFO - [2022-03-20 11:00:18,973] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:00:19,007] {logging_mixin.py:104} INFO - [2022-03-20 11:00:19,007] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:00:19,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:00:49,526] {scheduler_job.py:182} INFO - Started process (PID=7892) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:49,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:00:49,533] {logging_mixin.py:104} INFO - [2022-03-20 11:00:49,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:49,567] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:00:49,613] {logging_mixin.py:104} INFO - [2022-03-20 11:00:49,612] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:00:49,648] {logging_mixin.py:104} INFO - [2022-03-20 11:00:49,647] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:00:49,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:01:20,119] {scheduler_job.py:182} INFO - Started process (PID=7924) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:20,123] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:01:20,126] {logging_mixin.py:104} INFO - [2022-03-20 11:01:20,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:20,163] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:20,211] {logging_mixin.py:104} INFO - [2022-03-20 11:01:20,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:01:20,244] {logging_mixin.py:104} INFO - [2022-03-20 11:01:20,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:01:20,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:01:50,629] {scheduler_job.py:182} INFO - Started process (PID=7956) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:50,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:01:50,638] {logging_mixin.py:104} INFO - [2022-03-20 11:01:50,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:50,679] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:01:50,729] {logging_mixin.py:104} INFO - [2022-03-20 11:01:50,728] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:01:50,762] {logging_mixin.py:104} INFO - [2022-03-20 11:01:50,762] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:01:50,778] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 11:02:21,117] {scheduler_job.py:182} INFO - Started process (PID=7987) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:21,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:02:21,124] {logging_mixin.py:104} INFO - [2022-03-20 11:02:21,124] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:21,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:21,210] {logging_mixin.py:104} INFO - [2022-03-20 11:02:21,209] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:02:21,243] {logging_mixin.py:104} INFO - [2022-03-20 11:02:21,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:02:21,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:02:51,683] {scheduler_job.py:182} INFO - Started process (PID=8020) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:51,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:02:51,690] {logging_mixin.py:104} INFO - [2022-03-20 11:02:51,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:51,728] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:02:51,776] {logging_mixin.py:104} INFO - [2022-03-20 11:02:51,776] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:02:51,810] {logging_mixin.py:104} INFO - [2022-03-20 11:02:51,810] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:02:51,827] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:03:22,304] {scheduler_job.py:182} INFO - Started process (PID=8052) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:22,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:03:22,312] {logging_mixin.py:104} INFO - [2022-03-20 11:03:22,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:22,350] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:22,394] {logging_mixin.py:104} INFO - [2022-03-20 11:03:22,394] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:03:22,428] {logging_mixin.py:104} INFO - [2022-03-20 11:03:22,428] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:03:22,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:03:53,394] {scheduler_job.py:182} INFO - Started process (PID=8085) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:53,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:03:53,401] {logging_mixin.py:104} INFO - [2022-03-20 11:03:53,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:53,438] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:03:53,485] {logging_mixin.py:104} INFO - [2022-03-20 11:03:53,485] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:03:53,519] {logging_mixin.py:104} INFO - [2022-03-20 11:03:53,519] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:03:53,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:04:23,820] {scheduler_job.py:182} INFO - Started process (PID=8102) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:23,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:04:23,826] {logging_mixin.py:104} INFO - [2022-03-20 11:04:23,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:23,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:23,907] {logging_mixin.py:104} INFO - [2022-03-20 11:04:23,906] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:04:23,939] {logging_mixin.py:104} INFO - [2022-03-20 11:04:23,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:04:23,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 11:04:54,575] {scheduler_job.py:182} INFO - Started process (PID=8134) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:54,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:04:54,584] {logging_mixin.py:104} INFO - [2022-03-20 11:04:54,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:54,618] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:04:54,664] {logging_mixin.py:104} INFO - [2022-03-20 11:04:54,663] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:04:54,696] {logging_mixin.py:104} INFO - [2022-03-20 11:04:54,696] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:04:54,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:05:25,458] {scheduler_job.py:182} INFO - Started process (PID=8165) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:25,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:05:25,467] {logging_mixin.py:104} INFO - [2022-03-20 11:05:25,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:25,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:25,549] {logging_mixin.py:104} INFO - [2022-03-20 11:05:25,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:05:25,584] {logging_mixin.py:104} INFO - [2022-03-20 11:05:25,583] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:05:25,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 11:05:56,234] {scheduler_job.py:182} INFO - Started process (PID=8198) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:56,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:05:56,240] {logging_mixin.py:104} INFO - [2022-03-20 11:05:56,240] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:56,275] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:05:56,320] {logging_mixin.py:104} INFO - [2022-03-20 11:05:56,320] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:05:56,356] {logging_mixin.py:104} INFO - [2022-03-20 11:05:56,355] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:05:56,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:06:26,787] {scheduler_job.py:182} INFO - Started process (PID=8229) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:26,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:06:26,795] {logging_mixin.py:104} INFO - [2022-03-20 11:06:26,795] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:26,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:26,880] {logging_mixin.py:104} INFO - [2022-03-20 11:06:26,879] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:06:26,918] {logging_mixin.py:104} INFO - [2022-03-20 11:06:26,918] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:06:26,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 11:06:57,433] {scheduler_job.py:182} INFO - Started process (PID=8262) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:57,437] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:06:57,440] {logging_mixin.py:104} INFO - [2022-03-20 11:06:57,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:57,476] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:06:57,522] {logging_mixin.py:104} INFO - [2022-03-20 11:06:57,522] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:06:57,556] {logging_mixin.py:104} INFO - [2022-03-20 11:06:57,556] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:06:57,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:07:28,076] {scheduler_job.py:182} INFO - Started process (PID=8293) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:28,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:07:28,084] {logging_mixin.py:104} INFO - [2022-03-20 11:07:28,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:28,119] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:28,165] {logging_mixin.py:104} INFO - [2022-03-20 11:07:28,165] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:07:28,198] {logging_mixin.py:104} INFO - [2022-03-20 11:07:28,198] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:07:28,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:07:58,732] {scheduler_job.py:182} INFO - Started process (PID=8327) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:58,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:07:58,739] {logging_mixin.py:104} INFO - [2022-03-20 11:07:58,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:58,773] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:07:58,819] {logging_mixin.py:104} INFO - [2022-03-20 11:07:58,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:07:58,851] {logging_mixin.py:104} INFO - [2022-03-20 11:07:58,851] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:07:58,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:08:29,687] {scheduler_job.py:182} INFO - Started process (PID=8352) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:08:29,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:08:29,693] {logging_mixin.py:104} INFO - [2022-03-20 11:08:29,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:08:29,729] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:08:29,771] {logging_mixin.py:104} INFO - [2022-03-20 11:08:29,771] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:08:29,803] {logging_mixin.py:104} INFO - [2022-03-20 11:08:29,803] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:08:29,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 11:08:59,918] {scheduler_job.py:182} INFO - Started process (PID=8376) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:08:59,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:08:59,924] {logging_mixin.py:104} INFO - [2022-03-20 11:08:59,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:08:59,960] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:09:00,006] {logging_mixin.py:104} INFO - [2022-03-20 11:09:00,005] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:09:00,041] {logging_mixin.py:104} INFO - [2022-03-20 11:09:00,040] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:09:00,057] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:09:30,342] {scheduler_job.py:182} INFO - Started process (PID=8408) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:09:30,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:09:30,349] {logging_mixin.py:104} INFO - [2022-03-20 11:09:30,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:09:30,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:09:30,431] {logging_mixin.py:104} INFO - [2022-03-20 11:09:30,431] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:09:30,466] {logging_mixin.py:104} INFO - [2022-03-20 11:09:30,466] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:09:30,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:10:01,010] {scheduler_job.py:182} INFO - Started process (PID=8440) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:01,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:10:01,016] {logging_mixin.py:104} INFO - [2022-03-20 11:10:01,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:01,052] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:01,097] {logging_mixin.py:104} INFO - [2022-03-20 11:10:01,096] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:10:01,131] {logging_mixin.py:104} INFO - [2022-03-20 11:10:01,131] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:10:01,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:10:31,516] {scheduler_job.py:182} INFO - Started process (PID=8472) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:31,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:10:31,524] {logging_mixin.py:104} INFO - [2022-03-20 11:10:31,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:31,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:10:31,607] {logging_mixin.py:104} INFO - [2022-03-20 11:10:31,606] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:10:31,639] {logging_mixin.py:104} INFO - [2022-03-20 11:10:31,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:10:31,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:11:02,045] {scheduler_job.py:182} INFO - Started process (PID=8503) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:02,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:11:02,053] {logging_mixin.py:104} INFO - [2022-03-20 11:11:02,053] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:02,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:02,132] {logging_mixin.py:104} INFO - [2022-03-20 11:11:02,132] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:11:02,163] {logging_mixin.py:104} INFO - [2022-03-20 11:11:02,163] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:11:02,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:11:32,675] {scheduler_job.py:182} INFO - Started process (PID=8535) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:32,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:11:32,682] {logging_mixin.py:104} INFO - [2022-03-20 11:11:32,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:32,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:11:32,761] {logging_mixin.py:104} INFO - [2022-03-20 11:11:32,760] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:11:32,796] {logging_mixin.py:104} INFO - [2022-03-20 11:11:32,795] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:11:32,812] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:12:03,387] {scheduler_job.py:182} INFO - Started process (PID=8568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:03,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:12:03,395] {logging_mixin.py:104} INFO - [2022-03-20 11:12:03,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:03,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:03,475] {logging_mixin.py:104} INFO - [2022-03-20 11:12:03,475] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:12:03,510] {logging_mixin.py:104} INFO - [2022-03-20 11:12:03,509] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:12:03,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:12:34,080] {scheduler_job.py:182} INFO - Started process (PID=8601) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:34,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:12:34,088] {logging_mixin.py:104} INFO - [2022-03-20 11:12:34,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:34,121] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:12:34,167] {logging_mixin.py:104} INFO - [2022-03-20 11:12:34,167] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:12:34,204] {logging_mixin.py:104} INFO - [2022-03-20 11:12:34,204] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:12:34,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:13:04,776] {scheduler_job.py:182} INFO - Started process (PID=8625) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:04,780] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:13:04,783] {logging_mixin.py:104} INFO - [2022-03-20 11:13:04,782] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:04,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:04,860] {logging_mixin.py:104} INFO - [2022-03-20 11:13:04,860] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:13:04,894] {logging_mixin.py:104} INFO - [2022-03-20 11:13:04,893] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:13:04,910] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 11:13:35,177] {scheduler_job.py:182} INFO - Started process (PID=8650) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:35,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:13:35,187] {logging_mixin.py:104} INFO - [2022-03-20 11:13:35,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:35,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:13:35,271] {logging_mixin.py:104} INFO - [2022-03-20 11:13:35,270] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:13:35,306] {logging_mixin.py:104} INFO - [2022-03-20 11:13:35,305] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:13:35,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:14:05,476] {scheduler_job.py:182} INFO - Started process (PID=8682) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:05,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:14:05,485] {logging_mixin.py:104} INFO - [2022-03-20 11:14:05,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:05,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:05,561] {logging_mixin.py:104} INFO - [2022-03-20 11:14:05,560] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:14:05,595] {logging_mixin.py:104} INFO - [2022-03-20 11:14:05,595] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:14:05,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:14:36,260] {scheduler_job.py:182} INFO - Started process (PID=8714) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:36,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:14:36,267] {logging_mixin.py:104} INFO - [2022-03-20 11:14:36,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:36,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:14:36,351] {logging_mixin.py:104} INFO - [2022-03-20 11:14:36,350] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:14:36,386] {logging_mixin.py:104} INFO - [2022-03-20 11:14:36,385] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:14:36,401] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:15:06,656] {scheduler_job.py:182} INFO - Started process (PID=8746) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:06,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:15:06,663] {logging_mixin.py:104} INFO - [2022-03-20 11:15:06,663] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:06,698] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:06,743] {logging_mixin.py:104} INFO - [2022-03-20 11:15:06,743] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:15:06,776] {logging_mixin.py:104} INFO - [2022-03-20 11:15:06,776] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:15:06,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:15:37,153] {scheduler_job.py:182} INFO - Started process (PID=8778) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:37,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:15:37,160] {logging_mixin.py:104} INFO - [2022-03-20 11:15:37,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:37,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:15:37,240] {logging_mixin.py:104} INFO - [2022-03-20 11:15:37,239] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:15:37,272] {logging_mixin.py:104} INFO - [2022-03-20 11:15:37,272] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:15:37,289] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:16:07,675] {scheduler_job.py:182} INFO - Started process (PID=8809) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:07,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:16:07,682] {logging_mixin.py:104} INFO - [2022-03-20 11:16:07,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:07,717] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:07,764] {logging_mixin.py:104} INFO - [2022-03-20 11:16:07,764] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:16:07,800] {logging_mixin.py:104} INFO - [2022-03-20 11:16:07,800] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:16:07,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 11:16:37,979] {scheduler_job.py:182} INFO - Started process (PID=8842) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:37,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:16:37,985] {logging_mixin.py:104} INFO - [2022-03-20 11:16:37,985] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:38,020] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:16:38,067] {logging_mixin.py:104} INFO - [2022-03-20 11:16:38,066] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:16:38,100] {logging_mixin.py:104} INFO - [2022-03-20 11:16:38,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:16:38,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:17:08,663] {scheduler_job.py:182} INFO - Started process (PID=8875) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:08,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:17:08,670] {logging_mixin.py:104} INFO - [2022-03-20 11:17:08,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:08,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:08,746] {logging_mixin.py:104} INFO - [2022-03-20 11:17:08,745] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:17:08,777] {logging_mixin.py:104} INFO - [2022-03-20 11:17:08,777] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:17:08,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.136 seconds
[2022-03-20 11:17:39,253] {scheduler_job.py:182} INFO - Started process (PID=8899) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:39,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:17:39,259] {logging_mixin.py:104} INFO - [2022-03-20 11:17:39,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:39,294] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:17:39,338] {logging_mixin.py:104} INFO - [2022-03-20 11:17:39,338] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:17:39,373] {logging_mixin.py:104} INFO - [2022-03-20 11:17:39,372] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:17:39,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:18:09,491] {scheduler_job.py:182} INFO - Started process (PID=8924) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:09,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:18:09,498] {logging_mixin.py:104} INFO - [2022-03-20 11:18:09,497] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:09,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:09,580] {logging_mixin.py:104} INFO - [2022-03-20 11:18:09,579] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:18:09,615] {logging_mixin.py:104} INFO - [2022-03-20 11:18:09,615] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:18:09,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:18:40,275] {scheduler_job.py:182} INFO - Started process (PID=8955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:40,278] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:18:40,281] {logging_mixin.py:104} INFO - [2022-03-20 11:18:40,281] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:40,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:18:40,368] {logging_mixin.py:104} INFO - [2022-03-20 11:18:40,367] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:18:40,403] {logging_mixin.py:104} INFO - [2022-03-20 11:18:40,402] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:18:40,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:19:10,952] {scheduler_job.py:182} INFO - Started process (PID=8988) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:10,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:19:10,959] {logging_mixin.py:104} INFO - [2022-03-20 11:19:10,958] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:10,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:11,042] {logging_mixin.py:104} INFO - [2022-03-20 11:19:11,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:19:11,074] {logging_mixin.py:104} INFO - [2022-03-20 11:19:11,073] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:19:11,092] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:19:41,693] {scheduler_job.py:182} INFO - Started process (PID=9020) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:41,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:19:41,706] {logging_mixin.py:104} INFO - [2022-03-20 11:19:41,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:41,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:19:41,791] {logging_mixin.py:104} INFO - [2022-03-20 11:19:41,790] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:19:41,826] {logging_mixin.py:104} INFO - [2022-03-20 11:19:41,825] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:19:41,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 11:20:12,246] {scheduler_job.py:182} INFO - Started process (PID=9052) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:12,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:20:12,253] {logging_mixin.py:104} INFO - [2022-03-20 11:20:12,252] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:12,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:12,331] {logging_mixin.py:104} INFO - [2022-03-20 11:20:12,331] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:20:12,365] {logging_mixin.py:104} INFO - [2022-03-20 11:20:12,365] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:20:12,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:20:42,878] {scheduler_job.py:182} INFO - Started process (PID=9084) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:42,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:20:42,885] {logging_mixin.py:104} INFO - [2022-03-20 11:20:42,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:42,918] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:20:42,964] {logging_mixin.py:104} INFO - [2022-03-20 11:20:42,963] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:20:42,997] {logging_mixin.py:104} INFO - [2022-03-20 11:20:42,997] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:20:43,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:21:13,597] {scheduler_job.py:182} INFO - Started process (PID=9117) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:13,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:21:13,604] {logging_mixin.py:104} INFO - [2022-03-20 11:21:13,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:13,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:13,685] {logging_mixin.py:104} INFO - [2022-03-20 11:21:13,684] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:21:13,717] {logging_mixin.py:104} INFO - [2022-03-20 11:21:13,717] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:21:13,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:21:44,598] {scheduler_job.py:182} INFO - Started process (PID=9142) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:44,602] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:21:44,605] {logging_mixin.py:104} INFO - [2022-03-20 11:21:44,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:44,640] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:21:44,684] {logging_mixin.py:104} INFO - [2022-03-20 11:21:44,684] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:21:44,719] {logging_mixin.py:104} INFO - [2022-03-20 11:21:44,718] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:21:44,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:22:14,914] {scheduler_job.py:182} INFO - Started process (PID=9169) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:14,917] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:22:14,920] {logging_mixin.py:104} INFO - [2022-03-20 11:22:14,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:14,954] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:14,997] {logging_mixin.py:104} INFO - [2022-03-20 11:22:14,996] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:22:15,028] {logging_mixin.py:104} INFO - [2022-03-20 11:22:15,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:22:15,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.136 seconds
[2022-03-20 11:22:45,269] {scheduler_job.py:182} INFO - Started process (PID=9199) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:45,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:22:45,277] {logging_mixin.py:104} INFO - [2022-03-20 11:22:45,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:45,311] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:22:45,353] {logging_mixin.py:104} INFO - [2022-03-20 11:22:45,352] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:22:45,382] {logging_mixin.py:104} INFO - [2022-03-20 11:22:45,381] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:22:45,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.134 seconds
[2022-03-20 11:23:15,793] {scheduler_job.py:182} INFO - Started process (PID=9229) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:15,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:23:15,799] {logging_mixin.py:104} INFO - [2022-03-20 11:23:15,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:15,835] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:15,885] {logging_mixin.py:104} INFO - [2022-03-20 11:23:15,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:23:15,921] {logging_mixin.py:104} INFO - [2022-03-20 11:23:15,920] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:23:15,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 11:23:46,522] {scheduler_job.py:182} INFO - Started process (PID=9262) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:46,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:23:46,529] {logging_mixin.py:104} INFO - [2022-03-20 11:23:46,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:46,564] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:23:46,610] {logging_mixin.py:104} INFO - [2022-03-20 11:23:46,609] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:23:46,642] {logging_mixin.py:104} INFO - [2022-03-20 11:23:46,642] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:23:46,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:24:17,193] {scheduler_job.py:182} INFO - Started process (PID=9293) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:17,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:24:17,200] {logging_mixin.py:104} INFO - [2022-03-20 11:24:17,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:17,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:17,283] {logging_mixin.py:104} INFO - [2022-03-20 11:24:17,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:24:17,316] {logging_mixin.py:104} INFO - [2022-03-20 11:24:17,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:24:17,333] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:24:47,911] {scheduler_job.py:182} INFO - Started process (PID=9325) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:47,916] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:24:47,920] {logging_mixin.py:104} INFO - [2022-03-20 11:24:47,919] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:47,955] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:24:48,001] {logging_mixin.py:104} INFO - [2022-03-20 11:24:48,001] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:24:48,035] {logging_mixin.py:104} INFO - [2022-03-20 11:24:48,034] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:24:48,051] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:25:18,606] {scheduler_job.py:182} INFO - Started process (PID=9358) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:18,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:25:18,613] {logging_mixin.py:104} INFO - [2022-03-20 11:25:18,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:18,650] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:18,696] {logging_mixin.py:104} INFO - [2022-03-20 11:25:18,695] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:25:18,729] {logging_mixin.py:104} INFO - [2022-03-20 11:25:18,729] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:25:18,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:25:49,539] {scheduler_job.py:182} INFO - Started process (PID=9391) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:49,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:25:49,547] {logging_mixin.py:104} INFO - [2022-03-20 11:25:49,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:49,580] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:25:49,626] {logging_mixin.py:104} INFO - [2022-03-20 11:25:49,626] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:25:49,659] {logging_mixin.py:104} INFO - [2022-03-20 11:25:49,659] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:25:49,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:26:20,509] {scheduler_job.py:182} INFO - Started process (PID=9415) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:20,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:26:20,516] {logging_mixin.py:104} INFO - [2022-03-20 11:26:20,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:20,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:20,589] {logging_mixin.py:104} INFO - [2022-03-20 11:26:20,589] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:26:20,620] {logging_mixin.py:104} INFO - [2022-03-20 11:26:20,620] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:26:20,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 11:26:50,831] {scheduler_job.py:182} INFO - Started process (PID=9439) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:50,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:26:50,839] {logging_mixin.py:104} INFO - [2022-03-20 11:26:50,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:50,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:26:50,920] {logging_mixin.py:104} INFO - [2022-03-20 11:26:50,919] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:26:50,953] {logging_mixin.py:104} INFO - [2022-03-20 11:26:50,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:26:50,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:27:21,575] {scheduler_job.py:182} INFO - Started process (PID=9472) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:21,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:27:21,583] {logging_mixin.py:104} INFO - [2022-03-20 11:27:21,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:21,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:21,661] {logging_mixin.py:104} INFO - [2022-03-20 11:27:21,661] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:27:21,695] {logging_mixin.py:104} INFO - [2022-03-20 11:27:21,694] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:27:21,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:27:52,388] {scheduler_job.py:182} INFO - Started process (PID=9504) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:52,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:27:52,395] {logging_mixin.py:104} INFO - [2022-03-20 11:27:52,395] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:52,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:27:52,479] {logging_mixin.py:104} INFO - [2022-03-20 11:27:52,479] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:27:52,513] {logging_mixin.py:104} INFO - [2022-03-20 11:27:52,513] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:27:52,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:28:23,218] {scheduler_job.py:182} INFO - Started process (PID=9536) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:23,222] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:28:23,226] {logging_mixin.py:104} INFO - [2022-03-20 11:28:23,225] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:23,263] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:23,309] {logging_mixin.py:104} INFO - [2022-03-20 11:28:23,309] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:28:23,343] {logging_mixin.py:104} INFO - [2022-03-20 11:28:23,343] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:28:23,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:28:53,916] {scheduler_job.py:182} INFO - Started process (PID=9568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:53,922] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:28:53,926] {logging_mixin.py:104} INFO - [2022-03-20 11:28:53,925] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:53,963] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:28:54,009] {logging_mixin.py:104} INFO - [2022-03-20 11:28:54,008] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:28:54,044] {logging_mixin.py:104} INFO - [2022-03-20 11:28:54,044] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:28:54,059] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 11:29:24,750] {scheduler_job.py:182} INFO - Started process (PID=9600) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:24,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:29:24,757] {logging_mixin.py:104} INFO - [2022-03-20 11:29:24,756] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:24,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:24,835] {logging_mixin.py:104} INFO - [2022-03-20 11:29:24,835] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:29:24,869] {logging_mixin.py:104} INFO - [2022-03-20 11:29:24,869] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:29:24,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:29:55,523] {scheduler_job.py:182} INFO - Started process (PID=9632) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:55,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:29:55,529] {logging_mixin.py:104} INFO - [2022-03-20 11:29:55,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:55,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:29:55,610] {logging_mixin.py:104} INFO - [2022-03-20 11:29:55,609] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:29:55,643] {logging_mixin.py:104} INFO - [2022-03-20 11:29:55,642] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:29:55,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:30:27,459] {scheduler_job.py:182} INFO - Started process (PID=9665) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:27,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:30:27,466] {logging_mixin.py:104} INFO - [2022-03-20 11:30:27,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:27,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:27,543] {logging_mixin.py:104} INFO - [2022-03-20 11:30:27,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:30:27,576] {logging_mixin.py:104} INFO - [2022-03-20 11:30:27,575] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:30:27,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 11:30:58,001] {scheduler_job.py:182} INFO - Started process (PID=9681) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:58,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:30:58,011] {logging_mixin.py:104} INFO - [2022-03-20 11:30:58,011] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:58,052] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:30:58,099] {logging_mixin.py:104} INFO - [2022-03-20 11:30:58,098] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:30:58,136] {logging_mixin.py:104} INFO - [2022-03-20 11:30:58,135] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:30:58,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 11:31:28,834] {scheduler_job.py:182} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:28,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:31:28,842] {logging_mixin.py:104} INFO - [2022-03-20 11:31:28,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:28,878] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:28,925] {logging_mixin.py:104} INFO - [2022-03-20 11:31:28,924] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:31:28,960] {logging_mixin.py:104} INFO - [2022-03-20 11:31:28,959] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:31:28,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:31:59,660] {scheduler_job.py:182} INFO - Started process (PID=9746) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:59,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:31:59,669] {logging_mixin.py:104} INFO - [2022-03-20 11:31:59,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:59,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:31:59,751] {logging_mixin.py:104} INFO - [2022-03-20 11:31:59,750] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:31:59,784] {logging_mixin.py:104} INFO - [2022-03-20 11:31:59,784] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:31:59,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:32:30,416] {scheduler_job.py:182} INFO - Started process (PID=9778) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:32:30,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:32:30,422] {logging_mixin.py:104} INFO - [2022-03-20 11:32:30,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:32:30,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:32:30,508] {logging_mixin.py:104} INFO - [2022-03-20 11:32:30,508] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:32:30,541] {logging_mixin.py:104} INFO - [2022-03-20 11:32:30,541] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:32:30,559] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 11:33:00,989] {scheduler_job.py:182} INFO - Started process (PID=9809) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:00,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:33:00,995] {logging_mixin.py:104} INFO - [2022-03-20 11:33:00,995] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:01,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:01,076] {logging_mixin.py:104} INFO - [2022-03-20 11:33:01,075] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:33:01,110] {logging_mixin.py:104} INFO - [2022-03-20 11:33:01,110] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:33:01,127] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:33:31,763] {scheduler_job.py:182} INFO - Started process (PID=9841) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:31,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:33:31,773] {logging_mixin.py:104} INFO - [2022-03-20 11:33:31,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:31,814] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:33:31,865] {logging_mixin.py:104} INFO - [2022-03-20 11:33:31,864] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:33:31,900] {logging_mixin.py:104} INFO - [2022-03-20 11:33:31,900] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:33:31,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 11:34:02,440] {scheduler_job.py:182} INFO - Started process (PID=9874) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:02,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:34:02,448] {logging_mixin.py:104} INFO - [2022-03-20 11:34:02,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:02,490] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:02,541] {logging_mixin.py:104} INFO - [2022-03-20 11:34:02,541] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:34:02,575] {logging_mixin.py:104} INFO - [2022-03-20 11:34:02,574] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:34:02,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 11:34:33,236] {scheduler_job.py:182} INFO - Started process (PID=9907) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:33,240] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:34:33,244] {logging_mixin.py:104} INFO - [2022-03-20 11:34:33,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:33,281] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:34:33,328] {logging_mixin.py:104} INFO - [2022-03-20 11:34:33,327] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:34:33,364] {logging_mixin.py:104} INFO - [2022-03-20 11:34:33,364] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:34:33,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:35:04,008] {scheduler_job.py:182} INFO - Started process (PID=9932) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:04,012] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:35:04,016] {logging_mixin.py:104} INFO - [2022-03-20 11:35:04,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:04,049] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:04,093] {logging_mixin.py:104} INFO - [2022-03-20 11:35:04,092] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:35:04,127] {logging_mixin.py:104} INFO - [2022-03-20 11:35:04,126] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:35:04,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:35:34,255] {scheduler_job.py:182} INFO - Started process (PID=9955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:34,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:35:34,262] {logging_mixin.py:104} INFO - [2022-03-20 11:35:34,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:34,296] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:35:34,342] {logging_mixin.py:104} INFO - [2022-03-20 11:35:34,341] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:35:34,375] {logging_mixin.py:104} INFO - [2022-03-20 11:35:34,375] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:35:34,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:36:04,907] {scheduler_job.py:182} INFO - Started process (PID=9987) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:04,910] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:36:04,913] {logging_mixin.py:104} INFO - [2022-03-20 11:36:04,912] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:04,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:04,993] {logging_mixin.py:104} INFO - [2022-03-20 11:36:04,993] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:36:05,028] {logging_mixin.py:104} INFO - [2022-03-20 11:36:05,027] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:36:05,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:36:35,453] {scheduler_job.py:182} INFO - Started process (PID=10020) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:35,457] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:36:35,461] {logging_mixin.py:104} INFO - [2022-03-20 11:36:35,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:35,495] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:36:35,543] {logging_mixin.py:104} INFO - [2022-03-20 11:36:35,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:36:35,578] {logging_mixin.py:104} INFO - [2022-03-20 11:36:35,578] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:36:35,594] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:37:05,962] {scheduler_job.py:182} INFO - Started process (PID=10052) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:05,966] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:37:05,968] {logging_mixin.py:104} INFO - [2022-03-20 11:37:05,968] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:06,003] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:06,049] {logging_mixin.py:104} INFO - [2022-03-20 11:37:06,049] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:37:06,083] {logging_mixin.py:104} INFO - [2022-03-20 11:37:06,083] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:37:06,099] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:37:36,619] {scheduler_job.py:182} INFO - Started process (PID=10083) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:36,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:37:36,625] {logging_mixin.py:104} INFO - [2022-03-20 11:37:36,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:36,660] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:37:36,706] {logging_mixin.py:104} INFO - [2022-03-20 11:37:36,705] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:37:36,738] {logging_mixin.py:104} INFO - [2022-03-20 11:37:36,738] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:37:36,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 11:38:07,194] {scheduler_job.py:182} INFO - Started process (PID=10115) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:07,199] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:38:07,202] {logging_mixin.py:104} INFO - [2022-03-20 11:38:07,202] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:07,236] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:07,280] {logging_mixin.py:104} INFO - [2022-03-20 11:38:07,280] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:38:07,313] {logging_mixin.py:104} INFO - [2022-03-20 11:38:07,312] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:38:07,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:38:37,837] {scheduler_job.py:182} INFO - Started process (PID=10147) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:37,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:38:37,843] {logging_mixin.py:104} INFO - [2022-03-20 11:38:37,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:37,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:38:37,925] {logging_mixin.py:104} INFO - [2022-03-20 11:38:37,925] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:38:37,958] {logging_mixin.py:104} INFO - [2022-03-20 11:38:37,958] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:38:37,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:39:08,564] {scheduler_job.py:182} INFO - Started process (PID=10181) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:08,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:39:08,571] {logging_mixin.py:104} INFO - [2022-03-20 11:39:08,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:08,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:08,648] {logging_mixin.py:104} INFO - [2022-03-20 11:39:08,647] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:39:08,680] {logging_mixin.py:104} INFO - [2022-03-20 11:39:08,680] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:39:08,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 11:39:39,166] {scheduler_job.py:182} INFO - Started process (PID=10197) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:39,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:39:39,171] {logging_mixin.py:104} INFO - [2022-03-20 11:39:39,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:39,205] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:39:39,249] {logging_mixin.py:104} INFO - [2022-03-20 11:39:39,248] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:39:39,285] {logging_mixin.py:104} INFO - [2022-03-20 11:39:39,284] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:39:39,302] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:40:09,766] {scheduler_job.py:182} INFO - Started process (PID=10229) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:09,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:40:09,772] {logging_mixin.py:104} INFO - [2022-03-20 11:40:09,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:09,806] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:09,855] {logging_mixin.py:104} INFO - [2022-03-20 11:40:09,854] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:40:09,887] {logging_mixin.py:104} INFO - [2022-03-20 11:40:09,887] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:40:09,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:40:40,594] {scheduler_job.py:182} INFO - Started process (PID=10262) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:40,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:40:40,601] {logging_mixin.py:104} INFO - [2022-03-20 11:40:40,600] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:40,635] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:40:40,682] {logging_mixin.py:104} INFO - [2022-03-20 11:40:40,682] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:40:40,716] {logging_mixin.py:104} INFO - [2022-03-20 11:40:40,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:40:40,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:41:11,328] {scheduler_job.py:182} INFO - Started process (PID=10294) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:11,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:41:11,336] {logging_mixin.py:104} INFO - [2022-03-20 11:41:11,336] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:11,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:11,415] {logging_mixin.py:104} INFO - [2022-03-20 11:41:11,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:41:11,449] {logging_mixin.py:104} INFO - [2022-03-20 11:41:11,449] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:41:11,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:41:41,905] {scheduler_job.py:182} INFO - Started process (PID=10325) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:41,910] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:41:41,913] {logging_mixin.py:104} INFO - [2022-03-20 11:41:41,912] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:41,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:41:41,993] {logging_mixin.py:104} INFO - [2022-03-20 11:41:41,993] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:41:42,027] {logging_mixin.py:104} INFO - [2022-03-20 11:41:42,026] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:41:42,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:42:12,493] {scheduler_job.py:182} INFO - Started process (PID=10358) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:12,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:42:12,504] {logging_mixin.py:104} INFO - [2022-03-20 11:42:12,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:12,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:12,582] {logging_mixin.py:104} INFO - [2022-03-20 11:42:12,581] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:42:12,616] {logging_mixin.py:104} INFO - [2022-03-20 11:42:12,616] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:42:12,632] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:42:43,289] {scheduler_job.py:182} INFO - Started process (PID=10390) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:43,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:42:43,296] {logging_mixin.py:104} INFO - [2022-03-20 11:42:43,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:43,334] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:42:43,379] {logging_mixin.py:104} INFO - [2022-03-20 11:42:43,379] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:42:43,413] {logging_mixin.py:104} INFO - [2022-03-20 11:42:43,412] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:42:43,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:43:14,123] {scheduler_job.py:182} INFO - Started process (PID=10423) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:14,127] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:43:14,131] {logging_mixin.py:104} INFO - [2022-03-20 11:43:14,130] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:14,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:14,211] {logging_mixin.py:104} INFO - [2022-03-20 11:43:14,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:43:14,245] {logging_mixin.py:104} INFO - [2022-03-20 11:43:14,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:43:14,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 11:43:44,962] {scheduler_job.py:182} INFO - Started process (PID=10448) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:44,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:43:44,969] {logging_mixin.py:104} INFO - [2022-03-20 11:43:44,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:45,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:43:45,045] {logging_mixin.py:104} INFO - [2022-03-20 11:43:45,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:43:45,079] {logging_mixin.py:104} INFO - [2022-03-20 11:43:45,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:43:45,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 11:44:15,155] {scheduler_job.py:182} INFO - Started process (PID=10472) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:15,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:44:15,162] {logging_mixin.py:104} INFO - [2022-03-20 11:44:15,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:15,197] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:15,243] {logging_mixin.py:104} INFO - [2022-03-20 11:44:15,243] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:44:15,278] {logging_mixin.py:104} INFO - [2022-03-20 11:44:15,277] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:44:15,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:44:45,908] {scheduler_job.py:182} INFO - Started process (PID=10504) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:45,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:44:45,915] {logging_mixin.py:104} INFO - [2022-03-20 11:44:45,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:45,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:44:45,996] {logging_mixin.py:104} INFO - [2022-03-20 11:44:45,996] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:44:46,029] {logging_mixin.py:104} INFO - [2022-03-20 11:44:46,029] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:44:46,045] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:45:16,491] {scheduler_job.py:182} INFO - Started process (PID=10536) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:16,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:45:16,498] {logging_mixin.py:104} INFO - [2022-03-20 11:45:16,498] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:16,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:16,584] {logging_mixin.py:104} INFO - [2022-03-20 11:45:16,583] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:45:16,620] {logging_mixin.py:104} INFO - [2022-03-20 11:45:16,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:45:16,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:45:47,099] {scheduler_job.py:182} INFO - Started process (PID=10568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:47,103] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:45:47,107] {logging_mixin.py:104} INFO - [2022-03-20 11:45:47,106] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:47,146] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:45:47,191] {logging_mixin.py:104} INFO - [2022-03-20 11:45:47,191] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:45:47,226] {logging_mixin.py:104} INFO - [2022-03-20 11:45:47,225] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:45:47,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:46:17,641] {scheduler_job.py:182} INFO - Started process (PID=10599) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:17,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:46:17,649] {logging_mixin.py:104} INFO - [2022-03-20 11:46:17,649] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:17,685] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:17,733] {logging_mixin.py:104} INFO - [2022-03-20 11:46:17,732] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:46:17,768] {logging_mixin.py:104} INFO - [2022-03-20 11:46:17,767] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:46:17,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 11:46:48,173] {scheduler_job.py:182} INFO - Started process (PID=10631) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:48,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:46:48,181] {logging_mixin.py:104} INFO - [2022-03-20 11:46:48,181] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:48,214] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:46:48,258] {logging_mixin.py:104} INFO - [2022-03-20 11:46:48,258] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:46:48,292] {logging_mixin.py:104} INFO - [2022-03-20 11:46:48,291] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:46:48,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:47:18,666] {scheduler_job.py:182} INFO - Started process (PID=10664) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:18,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:47:18,674] {logging_mixin.py:104} INFO - [2022-03-20 11:47:18,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:18,710] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:18,756] {logging_mixin.py:104} INFO - [2022-03-20 11:47:18,756] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:47:18,790] {logging_mixin.py:104} INFO - [2022-03-20 11:47:18,790] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:47:18,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:47:49,396] {scheduler_job.py:182} INFO - Started process (PID=10697) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:49,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:47:49,402] {logging_mixin.py:104} INFO - [2022-03-20 11:47:49,402] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:49,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:47:49,480] {logging_mixin.py:104} INFO - [2022-03-20 11:47:49,479] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:47:49,516] {logging_mixin.py:104} INFO - [2022-03-20 11:47:49,515] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:47:49,534] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:48:20,365] {scheduler_job.py:182} INFO - Started process (PID=10721) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:20,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:48:20,371] {logging_mixin.py:104} INFO - [2022-03-20 11:48:20,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:20,406] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:20,449] {logging_mixin.py:104} INFO - [2022-03-20 11:48:20,449] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:48:20,482] {logging_mixin.py:104} INFO - [2022-03-20 11:48:20,481] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:48:20,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 11:48:50,640] {scheduler_job.py:182} INFO - Started process (PID=10746) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:50,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:48:50,646] {logging_mixin.py:104} INFO - [2022-03-20 11:48:50,646] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:50,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:48:50,728] {logging_mixin.py:104} INFO - [2022-03-20 11:48:50,728] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:48:50,762] {logging_mixin.py:104} INFO - [2022-03-20 11:48:50,761] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:48:50,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:49:21,277] {scheduler_job.py:182} INFO - Started process (PID=10778) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:21,281] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:49:21,284] {logging_mixin.py:104} INFO - [2022-03-20 11:49:21,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:21,321] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:21,369] {logging_mixin.py:104} INFO - [2022-03-20 11:49:21,368] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:49:21,403] {logging_mixin.py:104} INFO - [2022-03-20 11:49:21,402] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:49:21,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:49:51,906] {scheduler_job.py:182} INFO - Started process (PID=10810) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:51,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:49:51,914] {logging_mixin.py:104} INFO - [2022-03-20 11:49:51,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:51,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:49:51,994] {logging_mixin.py:104} INFO - [2022-03-20 11:49:51,993] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:49:52,027] {logging_mixin.py:104} INFO - [2022-03-20 11:49:52,026] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:49:52,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:50:22,496] {scheduler_job.py:182} INFO - Started process (PID=10842) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:22,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:50:22,503] {logging_mixin.py:104} INFO - [2022-03-20 11:50:22,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:22,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:22,584] {logging_mixin.py:104} INFO - [2022-03-20 11:50:22,584] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:50:22,617] {logging_mixin.py:104} INFO - [2022-03-20 11:50:22,617] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:50:22,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:50:52,995] {scheduler_job.py:182} INFO - Started process (PID=10874) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:52,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:50:53,001] {logging_mixin.py:104} INFO - [2022-03-20 11:50:53,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:53,041] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:50:53,086] {logging_mixin.py:104} INFO - [2022-03-20 11:50:53,086] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:50:53,119] {logging_mixin.py:104} INFO - [2022-03-20 11:50:53,119] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:50:53,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 11:51:23,498] {scheduler_job.py:182} INFO - Started process (PID=10906) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:23,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:51:23,505] {logging_mixin.py:104} INFO - [2022-03-20 11:51:23,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:23,540] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:23,583] {logging_mixin.py:104} INFO - [2022-03-20 11:51:23,583] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:51:23,616] {logging_mixin.py:104} INFO - [2022-03-20 11:51:23,616] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:51:23,632] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:51:54,112] {scheduler_job.py:182} INFO - Started process (PID=10938) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:54,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:51:54,119] {logging_mixin.py:104} INFO - [2022-03-20 11:51:54,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:54,155] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:51:54,200] {logging_mixin.py:104} INFO - [2022-03-20 11:51:54,200] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:51:54,236] {logging_mixin.py:104} INFO - [2022-03-20 11:51:54,235] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:51:54,252] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 11:52:25,935] {scheduler_job.py:182} INFO - Started process (PID=10971) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:25,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:52:25,941] {logging_mixin.py:104} INFO - [2022-03-20 11:52:25,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:25,976] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:26,020] {logging_mixin.py:104} INFO - [2022-03-20 11:52:26,020] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:52:26,054] {logging_mixin.py:104} INFO - [2022-03-20 11:52:26,053] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:52:26,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 11:52:56,532] {scheduler_job.py:182} INFO - Started process (PID=10988) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:56,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:52:56,541] {logging_mixin.py:104} INFO - [2022-03-20 11:52:56,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:56,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:52:56,621] {logging_mixin.py:104} INFO - [2022-03-20 11:52:56,621] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:52:56,655] {logging_mixin.py:104} INFO - [2022-03-20 11:52:56,655] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:52:56,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:53:27,230] {scheduler_job.py:182} INFO - Started process (PID=11020) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:27,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:53:27,237] {logging_mixin.py:104} INFO - [2022-03-20 11:53:27,237] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:27,274] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:27,323] {logging_mixin.py:104} INFO - [2022-03-20 11:53:27,323] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:53:27,358] {logging_mixin.py:104} INFO - [2022-03-20 11:53:27,358] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:53:27,374] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 11:53:57,876] {scheduler_job.py:182} INFO - Started process (PID=11051) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:57,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:53:57,882] {logging_mixin.py:104} INFO - [2022-03-20 11:53:57,882] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:57,916] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:53:57,961] {logging_mixin.py:104} INFO - [2022-03-20 11:53:57,961] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:53:57,994] {logging_mixin.py:104} INFO - [2022-03-20 11:53:57,994] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:53:58,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 11:54:28,512] {scheduler_job.py:182} INFO - Started process (PID=11083) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:28,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:54:28,520] {logging_mixin.py:104} INFO - [2022-03-20 11:54:28,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:28,555] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:28,601] {logging_mixin.py:104} INFO - [2022-03-20 11:54:28,600] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:54:28,635] {logging_mixin.py:104} INFO - [2022-03-20 11:54:28,634] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:54:28,651] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 11:54:58,972] {scheduler_job.py:182} INFO - Started process (PID=11116) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:58,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:54:58,979] {logging_mixin.py:104} INFO - [2022-03-20 11:54:58,979] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:59,017] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:54:59,067] {logging_mixin.py:104} INFO - [2022-03-20 11:54:59,066] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:54:59,101] {logging_mixin.py:104} INFO - [2022-03-20 11:54:59,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:54:59,116] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 11:55:29,533] {scheduler_job.py:182} INFO - Started process (PID=11148) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:55:29,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:55:29,541] {logging_mixin.py:104} INFO - [2022-03-20 11:55:29,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:55:29,584] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:55:29,628] {logging_mixin.py:104} INFO - [2022-03-20 11:55:29,628] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:55:29,663] {logging_mixin.py:104} INFO - [2022-03-20 11:55:29,662] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:55:29,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 11:56:00,214] {scheduler_job.py:182} INFO - Started process (PID=11180) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:00,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:56:00,220] {logging_mixin.py:104} INFO - [2022-03-20 11:56:00,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:00,256] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:00,304] {logging_mixin.py:104} INFO - [2022-03-20 11:56:00,303] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:56:00,340] {logging_mixin.py:104} INFO - [2022-03-20 11:56:00,340] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:56:00,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 11:56:31,134] {scheduler_job.py:182} INFO - Started process (PID=11213) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:31,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:56:31,143] {logging_mixin.py:104} INFO - [2022-03-20 11:56:31,142] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:31,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:56:31,216] {logging_mixin.py:104} INFO - [2022-03-20 11:56:31,216] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:56:31,246] {logging_mixin.py:104} INFO - [2022-03-20 11:56:31,245] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:56:31,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 11:57:02,063] {scheduler_job.py:182} INFO - Started process (PID=11238) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:02,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:57:02,069] {logging_mixin.py:104} INFO - [2022-03-20 11:57:02,069] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:02,102] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:02,145] {logging_mixin.py:104} INFO - [2022-03-20 11:57:02,145] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:57:02,178] {logging_mixin.py:104} INFO - [2022-03-20 11:57:02,177] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:57:02,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 11:57:32,784] {scheduler_job.py:182} INFO - Started process (PID=11261) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:32,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:57:32,791] {logging_mixin.py:104} INFO - [2022-03-20 11:57:32,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:32,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:57:32,872] {logging_mixin.py:104} INFO - [2022-03-20 11:57:32,871] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:57:32,904] {logging_mixin.py:104} INFO - [2022-03-20 11:57:32,904] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:57:32,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 11:58:03,522] {scheduler_job.py:182} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:03,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:58:03,529] {logging_mixin.py:104} INFO - [2022-03-20 11:58:03,528] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:03,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:03,615] {logging_mixin.py:104} INFO - [2022-03-20 11:58:03,615] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:58:03,649] {logging_mixin.py:104} INFO - [2022-03-20 11:58:03,648] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:58:03,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 11:58:34,260] {scheduler_job.py:182} INFO - Started process (PID=11326) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:34,267] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:58:34,270] {logging_mixin.py:104} INFO - [2022-03-20 11:58:34,270] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:34,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:58:34,349] {logging_mixin.py:104} INFO - [2022-03-20 11:58:34,349] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:58:34,383] {logging_mixin.py:104} INFO - [2022-03-20 11:58:34,383] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:58:34,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 11:59:04,896] {scheduler_job.py:182} INFO - Started process (PID=11358) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:04,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:59:04,907] {logging_mixin.py:104} INFO - [2022-03-20 11:59:04,905] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:04,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:04,992] {logging_mixin.py:104} INFO - [2022-03-20 11:59:04,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:59:05,028] {logging_mixin.py:104} INFO - [2022-03-20 11:59:05,027] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:59:05,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 11:59:35,435] {scheduler_job.py:182} INFO - Started process (PID=11389) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:35,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 11:59:35,443] {logging_mixin.py:104} INFO - [2022-03-20 11:59:35,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:35,474] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 11:59:35,520] {logging_mixin.py:104} INFO - [2022-03-20 11:59:35,520] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 11:59:35,555] {logging_mixin.py:104} INFO - [2022-03-20 11:59:35,554] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 11:59:35,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:00:05,981] {scheduler_job.py:182} INFO - Started process (PID=11422) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:05,985] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:00:05,988] {logging_mixin.py:104} INFO - [2022-03-20 12:00:05,987] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:06,026] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:06,072] {logging_mixin.py:104} INFO - [2022-03-20 12:00:06,072] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:00:06,106] {logging_mixin.py:104} INFO - [2022-03-20 12:00:06,106] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:00:06,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:00:36,553] {scheduler_job.py:182} INFO - Started process (PID=11454) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:36,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:00:36,562] {logging_mixin.py:104} INFO - [2022-03-20 12:00:36,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:36,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:00:36,640] {logging_mixin.py:104} INFO - [2022-03-20 12:00:36,640] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:00:36,674] {logging_mixin.py:104} INFO - [2022-03-20 12:00:36,674] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:00:36,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:01:07,405] {scheduler_job.py:182} INFO - Started process (PID=11487) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:07,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:01:07,411] {logging_mixin.py:104} INFO - [2022-03-20 12:01:07,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:07,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:07,488] {logging_mixin.py:104} INFO - [2022-03-20 12:01:07,487] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:01:07,521] {logging_mixin.py:104} INFO - [2022-03-20 12:01:07,521] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:01:07,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:01:38,036] {scheduler_job.py:182} INFO - Started process (PID=11511) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:38,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:01:38,044] {logging_mixin.py:104} INFO - [2022-03-20 12:01:38,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:38,077] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:01:38,121] {logging_mixin.py:104} INFO - [2022-03-20 12:01:38,121] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:01:38,152] {logging_mixin.py:104} INFO - [2022-03-20 12:01:38,152] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:01:38,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 12:02:08,333] {scheduler_job.py:182} INFO - Started process (PID=11536) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:08,337] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:02:08,340] {logging_mixin.py:104} INFO - [2022-03-20 12:02:08,339] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:08,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:08,421] {logging_mixin.py:104} INFO - [2022-03-20 12:02:08,421] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:02:08,456] {logging_mixin.py:104} INFO - [2022-03-20 12:02:08,456] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:02:08,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:02:38,981] {scheduler_job.py:182} INFO - Started process (PID=11568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:38,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:02:38,989] {logging_mixin.py:104} INFO - [2022-03-20 12:02:38,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:39,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:02:39,070] {logging_mixin.py:104} INFO - [2022-03-20 12:02:39,069] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:02:39,106] {logging_mixin.py:104} INFO - [2022-03-20 12:02:39,105] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:02:39,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 12:03:09,546] {scheduler_job.py:182} INFO - Started process (PID=11599) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:09,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:03:09,552] {logging_mixin.py:104} INFO - [2022-03-20 12:03:09,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:09,588] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:09,632] {logging_mixin.py:104} INFO - [2022-03-20 12:03:09,632] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:03:09,666] {logging_mixin.py:104} INFO - [2022-03-20 12:03:09,665] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:03:09,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:03:40,285] {scheduler_job.py:182} INFO - Started process (PID=11631) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:40,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:03:40,292] {logging_mixin.py:104} INFO - [2022-03-20 12:03:40,292] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:40,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:03:40,379] {logging_mixin.py:104} INFO - [2022-03-20 12:03:40,379] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:03:40,414] {logging_mixin.py:104} INFO - [2022-03-20 12:03:40,413] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:03:40,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 12:04:11,103] {scheduler_job.py:182} INFO - Started process (PID=11664) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:11,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:04:11,112] {logging_mixin.py:104} INFO - [2022-03-20 12:04:11,111] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:11,146] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:11,193] {logging_mixin.py:104} INFO - [2022-03-20 12:04:11,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:04:11,225] {logging_mixin.py:104} INFO - [2022-03-20 12:04:11,225] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:04:11,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:04:41,905] {scheduler_job.py:182} INFO - Started process (PID=11696) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:41,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:04:41,914] {logging_mixin.py:104} INFO - [2022-03-20 12:04:41,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:41,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:04:41,996] {logging_mixin.py:104} INFO - [2022-03-20 12:04:41,995] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:04:42,029] {logging_mixin.py:104} INFO - [2022-03-20 12:04:42,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:04:42,045] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:05:12,727] {scheduler_job.py:182} INFO - Started process (PID=11728) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:12,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:05:12,733] {logging_mixin.py:104} INFO - [2022-03-20 12:05:12,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:12,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:12,812] {logging_mixin.py:104} INFO - [2022-03-20 12:05:12,811] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:05:12,846] {logging_mixin.py:104} INFO - [2022-03-20 12:05:12,845] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:05:12,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:05:44,673] {scheduler_job.py:182} INFO - Started process (PID=11761) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:44,677] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:05:44,679] {logging_mixin.py:104} INFO - [2022-03-20 12:05:44,679] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:44,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:05:44,758] {logging_mixin.py:104} INFO - [2022-03-20 12:05:44,758] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:05:44,791] {logging_mixin.py:104} INFO - [2022-03-20 12:05:44,791] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:05:44,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:06:15,260] {scheduler_job.py:182} INFO - Started process (PID=11778) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:15,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:06:15,266] {logging_mixin.py:104} INFO - [2022-03-20 12:06:15,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:15,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:15,344] {logging_mixin.py:104} INFO - [2022-03-20 12:06:15,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:06:15,377] {logging_mixin.py:104} INFO - [2022-03-20 12:06:15,377] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:06:15,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:06:45,886] {scheduler_job.py:182} INFO - Started process (PID=11809) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:45,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:06:45,893] {logging_mixin.py:104} INFO - [2022-03-20 12:06:45,892] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:45,930] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:06:45,979] {logging_mixin.py:104} INFO - [2022-03-20 12:06:45,978] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:06:46,012] {logging_mixin.py:104} INFO - [2022-03-20 12:06:46,011] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:06:46,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 12:07:16,435] {scheduler_job.py:182} INFO - Started process (PID=11842) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:16,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:07:16,443] {logging_mixin.py:104} INFO - [2022-03-20 12:07:16,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:16,476] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:16,519] {logging_mixin.py:104} INFO - [2022-03-20 12:07:16,519] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:07:16,552] {logging_mixin.py:104} INFO - [2022-03-20 12:07:16,551] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:07:16,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 12:07:46,871] {scheduler_job.py:182} INFO - Started process (PID=11874) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:46,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:07:46,877] {logging_mixin.py:104} INFO - [2022-03-20 12:07:46,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:46,915] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:07:46,962] {logging_mixin.py:104} INFO - [2022-03-20 12:07:46,962] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:07:46,995] {logging_mixin.py:104} INFO - [2022-03-20 12:07:46,995] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:07:47,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:08:17,549] {scheduler_job.py:182} INFO - Started process (PID=11905) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:17,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:08:17,555] {logging_mixin.py:104} INFO - [2022-03-20 12:08:17,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:17,587] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:17,631] {logging_mixin.py:104} INFO - [2022-03-20 12:08:17,631] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:08:17,666] {logging_mixin.py:104} INFO - [2022-03-20 12:08:17,666] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:08:17,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 12:08:48,120] {scheduler_job.py:182} INFO - Started process (PID=11938) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:48,124] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:08:48,128] {logging_mixin.py:104} INFO - [2022-03-20 12:08:48,127] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:48,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:08:48,218] {logging_mixin.py:104} INFO - [2022-03-20 12:08:48,218] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:08:48,252] {logging_mixin.py:104} INFO - [2022-03-20 12:08:48,251] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:08:48,267] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:09:18,653] {scheduler_job.py:182} INFO - Started process (PID=11969) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:18,656] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:09:18,658] {logging_mixin.py:104} INFO - [2022-03-20 12:09:18,658] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:18,694] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:18,741] {logging_mixin.py:104} INFO - [2022-03-20 12:09:18,740] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:09:18,774] {logging_mixin.py:104} INFO - [2022-03-20 12:09:18,773] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:09:18,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:09:49,325] {scheduler_job.py:182} INFO - Started process (PID=12003) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:49,329] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:09:49,332] {logging_mixin.py:104} INFO - [2022-03-20 12:09:49,332] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:49,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:09:49,415] {logging_mixin.py:104} INFO - [2022-03-20 12:09:49,415] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:09:49,445] {logging_mixin.py:104} INFO - [2022-03-20 12:09:49,445] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:09:49,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 12:10:20,117] {scheduler_job.py:182} INFO - Started process (PID=12028) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:20,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:10:20,125] {logging_mixin.py:104} INFO - [2022-03-20 12:10:20,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:20,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:20,202] {logging_mixin.py:104} INFO - [2022-03-20 12:10:20,201] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:10:20,235] {logging_mixin.py:104} INFO - [2022-03-20 12:10:20,235] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:10:20,252] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:10:50,397] {scheduler_job.py:182} INFO - Started process (PID=12052) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:50,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:10:50,404] {logging_mixin.py:104} INFO - [2022-03-20 12:10:50,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:50,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:10:50,488] {logging_mixin.py:104} INFO - [2022-03-20 12:10:50,487] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:10:50,522] {logging_mixin.py:104} INFO - [2022-03-20 12:10:50,521] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:10:50,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:11:21,070] {scheduler_job.py:182} INFO - Started process (PID=12084) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:21,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:11:21,075] {logging_mixin.py:104} INFO - [2022-03-20 12:11:21,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:21,112] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:21,158] {logging_mixin.py:104} INFO - [2022-03-20 12:11:21,158] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:11:21,191] {logging_mixin.py:104} INFO - [2022-03-20 12:11:21,191] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:11:21,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:11:51,743] {scheduler_job.py:182} INFO - Started process (PID=12116) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:51,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:11:51,749] {logging_mixin.py:104} INFO - [2022-03-20 12:11:51,749] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:51,783] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:11:51,826] {logging_mixin.py:104} INFO - [2022-03-20 12:11:51,826] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:11:51,861] {logging_mixin.py:104} INFO - [2022-03-20 12:11:51,860] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:11:51,877] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:12:22,267] {scheduler_job.py:182} INFO - Started process (PID=12147) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:22,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:12:22,273] {logging_mixin.py:104} INFO - [2022-03-20 12:12:22,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:22,310] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:22,355] {logging_mixin.py:104} INFO - [2022-03-20 12:12:22,354] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:12:22,389] {logging_mixin.py:104} INFO - [2022-03-20 12:12:22,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:12:22,405] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:12:52,932] {scheduler_job.py:182} INFO - Started process (PID=12180) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:52,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:12:52,938] {logging_mixin.py:104} INFO - [2022-03-20 12:12:52,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:52,976] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:12:53,023] {logging_mixin.py:104} INFO - [2022-03-20 12:12:53,022] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:12:53,055] {logging_mixin.py:104} INFO - [2022-03-20 12:12:53,054] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:12:53,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:13:23,507] {scheduler_job.py:182} INFO - Started process (PID=12212) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:23,511] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:13:23,513] {logging_mixin.py:104} INFO - [2022-03-20 12:13:23,513] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:23,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:23,592] {logging_mixin.py:104} INFO - [2022-03-20 12:13:23,592] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:13:23,626] {logging_mixin.py:104} INFO - [2022-03-20 12:13:23,626] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:13:23,642] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 12:13:54,163] {scheduler_job.py:182} INFO - Started process (PID=12243) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:54,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:13:54,169] {logging_mixin.py:104} INFO - [2022-03-20 12:13:54,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:54,203] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:13:54,250] {logging_mixin.py:104} INFO - [2022-03-20 12:13:54,250] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:13:54,284] {logging_mixin.py:104} INFO - [2022-03-20 12:13:54,283] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:13:54,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:14:24,925] {scheduler_job.py:182} INFO - Started process (PID=12277) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:24,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:14:24,931] {logging_mixin.py:104} INFO - [2022-03-20 12:14:24,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:24,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:25,009] {logging_mixin.py:104} INFO - [2022-03-20 12:14:25,009] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:14:25,044] {logging_mixin.py:104} INFO - [2022-03-20 12:14:25,043] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:14:25,060] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:14:55,531] {scheduler_job.py:182} INFO - Started process (PID=12294) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:55,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:14:55,539] {logging_mixin.py:104} INFO - [2022-03-20 12:14:55,538] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:55,575] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:14:55,620] {logging_mixin.py:104} INFO - [2022-03-20 12:14:55,619] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:14:55,654] {logging_mixin.py:104} INFO - [2022-03-20 12:14:55,653] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:14:55,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:15:26,105] {scheduler_job.py:182} INFO - Started process (PID=12325) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:26,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:15:26,111] {logging_mixin.py:104} INFO - [2022-03-20 12:15:26,111] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:26,149] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:26,195] {logging_mixin.py:104} INFO - [2022-03-20 12:15:26,195] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:15:26,229] {logging_mixin.py:104} INFO - [2022-03-20 12:15:26,229] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:15:26,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:15:56,921] {scheduler_job.py:182} INFO - Started process (PID=12357) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:56,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:15:56,932] {logging_mixin.py:104} INFO - [2022-03-20 12:15:56,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:56,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:15:57,013] {logging_mixin.py:104} INFO - [2022-03-20 12:15:57,013] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:15:57,046] {logging_mixin.py:104} INFO - [2022-03-20 12:15:57,045] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:15:57,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:16:27,621] {scheduler_job.py:182} INFO - Started process (PID=12390) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:27,626] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:16:27,629] {logging_mixin.py:104} INFO - [2022-03-20 12:16:27,628] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:27,661] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:27,706] {logging_mixin.py:104} INFO - [2022-03-20 12:16:27,706] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:16:27,740] {logging_mixin.py:104} INFO - [2022-03-20 12:16:27,739] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:16:27,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:16:58,179] {scheduler_job.py:182} INFO - Started process (PID=12422) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:58,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:16:58,186] {logging_mixin.py:104} INFO - [2022-03-20 12:16:58,185] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:58,221] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:16:58,266] {logging_mixin.py:104} INFO - [2022-03-20 12:16:58,266] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:16:58,301] {logging_mixin.py:104} INFO - [2022-03-20 12:16:58,300] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:16:58,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:17:28,808] {scheduler_job.py:182} INFO - Started process (PID=12453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:28,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:17:28,816] {logging_mixin.py:104} INFO - [2022-03-20 12:17:28,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:28,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:28,896] {logging_mixin.py:104} INFO - [2022-03-20 12:17:28,896] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:17:28,929] {logging_mixin.py:104} INFO - [2022-03-20 12:17:28,928] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:17:28,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:17:59,436] {scheduler_job.py:182} INFO - Started process (PID=12486) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:59,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:17:59,443] {logging_mixin.py:104} INFO - [2022-03-20 12:17:59,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:59,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:17:59,522] {logging_mixin.py:104} INFO - [2022-03-20 12:17:59,522] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:17:59,555] {logging_mixin.py:104} INFO - [2022-03-20 12:17:59,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:17:59,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:18:30,214] {scheduler_job.py:182} INFO - Started process (PID=12519) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:18:30,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:18:30,220] {logging_mixin.py:104} INFO - [2022-03-20 12:18:30,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:18:30,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:18:30,301] {logging_mixin.py:104} INFO - [2022-03-20 12:18:30,301] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:18:30,331] {logging_mixin.py:104} INFO - [2022-03-20 12:18:30,331] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:18:30,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 12:19:01,095] {scheduler_job.py:182} INFO - Started process (PID=12544) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:01,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:19:01,103] {logging_mixin.py:104} INFO - [2022-03-20 12:19:01,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:01,137] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:01,180] {logging_mixin.py:104} INFO - [2022-03-20 12:19:01,179] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:19:01,212] {logging_mixin.py:104} INFO - [2022-03-20 12:19:01,212] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:19:01,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:19:31,295] {scheduler_job.py:182} INFO - Started process (PID=12568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:31,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:19:31,302] {logging_mixin.py:104} INFO - [2022-03-20 12:19:31,301] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:31,337] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:19:31,384] {logging_mixin.py:104} INFO - [2022-03-20 12:19:31,383] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:19:31,418] {logging_mixin.py:104} INFO - [2022-03-20 12:19:31,418] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:19:31,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:20:02,027] {scheduler_job.py:182} INFO - Started process (PID=12600) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:02,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:20:02,036] {logging_mixin.py:104} INFO - [2022-03-20 12:20:02,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:02,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:02,115] {logging_mixin.py:104} INFO - [2022-03-20 12:20:02,115] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:20:02,149] {logging_mixin.py:104} INFO - [2022-03-20 12:20:02,148] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:20:02,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:20:32,626] {scheduler_job.py:182} INFO - Started process (PID=12632) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:32,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:20:32,633] {logging_mixin.py:104} INFO - [2022-03-20 12:20:32,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:32,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:20:32,713] {logging_mixin.py:104} INFO - [2022-03-20 12:20:32,712] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:20:32,745] {logging_mixin.py:104} INFO - [2022-03-20 12:20:32,745] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:20:32,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:21:03,354] {scheduler_job.py:182} INFO - Started process (PID=12664) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:03,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:21:03,362] {logging_mixin.py:104} INFO - [2022-03-20 12:21:03,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:03,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:03,447] {logging_mixin.py:104} INFO - [2022-03-20 12:21:03,447] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:21:03,483] {logging_mixin.py:104} INFO - [2022-03-20 12:21:03,482] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:21:03,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 12:21:33,897] {scheduler_job.py:182} INFO - Started process (PID=12695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:33,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:21:33,904] {logging_mixin.py:104} INFO - [2022-03-20 12:21:33,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:33,942] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:21:33,990] {logging_mixin.py:104} INFO - [2022-03-20 12:21:33,989] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:21:34,022] {logging_mixin.py:104} INFO - [2022-03-20 12:21:34,022] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:21:34,040] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:22:04,427] {scheduler_job.py:182} INFO - Started process (PID=12727) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:04,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:22:04,434] {logging_mixin.py:104} INFO - [2022-03-20 12:22:04,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:04,467] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:04,513] {logging_mixin.py:104} INFO - [2022-03-20 12:22:04,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:22:04,549] {logging_mixin.py:104} INFO - [2022-03-20 12:22:04,548] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:22:04,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:22:34,943] {scheduler_job.py:182} INFO - Started process (PID=12760) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:34,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:22:34,951] {logging_mixin.py:104} INFO - [2022-03-20 12:22:34,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:34,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:22:35,042] {logging_mixin.py:104} INFO - [2022-03-20 12:22:35,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:22:35,078] {logging_mixin.py:104} INFO - [2022-03-20 12:22:35,077] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:22:35,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 12:23:05,825] {scheduler_job.py:182} INFO - Started process (PID=12793) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:05,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:23:05,832] {logging_mixin.py:104} INFO - [2022-03-20 12:23:05,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:05,869] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:05,912] {logging_mixin.py:104} INFO - [2022-03-20 12:23:05,911] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:23:05,946] {logging_mixin.py:104} INFO - [2022-03-20 12:23:05,945] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:23:05,962] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 12:23:36,735] {scheduler_job.py:182} INFO - Started process (PID=12817) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:36,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:23:36,741] {logging_mixin.py:104} INFO - [2022-03-20 12:23:36,741] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:36,774] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:23:36,817] {logging_mixin.py:104} INFO - [2022-03-20 12:23:36,817] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:23:36,851] {logging_mixin.py:104} INFO - [2022-03-20 12:23:36,851] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:23:36,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:24:07,509] {scheduler_job.py:182} INFO - Started process (PID=12842) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:07,515] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:24:07,518] {logging_mixin.py:104} INFO - [2022-03-20 12:24:07,517] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:07,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:07,598] {logging_mixin.py:104} INFO - [2022-03-20 12:24:07,597] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:24:07,630] {logging_mixin.py:104} INFO - [2022-03-20 12:24:07,630] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:24:07,646] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:24:38,232] {scheduler_job.py:182} INFO - Started process (PID=12874) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:38,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:24:38,241] {logging_mixin.py:104} INFO - [2022-03-20 12:24:38,240] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:38,276] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:24:38,324] {logging_mixin.py:104} INFO - [2022-03-20 12:24:38,323] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:24:38,359] {logging_mixin.py:104} INFO - [2022-03-20 12:24:38,358] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:24:38,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 12:25:09,201] {scheduler_job.py:182} INFO - Started process (PID=12906) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:09,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:25:09,209] {logging_mixin.py:104} INFO - [2022-03-20 12:25:09,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:09,242] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:09,288] {logging_mixin.py:104} INFO - [2022-03-20 12:25:09,288] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:25:09,324] {logging_mixin.py:104} INFO - [2022-03-20 12:25:09,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:25:09,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:25:39,862] {scheduler_job.py:182} INFO - Started process (PID=12938) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:39,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:25:39,870] {logging_mixin.py:104} INFO - [2022-03-20 12:25:39,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:39,904] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:25:39,949] {logging_mixin.py:104} INFO - [2022-03-20 12:25:39,949] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:25:39,985] {logging_mixin.py:104} INFO - [2022-03-20 12:25:39,984] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:25:40,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:26:10,325] {scheduler_job.py:182} INFO - Started process (PID=12969) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:10,330] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:26:10,333] {logging_mixin.py:104} INFO - [2022-03-20 12:26:10,332] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:10,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:10,414] {logging_mixin.py:104} INFO - [2022-03-20 12:26:10,413] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:26:10,449] {logging_mixin.py:104} INFO - [2022-03-20 12:26:10,448] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:26:10,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:26:41,009] {scheduler_job.py:182} INFO - Started process (PID=13002) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:41,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:26:41,016] {logging_mixin.py:104} INFO - [2022-03-20 12:26:41,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:41,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:26:41,095] {logging_mixin.py:104} INFO - [2022-03-20 12:26:41,095] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:26:41,130] {logging_mixin.py:104} INFO - [2022-03-20 12:26:41,129] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:26:41,147] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:27:11,557] {scheduler_job.py:182} INFO - Started process (PID=13033) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:11,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:27:11,564] {logging_mixin.py:104} INFO - [2022-03-20 12:27:11,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:11,600] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:11,646] {logging_mixin.py:104} INFO - [2022-03-20 12:27:11,646] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:27:11,679] {logging_mixin.py:104} INFO - [2022-03-20 12:27:11,679] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:27:11,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:27:42,302] {scheduler_job.py:182} INFO - Started process (PID=13067) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:42,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:27:42,310] {logging_mixin.py:104} INFO - [2022-03-20 12:27:42,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:42,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:27:42,385] {logging_mixin.py:104} INFO - [2022-03-20 12:27:42,385] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:27:42,418] {logging_mixin.py:104} INFO - [2022-03-20 12:27:42,417] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:27:42,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 12:28:13,229] {scheduler_job.py:182} INFO - Started process (PID=13091) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:13,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:28:13,235] {logging_mixin.py:104} INFO - [2022-03-20 12:28:13,235] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:13,269] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:13,311] {logging_mixin.py:104} INFO - [2022-03-20 12:28:13,311] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:28:13,344] {logging_mixin.py:104} INFO - [2022-03-20 12:28:13,344] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:28:13,362] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:28:43,475] {scheduler_job.py:182} INFO - Started process (PID=13116) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:43,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:28:43,482] {logging_mixin.py:104} INFO - [2022-03-20 12:28:43,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:43,521] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:28:43,565] {logging_mixin.py:104} INFO - [2022-03-20 12:28:43,564] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:28:43,597] {logging_mixin.py:104} INFO - [2022-03-20 12:28:43,596] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:28:43,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:29:14,113] {scheduler_job.py:182} INFO - Started process (PID=13148) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:14,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:29:14,120] {logging_mixin.py:104} INFO - [2022-03-20 12:29:14,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:14,158] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:14,203] {logging_mixin.py:104} INFO - [2022-03-20 12:29:14,202] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:29:14,237] {logging_mixin.py:104} INFO - [2022-03-20 12:29:14,236] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:29:14,253] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:29:44,753] {scheduler_job.py:182} INFO - Started process (PID=13180) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:44,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:29:44,761] {logging_mixin.py:104} INFO - [2022-03-20 12:29:44,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:44,798] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:29:44,843] {logging_mixin.py:104} INFO - [2022-03-20 12:29:44,843] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:29:44,876] {logging_mixin.py:104} INFO - [2022-03-20 12:29:44,876] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:29:44,892] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:30:15,354] {scheduler_job.py:182} INFO - Started process (PID=13211) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:15,358] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:30:15,361] {logging_mixin.py:104} INFO - [2022-03-20 12:30:15,360] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:15,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:15,441] {logging_mixin.py:104} INFO - [2022-03-20 12:30:15,441] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:30:15,475] {logging_mixin.py:104} INFO - [2022-03-20 12:30:15,474] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:30:15,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:30:46,145] {scheduler_job.py:182} INFO - Started process (PID=13243) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:46,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:30:46,154] {logging_mixin.py:104} INFO - [2022-03-20 12:30:46,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:46,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:30:46,236] {logging_mixin.py:104} INFO - [2022-03-20 12:30:46,235] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:30:46,268] {logging_mixin.py:104} INFO - [2022-03-20 12:30:46,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:30:46,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:31:16,849] {scheduler_job.py:182} INFO - Started process (PID=13276) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:16,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:31:16,856] {logging_mixin.py:104} INFO - [2022-03-20 12:31:16,855] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:16,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:16,933] {logging_mixin.py:104} INFO - [2022-03-20 12:31:16,932] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:31:16,965] {logging_mixin.py:104} INFO - [2022-03-20 12:31:16,965] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:31:16,981] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 12:31:47,682] {scheduler_job.py:182} INFO - Started process (PID=13308) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:47,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:31:47,689] {logging_mixin.py:104} INFO - [2022-03-20 12:31:47,689] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:47,725] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:31:47,770] {logging_mixin.py:104} INFO - [2022-03-20 12:31:47,770] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:31:47,804] {logging_mixin.py:104} INFO - [2022-03-20 12:31:47,804] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:31:47,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:32:19,740] {scheduler_job.py:182} INFO - Started process (PID=13341) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:19,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:32:19,747] {logging_mixin.py:104} INFO - [2022-03-20 12:32:19,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:19,780] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:19,828] {logging_mixin.py:104} INFO - [2022-03-20 12:32:19,827] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:32:19,863] {logging_mixin.py:104} INFO - [2022-03-20 12:32:19,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:32:19,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:32:50,259] {scheduler_job.py:182} INFO - Started process (PID=13358) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:50,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:32:50,268] {logging_mixin.py:104} INFO - [2022-03-20 12:32:50,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:50,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:32:50,352] {logging_mixin.py:104} INFO - [2022-03-20 12:32:50,352] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:32:50,389] {logging_mixin.py:104} INFO - [2022-03-20 12:32:50,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:32:50,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 12:33:21,019] {scheduler_job.py:182} INFO - Started process (PID=13390) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:21,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:33:21,026] {logging_mixin.py:104} INFO - [2022-03-20 12:33:21,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:21,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:21,108] {logging_mixin.py:104} INFO - [2022-03-20 12:33:21,107] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:33:21,140] {logging_mixin.py:104} INFO - [2022-03-20 12:33:21,139] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:33:21,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:33:51,639] {scheduler_job.py:182} INFO - Started process (PID=13422) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:51,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:33:51,647] {logging_mixin.py:104} INFO - [2022-03-20 12:33:51,646] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:51,681] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:33:51,726] {logging_mixin.py:104} INFO - [2022-03-20 12:33:51,726] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:33:51,761] {logging_mixin.py:104} INFO - [2022-03-20 12:33:51,761] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:33:51,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:34:22,226] {scheduler_job.py:182} INFO - Started process (PID=13453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:22,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:34:22,234] {logging_mixin.py:104} INFO - [2022-03-20 12:34:22,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:22,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:22,324] {logging_mixin.py:104} INFO - [2022-03-20 12:34:22,323] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:34:22,357] {logging_mixin.py:104} INFO - [2022-03-20 12:34:22,356] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:34:22,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 12:34:52,914] {scheduler_job.py:182} INFO - Started process (PID=13485) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:52,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:34:52,921] {logging_mixin.py:104} INFO - [2022-03-20 12:34:52,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:52,958] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:34:53,003] {logging_mixin.py:104} INFO - [2022-03-20 12:34:53,003] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:34:53,038] {logging_mixin.py:104} INFO - [2022-03-20 12:34:53,038] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:34:53,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:35:23,757] {scheduler_job.py:182} INFO - Started process (PID=13517) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:23,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:35:23,762] {logging_mixin.py:104} INFO - [2022-03-20 12:35:23,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:23,799] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:23,846] {logging_mixin.py:104} INFO - [2022-03-20 12:35:23,845] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:35:23,879] {logging_mixin.py:104} INFO - [2022-03-20 12:35:23,878] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:35:23,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:35:54,418] {scheduler_job.py:182} INFO - Started process (PID=13550) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:54,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:35:54,426] {logging_mixin.py:104} INFO - [2022-03-20 12:35:54,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:54,460] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:35:54,505] {logging_mixin.py:104} INFO - [2022-03-20 12:35:54,504] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:35:54,543] {logging_mixin.py:104} INFO - [2022-03-20 12:35:54,543] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:35:54,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 12:36:25,204] {scheduler_job.py:182} INFO - Started process (PID=13583) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:25,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:36:25,211] {logging_mixin.py:104} INFO - [2022-03-20 12:36:25,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:25,247] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:25,292] {logging_mixin.py:104} INFO - [2022-03-20 12:36:25,291] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:36:25,327] {logging_mixin.py:104} INFO - [2022-03-20 12:36:25,327] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:36:25,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:36:56,210] {scheduler_job.py:182} INFO - Started process (PID=13608) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:56,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:36:56,217] {logging_mixin.py:104} INFO - [2022-03-20 12:36:56,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:56,249] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:36:56,292] {logging_mixin.py:104} INFO - [2022-03-20 12:36:56,292] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:36:56,324] {logging_mixin.py:104} INFO - [2022-03-20 12:36:56,324] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:36:56,341] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 12:37:26,577] {scheduler_job.py:182} INFO - Started process (PID=13631) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:26,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:37:26,585] {logging_mixin.py:104} INFO - [2022-03-20 12:37:26,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:26,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:26,665] {logging_mixin.py:104} INFO - [2022-03-20 12:37:26,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:37:26,698] {logging_mixin.py:104} INFO - [2022-03-20 12:37:26,697] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:37:26,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:37:57,352] {scheduler_job.py:182} INFO - Started process (PID=13664) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:57,357] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:37:57,359] {logging_mixin.py:104} INFO - [2022-03-20 12:37:57,359] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:57,396] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:37:57,440] {logging_mixin.py:104} INFO - [2022-03-20 12:37:57,439] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:37:57,473] {logging_mixin.py:104} INFO - [2022-03-20 12:37:57,473] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:37:57,488] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:38:28,101] {scheduler_job.py:182} INFO - Started process (PID=13695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:28,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:38:28,109] {logging_mixin.py:104} INFO - [2022-03-20 12:38:28,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:28,144] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:28,188] {logging_mixin.py:104} INFO - [2022-03-20 12:38:28,188] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:38:28,222] {logging_mixin.py:104} INFO - [2022-03-20 12:38:28,221] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:38:28,239] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:38:58,910] {scheduler_job.py:182} INFO - Started process (PID=13728) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:58,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:38:58,918] {logging_mixin.py:104} INFO - [2022-03-20 12:38:58,917] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:58,956] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:38:59,003] {logging_mixin.py:104} INFO - [2022-03-20 12:38:59,003] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:38:59,036] {logging_mixin.py:104} INFO - [2022-03-20 12:38:59,036] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:38:59,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 12:39:29,528] {scheduler_job.py:182} INFO - Started process (PID=13759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:39:29,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:39:29,535] {logging_mixin.py:104} INFO - [2022-03-20 12:39:29,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:39:29,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:39:29,614] {logging_mixin.py:104} INFO - [2022-03-20 12:39:29,614] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:39:29,648] {logging_mixin.py:104} INFO - [2022-03-20 12:39:29,648] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:39:29,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 12:40:00,240] {scheduler_job.py:182} INFO - Started process (PID=13792) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:00,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:40:00,246] {logging_mixin.py:104} INFO - [2022-03-20 12:40:00,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:00,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:00,327] {logging_mixin.py:104} INFO - [2022-03-20 12:40:00,326] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:40:00,360] {logging_mixin.py:104} INFO - [2022-03-20 12:40:00,360] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:40:00,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:40:30,956] {scheduler_job.py:182} INFO - Started process (PID=13824) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:30,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:40:30,963] {logging_mixin.py:104} INFO - [2022-03-20 12:40:30,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:31,000] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:40:31,045] {logging_mixin.py:104} INFO - [2022-03-20 12:40:31,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:40:31,080] {logging_mixin.py:104} INFO - [2022-03-20 12:40:31,080] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:40:31,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:41:01,983] {scheduler_job.py:182} INFO - Started process (PID=13857) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:01,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:41:01,990] {logging_mixin.py:104} INFO - [2022-03-20 12:41:01,990] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:02,025] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:02,071] {logging_mixin.py:104} INFO - [2022-03-20 12:41:02,071] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:41:02,105] {logging_mixin.py:104} INFO - [2022-03-20 12:41:02,104] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:41:02,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:41:32,696] {scheduler_job.py:182} INFO - Started process (PID=13873) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:32,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:41:32,704] {logging_mixin.py:104} INFO - [2022-03-20 12:41:32,704] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:32,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:41:32,788] {logging_mixin.py:104} INFO - [2022-03-20 12:41:32,787] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:41:32,823] {logging_mixin.py:104} INFO - [2022-03-20 12:41:32,823] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:41:32,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:42:03,783] {scheduler_job.py:182} INFO - Started process (PID=13906) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:03,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:42:03,792] {logging_mixin.py:104} INFO - [2022-03-20 12:42:03,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:03,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:03,875] {logging_mixin.py:104} INFO - [2022-03-20 12:42:03,875] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:42:03,911] {logging_mixin.py:104} INFO - [2022-03-20 12:42:03,910] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:42:03,927] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 12:42:34,604] {scheduler_job.py:182} INFO - Started process (PID=13938) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:34,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:42:34,612] {logging_mixin.py:104} INFO - [2022-03-20 12:42:34,611] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:34,646] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:42:34,693] {logging_mixin.py:104} INFO - [2022-03-20 12:42:34,692] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:42:34,728] {logging_mixin.py:104} INFO - [2022-03-20 12:42:34,728] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:42:34,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:43:05,418] {scheduler_job.py:182} INFO - Started process (PID=13969) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:05,421] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:43:05,424] {logging_mixin.py:104} INFO - [2022-03-20 12:43:05,424] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:05,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:05,511] {logging_mixin.py:104} INFO - [2022-03-20 12:43:05,510] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:43:05,544] {logging_mixin.py:104} INFO - [2022-03-20 12:43:05,543] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:43:05,559] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:43:36,324] {scheduler_job.py:182} INFO - Started process (PID=14002) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:36,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:43:36,331] {logging_mixin.py:104} INFO - [2022-03-20 12:43:36,331] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:36,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:43:36,412] {logging_mixin.py:104} INFO - [2022-03-20 12:43:36,412] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:43:36,447] {logging_mixin.py:104} INFO - [2022-03-20 12:43:36,447] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:43:36,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:44:07,181] {scheduler_job.py:182} INFO - Started process (PID=14034) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:07,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:44:07,188] {logging_mixin.py:104} INFO - [2022-03-20 12:44:07,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:07,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:07,266] {logging_mixin.py:104} INFO - [2022-03-20 12:44:07,265] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:44:07,299] {logging_mixin.py:104} INFO - [2022-03-20 12:44:07,299] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:44:07,314] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 12:44:38,002] {scheduler_job.py:182} INFO - Started process (PID=14066) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:38,007] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:44:38,010] {logging_mixin.py:104} INFO - [2022-03-20 12:44:38,010] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:38,046] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:44:38,091] {logging_mixin.py:104} INFO - [2022-03-20 12:44:38,090] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:44:38,124] {logging_mixin.py:104} INFO - [2022-03-20 12:44:38,124] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:44:38,140] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:45:08,820] {scheduler_job.py:182} INFO - Started process (PID=14098) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:08,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:45:08,827] {logging_mixin.py:104} INFO - [2022-03-20 12:45:08,827] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:08,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:08,908] {logging_mixin.py:104} INFO - [2022-03-20 12:45:08,908] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:45:08,943] {logging_mixin.py:104} INFO - [2022-03-20 12:45:08,943] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:45:08,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:45:41,813] {scheduler_job.py:182} INFO - Started process (PID=14131) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:41,818] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:45:41,820] {logging_mixin.py:104} INFO - [2022-03-20 12:45:41,820] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:41,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:45:41,899] {logging_mixin.py:104} INFO - [2022-03-20 12:45:41,898] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:45:41,935] {logging_mixin.py:104} INFO - [2022-03-20 12:45:41,934] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:45:41,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:46:12,469] {scheduler_job.py:182} INFO - Started process (PID=14148) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:12,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:46:12,478] {logging_mixin.py:104} INFO - [2022-03-20 12:46:12,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:12,515] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:12,561] {logging_mixin.py:104} INFO - [2022-03-20 12:46:12,561] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:46:12,597] {logging_mixin.py:104} INFO - [2022-03-20 12:46:12,596] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:46:12,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 12:46:43,341] {scheduler_job.py:182} INFO - Started process (PID=14180) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:43,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:46:43,352] {logging_mixin.py:104} INFO - [2022-03-20 12:46:43,351] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:43,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:46:43,432] {logging_mixin.py:104} INFO - [2022-03-20 12:46:43,431] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:46:43,467] {logging_mixin.py:104} INFO - [2022-03-20 12:46:43,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:46:43,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:47:14,188] {scheduler_job.py:182} INFO - Started process (PID=14211) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:14,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:47:14,194] {logging_mixin.py:104} INFO - [2022-03-20 12:47:14,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:14,231] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:14,277] {logging_mixin.py:104} INFO - [2022-03-20 12:47:14,277] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:47:14,313] {logging_mixin.py:104} INFO - [2022-03-20 12:47:14,313] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:47:14,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 12:47:45,000] {scheduler_job.py:182} INFO - Started process (PID=14244) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:45,003] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:47:45,006] {logging_mixin.py:104} INFO - [2022-03-20 12:47:45,005] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:45,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:47:45,084] {logging_mixin.py:104} INFO - [2022-03-20 12:47:45,084] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:47:45,118] {logging_mixin.py:104} INFO - [2022-03-20 12:47:45,118] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:47:45,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:48:15,808] {scheduler_job.py:182} INFO - Started process (PID=14275) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:15,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:48:15,816] {logging_mixin.py:104} INFO - [2022-03-20 12:48:15,815] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:15,850] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:15,910] {logging_mixin.py:104} INFO - [2022-03-20 12:48:15,909] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:48:15,941] {logging_mixin.py:104} INFO - [2022-03-20 12:48:15,941] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:48:15,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 12:48:46,606] {scheduler_job.py:182} INFO - Started process (PID=14308) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:46,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:48:46,615] {logging_mixin.py:104} INFO - [2022-03-20 12:48:46,615] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:46,650] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:48:46,697] {logging_mixin.py:104} INFO - [2022-03-20 12:48:46,696] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:48:46,730] {logging_mixin.py:104} INFO - [2022-03-20 12:48:46,729] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:48:46,746] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 12:49:17,381] {scheduler_job.py:182} INFO - Started process (PID=14340) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:17,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:49:17,388] {logging_mixin.py:104} INFO - [2022-03-20 12:49:17,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:17,426] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:17,471] {logging_mixin.py:104} INFO - [2022-03-20 12:49:17,471] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:49:17,504] {logging_mixin.py:104} INFO - [2022-03-20 12:49:17,503] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:49:17,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:49:48,113] {scheduler_job.py:182} INFO - Started process (PID=14371) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:48,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:49:48,120] {logging_mixin.py:104} INFO - [2022-03-20 12:49:48,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:48,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:49:48,198] {logging_mixin.py:104} INFO - [2022-03-20 12:49:48,198] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:49:48,232] {logging_mixin.py:104} INFO - [2022-03-20 12:49:48,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:49:48,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 12:50:21,032] {scheduler_job.py:182} INFO - Started process (PID=14405) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:21,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:50:21,038] {logging_mixin.py:104} INFO - [2022-03-20 12:50:21,038] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:21,073] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:21,117] {logging_mixin.py:104} INFO - [2022-03-20 12:50:21,117] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:50:21,147] {logging_mixin.py:104} INFO - [2022-03-20 12:50:21,146] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:50:21,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 12:50:51,702] {scheduler_job.py:182} INFO - Started process (PID=14422) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:51,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:50:51,710] {logging_mixin.py:104} INFO - [2022-03-20 12:50:51,709] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:51,750] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:50:51,797] {logging_mixin.py:104} INFO - [2022-03-20 12:50:51,796] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:50:51,831] {logging_mixin.py:104} INFO - [2022-03-20 12:50:51,831] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:50:51,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:51:22,563] {scheduler_job.py:182} INFO - Started process (PID=14453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:22,569] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:51:22,571] {logging_mixin.py:104} INFO - [2022-03-20 12:51:22,571] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:22,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:22,653] {logging_mixin.py:104} INFO - [2022-03-20 12:51:22,653] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:51:22,686] {logging_mixin.py:104} INFO - [2022-03-20 12:51:22,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:51:22,702] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:51:53,385] {scheduler_job.py:182} INFO - Started process (PID=14485) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:53,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:51:53,392] {logging_mixin.py:104} INFO - [2022-03-20 12:51:53,392] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:53,428] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:51:53,473] {logging_mixin.py:104} INFO - [2022-03-20 12:51:53,472] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:51:53,506] {logging_mixin.py:104} INFO - [2022-03-20 12:51:53,506] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:51:53,522] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:52:24,314] {scheduler_job.py:182} INFO - Started process (PID=14517) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:24,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:52:24,320] {logging_mixin.py:104} INFO - [2022-03-20 12:52:24,320] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:24,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:24,404] {logging_mixin.py:104} INFO - [2022-03-20 12:52:24,404] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:52:24,437] {logging_mixin.py:104} INFO - [2022-03-20 12:52:24,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:52:24,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 12:52:55,179] {scheduler_job.py:182} INFO - Started process (PID=14549) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:55,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:52:55,188] {logging_mixin.py:104} INFO - [2022-03-20 12:52:55,188] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:55,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:52:55,272] {logging_mixin.py:104} INFO - [2022-03-20 12:52:55,271] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:52:55,307] {logging_mixin.py:104} INFO - [2022-03-20 12:52:55,307] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:52:55,326] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 12:53:25,963] {scheduler_job.py:182} INFO - Started process (PID=14582) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:25,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:53:25,969] {logging_mixin.py:104} INFO - [2022-03-20 12:53:25,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:26,006] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:26,056] {logging_mixin.py:104} INFO - [2022-03-20 12:53:26,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:53:26,092] {logging_mixin.py:104} INFO - [2022-03-20 12:53:26,091] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:53:26,108] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:53:56,990] {scheduler_job.py:182} INFO - Started process (PID=14614) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:56,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:53:56,996] {logging_mixin.py:104} INFO - [2022-03-20 12:53:56,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:57,033] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:53:57,082] {logging_mixin.py:104} INFO - [2022-03-20 12:53:57,081] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:53:57,117] {logging_mixin.py:104} INFO - [2022-03-20 12:53:57,117] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:53:57,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:54:27,967] {scheduler_job.py:182} INFO - Started process (PID=14645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:54:27,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:54:27,992] {logging_mixin.py:104} INFO - [2022-03-20 12:54:27,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:54:28,026] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:54:28,078] {logging_mixin.py:104} INFO - [2022-03-20 12:54:28,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:54:28,113] {logging_mixin.py:104} INFO - [2022-03-20 12:54:28,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:54:28,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 12:55:00,995] {scheduler_job.py:182} INFO - Started process (PID=14679) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:00,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:55:01,002] {logging_mixin.py:104} INFO - [2022-03-20 12:55:01,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:01,036] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:01,079] {logging_mixin.py:104} INFO - [2022-03-20 12:55:01,079] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:55:01,111] {logging_mixin.py:104} INFO - [2022-03-20 12:55:01,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:55:01,127] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 12:55:31,754] {scheduler_job.py:182} INFO - Started process (PID=14695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:31,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:55:31,760] {logging_mixin.py:104} INFO - [2022-03-20 12:55:31,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:31,796] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:55:31,842] {logging_mixin.py:104} INFO - [2022-03-20 12:55:31,842] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:55:31,876] {logging_mixin.py:104} INFO - [2022-03-20 12:55:31,876] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:55:31,892] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 12:56:02,878] {scheduler_job.py:182} INFO - Started process (PID=14727) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:02,885] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:56:02,888] {logging_mixin.py:104} INFO - [2022-03-20 12:56:02,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:02,924] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:02,972] {logging_mixin.py:104} INFO - [2022-03-20 12:56:02,972] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:56:03,005] {logging_mixin.py:104} INFO - [2022-03-20 12:56:03,005] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:56:03,022] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 12:56:33,185] {scheduler_job.py:182} INFO - Started process (PID=14759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:33,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:56:33,193] {logging_mixin.py:104} INFO - [2022-03-20 12:56:33,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:33,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:56:33,275] {logging_mixin.py:104} INFO - [2022-03-20 12:56:33,274] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:56:33,309] {logging_mixin.py:104} INFO - [2022-03-20 12:56:33,309] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:56:33,326] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:57:04,061] {scheduler_job.py:182} INFO - Started process (PID=14791) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:04,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:57:04,068] {logging_mixin.py:104} INFO - [2022-03-20 12:57:04,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:04,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:04,156] {logging_mixin.py:104} INFO - [2022-03-20 12:57:04,156] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:57:04,192] {logging_mixin.py:104} INFO - [2022-03-20 12:57:04,192] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:57:04,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 12:57:34,876] {scheduler_job.py:182} INFO - Started process (PID=14823) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:34,881] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:57:34,884] {logging_mixin.py:104} INFO - [2022-03-20 12:57:34,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:34,920] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:57:34,970] {logging_mixin.py:104} INFO - [2022-03-20 12:57:34,969] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:57:35,004] {logging_mixin.py:104} INFO - [2022-03-20 12:57:35,003] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:57:35,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 12:58:05,630] {scheduler_job.py:182} INFO - Started process (PID=14856) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:05,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:58:05,638] {logging_mixin.py:104} INFO - [2022-03-20 12:58:05,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:05,673] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:05,719] {logging_mixin.py:104} INFO - [2022-03-20 12:58:05,719] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:58:05,752] {logging_mixin.py:104} INFO - [2022-03-20 12:58:05,752] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:58:05,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 12:58:36,717] {scheduler_job.py:182} INFO - Started process (PID=14887) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:36,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:58:36,724] {logging_mixin.py:104} INFO - [2022-03-20 12:58:36,724] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:36,763] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:58:36,809] {logging_mixin.py:104} INFO - [2022-03-20 12:58:36,808] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:58:36,842] {logging_mixin.py:104} INFO - [2022-03-20 12:58:36,841] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:58:36,857] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 12:59:07,532] {scheduler_job.py:182} INFO - Started process (PID=14920) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:07,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:59:07,539] {logging_mixin.py:104} INFO - [2022-03-20 12:59:07,539] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:07,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:07,623] {logging_mixin.py:104} INFO - [2022-03-20 12:59:07,622] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:59:07,659] {logging_mixin.py:104} INFO - [2022-03-20 12:59:07,658] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:59:07,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 12:59:40,454] {scheduler_job.py:182} INFO - Started process (PID=14953) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:40,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 12:59:40,460] {logging_mixin.py:104} INFO - [2022-03-20 12:59:40,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:40,496] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 12:59:40,541] {logging_mixin.py:104} INFO - [2022-03-20 12:59:40,541] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 12:59:40,575] {logging_mixin.py:104} INFO - [2022-03-20 12:59:40,574] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 12:59:40,593] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 13:00:11,001] {scheduler_job.py:182} INFO - Started process (PID=14969) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:11,007] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:00:11,010] {logging_mixin.py:104} INFO - [2022-03-20 13:00:11,010] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:11,047] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:11,091] {logging_mixin.py:104} INFO - [2022-03-20 13:00:11,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:00:11,125] {logging_mixin.py:104} INFO - [2022-03-20 13:00:11,125] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:00:11,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 13:00:41,740] {scheduler_job.py:182} INFO - Started process (PID=15002) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:41,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:00:41,748] {logging_mixin.py:104} INFO - [2022-03-20 13:00:41,747] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:41,783] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:00:41,829] {logging_mixin.py:104} INFO - [2022-03-20 13:00:41,828] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:00:41,862] {logging_mixin.py:104} INFO - [2022-03-20 13:00:41,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:00:41,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 13:01:12,537] {scheduler_job.py:182} INFO - Started process (PID=15033) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:12,542] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:01:12,544] {logging_mixin.py:104} INFO - [2022-03-20 13:01:12,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:12,581] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:12,626] {logging_mixin.py:104} INFO - [2022-03-20 13:01:12,625] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:01:12,662] {logging_mixin.py:104} INFO - [2022-03-20 13:01:12,662] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:01:12,680] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 13:01:43,723] {scheduler_job.py:182} INFO - Started process (PID=15066) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:43,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:01:43,730] {logging_mixin.py:104} INFO - [2022-03-20 13:01:43,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:43,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:01:43,815] {logging_mixin.py:104} INFO - [2022-03-20 13:01:43,814] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:01:43,847] {logging_mixin.py:104} INFO - [2022-03-20 13:01:43,846] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:01:43,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 13:02:14,566] {scheduler_job.py:182} INFO - Started process (PID=15098) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:14,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:02:14,577] {logging_mixin.py:104} INFO - [2022-03-20 13:02:14,576] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:14,613] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:14,659] {logging_mixin.py:104} INFO - [2022-03-20 13:02:14,658] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:02:14,693] {logging_mixin.py:104} INFO - [2022-03-20 13:02:14,693] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:02:14,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 13:02:45,358] {scheduler_job.py:182} INFO - Started process (PID=15129) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:45,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:02:45,365] {logging_mixin.py:104} INFO - [2022-03-20 13:02:45,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:45,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:02:45,446] {logging_mixin.py:104} INFO - [2022-03-20 13:02:45,446] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:02:45,479] {logging_mixin.py:104} INFO - [2022-03-20 13:02:45,479] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:02:45,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 13:03:16,290] {scheduler_job.py:182} INFO - Started process (PID=15162) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:16,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:03:16,298] {logging_mixin.py:104} INFO - [2022-03-20 13:03:16,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:16,336] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:16,387] {logging_mixin.py:104} INFO - [2022-03-20 13:03:16,387] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:03:16,425] {logging_mixin.py:104} INFO - [2022-03-20 13:03:16,425] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:03:16,443] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 13:03:46,943] {scheduler_job.py:182} INFO - Started process (PID=15194) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:46,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:03:46,949] {logging_mixin.py:104} INFO - [2022-03-20 13:03:46,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:46,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:03:47,028] {logging_mixin.py:104} INFO - [2022-03-20 13:03:47,028] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:03:47,062] {logging_mixin.py:104} INFO - [2022-03-20 13:03:47,061] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:03:47,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 13:04:19,822] {scheduler_job.py:182} INFO - Started process (PID=15227) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:19,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:04:19,829] {logging_mixin.py:104} INFO - [2022-03-20 13:04:19,828] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:19,863] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:19,907] {logging_mixin.py:104} INFO - [2022-03-20 13:04:19,907] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:04:19,940] {logging_mixin.py:104} INFO - [2022-03-20 13:04:19,940] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:04:19,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 13:04:50,222] {scheduler_job.py:182} INFO - Started process (PID=15244) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:50,227] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:04:50,231] {logging_mixin.py:104} INFO - [2022-03-20 13:04:50,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:50,267] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:04:50,311] {logging_mixin.py:104} INFO - [2022-03-20 13:04:50,311] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:04:50,347] {logging_mixin.py:104} INFO - [2022-03-20 13:04:50,347] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:04:50,363] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 13:05:20,824] {scheduler_job.py:182} INFO - Started process (PID=15276) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:20,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:05:20,832] {logging_mixin.py:104} INFO - [2022-03-20 13:05:20,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:20,868] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:20,917] {logging_mixin.py:104} INFO - [2022-03-20 13:05:20,917] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:05:20,951] {logging_mixin.py:104} INFO - [2022-03-20 13:05:20,950] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:05:20,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 13:05:51,450] {scheduler_job.py:182} INFO - Started process (PID=15308) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:51,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:05:51,458] {logging_mixin.py:104} INFO - [2022-03-20 13:05:51,458] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:51,496] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:05:51,543] {logging_mixin.py:104} INFO - [2022-03-20 13:05:51,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:05:51,575] {logging_mixin.py:104} INFO - [2022-03-20 13:05:51,575] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:05:51,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 13:06:22,071] {scheduler_job.py:182} INFO - Started process (PID=15340) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:22,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:06:22,079] {logging_mixin.py:104} INFO - [2022-03-20 13:06:22,079] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:22,113] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:22,158] {logging_mixin.py:104} INFO - [2022-03-20 13:06:22,158] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:06:22,192] {logging_mixin.py:104} INFO - [2022-03-20 13:06:22,191] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:06:22,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 13:06:52,822] {scheduler_job.py:182} INFO - Started process (PID=15371) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:52,825] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:06:52,828] {logging_mixin.py:104} INFO - [2022-03-20 13:06:52,828] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:52,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:06:52,907] {logging_mixin.py:104} INFO - [2022-03-20 13:06:52,906] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:06:52,940] {logging_mixin.py:104} INFO - [2022-03-20 13:06:52,940] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:06:52,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 13:07:23,684] {scheduler_job.py:182} INFO - Started process (PID=15404) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:23,689] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:07:23,692] {logging_mixin.py:104} INFO - [2022-03-20 13:07:23,692] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:23,727] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:23,771] {logging_mixin.py:104} INFO - [2022-03-20 13:07:23,771] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:07:23,804] {logging_mixin.py:104} INFO - [2022-03-20 13:07:23,804] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:07:23,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 13:07:54,481] {scheduler_job.py:182} INFO - Started process (PID=15436) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:54,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:07:54,488] {logging_mixin.py:104} INFO - [2022-03-20 13:07:54,488] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:54,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:07:54,569] {logging_mixin.py:104} INFO - [2022-03-20 13:07:54,568] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:07:54,602] {logging_mixin.py:104} INFO - [2022-03-20 13:07:54,602] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:07:54,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 13:08:25,400] {scheduler_job.py:182} INFO - Started process (PID=15467) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:25,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:08:25,408] {logging_mixin.py:104} INFO - [2022-03-20 13:08:25,408] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:25,442] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:25,490] {logging_mixin.py:104} INFO - [2022-03-20 13:08:25,489] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:08:25,525] {logging_mixin.py:104} INFO - [2022-03-20 13:08:25,524] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:08:25,541] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 13:08:58,247] {scheduler_job.py:182} INFO - Started process (PID=15501) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:58,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:08:58,254] {logging_mixin.py:104} INFO - [2022-03-20 13:08:58,254] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:58,290] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:08:58,335] {logging_mixin.py:104} INFO - [2022-03-20 13:08:58,335] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:08:58,370] {logging_mixin.py:104} INFO - [2022-03-20 13:08:58,370] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:08:58,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 13:09:28,700] {scheduler_job.py:182} INFO - Started process (PID=15518) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:28,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:09:28,708] {logging_mixin.py:104} INFO - [2022-03-20 13:09:28,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:28,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:28,786] {logging_mixin.py:104} INFO - [2022-03-20 13:09:28,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:09:28,819] {logging_mixin.py:104} INFO - [2022-03-20 13:09:28,819] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:09:28,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 13:09:59,446] {scheduler_job.py:182} INFO - Started process (PID=15549) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:59,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:09:59,453] {logging_mixin.py:104} INFO - [2022-03-20 13:09:59,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:59,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:09:59,534] {logging_mixin.py:104} INFO - [2022-03-20 13:09:59,533] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:09:59,567] {logging_mixin.py:104} INFO - [2022-03-20 13:09:59,566] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:09:59,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 13:10:30,056] {scheduler_job.py:182} INFO - Started process (PID=15581) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:10:30,059] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:10:30,062] {logging_mixin.py:104} INFO - [2022-03-20 13:10:30,061] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:10:30,096] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:10:30,141] {logging_mixin.py:104} INFO - [2022-03-20 13:10:30,140] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:10:30,173] {logging_mixin.py:104} INFO - [2022-03-20 13:10:30,173] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:10:30,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.139 seconds
[2022-03-20 13:11:00,630] {scheduler_job.py:182} INFO - Started process (PID=15614) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:00,633] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:11:00,637] {logging_mixin.py:104} INFO - [2022-03-20 13:11:00,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:00,672] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:00,718] {logging_mixin.py:104} INFO - [2022-03-20 13:11:00,718] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:11:00,753] {logging_mixin.py:104} INFO - [2022-03-20 13:11:00,752] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:11:00,768] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 13:11:31,197] {scheduler_job.py:182} INFO - Started process (PID=15645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:31,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:11:31,206] {logging_mixin.py:104} INFO - [2022-03-20 13:11:31,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:31,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:11:31,290] {logging_mixin.py:104} INFO - [2022-03-20 13:11:31,289] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:11:31,323] {logging_mixin.py:104} INFO - [2022-03-20 13:11:31,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:11:31,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 13:14:43,989] {scheduler_job.py:182} INFO - Started process (PID=15685) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:14:44,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:14:44,008] {logging_mixin.py:104} INFO - [2022-03-20 13:14:44,008] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:14:44,084] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:14:44,196] {logging_mixin.py:104} INFO - [2022-03-20 13:14:44,195] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:14:44,260] {logging_mixin.py:104} INFO - [2022-03-20 13:14:44,260] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:14:44,290] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.315 seconds
[2022-03-20 13:15:14,605] {scheduler_job.py:182} INFO - Started process (PID=15713) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:14,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:15:14,613] {logging_mixin.py:104} INFO - [2022-03-20 13:15:14,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:14,662] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:14,732] {logging_mixin.py:104} INFO - [2022-03-20 13:15:14,731] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:15:14,808] {logging_mixin.py:104} INFO - [2022-03-20 13:15:14,807] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:15:14,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.233 seconds
[2022-03-20 13:15:45,077] {scheduler_job.py:182} INFO - Started process (PID=15742) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:45,082] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:15:45,085] {logging_mixin.py:104} INFO - [2022-03-20 13:15:45,085] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:45,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:15:45,174] {logging_mixin.py:104} INFO - [2022-03-20 13:15:45,174] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:15:45,209] {logging_mixin.py:104} INFO - [2022-03-20 13:15:45,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:15:45,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 13:17:05,103] {scheduler_job.py:182} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:05,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:17:05,110] {logging_mixin.py:104} INFO - [2022-03-20 13:17:05,110] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:05,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:05,229] {logging_mixin.py:104} INFO - [2022-03-20 13:17:05,229] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:17:05,281] {logging_mixin.py:104} INFO - [2022-03-20 13:17:05,280] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:17:05,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.204 seconds
[2022-03-20 13:17:40,150] {scheduler_job.py:182} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:40,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:17:40,157] {logging_mixin.py:104} INFO - [2022-03-20 13:17:40,157] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:40,216] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:17:40,265] {logging_mixin.py:104} INFO - [2022-03-20 13:17:40,264] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:17:40,316] {logging_mixin.py:104} INFO - [2022-03-20 13:17:40,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:17:40,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.195 seconds
[2022-03-20 13:18:15,265] {scheduler_job.py:182} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:15,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:18:15,272] {logging_mixin.py:104} INFO - [2022-03-20 13:18:15,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:15,329] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:15,376] {logging_mixin.py:104} INFO - [2022-03-20 13:18:15,376] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:18:15,428] {logging_mixin.py:104} INFO - [2022-03-20 13:18:15,428] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:18:15,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-20 13:18:51,319] {scheduler_job.py:182} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:51,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:18:51,329] {logging_mixin.py:104} INFO - [2022-03-20 13:18:51,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:51,428] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:18:51,481] {logging_mixin.py:104} INFO - [2022-03-20 13:18:51,480] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:18:51,535] {logging_mixin.py:104} INFO - [2022-03-20 13:18:51,535] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:18:51,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.253 seconds
[2022-03-20 13:19:26,101] {scheduler_job.py:182} INFO - Started process (PID=357) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:19:26,105] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:19:26,107] {logging_mixin.py:104} INFO - [2022-03-20 13:19:26,107] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:19:26,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:19:26,206] {logging_mixin.py:104} INFO - [2022-03-20 13:19:26,205] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:19:26,258] {logging_mixin.py:104} INFO - [2022-03-20 13:19:26,258] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:19:26,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 13:20:01,125] {scheduler_job.py:182} INFO - Started process (PID=389) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:01,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:20:01,132] {logging_mixin.py:104} INFO - [2022-03-20 13:20:01,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:01,263] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:01,335] {logging_mixin.py:104} INFO - [2022-03-20 13:20:01,335] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:20:01,385] {logging_mixin.py:104} INFO - [2022-03-20 13:20:01,384] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:20:01,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.286 seconds
[2022-03-20 13:20:04,107] {scheduler_job.py:182} INFO - Started process (PID=409) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:04,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:20:04,113] {logging_mixin.py:104} INFO - [2022-03-20 13:20:04,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:04,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:04,223] {logging_mixin.py:104} INFO - [2022-03-20 13:20:04,223] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:20:04,265] {logging_mixin.py:104} INFO - [2022-03-20 13:20:04,265] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:20:04,285] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 13:20:35,891] {scheduler_job.py:182} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:35,895] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:20:35,898] {logging_mixin.py:104} INFO - [2022-03-20 13:20:35,898] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:35,950] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:20:36,001] {logging_mixin.py:104} INFO - [2022-03-20 13:20:36,001] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:20:36,043] {logging_mixin.py:104} INFO - [2022-03-20 13:20:36,042] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:20:36,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 13:21:10,614] {scheduler_job.py:182} INFO - Started process (PID=465) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:10,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:21:10,621] {logging_mixin.py:104} INFO - [2022-03-20 13:21:10,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:10,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:10,725] {logging_mixin.py:104} INFO - [2022-03-20 13:21:10,724] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:21:10,771] {logging_mixin.py:104} INFO - [2022-03-20 13:21:10,770] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:21:10,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 13:21:45,384] {scheduler_job.py:182} INFO - Started process (PID=497) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:45,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:21:45,390] {logging_mixin.py:104} INFO - [2022-03-20 13:21:45,390] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:45,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:21:45,485] {logging_mixin.py:104} INFO - [2022-03-20 13:21:45,485] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:21:45,539] {logging_mixin.py:104} INFO - [2022-03-20 13:21:45,538] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:21:45,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 13:22:19,550] {scheduler_job.py:182} INFO - Started process (PID=529) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:19,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:22:19,557] {logging_mixin.py:104} INFO - [2022-03-20 13:22:19,556] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:19,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:19,650] {logging_mixin.py:104} INFO - [2022-03-20 13:22:19,649] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:22:19,692] {logging_mixin.py:104} INFO - [2022-03-20 13:22:19,691] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:22:19,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 13:22:49,965] {scheduler_job.py:182} INFO - Started process (PID=549) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:49,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:22:49,971] {logging_mixin.py:104} INFO - [2022-03-20 13:22:49,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:50,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:22:50,071] {logging_mixin.py:104} INFO - [2022-03-20 13:22:50,070] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:22:50,114] {logging_mixin.py:104} INFO - [2022-03-20 13:22:50,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:22:50,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:23:20,560] {scheduler_job.py:182} INFO - Started process (PID=581) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:20,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:23:20,566] {logging_mixin.py:104} INFO - [2022-03-20 13:23:20,566] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:20,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:20,657] {logging_mixin.py:104} INFO - [2022-03-20 13:23:20,657] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:23:20,696] {logging_mixin.py:104} INFO - [2022-03-20 13:23:20,696] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:23:20,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 13:23:51,151] {scheduler_job.py:182} INFO - Started process (PID=613) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:51,155] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:23:51,158] {logging_mixin.py:104} INFO - [2022-03-20 13:23:51,157] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:51,211] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:23:51,255] {logging_mixin.py:104} INFO - [2022-03-20 13:23:51,254] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:23:51,295] {logging_mixin.py:104} INFO - [2022-03-20 13:23:51,294] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:23:51,312] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:24:21,609] {scheduler_job.py:182} INFO - Started process (PID=645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:21,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:24:21,617] {logging_mixin.py:104} INFO - [2022-03-20 13:24:21,617] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:21,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:21,713] {logging_mixin.py:104} INFO - [2022-03-20 13:24:21,712] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:24:21,754] {logging_mixin.py:104} INFO - [2022-03-20 13:24:21,754] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:24:21,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 13:24:52,186] {scheduler_job.py:182} INFO - Started process (PID=677) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:52,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:24:52,194] {logging_mixin.py:104} INFO - [2022-03-20 13:24:52,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:52,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:24:52,291] {logging_mixin.py:104} INFO - [2022-03-20 13:24:52,290] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:24:52,335] {logging_mixin.py:104} INFO - [2022-03-20 13:24:52,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:24:52,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 13:25:22,787] {scheduler_job.py:182} INFO - Started process (PID=709) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:22,792] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:25:22,796] {logging_mixin.py:104} INFO - [2022-03-20 13:25:22,796] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:22,850] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:22,895] {logging_mixin.py:104} INFO - [2022-03-20 13:25:22,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:25:22,939] {logging_mixin.py:104} INFO - [2022-03-20 13:25:22,938] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:25:22,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 13:25:53,416] {scheduler_job.py:182} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:53,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:25:53,423] {logging_mixin.py:104} INFO - [2022-03-20 13:25:53,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:53,472] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:25:53,516] {logging_mixin.py:104} INFO - [2022-03-20 13:25:53,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:25:53,556] {logging_mixin.py:104} INFO - [2022-03-20 13:25:53,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:25:53,572] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 13:26:23,843] {scheduler_job.py:182} INFO - Started process (PID=773) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:23,848] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:26:23,851] {logging_mixin.py:104} INFO - [2022-03-20 13:26:23,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:23,899] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:23,945] {logging_mixin.py:104} INFO - [2022-03-20 13:26:23,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:26:23,988] {logging_mixin.py:104} INFO - [2022-03-20 13:26:23,987] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:26:24,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 13:26:56,578] {scheduler_job.py:182} INFO - Started process (PID=803) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:56,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:26:56,584] {logging_mixin.py:104} INFO - [2022-03-20 13:26:56,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:56,633] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:26:56,678] {logging_mixin.py:104} INFO - [2022-03-20 13:26:56,678] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:26:56,722] {logging_mixin.py:104} INFO - [2022-03-20 13:26:56,722] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:26:56,741] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 13:27:27,455] {scheduler_job.py:182} INFO - Started process (PID=823) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:27,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:27:27,463] {logging_mixin.py:104} INFO - [2022-03-20 13:27:27,462] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:27,515] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:27,560] {logging_mixin.py:104} INFO - [2022-03-20 13:27:27,560] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:27:27,601] {logging_mixin.py:104} INFO - [2022-03-20 13:27:27,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:27:27,618] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 13:27:58,511] {scheduler_job.py:182} INFO - Started process (PID=855) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:58,515] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:27:58,518] {logging_mixin.py:104} INFO - [2022-03-20 13:27:58,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:58,572] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:27:58,618] {logging_mixin.py:104} INFO - [2022-03-20 13:27:58,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:27:58,661] {logging_mixin.py:104} INFO - [2022-03-20 13:27:58,660] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:27:58,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 13:28:29,308] {scheduler_job.py:182} INFO - Started process (PID=887) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:28:29,314] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:28:29,317] {logging_mixin.py:104} INFO - [2022-03-20 13:28:29,316] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:28:29,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:28:29,415] {logging_mixin.py:104} INFO - [2022-03-20 13:28:29,415] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:28:29,456] {logging_mixin.py:104} INFO - [2022-03-20 13:28:29,456] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:28:29,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 13:29:00,071] {scheduler_job.py:182} INFO - Started process (PID=919) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:00,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:29:00,079] {logging_mixin.py:104} INFO - [2022-03-20 13:29:00,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:00,131] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:00,177] {logging_mixin.py:104} INFO - [2022-03-20 13:29:00,176] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:29:00,219] {logging_mixin.py:104} INFO - [2022-03-20 13:29:00,218] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:29:00,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:29:30,792] {scheduler_job.py:182} INFO - Started process (PID=951) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:30,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:29:30,800] {logging_mixin.py:104} INFO - [2022-03-20 13:29:30,800] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:30,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:29:30,896] {logging_mixin.py:104} INFO - [2022-03-20 13:29:30,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:29:30,939] {logging_mixin.py:104} INFO - [2022-03-20 13:29:30,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:29:30,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 13:30:01,507] {scheduler_job.py:182} INFO - Started process (PID=983) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:01,511] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:30:01,514] {logging_mixin.py:104} INFO - [2022-03-20 13:30:01,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:01,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:01,612] {logging_mixin.py:104} INFO - [2022-03-20 13:30:01,612] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:30:01,652] {logging_mixin.py:104} INFO - [2022-03-20 13:30:01,651] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:30:01,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 13:30:32,556] {scheduler_job.py:182} INFO - Started process (PID=1015) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:32,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:30:32,565] {logging_mixin.py:104} INFO - [2022-03-20 13:30:32,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:32,613] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:30:32,659] {logging_mixin.py:104} INFO - [2022-03-20 13:30:32,658] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:30:32,700] {logging_mixin.py:104} INFO - [2022-03-20 13:30:32,699] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:30:32,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 13:31:03,170] {scheduler_job.py:182} INFO - Started process (PID=1047) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:03,174] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:31:03,177] {logging_mixin.py:104} INFO - [2022-03-20 13:31:03,177] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:03,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:03,278] {logging_mixin.py:104} INFO - [2022-03-20 13:31:03,278] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:31:03,319] {logging_mixin.py:104} INFO - [2022-03-20 13:31:03,319] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:31:03,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:31:33,665] {scheduler_job.py:182} INFO - Started process (PID=1077) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:33,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:31:33,673] {logging_mixin.py:104} INFO - [2022-03-20 13:31:33,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:33,726] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:31:33,778] {logging_mixin.py:104} INFO - [2022-03-20 13:31:33,777] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:31:33,823] {logging_mixin.py:104} INFO - [2022-03-20 13:31:33,823] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:31:33,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 13:32:04,494] {scheduler_job.py:182} INFO - Started process (PID=1097) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:04,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:32:04,500] {logging_mixin.py:104} INFO - [2022-03-20 13:32:04,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:04,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:04,601] {logging_mixin.py:104} INFO - [2022-03-20 13:32:04,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:32:04,643] {logging_mixin.py:104} INFO - [2022-03-20 13:32:04,642] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:32:04,660] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 13:32:35,410] {scheduler_job.py:182} INFO - Started process (PID=1129) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:35,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:32:35,418] {logging_mixin.py:104} INFO - [2022-03-20 13:32:35,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:35,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:32:35,514] {logging_mixin.py:104} INFO - [2022-03-20 13:32:35,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:32:35,556] {logging_mixin.py:104} INFO - [2022-03-20 13:32:35,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:32:35,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 13:33:05,961] {scheduler_job.py:182} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:05,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:33:05,968] {logging_mixin.py:104} INFO - [2022-03-20 13:33:05,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:06,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:06,060] {logging_mixin.py:104} INFO - [2022-03-20 13:33:06,060] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:33:06,099] {logging_mixin.py:104} INFO - [2022-03-20 13:33:06,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:33:06,115] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 13:33:36,340] {scheduler_job.py:182} INFO - Started process (PID=1193) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:36,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:33:36,346] {logging_mixin.py:104} INFO - [2022-03-20 13:33:36,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:36,395] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:33:36,437] {logging_mixin.py:104} INFO - [2022-03-20 13:33:36,436] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:33:36,477] {logging_mixin.py:104} INFO - [2022-03-20 13:33:36,477] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:33:36,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 13:34:07,019] {scheduler_job.py:182} INFO - Started process (PID=1225) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:07,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:34:07,026] {logging_mixin.py:104} INFO - [2022-03-20 13:34:07,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:07,077] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:07,118] {logging_mixin.py:104} INFO - [2022-03-20 13:34:07,118] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:34:07,158] {logging_mixin.py:104} INFO - [2022-03-20 13:34:07,158] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:34:07,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 13:34:37,686] {scheduler_job.py:182} INFO - Started process (PID=1257) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:37,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:34:37,693] {logging_mixin.py:104} INFO - [2022-03-20 13:34:37,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:37,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:34:37,785] {logging_mixin.py:104} INFO - [2022-03-20 13:34:37,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:34:37,827] {logging_mixin.py:104} INFO - [2022-03-20 13:34:37,827] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:34:37,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:35:08,405] {scheduler_job.py:182} INFO - Started process (PID=1289) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:08,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:35:08,412] {logging_mixin.py:104} INFO - [2022-03-20 13:35:08,412] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:08,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:08,506] {logging_mixin.py:104} INFO - [2022-03-20 13:35:08,506] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:35:08,546] {logging_mixin.py:104} INFO - [2022-03-20 13:35:08,546] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:35:08,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:35:38,859] {scheduler_job.py:182} INFO - Started process (PID=1321) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:38,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:35:38,866] {logging_mixin.py:104} INFO - [2022-03-20 13:35:38,865] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:38,915] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:35:38,959] {logging_mixin.py:104} INFO - [2022-03-20 13:35:38,959] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:35:39,001] {logging_mixin.py:104} INFO - [2022-03-20 13:35:39,000] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:35:39,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 13:36:10,414] {scheduler_job.py:182} INFO - Started process (PID=1351) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:10,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:36:10,420] {logging_mixin.py:104} INFO - [2022-03-20 13:36:10,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:10,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:10,514] {logging_mixin.py:104} INFO - [2022-03-20 13:36:10,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:36:10,555] {logging_mixin.py:104} INFO - [2022-03-20 13:36:10,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:36:10,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 13:36:41,254] {scheduler_job.py:182} INFO - Started process (PID=1371) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:41,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:36:41,260] {logging_mixin.py:104} INFO - [2022-03-20 13:36:41,260] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:41,310] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:36:41,355] {logging_mixin.py:104} INFO - [2022-03-20 13:36:41,354] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:36:41,396] {logging_mixin.py:104} INFO - [2022-03-20 13:36:41,396] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:36:41,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:37:12,320] {scheduler_job.py:182} INFO - Started process (PID=1403) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:12,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:37:12,328] {logging_mixin.py:104} INFO - [2022-03-20 13:37:12,328] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:12,381] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:12,426] {logging_mixin.py:104} INFO - [2022-03-20 13:37:12,426] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:37:12,467] {logging_mixin.py:104} INFO - [2022-03-20 13:37:12,466] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:37:12,485] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:37:43,051] {scheduler_job.py:182} INFO - Started process (PID=1435) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:43,056] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:37:43,059] {logging_mixin.py:104} INFO - [2022-03-20 13:37:43,058] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:43,106] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:37:43,148] {logging_mixin.py:104} INFO - [2022-03-20 13:37:43,148] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:37:43,191] {logging_mixin.py:104} INFO - [2022-03-20 13:37:43,190] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:37:43,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 13:38:13,727] {scheduler_job.py:182} INFO - Started process (PID=1467) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:13,732] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:38:13,735] {logging_mixin.py:104} INFO - [2022-03-20 13:38:13,735] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:13,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:13,836] {logging_mixin.py:104} INFO - [2022-03-20 13:38:13,835] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:38:13,878] {logging_mixin.py:104} INFO - [2022-03-20 13:38:13,878] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:38:13,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 13:38:44,446] {scheduler_job.py:182} INFO - Started process (PID=1499) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:44,451] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:38:44,453] {logging_mixin.py:104} INFO - [2022-03-20 13:38:44,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:44,503] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:38:44,548] {logging_mixin.py:104} INFO - [2022-03-20 13:38:44,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:38:44,587] {logging_mixin.py:104} INFO - [2022-03-20 13:38:44,587] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:38:44,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 13:39:15,066] {scheduler_job.py:182} INFO - Started process (PID=1531) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:15,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:39:15,074] {logging_mixin.py:104} INFO - [2022-03-20 13:39:15,073] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:15,132] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:15,179] {logging_mixin.py:104} INFO - [2022-03-20 13:39:15,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:39:15,223] {logging_mixin.py:104} INFO - [2022-03-20 13:39:15,223] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:39:15,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 13:39:45,566] {scheduler_job.py:182} INFO - Started process (PID=1563) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:45,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:39:45,574] {logging_mixin.py:104} INFO - [2022-03-20 13:39:45,573] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:45,624] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:39:45,666] {logging_mixin.py:104} INFO - [2022-03-20 13:39:45,666] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:39:45,706] {logging_mixin.py:104} INFO - [2022-03-20 13:39:45,705] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:39:45,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 13:40:16,217] {scheduler_job.py:182} INFO - Started process (PID=1595) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:16,222] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:40:16,226] {logging_mixin.py:104} INFO - [2022-03-20 13:40:16,225] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:16,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:16,319] {logging_mixin.py:104} INFO - [2022-03-20 13:40:16,319] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:40:16,359] {logging_mixin.py:104} INFO - [2022-03-20 13:40:16,359] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:40:16,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 13:40:47,830] {scheduler_job.py:182} INFO - Started process (PID=1625) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:47,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:40:47,837] {logging_mixin.py:104} INFO - [2022-03-20 13:40:47,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:47,886] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:40:47,930] {logging_mixin.py:104} INFO - [2022-03-20 13:40:47,929] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:40:47,970] {logging_mixin.py:104} INFO - [2022-03-20 13:40:47,970] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:40:47,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 13:41:18,604] {scheduler_job.py:182} INFO - Started process (PID=1645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:18,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:41:18,611] {logging_mixin.py:104} INFO - [2022-03-20 13:41:18,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:18,657] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:18,701] {logging_mixin.py:104} INFO - [2022-03-20 13:41:18,701] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:41:18,743] {logging_mixin.py:104} INFO - [2022-03-20 13:41:18,742] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:41:18,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 13:41:49,551] {scheduler_job.py:182} INFO - Started process (PID=1677) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:49,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:41:49,559] {logging_mixin.py:104} INFO - [2022-03-20 13:41:49,558] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:49,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:41:49,652] {logging_mixin.py:104} INFO - [2022-03-20 13:41:49,651] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:41:49,693] {logging_mixin.py:104} INFO - [2022-03-20 13:41:49,692] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:41:49,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:42:20,362] {scheduler_job.py:182} INFO - Started process (PID=1709) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:20,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:42:20,369] {logging_mixin.py:104} INFO - [2022-03-20 13:42:20,369] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:20,418] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:20,462] {logging_mixin.py:104} INFO - [2022-03-20 13:42:20,462] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:42:20,503] {logging_mixin.py:104} INFO - [2022-03-20 13:42:20,503] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:42:20,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 13:42:50,974] {scheduler_job.py:182} INFO - Started process (PID=1741) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:50,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:42:50,982] {logging_mixin.py:104} INFO - [2022-03-20 13:42:50,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:51,034] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:42:51,076] {logging_mixin.py:104} INFO - [2022-03-20 13:42:51,076] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:42:51,117] {logging_mixin.py:104} INFO - [2022-03-20 13:42:51,117] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:42:51,133] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 13:43:21,657] {scheduler_job.py:182} INFO - Started process (PID=1773) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:21,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:43:21,667] {logging_mixin.py:104} INFO - [2022-03-20 13:43:21,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:21,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:21,764] {logging_mixin.py:104} INFO - [2022-03-20 13:43:21,763] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:43:21,805] {logging_mixin.py:104} INFO - [2022-03-20 13:43:21,804] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:43:21,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 13:43:52,281] {scheduler_job.py:182} INFO - Started process (PID=1805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:52,286] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:43:52,290] {logging_mixin.py:104} INFO - [2022-03-20 13:43:52,289] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:52,339] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:43:52,382] {logging_mixin.py:104} INFO - [2022-03-20 13:43:52,382] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:43:52,422] {logging_mixin.py:104} INFO - [2022-03-20 13:43:52,422] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:43:52,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 13:44:22,671] {scheduler_job.py:182} INFO - Started process (PID=1837) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:22,676] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:44:22,680] {logging_mixin.py:104} INFO - [2022-03-20 13:44:22,679] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:22,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:22,772] {logging_mixin.py:104} INFO - [2022-03-20 13:44:22,772] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:44:22,812] {logging_mixin.py:104} INFO - [2022-03-20 13:44:22,812] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:44:22,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:44:53,436] {scheduler_job.py:182} INFO - Started process (PID=1869) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:53,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:44:53,444] {logging_mixin.py:104} INFO - [2022-03-20 13:44:53,444] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:53,496] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:44:53,540] {logging_mixin.py:104} INFO - [2022-03-20 13:44:53,540] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:44:53,579] {logging_mixin.py:104} INFO - [2022-03-20 13:44:53,578] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:44:53,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 13:45:24,915] {scheduler_job.py:182} INFO - Started process (PID=1899) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:24,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:45:24,921] {logging_mixin.py:104} INFO - [2022-03-20 13:45:24,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:24,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:25,023] {logging_mixin.py:104} INFO - [2022-03-20 13:45:25,023] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:45:25,073] {logging_mixin.py:104} INFO - [2022-03-20 13:45:25,073] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:45:25,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 13:45:55,709] {scheduler_job.py:182} INFO - Started process (PID=1919) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:55,713] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:45:55,715] {logging_mixin.py:104} INFO - [2022-03-20 13:45:55,715] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:55,770] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:45:55,816] {logging_mixin.py:104} INFO - [2022-03-20 13:45:55,815] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:45:55,859] {logging_mixin.py:104} INFO - [2022-03-20 13:45:55,858] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:45:55,877] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:46:26,651] {scheduler_job.py:182} INFO - Started process (PID=1951) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:26,656] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:46:26,659] {logging_mixin.py:104} INFO - [2022-03-20 13:46:26,659] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:26,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:26,753] {logging_mixin.py:104} INFO - [2022-03-20 13:46:26,752] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:46:26,794] {logging_mixin.py:104} INFO - [2022-03-20 13:46:26,794] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:46:26,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 13:46:57,411] {scheduler_job.py:182} INFO - Started process (PID=1983) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:57,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:46:57,417] {logging_mixin.py:104} INFO - [2022-03-20 13:46:57,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:57,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:46:57,514] {logging_mixin.py:104} INFO - [2022-03-20 13:46:57,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:46:57,555] {logging_mixin.py:104} INFO - [2022-03-20 13:46:57,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:46:57,572] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:47:28,249] {scheduler_job.py:182} INFO - Started process (PID=2015) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:28,253] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:47:28,255] {logging_mixin.py:104} INFO - [2022-03-20 13:47:28,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:28,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:28,349] {logging_mixin.py:104} INFO - [2022-03-20 13:47:28,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:47:28,390] {logging_mixin.py:104} INFO - [2022-03-20 13:47:28,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:47:28,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 13:47:59,008] {scheduler_job.py:182} INFO - Started process (PID=2047) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:59,012] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:47:59,015] {logging_mixin.py:104} INFO - [2022-03-20 13:47:59,014] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:59,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:47:59,111] {logging_mixin.py:104} INFO - [2022-03-20 13:47:59,110] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:47:59,155] {logging_mixin.py:104} INFO - [2022-03-20 13:47:59,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:47:59,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:48:29,620] {scheduler_job.py:182} INFO - Started process (PID=2079) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:48:29,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:48:29,627] {logging_mixin.py:104} INFO - [2022-03-20 13:48:29,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:48:29,677] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:48:29,722] {logging_mixin.py:104} INFO - [2022-03-20 13:48:29,721] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:48:29,766] {logging_mixin.py:104} INFO - [2022-03-20 13:48:29,766] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:48:29,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 13:49:00,219] {scheduler_job.py:182} INFO - Started process (PID=2111) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:00,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:49:00,226] {logging_mixin.py:104} INFO - [2022-03-20 13:49:00,226] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:00,274] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:00,318] {logging_mixin.py:104} INFO - [2022-03-20 13:49:00,317] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:49:00,362] {logging_mixin.py:104} INFO - [2022-03-20 13:49:00,362] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:49:00,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:49:30,977] {scheduler_job.py:182} INFO - Started process (PID=2143) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:30,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:49:30,984] {logging_mixin.py:104} INFO - [2022-03-20 13:49:30,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:31,034] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:49:31,078] {logging_mixin.py:104} INFO - [2022-03-20 13:49:31,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:49:31,119] {logging_mixin.py:104} INFO - [2022-03-20 13:49:31,118] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:49:31,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 13:50:02,552] {scheduler_job.py:182} INFO - Started process (PID=2173) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:50:02,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:50:02,558] {logging_mixin.py:104} INFO - [2022-03-20 13:50:02,558] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:50:02,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:50:02,655] {logging_mixin.py:104} INFO - [2022-03-20 13:50:02,654] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:50:02,698] {logging_mixin.py:104} INFO - [2022-03-20 13:50:02,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:50:02,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 13:52:59,462] {scheduler_job.py:182} INFO - Started process (PID=2207) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:52:59,468] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:52:59,472] {logging_mixin.py:104} INFO - [2022-03-20 13:52:59,471] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:52:59,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:52:59,624] {logging_mixin.py:104} INFO - [2022-03-20 13:52:59,623] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:52:59,708] {logging_mixin.py:104} INFO - [2022-03-20 13:52:59,708] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:52:59,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.279 seconds
[2022-03-20 13:53:33,524] {scheduler_job.py:182} INFO - Started process (PID=2237) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:53:33,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:53:33,530] {logging_mixin.py:104} INFO - [2022-03-20 13:53:33,530] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:53:33,582] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:53:33,628] {logging_mixin.py:104} INFO - [2022-03-20 13:53:33,628] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:53:33,673] {logging_mixin.py:104} INFO - [2022-03-20 13:53:33,672] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:53:33,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 13:54:08,369] {scheduler_job.py:182} INFO - Started process (PID=2269) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:08,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:54:08,376] {logging_mixin.py:104} INFO - [2022-03-20 13:54:08,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:08,426] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:08,472] {logging_mixin.py:104} INFO - [2022-03-20 13:54:08,471] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:54:08,520] {logging_mixin.py:104} INFO - [2022-03-20 13:54:08,519] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:54:08,543] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 13:54:42,431] {scheduler_job.py:182} INFO - Started process (PID=2301) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:42,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:54:42,438] {logging_mixin.py:104} INFO - [2022-03-20 13:54:42,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:42,484] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:54:42,530] {logging_mixin.py:104} INFO - [2022-03-20 13:54:42,529] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:54:42,571] {logging_mixin.py:104} INFO - [2022-03-20 13:54:42,571] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:54:42,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 13:55:13,011] {scheduler_job.py:182} INFO - Started process (PID=2321) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:13,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:55:13,018] {logging_mixin.py:104} INFO - [2022-03-20 13:55:13,018] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:13,067] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:13,113] {logging_mixin.py:104} INFO - [2022-03-20 13:55:13,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:55:13,155] {logging_mixin.py:104} INFO - [2022-03-20 13:55:13,154] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:55:13,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 13:55:43,411] {scheduler_job.py:182} INFO - Started process (PID=2353) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:43,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:55:43,419] {logging_mixin.py:104} INFO - [2022-03-20 13:55:43,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:43,473] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:55:43,528] {logging_mixin.py:104} INFO - [2022-03-20 13:55:43,527] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:55:43,581] {logging_mixin.py:104} INFO - [2022-03-20 13:55:43,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:55:43,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.198 seconds
[2022-03-20 13:56:13,755] {scheduler_job.py:182} INFO - Started process (PID=2385) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:13,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:56:13,762] {logging_mixin.py:104} INFO - [2022-03-20 13:56:13,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:13,809] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:13,849] {logging_mixin.py:104} INFO - [2022-03-20 13:56:13,849] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:56:13,887] {logging_mixin.py:104} INFO - [2022-03-20 13:56:13,887] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:56:13,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 13:56:44,794] {scheduler_job.py:182} INFO - Started process (PID=2417) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:44,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:56:44,803] {logging_mixin.py:104} INFO - [2022-03-20 13:56:44,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:44,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:56:44,895] {logging_mixin.py:104} INFO - [2022-03-20 13:56:44,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:56:44,935] {logging_mixin.py:104} INFO - [2022-03-20 13:56:44,935] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:56:44,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:57:15,486] {scheduler_job.py:182} INFO - Started process (PID=2449) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:15,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:57:15,493] {logging_mixin.py:104} INFO - [2022-03-20 13:57:15,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:15,554] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:15,602] {logging_mixin.py:104} INFO - [2022-03-20 13:57:15,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:57:15,643] {logging_mixin.py:104} INFO - [2022-03-20 13:57:15,643] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:57:15,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 13:57:46,089] {scheduler_job.py:182} INFO - Started process (PID=2481) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:46,095] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:57:46,099] {logging_mixin.py:104} INFO - [2022-03-20 13:57:46,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:46,149] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:57:46,194] {logging_mixin.py:104} INFO - [2022-03-20 13:57:46,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:57:46,232] {logging_mixin.py:104} INFO - [2022-03-20 13:57:46,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:57:46,250] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 13:58:17,257] {scheduler_job.py:182} INFO - Started process (PID=2513) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:17,262] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:58:17,265] {logging_mixin.py:104} INFO - [2022-03-20 13:58:17,265] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:17,315] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:17,361] {logging_mixin.py:104} INFO - [2022-03-20 13:58:17,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:58:17,405] {logging_mixin.py:104} INFO - [2022-03-20 13:58:17,405] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:58:17,423] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 13:58:23,412] {scheduler_job.py:182} INFO - Started process (PID=2525) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:23,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:58:23,420] {logging_mixin.py:104} INFO - [2022-03-20 13:58:23,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:23,474] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:23,535] {logging_mixin.py:104} INFO - [2022-03-20 13:58:23,534] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:58:23,578] {logging_mixin.py:104} INFO - [2022-03-20 13:58:23,578] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-20 13:58:23,599] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-20 13:58:54,070] {scheduler_job.py:182} INFO - Started process (PID=2557) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:54,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:58:54,079] {logging_mixin.py:104} INFO - [2022-03-20 13:58:54,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:54,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:58:54,178] {logging_mixin.py:104} INFO - [2022-03-20 13:58:54,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:58:54,204] {logging_mixin.py:104} INFO - [2022-03-20 13:58:54,204] {dag.py:1837} INFO - Creating ORM DAG for sparkoperator_demo
[2022-03-20 13:58:54,219] {logging_mixin.py:104} INFO - [2022-03-20 13:58:54,219] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 13:58:54,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 13:59:24,944] {scheduler_job.py:182} INFO - Started process (PID=2589) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:24,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:59:24,951] {logging_mixin.py:104} INFO - [2022-03-20 13:59:24,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:24,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:25,041] {logging_mixin.py:104} INFO - [2022-03-20 13:59:25,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:59:25,079] {logging_mixin.py:104} INFO - [2022-03-20 13:59:25,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 13:59:25,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 13:59:55,625] {scheduler_job.py:182} INFO - Started process (PID=2620) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:55,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 13:59:55,633] {logging_mixin.py:104} INFO - [2022-03-20 13:59:55,632] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:55,682] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 13:59:55,727] {logging_mixin.py:104} INFO - [2022-03-20 13:59:55,727] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 13:59:55,768] {logging_mixin.py:104} INFO - [2022-03-20 13:59:55,767] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 13:59:55,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 14:00:29,528] {scheduler_job.py:182} INFO - Started process (PID=2651) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:00:29,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:00:29,535] {logging_mixin.py:104} INFO - [2022-03-20 14:00:29,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:00:29,583] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:00:29,629] {logging_mixin.py:104} INFO - [2022-03-20 14:00:29,628] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:00:29,671] {logging_mixin.py:104} INFO - [2022-03-20 14:00:29,671] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:00:29,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 14:01:00,199] {scheduler_job.py:182} INFO - Started process (PID=2671) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:00,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:01:00,207] {logging_mixin.py:104} INFO - [2022-03-20 14:01:00,206] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:00,258] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:00,303] {logging_mixin.py:104} INFO - [2022-03-20 14:01:00,302] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:01:00,345] {logging_mixin.py:104} INFO - [2022-03-20 14:01:00,345] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:01:00,363] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:01:30,890] {scheduler_job.py:182} INFO - Started process (PID=2703) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:30,895] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:01:30,898] {logging_mixin.py:104} INFO - [2022-03-20 14:01:30,898] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:30,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:01:30,990] {logging_mixin.py:104} INFO - [2022-03-20 14:01:30,990] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:01:31,030] {logging_mixin.py:104} INFO - [2022-03-20 14:01:31,029] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:01:31,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 14:02:01,370] {scheduler_job.py:182} INFO - Started process (PID=2735) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:01,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:02:01,376] {logging_mixin.py:104} INFO - [2022-03-20 14:02:01,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:01,422] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:01,463] {logging_mixin.py:104} INFO - [2022-03-20 14:02:01,463] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:02:01,501] {logging_mixin.py:104} INFO - [2022-03-20 14:02:01,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:02:01,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 14:02:32,092] {scheduler_job.py:182} INFO - Started process (PID=2767) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:32,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:02:32,100] {logging_mixin.py:104} INFO - [2022-03-20 14:02:32,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:32,147] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:02:32,188] {logging_mixin.py:104} INFO - [2022-03-20 14:02:32,187] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:02:32,225] {logging_mixin.py:104} INFO - [2022-03-20 14:02:32,225] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:02:32,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 14:03:02,858] {scheduler_job.py:182} INFO - Started process (PID=2799) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:02,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:03:02,867] {logging_mixin.py:104} INFO - [2022-03-20 14:03:02,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:02,916] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:02,956] {logging_mixin.py:104} INFO - [2022-03-20 14:03:02,956] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:03:02,994] {logging_mixin.py:104} INFO - [2022-03-20 14:03:02,993] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:03:03,010] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:03:33,865] {scheduler_job.py:182} INFO - Started process (PID=2831) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:33,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:03:33,875] {logging_mixin.py:104} INFO - [2022-03-20 14:03:33,874] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:33,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:03:33,969] {logging_mixin.py:104} INFO - [2022-03-20 14:03:33,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:03:34,009] {logging_mixin.py:104} INFO - [2022-03-20 14:03:34,008] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:03:34,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 14:04:04,582] {scheduler_job.py:182} INFO - Started process (PID=2863) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:04,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:04:04,590] {logging_mixin.py:104} INFO - [2022-03-20 14:04:04,589] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:04,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:04,676] {logging_mixin.py:104} INFO - [2022-03-20 14:04:04,676] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:04:04,716] {logging_mixin.py:104} INFO - [2022-03-20 14:04:04,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:04:04,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 14:04:35,340] {scheduler_job.py:182} INFO - Started process (PID=2895) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:35,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:04:35,349] {logging_mixin.py:104} INFO - [2022-03-20 14:04:35,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:35,407] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:04:35,454] {logging_mixin.py:104} INFO - [2022-03-20 14:04:35,454] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:04:35,499] {logging_mixin.py:104} INFO - [2022-03-20 14:04:35,499] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:04:35,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-20 14:05:07,196] {scheduler_job.py:182} INFO - Started process (PID=2925) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:07,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:05:07,203] {logging_mixin.py:104} INFO - [2022-03-20 14:05:07,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:07,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:07,298] {logging_mixin.py:104} INFO - [2022-03-20 14:05:07,297] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:05:07,339] {logging_mixin.py:104} INFO - [2022-03-20 14:05:07,338] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:05:07,356] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:05:37,964] {scheduler_job.py:182} INFO - Started process (PID=2945) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:37,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:05:37,972] {logging_mixin.py:104} INFO - [2022-03-20 14:05:37,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:38,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:05:38,066] {logging_mixin.py:104} INFO - [2022-03-20 14:05:38,066] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:05:38,109] {logging_mixin.py:104} INFO - [2022-03-20 14:05:38,108] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:05:38,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 14:06:08,585] {scheduler_job.py:182} INFO - Started process (PID=2977) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:08,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:06:08,592] {logging_mixin.py:104} INFO - [2022-03-20 14:06:08,592] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:08,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:08,680] {logging_mixin.py:104} INFO - [2022-03-20 14:06:08,680] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:06:08,719] {logging_mixin.py:104} INFO - [2022-03-20 14:06:08,718] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:06:08,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 14:06:39,379] {scheduler_job.py:182} INFO - Started process (PID=3009) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:39,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:06:39,390] {logging_mixin.py:104} INFO - [2022-03-20 14:06:39,390] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:39,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:06:39,487] {logging_mixin.py:104} INFO - [2022-03-20 14:06:39,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:06:39,527] {logging_mixin.py:104} INFO - [2022-03-20 14:06:39,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:06:39,543] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:07:10,309] {scheduler_job.py:182} INFO - Started process (PID=3041) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:10,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:07:10,316] {logging_mixin.py:104} INFO - [2022-03-20 14:07:10,316] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:10,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:10,408] {logging_mixin.py:104} INFO - [2022-03-20 14:07:10,407] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:07:10,446] {logging_mixin.py:104} INFO - [2022-03-20 14:07:10,445] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:07:10,462] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 14:07:40,825] {scheduler_job.py:182} INFO - Started process (PID=3073) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:40,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:07:40,833] {logging_mixin.py:104} INFO - [2022-03-20 14:07:40,833] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:40,877] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:07:40,917] {logging_mixin.py:104} INFO - [2022-03-20 14:07:40,916] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:07:40,956] {logging_mixin.py:104} INFO - [2022-03-20 14:07:40,956] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:07:40,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 14:08:11,686] {scheduler_job.py:182} INFO - Started process (PID=3105) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:11,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:08:11,696] {logging_mixin.py:104} INFO - [2022-03-20 14:08:11,695] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:11,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:11,794] {logging_mixin.py:104} INFO - [2022-03-20 14:08:11,793] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:08:11,831] {logging_mixin.py:104} INFO - [2022-03-20 14:08:11,831] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:08:11,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:08:42,428] {scheduler_job.py:182} INFO - Started process (PID=3137) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:42,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:08:42,435] {logging_mixin.py:104} INFO - [2022-03-20 14:08:42,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:42,494] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:08:42,544] {logging_mixin.py:104} INFO - [2022-03-20 14:08:42,544] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:08:42,589] {logging_mixin.py:104} INFO - [2022-03-20 14:08:42,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:08:42,607] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-20 14:09:13,105] {scheduler_job.py:182} INFO - Started process (PID=3169) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:13,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:09:13,115] {logging_mixin.py:104} INFO - [2022-03-20 14:09:13,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:13,164] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:13,205] {logging_mixin.py:104} INFO - [2022-03-20 14:09:13,204] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:09:13,244] {logging_mixin.py:104} INFO - [2022-03-20 14:09:13,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:09:13,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 14:09:46,066] {scheduler_job.py:182} INFO - Started process (PID=3201) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:46,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:09:46,072] {logging_mixin.py:104} INFO - [2022-03-20 14:09:46,072] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:46,119] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:09:46,160] {logging_mixin.py:104} INFO - [2022-03-20 14:09:46,159] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:09:46,198] {logging_mixin.py:104} INFO - [2022-03-20 14:09:46,197] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:09:46,213] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 14:10:20,956] {scheduler_job.py:182} INFO - Started process (PID=3227) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:20,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:10:20,962] {logging_mixin.py:104} INFO - [2022-03-20 14:10:20,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:21,009] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:21,052] {logging_mixin.py:104} INFO - [2022-03-20 14:10:21,052] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:10:21,095] {logging_mixin.py:104} INFO - [2022-03-20 14:10:21,095] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:10:21,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 14:10:56,355] {scheduler_job.py:182} INFO - Started process (PID=3259) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:56,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:10:56,361] {logging_mixin.py:104} INFO - [2022-03-20 14:10:56,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:56,414] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:10:56,461] {logging_mixin.py:104} INFO - [2022-03-20 14:10:56,461] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:10:56,502] {logging_mixin.py:104} INFO - [2022-03-20 14:10:56,502] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:10:56,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 14:13:37,617] {scheduler_job.py:182} INFO - Started process (PID=228) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:13:37,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:13:37,624] {logging_mixin.py:104} INFO - [2022-03-20 14:13:37,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:13:37,700] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:13:37,752] {logging_mixin.py:104} INFO - [2022-03-20 14:13:37,752] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:13:37,802] {logging_mixin.py:104} INFO - [2022-03-20 14:13:37,801] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:13:37,823] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.213 seconds
[2022-03-20 14:14:08,241] {scheduler_job.py:182} INFO - Started process (PID=247) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:08,244] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:14:08,247] {logging_mixin.py:104} INFO - [2022-03-20 14:14:08,247] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:08,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:08,355] {logging_mixin.py:104} INFO - [2022-03-20 14:14:08,354] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:14:08,402] {logging_mixin.py:104} INFO - [2022-03-20 14:14:08,402] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:14:08,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 14:14:39,153] {scheduler_job.py:182} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:39,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:14:39,160] {logging_mixin.py:104} INFO - [2022-03-20 14:14:39,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:39,215] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:14:39,267] {logging_mixin.py:104} INFO - [2022-03-20 14:14:39,266] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:14:39,319] {logging_mixin.py:104} INFO - [2022-03-20 14:14:39,318] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:14:39,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 14:15:09,811] {scheduler_job.py:182} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:09,819] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:15:09,824] {logging_mixin.py:104} INFO - [2022-03-20 14:15:09,823] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:09,950] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:10,003] {logging_mixin.py:104} INFO - [2022-03-20 14:15:10,002] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:15:10,067] {logging_mixin.py:104} INFO - [2022-03-20 14:15:10,067] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:15:10,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.296 seconds
[2022-03-20 14:15:40,879] {scheduler_job.py:182} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:40,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:15:40,888] {logging_mixin.py:104} INFO - [2022-03-20 14:15:40,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:40,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:15:41,060] {logging_mixin.py:104} INFO - [2022-03-20 14:15:41,059] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:15:41,112] {logging_mixin.py:104} INFO - [2022-03-20 14:15:41,112] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:15:41,142] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.276 seconds
[2022-03-20 14:16:12,087] {scheduler_job.py:182} INFO - Started process (PID=375) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:12,092] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:16:12,095] {logging_mixin.py:104} INFO - [2022-03-20 14:16:12,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:12,151] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:12,196] {logging_mixin.py:104} INFO - [2022-03-20 14:16:12,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:16:12,241] {logging_mixin.py:104} INFO - [2022-03-20 14:16:12,240] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:16:12,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 14:16:42,842] {scheduler_job.py:182} INFO - Started process (PID=407) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:42,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:16:42,856] {logging_mixin.py:104} INFO - [2022-03-20 14:16:42,856] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:42,909] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:16:42,959] {logging_mixin.py:104} INFO - [2022-03-20 14:16:42,959] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:16:43,008] {logging_mixin.py:104} INFO - [2022-03-20 14:16:43,007] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:16:43,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 14:17:16,649] {scheduler_job.py:182} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:16,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:17:16,656] {logging_mixin.py:104} INFO - [2022-03-20 14:17:16,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:16,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:16,747] {logging_mixin.py:104} INFO - [2022-03-20 14:17:16,746] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:17:16,787] {logging_mixin.py:104} INFO - [2022-03-20 14:17:16,787] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:17:16,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:17:47,952] {scheduler_job.py:182} INFO - Started process (PID=470) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:47,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:17:47,959] {logging_mixin.py:104} INFO - [2022-03-20 14:17:47,959] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:48,009] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:17:48,057] {logging_mixin.py:104} INFO - [2022-03-20 14:17:48,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:17:48,101] {logging_mixin.py:104} INFO - [2022-03-20 14:17:48,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:17:48,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:18:18,615] {scheduler_job.py:182} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:18,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:18:18,621] {logging_mixin.py:104} INFO - [2022-03-20 14:18:18,621] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:18,676] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:18,727] {logging_mixin.py:104} INFO - [2022-03-20 14:18:18,727] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:18:18,775] {logging_mixin.py:104} INFO - [2022-03-20 14:18:18,775] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:18:18,795] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 14:18:49,397] {scheduler_job.py:182} INFO - Started process (PID=530) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:49,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:18:49,404] {logging_mixin.py:104} INFO - [2022-03-20 14:18:49,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:49,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:18:49,508] {logging_mixin.py:104} INFO - [2022-03-20 14:18:49,508] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:18:49,554] {logging_mixin.py:104} INFO - [2022-03-20 14:18:49,554] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:18:49,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 14:19:20,225] {scheduler_job.py:182} INFO - Started process (PID=563) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:20,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:19:20,233] {logging_mixin.py:104} INFO - [2022-03-20 14:19:20,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:20,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:20,330] {logging_mixin.py:104} INFO - [2022-03-20 14:19:20,330] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:19:20,374] {logging_mixin.py:104} INFO - [2022-03-20 14:19:20,374] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:19:20,392] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 14:19:50,974] {scheduler_job.py:182} INFO - Started process (PID=596) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:50,978] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:19:50,980] {logging_mixin.py:104} INFO - [2022-03-20 14:19:50,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:51,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:19:51,077] {logging_mixin.py:104} INFO - [2022-03-20 14:19:51,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:19:51,119] {logging_mixin.py:104} INFO - [2022-03-20 14:19:51,119] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:19:51,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:20:21,372] {scheduler_job.py:182} INFO - Started process (PID=623) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:21,375] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:20:21,377] {logging_mixin.py:104} INFO - [2022-03-20 14:20:21,377] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:21,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:21,467] {logging_mixin.py:104} INFO - [2022-03-20 14:20:21,467] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:20:21,512] {logging_mixin.py:104} INFO - [2022-03-20 14:20:21,511] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:20:21,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:20:51,698] {scheduler_job.py:182} INFO - Started process (PID=651) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:51,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:20:51,705] {logging_mixin.py:104} INFO - [2022-03-20 14:20:51,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:51,757] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:20:51,806] {logging_mixin.py:104} INFO - [2022-03-20 14:20:51,806] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:20:51,849] {logging_mixin.py:104} INFO - [2022-03-20 14:20:51,849] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:20:51,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:21:22,012] {scheduler_job.py:182} INFO - Started process (PID=684) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:22,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:21:22,019] {logging_mixin.py:104} INFO - [2022-03-20 14:21:22,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:22,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:22,116] {logging_mixin.py:104} INFO - [2022-03-20 14:21:22,116] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:21:22,159] {logging_mixin.py:104} INFO - [2022-03-20 14:21:22,158] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:21:22,178] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:21:52,864] {scheduler_job.py:182} INFO - Started process (PID=716) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:52,868] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:21:52,874] {logging_mixin.py:104} INFO - [2022-03-20 14:21:52,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:52,927] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:21:52,973] {logging_mixin.py:104} INFO - [2022-03-20 14:21:52,973] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:21:53,015] {logging_mixin.py:104} INFO - [2022-03-20 14:21:53,015] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:21:53,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 14:22:23,584] {scheduler_job.py:182} INFO - Started process (PID=749) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:23,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:22:23,592] {logging_mixin.py:104} INFO - [2022-03-20 14:22:23,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:23,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:23,690] {logging_mixin.py:104} INFO - [2022-03-20 14:22:23,689] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:22:23,735] {logging_mixin.py:104} INFO - [2022-03-20 14:22:23,735] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:22:23,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:22:53,897] {scheduler_job.py:182} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:53,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:22:53,903] {logging_mixin.py:104} INFO - [2022-03-20 14:22:53,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:53,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:22:53,992] {logging_mixin.py:104} INFO - [2022-03-20 14:22:53,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:22:54,031] {logging_mixin.py:104} INFO - [2022-03-20 14:22:54,030] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:22:54,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 14:23:24,129] {scheduler_job.py:182} INFO - Started process (PID=805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:24,133] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:23:24,135] {logging_mixin.py:104} INFO - [2022-03-20 14:23:24,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:24,184] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:24,231] {logging_mixin.py:104} INFO - [2022-03-20 14:23:24,230] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:23:24,274] {logging_mixin.py:104} INFO - [2022-03-20 14:23:24,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:23:24,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:23:54,379] {scheduler_job.py:182} INFO - Started process (PID=834) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:54,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:23:54,389] {logging_mixin.py:104} INFO - [2022-03-20 14:23:54,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:54,443] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:23:54,484] {logging_mixin.py:104} INFO - [2022-03-20 14:23:54,484] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:23:54,522] {logging_mixin.py:104} INFO - [2022-03-20 14:23:54,521] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:23:54,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 14:24:25,179] {scheduler_job.py:182} INFO - Started process (PID=870) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:25,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:24:25,185] {logging_mixin.py:104} INFO - [2022-03-20 14:24:25,185] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:25,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:25,280] {logging_mixin.py:104} INFO - [2022-03-20 14:24:25,280] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:24:25,323] {logging_mixin.py:104} INFO - [2022-03-20 14:24:25,322] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:24:25,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 14:24:55,822] {scheduler_job.py:182} INFO - Started process (PID=894) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:55,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:24:55,828] {logging_mixin.py:104} INFO - [2022-03-20 14:24:55,828] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:55,877] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:24:55,924] {logging_mixin.py:104} INFO - [2022-03-20 14:24:55,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:24:55,967] {logging_mixin.py:104} INFO - [2022-03-20 14:24:55,967] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:24:55,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:25:26,702] {scheduler_job.py:182} INFO - Started process (PID=926) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:26,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:25:26,710] {logging_mixin.py:104} INFO - [2022-03-20 14:25:26,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:26,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:26,808] {logging_mixin.py:104} INFO - [2022-03-20 14:25:26,808] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:25:26,852] {logging_mixin.py:104} INFO - [2022-03-20 14:25:26,851] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:25:26,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:25:57,530] {scheduler_job.py:182} INFO - Started process (PID=958) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:57,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:25:57,536] {logging_mixin.py:104} INFO - [2022-03-20 14:25:57,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:57,588] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:25:57,637] {logging_mixin.py:104} INFO - [2022-03-20 14:25:57,636] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:25:57,678] {logging_mixin.py:104} INFO - [2022-03-20 14:25:57,678] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:25:57,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:26:28,339] {scheduler_job.py:182} INFO - Started process (PID=990) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:28,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:26:28,346] {logging_mixin.py:104} INFO - [2022-03-20 14:26:28,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:28,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:28,447] {logging_mixin.py:104} INFO - [2022-03-20 14:26:28,447] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:26:28,490] {logging_mixin.py:104} INFO - [2022-03-20 14:26:28,490] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:26:28,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:26:58,695] {scheduler_job.py:182} INFO - Started process (PID=1022) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:58,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:26:58,702] {logging_mixin.py:104} INFO - [2022-03-20 14:26:58,702] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:58,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:26:58,801] {logging_mixin.py:104} INFO - [2022-03-20 14:26:58,801] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:26:58,846] {logging_mixin.py:104} INFO - [2022-03-20 14:26:58,846] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:26:58,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 14:27:29,407] {scheduler_job.py:182} INFO - Started process (PID=1054) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:27:29,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:27:29,417] {logging_mixin.py:104} INFO - [2022-03-20 14:27:29,416] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:27:29,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:27:29,530] {logging_mixin.py:104} INFO - [2022-03-20 14:27:29,529] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:27:29,576] {logging_mixin.py:104} INFO - [2022-03-20 14:27:29,575] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:27:29,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.195 seconds
[2022-03-20 14:27:59,949] {scheduler_job.py:182} INFO - Started process (PID=1079) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:27:59,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:27:59,955] {logging_mixin.py:104} INFO - [2022-03-20 14:27:59,954] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:28:00,005] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:28:00,053] {logging_mixin.py:104} INFO - [2022-03-20 14:28:00,052] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:28:00,097] {logging_mixin.py:104} INFO - [2022-03-20 14:28:00,096] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:28:00,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 14:28:30,763] {scheduler_job.py:182} INFO - Started process (PID=1111) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:28:30,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:28:30,770] {logging_mixin.py:104} INFO - [2022-03-20 14:28:30,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:28:30,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:28:30,867] {logging_mixin.py:104} INFO - [2022-03-20 14:28:30,867] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:28:30,912] {logging_mixin.py:104} INFO - [2022-03-20 14:28:30,912] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:28:30,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 14:29:01,564] {scheduler_job.py:182} INFO - Started process (PID=1143) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:01,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:29:01,571] {logging_mixin.py:104} INFO - [2022-03-20 14:29:01,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:01,623] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:01,670] {logging_mixin.py:104} INFO - [2022-03-20 14:29:01,669] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:29:01,711] {logging_mixin.py:104} INFO - [2022-03-20 14:29:01,710] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:29:01,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 14:29:32,202] {scheduler_job.py:182} INFO - Started process (PID=1176) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:32,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:29:32,208] {logging_mixin.py:104} INFO - [2022-03-20 14:29:32,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:32,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:29:32,301] {logging_mixin.py:104} INFO - [2022-03-20 14:29:32,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:29:32,344] {logging_mixin.py:104} INFO - [2022-03-20 14:29:32,344] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:29:32,362] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:30:02,760] {scheduler_job.py:182} INFO - Started process (PID=1199) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:02,766] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:30:02,768] {logging_mixin.py:104} INFO - [2022-03-20 14:30:02,768] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:02,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:02,872] {logging_mixin.py:104} INFO - [2022-03-20 14:30:02,871] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:30:02,914] {logging_mixin.py:104} INFO - [2022-03-20 14:30:02,913] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:30:02,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 14:30:33,687] {scheduler_job.py:182} INFO - Started process (PID=1232) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:33,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:30:33,693] {logging_mixin.py:104} INFO - [2022-03-20 14:30:33,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:33,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:30:33,787] {logging_mixin.py:104} INFO - [2022-03-20 14:30:33,786] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:30:33,830] {logging_mixin.py:104} INFO - [2022-03-20 14:30:33,829] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:30:33,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:31:04,435] {scheduler_job.py:182} INFO - Started process (PID=1264) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:04,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:31:04,441] {logging_mixin.py:104} INFO - [2022-03-20 14:31:04,441] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:04,490] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:04,536] {logging_mixin.py:104} INFO - [2022-03-20 14:31:04,535] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:31:04,580] {logging_mixin.py:104} INFO - [2022-03-20 14:31:04,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:31:04,598] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:31:35,179] {scheduler_job.py:182} INFO - Started process (PID=1296) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:35,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:31:35,186] {logging_mixin.py:104} INFO - [2022-03-20 14:31:35,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:35,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:31:35,281] {logging_mixin.py:104} INFO - [2022-03-20 14:31:35,281] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:31:35,323] {logging_mixin.py:104} INFO - [2022-03-20 14:31:35,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:31:35,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:32:06,048] {scheduler_job.py:182} INFO - Started process (PID=1328) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:06,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:32:06,056] {logging_mixin.py:104} INFO - [2022-03-20 14:32:06,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:06,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:06,156] {logging_mixin.py:104} INFO - [2022-03-20 14:32:06,155] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:32:06,199] {logging_mixin.py:104} INFO - [2022-03-20 14:32:06,198] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:32:06,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:32:36,607] {scheduler_job.py:182} INFO - Started process (PID=1361) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:36,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:32:36,614] {logging_mixin.py:104} INFO - [2022-03-20 14:32:36,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:36,666] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:32:36,710] {logging_mixin.py:104} INFO - [2022-03-20 14:32:36,710] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:32:36,753] {logging_mixin.py:104} INFO - [2022-03-20 14:32:36,753] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:32:36,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 14:33:07,487] {scheduler_job.py:182} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:07,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:33:07,494] {logging_mixin.py:104} INFO - [2022-03-20 14:33:07,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:07,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:07,587] {logging_mixin.py:104} INFO - [2022-03-20 14:33:07,587] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:33:07,628] {logging_mixin.py:104} INFO - [2022-03-20 14:33:07,627] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:33:07,646] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 14:33:38,061] {scheduler_job.py:182} INFO - Started process (PID=1417) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:38,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:33:38,069] {logging_mixin.py:104} INFO - [2022-03-20 14:33:38,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:38,119] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:33:38,166] {logging_mixin.py:104} INFO - [2022-03-20 14:33:38,165] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:33:38,208] {logging_mixin.py:104} INFO - [2022-03-20 14:33:38,207] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:33:38,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 14:34:08,990] {scheduler_job.py:182} INFO - Started process (PID=1449) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:08,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:34:08,998] {logging_mixin.py:104} INFO - [2022-03-20 14:34:08,998] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:09,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:09,097] {logging_mixin.py:104} INFO - [2022-03-20 14:34:09,097] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:34:09,139] {logging_mixin.py:104} INFO - [2022-03-20 14:34:09,139] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:34:09,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 14:34:39,746] {scheduler_job.py:182} INFO - Started process (PID=1481) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:39,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:34:39,753] {logging_mixin.py:104} INFO - [2022-03-20 14:34:39,753] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:39,802] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:34:39,848] {logging_mixin.py:104} INFO - [2022-03-20 14:34:39,847] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:34:39,891] {logging_mixin.py:104} INFO - [2022-03-20 14:34:39,891] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:34:39,907] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 14:35:10,293] {scheduler_job.py:182} INFO - Started process (PID=1514) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:10,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:35:10,299] {logging_mixin.py:104} INFO - [2022-03-20 14:35:10,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:10,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:10,392] {logging_mixin.py:104} INFO - [2022-03-20 14:35:10,392] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:35:10,434] {logging_mixin.py:104} INFO - [2022-03-20 14:35:10,433] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:35:10,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:35:40,865] {scheduler_job.py:182} INFO - Started process (PID=1538) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:40,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:35:40,872] {logging_mixin.py:104} INFO - [2022-03-20 14:35:40,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:40,921] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:35:40,969] {logging_mixin.py:104} INFO - [2022-03-20 14:35:40,969] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:35:41,013] {logging_mixin.py:104} INFO - [2022-03-20 14:35:41,012] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:35:41,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:36:11,699] {scheduler_job.py:182} INFO - Started process (PID=1570) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:11,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:36:11,705] {logging_mixin.py:104} INFO - [2022-03-20 14:36:11,704] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:11,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:11,801] {logging_mixin.py:104} INFO - [2022-03-20 14:36:11,800] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:36:11,848] {logging_mixin.py:104} INFO - [2022-03-20 14:36:11,847] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:36:11,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:36:42,503] {scheduler_job.py:182} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:42,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:36:42,510] {logging_mixin.py:104} INFO - [2022-03-20 14:36:42,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:42,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:36:42,605] {logging_mixin.py:104} INFO - [2022-03-20 14:36:42,605] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:36:42,651] {logging_mixin.py:104} INFO - [2022-03-20 14:36:42,651] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:36:42,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 14:37:13,295] {scheduler_job.py:182} INFO - Started process (PID=1634) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:13,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:37:13,303] {logging_mixin.py:104} INFO - [2022-03-20 14:37:13,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:13,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:13,400] {logging_mixin.py:104} INFO - [2022-03-20 14:37:13,399] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:37:13,445] {logging_mixin.py:104} INFO - [2022-03-20 14:37:13,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:37:13,462] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 14:37:44,108] {scheduler_job.py:182} INFO - Started process (PID=1666) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:44,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:37:44,115] {logging_mixin.py:104} INFO - [2022-03-20 14:37:44,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:44,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:37:44,212] {logging_mixin.py:104} INFO - [2022-03-20 14:37:44,211] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:37:44,258] {logging_mixin.py:104} INFO - [2022-03-20 14:37:44,258] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:37:44,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 14:38:14,804] {scheduler_job.py:182} INFO - Started process (PID=1699) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:14,808] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:38:14,810] {logging_mixin.py:104} INFO - [2022-03-20 14:38:14,810] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:14,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:14,907] {logging_mixin.py:104} INFO - [2022-03-20 14:38:14,906] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:38:14,959] {logging_mixin.py:104} INFO - [2022-03-20 14:38:14,958] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:38:14,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 14:38:45,280] {scheduler_job.py:182} INFO - Started process (PID=1723) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:45,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:38:45,288] {logging_mixin.py:104} INFO - [2022-03-20 14:38:45,287] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:45,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:38:45,391] {logging_mixin.py:104} INFO - [2022-03-20 14:38:45,390] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:38:45,435] {logging_mixin.py:104} INFO - [2022-03-20 14:38:45,434] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:38:45,452] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 14:39:15,588] {scheduler_job.py:182} INFO - Started process (PID=1755) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:15,593] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:39:15,596] {logging_mixin.py:104} INFO - [2022-03-20 14:39:15,595] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:15,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:15,696] {logging_mixin.py:104} INFO - [2022-03-20 14:39:15,696] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:39:15,738] {logging_mixin.py:104} INFO - [2022-03-20 14:39:15,738] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:39:15,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 14:39:46,506] {scheduler_job.py:182} INFO - Started process (PID=1787) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:46,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:39:46,512] {logging_mixin.py:104} INFO - [2022-03-20 14:39:46,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:46,566] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:39:46,618] {logging_mixin.py:104} INFO - [2022-03-20 14:39:46,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:39:46,673] {logging_mixin.py:104} INFO - [2022-03-20 14:39:46,672] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:39:46,694] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-20 14:40:17,552] {scheduler_job.py:182} INFO - Started process (PID=1820) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:17,557] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:40:17,559] {logging_mixin.py:104} INFO - [2022-03-20 14:40:17,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:17,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:17,654] {logging_mixin.py:104} INFO - [2022-03-20 14:40:17,653] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:40:17,699] {logging_mixin.py:104} INFO - [2022-03-20 14:40:17,699] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:40:17,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:40:48,219] {scheduler_job.py:182} INFO - Started process (PID=1843) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:48,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:40:48,227] {logging_mixin.py:104} INFO - [2022-03-20 14:40:48,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:48,283] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:40:48,334] {logging_mixin.py:104} INFO - [2022-03-20 14:40:48,333] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:40:48,378] {logging_mixin.py:104} INFO - [2022-03-20 14:40:48,378] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:40:48,395] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 14:41:19,155] {scheduler_job.py:182} INFO - Started process (PID=1876) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:19,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:41:19,163] {logging_mixin.py:104} INFO - [2022-03-20 14:41:19,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:19,211] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:19,258] {logging_mixin.py:104} INFO - [2022-03-20 14:41:19,257] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:41:19,300] {logging_mixin.py:104} INFO - [2022-03-20 14:41:19,299] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:41:19,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:41:49,928] {scheduler_job.py:182} INFO - Started process (PID=1907) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:49,933] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:41:49,936] {logging_mixin.py:104} INFO - [2022-03-20 14:41:49,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:49,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:41:50,030] {logging_mixin.py:104} INFO - [2022-03-20 14:41:50,029] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:41:50,075] {logging_mixin.py:104} INFO - [2022-03-20 14:41:50,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:41:50,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 14:42:20,677] {scheduler_job.py:182} INFO - Started process (PID=1940) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:20,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:42:20,684] {logging_mixin.py:104} INFO - [2022-03-20 14:42:20,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:20,736] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:20,784] {logging_mixin.py:104} INFO - [2022-03-20 14:42:20,783] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:42:20,827] {logging_mixin.py:104} INFO - [2022-03-20 14:42:20,826] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:42:20,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:42:51,468] {scheduler_job.py:182} INFO - Started process (PID=1971) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:51,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:42:51,475] {logging_mixin.py:104} INFO - [2022-03-20 14:42:51,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:51,526] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:42:51,571] {logging_mixin.py:104} INFO - [2022-03-20 14:42:51,571] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:42:51,615] {logging_mixin.py:104} INFO - [2022-03-20 14:42:51,614] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:42:51,632] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:43:22,133] {scheduler_job.py:182} INFO - Started process (PID=2005) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:22,137] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:43:22,139] {logging_mixin.py:104} INFO - [2022-03-20 14:43:22,139] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:22,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:22,234] {logging_mixin.py:104} INFO - [2022-03-20 14:43:22,234] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:43:22,277] {logging_mixin.py:104} INFO - [2022-03-20 14:43:22,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:43:22,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 14:43:52,740] {scheduler_job.py:182} INFO - Started process (PID=2029) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:52,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:43:52,747] {logging_mixin.py:104} INFO - [2022-03-20 14:43:52,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:52,798] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:43:52,845] {logging_mixin.py:104} INFO - [2022-03-20 14:43:52,845] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:43:52,891] {logging_mixin.py:104} INFO - [2022-03-20 14:43:52,890] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:43:52,907] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:44:23,615] {scheduler_job.py:182} INFO - Started process (PID=2061) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:23,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:44:23,622] {logging_mixin.py:104} INFO - [2022-03-20 14:44:23,622] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:23,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:23,717] {logging_mixin.py:104} INFO - [2022-03-20 14:44:23,717] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:44:23,764] {logging_mixin.py:104} INFO - [2022-03-20 14:44:23,763] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:44:23,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 14:44:54,338] {scheduler_job.py:182} INFO - Started process (PID=2093) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:54,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:44:54,343] {logging_mixin.py:104} INFO - [2022-03-20 14:44:54,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:54,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:44:54,441] {logging_mixin.py:104} INFO - [2022-03-20 14:44:54,440] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:44:54,485] {logging_mixin.py:104} INFO - [2022-03-20 14:44:54,484] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:44:54,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:45:24,553] {scheduler_job.py:182} INFO - Started process (PID=2122) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:24,557] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:45:24,559] {logging_mixin.py:104} INFO - [2022-03-20 14:45:24,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:24,612] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:24,659] {logging_mixin.py:104} INFO - [2022-03-20 14:45:24,659] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:45:24,705] {logging_mixin.py:104} INFO - [2022-03-20 14:45:24,704] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:45:24,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 14:45:55,046] {scheduler_job.py:182} INFO - Started process (PID=2152) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:55,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:45:55,052] {logging_mixin.py:104} INFO - [2022-03-20 14:45:55,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:55,103] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:45:55,147] {logging_mixin.py:104} INFO - [2022-03-20 14:45:55,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:45:55,190] {logging_mixin.py:104} INFO - [2022-03-20 14:45:55,190] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:45:55,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:46:25,554] {scheduler_job.py:182} INFO - Started process (PID=2179) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:25,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:46:25,562] {logging_mixin.py:104} INFO - [2022-03-20 14:46:25,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:25,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:25,652] {logging_mixin.py:104} INFO - [2022-03-20 14:46:25,652] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:46:25,691] {logging_mixin.py:104} INFO - [2022-03-20 14:46:25,691] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:46:25,709] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:46:56,209] {scheduler_job.py:182} INFO - Started process (PID=2211) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:56,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:46:56,216] {logging_mixin.py:104} INFO - [2022-03-20 14:46:56,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:56,262] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:46:56,304] {logging_mixin.py:104} INFO - [2022-03-20 14:46:56,304] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:46:56,341] {logging_mixin.py:104} INFO - [2022-03-20 14:46:56,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:46:56,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 14:47:26,579] {scheduler_job.py:182} INFO - Started process (PID=2243) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:26,583] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:47:26,586] {logging_mixin.py:104} INFO - [2022-03-20 14:47:26,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:26,632] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:26,677] {logging_mixin.py:104} INFO - [2022-03-20 14:47:26,676] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:47:26,719] {logging_mixin.py:104} INFO - [2022-03-20 14:47:26,718] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:47:26,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:47:57,235] {scheduler_job.py:182} INFO - Started process (PID=2275) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:57,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:47:57,242] {logging_mixin.py:104} INFO - [2022-03-20 14:47:57,242] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:57,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:47:57,343] {logging_mixin.py:104} INFO - [2022-03-20 14:47:57,342] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:47:57,386] {logging_mixin.py:104} INFO - [2022-03-20 14:47:57,385] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:47:57,403] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 14:48:27,536] {scheduler_job.py:182} INFO - Started process (PID=2305) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:27,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:48:27,543] {logging_mixin.py:104} INFO - [2022-03-20 14:48:27,542] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:27,597] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:27,643] {logging_mixin.py:104} INFO - [2022-03-20 14:48:27,643] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:48:27,685] {logging_mixin.py:104} INFO - [2022-03-20 14:48:27,685] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:48:27,703] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:48:58,168] {scheduler_job.py:182} INFO - Started process (PID=2332) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:58,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:48:58,177] {logging_mixin.py:104} INFO - [2022-03-20 14:48:58,176] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:58,236] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:48:58,285] {logging_mixin.py:104} INFO - [2022-03-20 14:48:58,284] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:48:58,324] {logging_mixin.py:104} INFO - [2022-03-20 14:48:58,324] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:48:58,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 14:49:29,036] {scheduler_job.py:182} INFO - Started process (PID=2364) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:29,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:49:29,043] {logging_mixin.py:104} INFO - [2022-03-20 14:49:29,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:29,090] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:29,132] {logging_mixin.py:104} INFO - [2022-03-20 14:49:29,131] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:49:29,170] {logging_mixin.py:104} INFO - [2022-03-20 14:49:29,169] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:49:29,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 14:49:59,670] {scheduler_job.py:182} INFO - Started process (PID=2396) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:59,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:49:59,678] {logging_mixin.py:104} INFO - [2022-03-20 14:49:59,678] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:59,725] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:49:59,766] {logging_mixin.py:104} INFO - [2022-03-20 14:49:59,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:49:59,804] {logging_mixin.py:104} INFO - [2022-03-20 14:49:59,803] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:49:59,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 14:50:30,015] {scheduler_job.py:182} INFO - Started process (PID=2426) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:50:30,019] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:50:30,021] {logging_mixin.py:104} INFO - [2022-03-20 14:50:30,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:50:30,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:50:30,115] {logging_mixin.py:104} INFO - [2022-03-20 14:50:30,114] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:50:30,156] {logging_mixin.py:104} INFO - [2022-03-20 14:50:30,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:50:30,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 14:51:00,630] {scheduler_job.py:182} INFO - Started process (PID=2453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:00,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:51:00,638] {logging_mixin.py:104} INFO - [2022-03-20 14:51:00,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:00,685] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:00,726] {logging_mixin.py:104} INFO - [2022-03-20 14:51:00,726] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:51:00,766] {logging_mixin.py:104} INFO - [2022-03-20 14:51:00,766] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:51:00,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 14:51:31,026] {scheduler_job.py:182} INFO - Started process (PID=2485) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:31,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:51:31,034] {logging_mixin.py:104} INFO - [2022-03-20 14:51:31,033] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:31,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:51:31,121] {logging_mixin.py:104} INFO - [2022-03-20 14:51:31,121] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:51:31,159] {logging_mixin.py:104} INFO - [2022-03-20 14:51:31,159] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:51:31,177] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 14:52:01,948] {scheduler_job.py:182} INFO - Started process (PID=2517) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:01,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:52:01,956] {logging_mixin.py:104} INFO - [2022-03-20 14:52:01,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:02,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:02,047] {logging_mixin.py:104} INFO - [2022-03-20 14:52:02,047] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:52:02,087] {logging_mixin.py:104} INFO - [2022-03-20 14:52:02,086] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:52:02,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 14:52:32,687] {scheduler_job.py:182} INFO - Started process (PID=2549) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:32,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:52:32,696] {logging_mixin.py:104} INFO - [2022-03-20 14:52:32,696] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:32,744] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:52:32,785] {logging_mixin.py:104} INFO - [2022-03-20 14:52:32,784] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:52:32,823] {logging_mixin.py:104} INFO - [2022-03-20 14:52:32,823] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:52:32,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 14:53:02,943] {scheduler_job.py:182} INFO - Started process (PID=2581) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:02,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:53:02,950] {logging_mixin.py:104} INFO - [2022-03-20 14:53:02,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:02,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:03,037] {logging_mixin.py:104} INFO - [2022-03-20 14:53:03,036] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:53:03,075] {logging_mixin.py:104} INFO - [2022-03-20 14:53:03,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:53:03,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 14:53:33,578] {scheduler_job.py:182} INFO - Started process (PID=2608) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:33,583] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:53:33,586] {logging_mixin.py:104} INFO - [2022-03-20 14:53:33,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:33,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:53:33,686] {logging_mixin.py:104} INFO - [2022-03-20 14:53:33,686] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:53:33,730] {logging_mixin.py:104} INFO - [2022-03-20 14:53:33,730] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:53:33,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 14:54:04,552] {scheduler_job.py:182} INFO - Started process (PID=2638) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:04,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:54:04,561] {logging_mixin.py:104} INFO - [2022-03-20 14:54:04,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:04,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:04,662] {logging_mixin.py:104} INFO - [2022-03-20 14:54:04,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:54:04,703] {logging_mixin.py:104} INFO - [2022-03-20 14:54:04,703] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:54:04,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 14:54:34,944] {scheduler_job.py:182} INFO - Started process (PID=2670) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:34,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:54:34,952] {logging_mixin.py:104} INFO - [2022-03-20 14:54:34,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:34,998] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:54:35,043] {logging_mixin.py:104} INFO - [2022-03-20 14:54:35,043] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:54:35,081] {logging_mixin.py:104} INFO - [2022-03-20 14:54:35,081] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:54:35,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 14:55:05,330] {scheduler_job.py:182} INFO - Started process (PID=2700) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:05,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:55:05,337] {logging_mixin.py:104} INFO - [2022-03-20 14:55:05,336] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:05,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:05,432] {logging_mixin.py:104} INFO - [2022-03-20 14:55:05,432] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:55:05,477] {logging_mixin.py:104} INFO - [2022-03-20 14:55:05,477] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:55:05,496] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 14:55:36,033] {scheduler_job.py:182} INFO - Started process (PID=2727) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:36,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:55:36,042] {logging_mixin.py:104} INFO - [2022-03-20 14:55:36,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:36,090] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:55:36,132] {logging_mixin.py:104} INFO - [2022-03-20 14:55:36,132] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:55:36,170] {logging_mixin.py:104} INFO - [2022-03-20 14:55:36,170] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:55:36,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 14:56:06,492] {scheduler_job.py:182} INFO - Started process (PID=2759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:06,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:56:06,502] {logging_mixin.py:104} INFO - [2022-03-20 14:56:06,501] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:06,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:06,595] {logging_mixin.py:104} INFO - [2022-03-20 14:56:06,594] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:56:06,635] {logging_mixin.py:104} INFO - [2022-03-20 14:56:06,635] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:56:06,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 14:56:36,872] {scheduler_job.py:182} INFO - Started process (PID=2791) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:36,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:56:36,880] {logging_mixin.py:104} INFO - [2022-03-20 14:56:36,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:36,930] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:56:36,975] {logging_mixin.py:104} INFO - [2022-03-20 14:56:36,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:56:37,016] {logging_mixin.py:104} INFO - [2022-03-20 14:56:37,015] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:56:37,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 14:57:07,616] {scheduler_job.py:182} INFO - Started process (PID=2823) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:07,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:57:07,625] {logging_mixin.py:104} INFO - [2022-03-20 14:57:07,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:07,672] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:07,718] {logging_mixin.py:104} INFO - [2022-03-20 14:57:07,717] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:57:07,756] {logging_mixin.py:104} INFO - [2022-03-20 14:57:07,756] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:57:07,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 14:57:38,159] {scheduler_job.py:182} INFO - Started process (PID=2853) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:38,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:57:38,166] {logging_mixin.py:104} INFO - [2022-03-20 14:57:38,166] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:38,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:57:38,265] {logging_mixin.py:104} INFO - [2022-03-20 14:57:38,264] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:57:38,307] {logging_mixin.py:104} INFO - [2022-03-20 14:57:38,307] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:57:38,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 14:58:08,788] {scheduler_job.py:182} INFO - Started process (PID=2880) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:08,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:58:08,795] {logging_mixin.py:104} INFO - [2022-03-20 14:58:08,795] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:08,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:08,885] {logging_mixin.py:104} INFO - [2022-03-20 14:58:08,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:58:08,925] {logging_mixin.py:104} INFO - [2022-03-20 14:58:08,925] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:58:08,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 14:58:39,716] {scheduler_job.py:182} INFO - Started process (PID=2912) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:39,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:58:39,722] {logging_mixin.py:104} INFO - [2022-03-20 14:58:39,722] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:39,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:58:39,810] {logging_mixin.py:104} INFO - [2022-03-20 14:58:39,809] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:58:39,847] {logging_mixin.py:104} INFO - [2022-03-20 14:58:39,847] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:58:39,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 14:59:10,519] {scheduler_job.py:182} INFO - Started process (PID=2944) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:10,523] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:59:10,526] {logging_mixin.py:104} INFO - [2022-03-20 14:59:10,526] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:10,575] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:10,617] {logging_mixin.py:104} INFO - [2022-03-20 14:59:10,616] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:59:10,654] {logging_mixin.py:104} INFO - [2022-03-20 14:59:10,653] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:59:10,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 14:59:41,226] {scheduler_job.py:182} INFO - Started process (PID=2976) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:41,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 14:59:41,233] {logging_mixin.py:104} INFO - [2022-03-20 14:59:41,232] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:41,276] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 14:59:41,318] {logging_mixin.py:104} INFO - [2022-03-20 14:59:41,317] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 14:59:41,355] {logging_mixin.py:104} INFO - [2022-03-20 14:59:41,355] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 14:59:41,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 15:00:11,856] {scheduler_job.py:182} INFO - Started process (PID=3006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:11,860] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:00:11,862] {logging_mixin.py:104} INFO - [2022-03-20 15:00:11,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:11,909] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:11,953] {logging_mixin.py:104} INFO - [2022-03-20 15:00:11,952] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:00:11,994] {logging_mixin.py:104} INFO - [2022-03-20 15:00:11,994] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:00:12,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:00:42,860] {scheduler_job.py:182} INFO - Started process (PID=3033) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:42,865] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:00:42,869] {logging_mixin.py:104} INFO - [2022-03-20 15:00:42,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:42,917] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:00:42,960] {logging_mixin.py:104} INFO - [2022-03-20 15:00:42,960] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:00:42,999] {logging_mixin.py:104} INFO - [2022-03-20 15:00:42,998] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:00:43,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:01:13,660] {scheduler_job.py:182} INFO - Started process (PID=3065) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:13,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:01:13,668] {logging_mixin.py:104} INFO - [2022-03-20 15:01:13,668] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:13,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:13,759] {logging_mixin.py:104} INFO - [2022-03-20 15:01:13,758] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:01:13,799] {logging_mixin.py:104} INFO - [2022-03-20 15:01:13,799] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:01:13,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 15:01:44,276] {scheduler_job.py:182} INFO - Started process (PID=3097) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:44,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:01:44,285] {logging_mixin.py:104} INFO - [2022-03-20 15:01:44,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:44,329] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:01:44,370] {logging_mixin.py:104} INFO - [2022-03-20 15:01:44,370] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:01:44,410] {logging_mixin.py:104} INFO - [2022-03-20 15:01:44,409] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:01:44,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 15:02:14,630] {scheduler_job.py:182} INFO - Started process (PID=3129) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:14,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:02:14,638] {logging_mixin.py:104} INFO - [2022-03-20 15:02:14,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:14,686] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:14,728] {logging_mixin.py:104} INFO - [2022-03-20 15:02:14,727] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:02:14,765] {logging_mixin.py:104} INFO - [2022-03-20 15:02:14,765] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:02:14,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 15:02:44,874] {scheduler_job.py:182} INFO - Started process (PID=3161) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:44,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:02:44,880] {logging_mixin.py:104} INFO - [2022-03-20 15:02:44,880] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:44,926] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:02:44,967] {logging_mixin.py:104} INFO - [2022-03-20 15:02:44,967] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:02:45,008] {logging_mixin.py:104} INFO - [2022-03-20 15:02:45,007] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:02:45,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 15:03:15,175] {scheduler_job.py:182} INFO - Started process (PID=3189) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:15,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:03:15,182] {logging_mixin.py:104} INFO - [2022-03-20 15:03:15,182] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:15,230] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:15,276] {logging_mixin.py:104} INFO - [2022-03-20 15:03:15,276] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:03:15,319] {logging_mixin.py:104} INFO - [2022-03-20 15:03:15,319] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:03:15,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 15:03:46,149] {scheduler_job.py:182} INFO - Started process (PID=3218) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:46,155] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:03:46,159] {logging_mixin.py:104} INFO - [2022-03-20 15:03:46,158] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:46,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:03:46,264] {logging_mixin.py:104} INFO - [2022-03-20 15:03:46,263] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:03:46,306] {logging_mixin.py:104} INFO - [2022-03-20 15:03:46,305] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:03:46,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 15:04:17,011] {scheduler_job.py:182} INFO - Started process (PID=3250) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:17,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:04:17,019] {logging_mixin.py:104} INFO - [2022-03-20 15:04:17,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:17,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:17,105] {logging_mixin.py:104} INFO - [2022-03-20 15:04:17,104] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:04:17,142] {logging_mixin.py:104} INFO - [2022-03-20 15:04:17,142] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:04:17,158] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 15:04:47,390] {scheduler_job.py:182} INFO - Started process (PID=3280) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:47,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:04:47,397] {logging_mixin.py:104} INFO - [2022-03-20 15:04:47,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:47,452] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:04:47,507] {logging_mixin.py:104} INFO - [2022-03-20 15:04:47,507] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:04:47,557] {logging_mixin.py:104} INFO - [2022-03-20 15:04:47,557] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:04:47,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.195 seconds
[2022-03-20 15:05:17,773] {scheduler_job.py:182} INFO - Started process (PID=3307) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:17,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:05:17,782] {logging_mixin.py:104} INFO - [2022-03-20 15:05:17,782] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:17,830] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:17,872] {logging_mixin.py:104} INFO - [2022-03-20 15:05:17,872] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:05:17,910] {logging_mixin.py:104} INFO - [2022-03-20 15:05:17,910] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:05:17,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:05:48,811] {scheduler_job.py:182} INFO - Started process (PID=3339) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:48,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:05:48,819] {logging_mixin.py:104} INFO - [2022-03-20 15:05:48,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:48,868] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:05:48,910] {logging_mixin.py:104} INFO - [2022-03-20 15:05:48,909] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:05:48,949] {logging_mixin.py:104} INFO - [2022-03-20 15:05:48,948] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:05:48,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:06:19,232] {scheduler_job.py:182} INFO - Started process (PID=3371) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:19,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:06:19,242] {logging_mixin.py:104} INFO - [2022-03-20 15:06:19,242] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:19,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:19,337] {logging_mixin.py:104} INFO - [2022-03-20 15:06:19,337] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:06:19,375] {logging_mixin.py:104} INFO - [2022-03-20 15:06:19,375] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:06:19,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:06:49,498] {scheduler_job.py:182} INFO - Started process (PID=3403) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:49,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:06:49,506] {logging_mixin.py:104} INFO - [2022-03-20 15:06:49,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:49,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:06:49,597] {logging_mixin.py:104} INFO - [2022-03-20 15:06:49,597] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:06:49,636] {logging_mixin.py:104} INFO - [2022-03-20 15:06:49,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:06:49,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 15:07:20,185] {scheduler_job.py:182} INFO - Started process (PID=3435) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:20,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:07:20,193] {logging_mixin.py:104} INFO - [2022-03-20 15:07:20,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:20,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:20,278] {logging_mixin.py:104} INFO - [2022-03-20 15:07:20,277] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:07:20,316] {logging_mixin.py:104} INFO - [2022-03-20 15:07:20,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:07:20,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 15:07:50,548] {scheduler_job.py:182} INFO - Started process (PID=3465) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:50,552] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:07:50,555] {logging_mixin.py:104} INFO - [2022-03-20 15:07:50,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:50,603] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:07:50,648] {logging_mixin.py:104} INFO - [2022-03-20 15:07:50,648] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:07:50,691] {logging_mixin.py:104} INFO - [2022-03-20 15:07:50,691] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:07:50,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 15:08:21,541] {scheduler_job.py:182} INFO - Started process (PID=3492) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:21,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:08:21,549] {logging_mixin.py:104} INFO - [2022-03-20 15:08:21,549] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:21,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:21,639] {logging_mixin.py:104} INFO - [2022-03-20 15:08:21,639] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:08:21,679] {logging_mixin.py:104} INFO - [2022-03-20 15:08:21,679] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:08:21,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 15:08:51,965] {scheduler_job.py:182} INFO - Started process (PID=3524) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:51,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:08:51,972] {logging_mixin.py:104} INFO - [2022-03-20 15:08:51,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:52,018] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:08:52,061] {logging_mixin.py:104} INFO - [2022-03-20 15:08:52,061] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:08:52,099] {logging_mixin.py:104} INFO - [2022-03-20 15:08:52,098] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:08:52,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 15:09:22,614] {scheduler_job.py:182} INFO - Started process (PID=3556) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:22,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:09:22,620] {logging_mixin.py:104} INFO - [2022-03-20 15:09:22,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:22,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:22,713] {logging_mixin.py:104} INFO - [2022-03-20 15:09:22,713] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:09:22,753] {logging_mixin.py:104} INFO - [2022-03-20 15:09:22,752] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:09:22,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:09:53,238] {scheduler_job.py:182} INFO - Started process (PID=3581) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:53,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:09:53,247] {logging_mixin.py:104} INFO - [2022-03-20 15:09:53,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:53,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:09:53,348] {logging_mixin.py:104} INFO - [2022-03-20 15:09:53,347] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:09:53,391] {logging_mixin.py:104} INFO - [2022-03-20 15:09:53,391] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:09:53,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 15:10:24,196] {scheduler_job.py:182} INFO - Started process (PID=3613) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:24,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:10:24,205] {logging_mixin.py:104} INFO - [2022-03-20 15:10:24,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:24,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:24,298] {logging_mixin.py:104} INFO - [2022-03-20 15:10:24,298] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:10:24,337] {logging_mixin.py:104} INFO - [2022-03-20 15:10:24,337] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:10:24,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 15:10:54,485] {scheduler_job.py:182} INFO - Started process (PID=3645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:54,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:10:54,492] {logging_mixin.py:104} INFO - [2022-03-20 15:10:54,492] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:54,540] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:10:54,583] {logging_mixin.py:104} INFO - [2022-03-20 15:10:54,583] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:10:54,622] {logging_mixin.py:104} INFO - [2022-03-20 15:10:54,621] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:10:54,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:11:24,766] {scheduler_job.py:182} INFO - Started process (PID=3677) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:24,771] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:11:24,774] {logging_mixin.py:104} INFO - [2022-03-20 15:11:24,774] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:24,820] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:24,863] {logging_mixin.py:104} INFO - [2022-03-20 15:11:24,862] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:11:24,902] {logging_mixin.py:104} INFO - [2022-03-20 15:11:24,901] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:11:24,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 15:11:55,677] {scheduler_job.py:182} INFO - Started process (PID=3709) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:55,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:11:55,685] {logging_mixin.py:104} INFO - [2022-03-20 15:11:55,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:55,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:11:55,785] {logging_mixin.py:104} INFO - [2022-03-20 15:11:55,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:11:55,825] {logging_mixin.py:104} INFO - [2022-03-20 15:11:55,825] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:11:55,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:12:25,995] {scheduler_job.py:182} INFO - Started process (PID=3741) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:25,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:12:26,001] {logging_mixin.py:104} INFO - [2022-03-20 15:12:26,000] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:26,046] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:26,086] {logging_mixin.py:104} INFO - [2022-03-20 15:12:26,086] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:12:26,127] {logging_mixin.py:104} INFO - [2022-03-20 15:12:26,126] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:12:26,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 15:12:56,340] {scheduler_job.py:182} INFO - Started process (PID=3769) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:56,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:12:56,347] {logging_mixin.py:104} INFO - [2022-03-20 15:12:56,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:56,399] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:12:56,445] {logging_mixin.py:104} INFO - [2022-03-20 15:12:56,444] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:12:56,490] {logging_mixin.py:104} INFO - [2022-03-20 15:12:56,489] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:12:56,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 15:13:27,579] {scheduler_job.py:182} INFO - Started process (PID=3798) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:27,584] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:13:27,588] {logging_mixin.py:104} INFO - [2022-03-20 15:13:27,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:27,641] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:27,686] {logging_mixin.py:104} INFO - [2022-03-20 15:13:27,686] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:13:27,729] {logging_mixin.py:104} INFO - [2022-03-20 15:13:27,728] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:13:27,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 15:13:57,818] {scheduler_job.py:182} INFO - Started process (PID=3830) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:57,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:13:57,826] {logging_mixin.py:104} INFO - [2022-03-20 15:13:57,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:57,876] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:13:57,921] {logging_mixin.py:104} INFO - [2022-03-20 15:13:57,920] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:13:57,962] {logging_mixin.py:104} INFO - [2022-03-20 15:13:57,961] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:13:57,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 15:14:28,969] {scheduler_job.py:182} INFO - Started process (PID=3866) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:28,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:14:28,975] {logging_mixin.py:104} INFO - [2022-03-20 15:14:28,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:29,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:29,070] {logging_mixin.py:104} INFO - [2022-03-20 15:14:29,069] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:14:29,111] {logging_mixin.py:104} INFO - [2022-03-20 15:14:29,110] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:14:29,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 15:14:59,666] {scheduler_job.py:182} INFO - Started process (PID=3890) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:59,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:14:59,673] {logging_mixin.py:104} INFO - [2022-03-20 15:14:59,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:59,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:14:59,773] {logging_mixin.py:104} INFO - [2022-03-20 15:14:59,772] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:14:59,816] {logging_mixin.py:104} INFO - [2022-03-20 15:14:59,816] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:14:59,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:15:30,502] {scheduler_job.py:182} INFO - Started process (PID=3921) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:15:30,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:15:30,509] {logging_mixin.py:104} INFO - [2022-03-20 15:15:30,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:15:30,561] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:15:30,606] {logging_mixin.py:104} INFO - [2022-03-20 15:15:30,606] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:15:30,649] {logging_mixin.py:104} INFO - [2022-03-20 15:15:30,648] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:15:30,667] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:16:01,306] {scheduler_job.py:182} INFO - Started process (PID=3954) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:01,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:16:01,312] {logging_mixin.py:104} INFO - [2022-03-20 15:16:01,311] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:01,363] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:01,412] {logging_mixin.py:104} INFO - [2022-03-20 15:16:01,412] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:16:01,455] {logging_mixin.py:104} INFO - [2022-03-20 15:16:01,454] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:16:01,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 15:16:32,243] {scheduler_job.py:182} INFO - Started process (PID=3986) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:32,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:16:32,250] {logging_mixin.py:104} INFO - [2022-03-20 15:16:32,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:32,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:16:32,347] {logging_mixin.py:104} INFO - [2022-03-20 15:16:32,346] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:16:32,390] {logging_mixin.py:104} INFO - [2022-03-20 15:16:32,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:16:32,406] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:17:03,042] {scheduler_job.py:182} INFO - Started process (PID=4017) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:03,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:17:03,050] {logging_mixin.py:104} INFO - [2022-03-20 15:17:03,050] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:03,100] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:03,148] {logging_mixin.py:104} INFO - [2022-03-20 15:17:03,148] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:17:03,190] {logging_mixin.py:104} INFO - [2022-03-20 15:17:03,190] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:17:03,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:17:33,657] {scheduler_job.py:182} INFO - Started process (PID=4050) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:33,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:17:33,666] {logging_mixin.py:104} INFO - [2022-03-20 15:17:33,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:33,718] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:17:33,767] {logging_mixin.py:104} INFO - [2022-03-20 15:17:33,767] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:17:33,813] {logging_mixin.py:104} INFO - [2022-03-20 15:17:33,812] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:17:33,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 15:18:04,301] {scheduler_job.py:182} INFO - Started process (PID=4082) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:04,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:18:04,308] {logging_mixin.py:104} INFO - [2022-03-20 15:18:04,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:04,357] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:04,404] {logging_mixin.py:104} INFO - [2022-03-20 15:18:04,403] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:18:04,446] {logging_mixin.py:104} INFO - [2022-03-20 15:18:04,445] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:18:04,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:18:35,057] {scheduler_job.py:182} INFO - Started process (PID=4107) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:35,066] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:18:35,070] {logging_mixin.py:104} INFO - [2022-03-20 15:18:35,069] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:35,131] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:18:35,185] {logging_mixin.py:104} INFO - [2022-03-20 15:18:35,184] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:18:35,241] {logging_mixin.py:104} INFO - [2022-03-20 15:18:35,240] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:18:35,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.220 seconds
[2022-03-20 15:19:05,766] {scheduler_job.py:182} INFO - Started process (PID=4139) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:05,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:19:05,773] {logging_mixin.py:104} INFO - [2022-03-20 15:19:05,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:05,822] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:05,869] {logging_mixin.py:104} INFO - [2022-03-20 15:19:05,869] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:19:05,914] {logging_mixin.py:104} INFO - [2022-03-20 15:19:05,914] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:19:05,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:19:36,439] {scheduler_job.py:182} INFO - Started process (PID=4172) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:36,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:19:36,447] {logging_mixin.py:104} INFO - [2022-03-20 15:19:36,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:36,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:19:36,548] {logging_mixin.py:104} INFO - [2022-03-20 15:19:36,547] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:19:36,593] {logging_mixin.py:104} INFO - [2022-03-20 15:19:36,592] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:19:36,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 15:20:06,847] {scheduler_job.py:182} INFO - Started process (PID=4199) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:06,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:20:06,853] {logging_mixin.py:104} INFO - [2022-03-20 15:20:06,852] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:06,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:06,947] {logging_mixin.py:104} INFO - [2022-03-20 15:20:06,946] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:20:06,988] {logging_mixin.py:104} INFO - [2022-03-20 15:20:06,987] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:20:07,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:20:37,393] {scheduler_job.py:182} INFO - Started process (PID=4228) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:37,407] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:20:37,411] {logging_mixin.py:104} INFO - [2022-03-20 15:20:37,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:37,472] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:20:37,526] {logging_mixin.py:104} INFO - [2022-03-20 15:20:37,526] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:20:37,572] {logging_mixin.py:104} INFO - [2022-03-20 15:20:37,572] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:20:37,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.205 seconds
[2022-03-20 15:21:08,334] {scheduler_job.py:182} INFO - Started process (PID=4260) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:21:08,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:21:08,342] {logging_mixin.py:104} INFO - [2022-03-20 15:21:08,342] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:21:08,396] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:21:08,444] {logging_mixin.py:104} INFO - [2022-03-20 15:21:08,443] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:21:08,487] {logging_mixin.py:104} INFO - [2022-03-20 15:21:08,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:21:08,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 15:36:48,957] {scheduler_job.py:182} INFO - Started process (PID=4298) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:36:48,964] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:36:48,968] {logging_mixin.py:104} INFO - [2022-03-20 15:36:48,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:36:49,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:36:49,131] {logging_mixin.py:104} INFO - [2022-03-20 15:36:49,130] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:36:49,183] {logging_mixin.py:104} INFO - [2022-03-20 15:36:49,182] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:36:49,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.263 seconds
[2022-03-20 15:37:19,486] {scheduler_job.py:182} INFO - Started process (PID=4324) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:19,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:37:19,511] {logging_mixin.py:104} INFO - [2022-03-20 15:37:19,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:19,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:19,666] {logging_mixin.py:104} INFO - [2022-03-20 15:37:19,666] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:37:19,721] {logging_mixin.py:104} INFO - [2022-03-20 15:37:19,721] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:37:19,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.279 seconds
[2022-03-20 15:37:50,147] {scheduler_job.py:182} INFO - Started process (PID=4354) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:50,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:37:50,155] {logging_mixin.py:104} INFO - [2022-03-20 15:37:50,155] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:50,204] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:37:50,251] {logging_mixin.py:104} INFO - [2022-03-20 15:37:50,250] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:37:50,295] {logging_mixin.py:104} INFO - [2022-03-20 15:37:50,294] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:37:50,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:38:20,855] {scheduler_job.py:182} INFO - Started process (PID=4387) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:20,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:38:20,862] {logging_mixin.py:104} INFO - [2022-03-20 15:38:20,861] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:20,913] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:20,960] {logging_mixin.py:104} INFO - [2022-03-20 15:38:20,959] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:38:21,003] {logging_mixin.py:104} INFO - [2022-03-20 15:38:21,003] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:38:21,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 15:38:51,572] {scheduler_job.py:182} INFO - Started process (PID=4419) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:51,576] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:38:51,579] {logging_mixin.py:104} INFO - [2022-03-20 15:38:51,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:51,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:38:51,679] {logging_mixin.py:104} INFO - [2022-03-20 15:38:51,679] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:38:51,725] {logging_mixin.py:104} INFO - [2022-03-20 15:38:51,724] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:38:51,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 15:39:22,356] {scheduler_job.py:182} INFO - Started process (PID=4451) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:22,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:39:22,363] {logging_mixin.py:104} INFO - [2022-03-20 15:39:22,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:22,413] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:22,460] {logging_mixin.py:104} INFO - [2022-03-20 15:39:22,460] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:39:22,503] {logging_mixin.py:104} INFO - [2022-03-20 15:39:22,502] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:39:22,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 15:39:53,118] {scheduler_job.py:182} INFO - Started process (PID=4483) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:53,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:39:53,124] {logging_mixin.py:104} INFO - [2022-03-20 15:39:53,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:53,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:39:53,220] {logging_mixin.py:104} INFO - [2022-03-20 15:39:53,220] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:39:53,263] {logging_mixin.py:104} INFO - [2022-03-20 15:39:53,263] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:39:53,279] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 15:40:23,889] {scheduler_job.py:182} INFO - Started process (PID=4514) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:23,892] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:40:23,895] {logging_mixin.py:104} INFO - [2022-03-20 15:40:23,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:23,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:23,992] {logging_mixin.py:104} INFO - [2022-03-20 15:40:23,991] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:40:24,037] {logging_mixin.py:104} INFO - [2022-03-20 15:40:24,036] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:40:24,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:40:56,952] {scheduler_job.py:182} INFO - Started process (PID=4548) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:56,955] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:40:56,958] {logging_mixin.py:104} INFO - [2022-03-20 15:40:56,957] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:57,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:40:57,052] {logging_mixin.py:104} INFO - [2022-03-20 15:40:57,052] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:40:57,093] {logging_mixin.py:104} INFO - [2022-03-20 15:40:57,092] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:40:57,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 15:41:27,574] {scheduler_job.py:182} INFO - Started process (PID=4572) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:27,578] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:41:27,581] {logging_mixin.py:104} INFO - [2022-03-20 15:41:27,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:27,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:27,676] {logging_mixin.py:104} INFO - [2022-03-20 15:41:27,676] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:41:27,717] {logging_mixin.py:104} INFO - [2022-03-20 15:41:27,717] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:41:27,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 15:41:58,407] {scheduler_job.py:182} INFO - Started process (PID=4591) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:58,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:41:58,413] {logging_mixin.py:104} INFO - [2022-03-20 15:41:58,413] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:58,464] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:41:58,512] {logging_mixin.py:104} INFO - [2022-03-20 15:41:58,512] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:41:58,558] {logging_mixin.py:104} INFO - [2022-03-20 15:41:58,557] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:41:58,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 15:42:29,170] {scheduler_job.py:182} INFO - Started process (PID=4623) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:29,174] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:42:29,177] {logging_mixin.py:104} INFO - [2022-03-20 15:42:29,177] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:29,231] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:29,276] {logging_mixin.py:104} INFO - [2022-03-20 15:42:29,276] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:42:29,321] {logging_mixin.py:104} INFO - [2022-03-20 15:42:29,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:42:29,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 15:42:59,661] {scheduler_job.py:182} INFO - Started process (PID=4654) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:59,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:42:59,667] {logging_mixin.py:104} INFO - [2022-03-20 15:42:59,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:59,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:42:59,763] {logging_mixin.py:104} INFO - [2022-03-20 15:42:59,763] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:42:59,806] {logging_mixin.py:104} INFO - [2022-03-20 15:42:59,805] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:42:59,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 15:43:30,359] {scheduler_job.py:182} INFO - Started process (PID=4687) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:43:30,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:43:30,367] {logging_mixin.py:104} INFO - [2022-03-20 15:43:30,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:43:30,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:43:30,460] {logging_mixin.py:104} INFO - [2022-03-20 15:43:30,460] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:43:30,501] {logging_mixin.py:104} INFO - [2022-03-20 15:43:30,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:43:30,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 15:44:01,020] {scheduler_job.py:182} INFO - Started process (PID=4719) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:01,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:44:01,028] {logging_mixin.py:104} INFO - [2022-03-20 15:44:01,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:01,075] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:01,122] {logging_mixin.py:104} INFO - [2022-03-20 15:44:01,121] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:44:01,165] {logging_mixin.py:104} INFO - [2022-03-20 15:44:01,164] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:44:01,181] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 15:44:31,630] {scheduler_job.py:182} INFO - Started process (PID=4750) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:31,634] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:44:31,637] {logging_mixin.py:104} INFO - [2022-03-20 15:44:31,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:31,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:44:31,740] {logging_mixin.py:104} INFO - [2022-03-20 15:44:31,739] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:44:31,782] {logging_mixin.py:104} INFO - [2022-03-20 15:44:31,781] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:44:31,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 15:45:02,128] {scheduler_job.py:182} INFO - Started process (PID=4783) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:02,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:45:02,135] {logging_mixin.py:104} INFO - [2022-03-20 15:45:02,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:02,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:02,231] {logging_mixin.py:104} INFO - [2022-03-20 15:45:02,231] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:45:02,276] {logging_mixin.py:104} INFO - [2022-03-20 15:45:02,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:45:02,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:45:32,729] {scheduler_job.py:182} INFO - Started process (PID=4816) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:32,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:45:32,736] {logging_mixin.py:104} INFO - [2022-03-20 15:45:32,735] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:32,782] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:45:32,826] {logging_mixin.py:104} INFO - [2022-03-20 15:45:32,826] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:45:32,867] {logging_mixin.py:104} INFO - [2022-03-20 15:45:32,867] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:45:32,884] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 15:46:03,808] {scheduler_job.py:182} INFO - Started process (PID=4841) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:03,812] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:46:03,814] {logging_mixin.py:104} INFO - [2022-03-20 15:46:03,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:03,864] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:03,911] {logging_mixin.py:104} INFO - [2022-03-20 15:46:03,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:46:03,953] {logging_mixin.py:104} INFO - [2022-03-20 15:46:03,953] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:46:03,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 15:46:34,277] {scheduler_job.py:182} INFO - Started process (PID=4865) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:34,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:46:34,284] {logging_mixin.py:104} INFO - [2022-03-20 15:46:34,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:34,335] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:46:34,382] {logging_mixin.py:104} INFO - [2022-03-20 15:46:34,382] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:46:34,425] {logging_mixin.py:104} INFO - [2022-03-20 15:46:34,424] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:46:34,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:47:04,856] {scheduler_job.py:182} INFO - Started process (PID=4897) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:04,860] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:47:04,862] {logging_mixin.py:104} INFO - [2022-03-20 15:47:04,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:04,911] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:04,958] {logging_mixin.py:104} INFO - [2022-03-20 15:47:04,957] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:47:05,000] {logging_mixin.py:104} INFO - [2022-03-20 15:47:05,000] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:47:05,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 15:47:35,570] {scheduler_job.py:182} INFO - Started process (PID=4928) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:35,575] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:47:35,579] {logging_mixin.py:104} INFO - [2022-03-20 15:47:35,578] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:35,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:47:35,673] {logging_mixin.py:104} INFO - [2022-03-20 15:47:35,672] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:47:35,717] {logging_mixin.py:104} INFO - [2022-03-20 15:47:35,717] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:47:35,734] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:48:05,927] {scheduler_job.py:182} INFO - Started process (PID=4961) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:05,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:48:05,933] {logging_mixin.py:104} INFO - [2022-03-20 15:48:05,933] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:05,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:06,031] {logging_mixin.py:104} INFO - [2022-03-20 15:48:06,031] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:48:06,078] {logging_mixin.py:104} INFO - [2022-03-20 15:48:06,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:48:06,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:48:36,437] {scheduler_job.py:182} INFO - Started process (PID=4993) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:36,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:48:36,444] {logging_mixin.py:104} INFO - [2022-03-20 15:48:36,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:36,497] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:48:36,545] {logging_mixin.py:104} INFO - [2022-03-20 15:48:36,544] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:48:36,587] {logging_mixin.py:104} INFO - [2022-03-20 15:48:36,586] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:48:36,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:49:06,865] {scheduler_job.py:182} INFO - Started process (PID=5025) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:06,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:49:06,873] {logging_mixin.py:104} INFO - [2022-03-20 15:49:06,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:06,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:06,968] {logging_mixin.py:104} INFO - [2022-03-20 15:49:06,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:49:07,012] {logging_mixin.py:104} INFO - [2022-03-20 15:49:07,011] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:49:07,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:49:37,350] {scheduler_job.py:182} INFO - Started process (PID=5057) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:37,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:49:37,358] {logging_mixin.py:104} INFO - [2022-03-20 15:49:37,358] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:37,406] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:49:37,452] {logging_mixin.py:104} INFO - [2022-03-20 15:49:37,451] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:49:37,495] {logging_mixin.py:104} INFO - [2022-03-20 15:49:37,495] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:49:37,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:50:08,093] {scheduler_job.py:182} INFO - Started process (PID=5090) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:08,096] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:50:08,099] {logging_mixin.py:104} INFO - [2022-03-20 15:50:08,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:08,147] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:08,193] {logging_mixin.py:104} INFO - [2022-03-20 15:50:08,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:50:08,234] {logging_mixin.py:104} INFO - [2022-03-20 15:50:08,234] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:50:08,251] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 15:50:38,668] {scheduler_job.py:182} INFO - Started process (PID=5115) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:38,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:50:38,674] {logging_mixin.py:104} INFO - [2022-03-20 15:50:38,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:38,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:50:38,765] {logging_mixin.py:104} INFO - [2022-03-20 15:50:38,764] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:50:38,806] {logging_mixin.py:104} INFO - [2022-03-20 15:50:38,806] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:50:38,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 15:51:09,115] {scheduler_job.py:182} INFO - Started process (PID=5142) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:09,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:51:09,121] {logging_mixin.py:104} INFO - [2022-03-20 15:51:09,121] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:09,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:09,206] {logging_mixin.py:104} INFO - [2022-03-20 15:51:09,206] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:51:09,244] {logging_mixin.py:104} INFO - [2022-03-20 15:51:09,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:51:09,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 15:51:39,965] {scheduler_job.py:182} INFO - Started process (PID=5171) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:39,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:51:39,971] {logging_mixin.py:104} INFO - [2022-03-20 15:51:39,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:40,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:51:40,068] {logging_mixin.py:104} INFO - [2022-03-20 15:51:40,067] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:51:40,113] {logging_mixin.py:104} INFO - [2022-03-20 15:51:40,112] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:51:40,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:52:10,882] {scheduler_job.py:182} INFO - Started process (PID=5202) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:10,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:52:10,888] {logging_mixin.py:104} INFO - [2022-03-20 15:52:10,888] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:10,937] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:10,985] {logging_mixin.py:104} INFO - [2022-03-20 15:52:10,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:52:11,028] {logging_mixin.py:104} INFO - [2022-03-20 15:52:11,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:52:11,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:52:41,753] {scheduler_job.py:182} INFO - Started process (PID=5235) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:41,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:52:41,761] {logging_mixin.py:104} INFO - [2022-03-20 15:52:41,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:41,809] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:52:41,854] {logging_mixin.py:104} INFO - [2022-03-20 15:52:41,853] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:52:41,896] {logging_mixin.py:104} INFO - [2022-03-20 15:52:41,896] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:52:41,913] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 15:53:12,588] {scheduler_job.py:182} INFO - Started process (PID=5266) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:12,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:53:12,595] {logging_mixin.py:104} INFO - [2022-03-20 15:53:12,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:12,644] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:12,692] {logging_mixin.py:104} INFO - [2022-03-20 15:53:12,692] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:53:12,734] {logging_mixin.py:104} INFO - [2022-03-20 15:53:12,734] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:53:12,751] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 15:53:43,503] {scheduler_job.py:182} INFO - Started process (PID=5299) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:43,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:53:43,510] {logging_mixin.py:104} INFO - [2022-03-20 15:53:43,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:43,563] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:53:43,610] {logging_mixin.py:104} INFO - [2022-03-20 15:53:43,610] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:53:43,654] {logging_mixin.py:104} INFO - [2022-03-20 15:53:43,654] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:53:43,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:54:14,310] {scheduler_job.py:182} INFO - Started process (PID=5331) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:14,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:54:14,319] {logging_mixin.py:104} INFO - [2022-03-20 15:54:14,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:14,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:14,414] {logging_mixin.py:104} INFO - [2022-03-20 15:54:14,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:54:14,456] {logging_mixin.py:104} INFO - [2022-03-20 15:54:14,456] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:54:14,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 15:54:45,128] {scheduler_job.py:182} INFO - Started process (PID=5363) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:45,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:54:45,135] {logging_mixin.py:104} INFO - [2022-03-20 15:54:45,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:45,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:54:45,232] {logging_mixin.py:104} INFO - [2022-03-20 15:54:45,232] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:54:45,274] {logging_mixin.py:104} INFO - [2022-03-20 15:54:45,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:54:45,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:55:16,003] {scheduler_job.py:182} INFO - Started process (PID=5395) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:16,008] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:55:16,011] {logging_mixin.py:104} INFO - [2022-03-20 15:55:16,011] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:16,059] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:16,103] {logging_mixin.py:104} INFO - [2022-03-20 15:55:16,103] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:55:16,148] {logging_mixin.py:104} INFO - [2022-03-20 15:55:16,148] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:55:16,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:55:46,727] {scheduler_job.py:182} INFO - Started process (PID=5428) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:46,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:55:46,734] {logging_mixin.py:104} INFO - [2022-03-20 15:55:46,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:46,781] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:55:46,826] {logging_mixin.py:104} INFO - [2022-03-20 15:55:46,825] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:55:46,866] {logging_mixin.py:104} INFO - [2022-03-20 15:55:46,865] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:55:46,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 15:56:17,648] {scheduler_job.py:182} INFO - Started process (PID=5453) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:17,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:56:17,655] {logging_mixin.py:104} INFO - [2022-03-20 15:56:17,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:17,706] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:17,754] {logging_mixin.py:104} INFO - [2022-03-20 15:56:17,754] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:56:17,797] {logging_mixin.py:104} INFO - [2022-03-20 15:56:17,796] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:56:17,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 15:56:48,064] {scheduler_job.py:182} INFO - Started process (PID=5477) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:48,068] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:56:48,072] {logging_mixin.py:104} INFO - [2022-03-20 15:56:48,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:48,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:56:48,167] {logging_mixin.py:104} INFO - [2022-03-20 15:56:48,166] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:56:48,211] {logging_mixin.py:104} INFO - [2022-03-20 15:56:48,210] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:56:48,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 15:57:19,106] {scheduler_job.py:182} INFO - Started process (PID=5508) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:19,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:57:19,112] {logging_mixin.py:104} INFO - [2022-03-20 15:57:19,112] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:19,163] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:19,211] {logging_mixin.py:104} INFO - [2022-03-20 15:57:19,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:57:19,253] {logging_mixin.py:104} INFO - [2022-03-20 15:57:19,252] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:57:19,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 15:57:50,116] {scheduler_job.py:182} INFO - Started process (PID=5541) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:50,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:57:50,126] {logging_mixin.py:104} INFO - [2022-03-20 15:57:50,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:50,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:57:50,223] {logging_mixin.py:104} INFO - [2022-03-20 15:57:50,223] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:57:50,265] {logging_mixin.py:104} INFO - [2022-03-20 15:57:50,264] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:57:50,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:58:20,936] {scheduler_job.py:182} INFO - Started process (PID=5572) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:20,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:58:20,942] {logging_mixin.py:104} INFO - [2022-03-20 15:58:20,942] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:20,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:21,040] {logging_mixin.py:104} INFO - [2022-03-20 15:58:21,039] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:58:21,083] {logging_mixin.py:104} INFO - [2022-03-20 15:58:21,083] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:58:21,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 15:58:51,854] {scheduler_job.py:182} INFO - Started process (PID=5605) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:51,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:58:51,862] {logging_mixin.py:104} INFO - [2022-03-20 15:58:51,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:51,914] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:58:51,960] {logging_mixin.py:104} INFO - [2022-03-20 15:58:51,960] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:58:52,002] {logging_mixin.py:104} INFO - [2022-03-20 15:58:52,002] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:58:52,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 15:59:22,809] {scheduler_job.py:182} INFO - Started process (PID=5636) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:22,812] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:59:22,815] {logging_mixin.py:104} INFO - [2022-03-20 15:59:22,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:22,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:22,918] {logging_mixin.py:104} INFO - [2022-03-20 15:59:22,917] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:59:22,963] {logging_mixin.py:104} INFO - [2022-03-20 15:59:22,963] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:59:22,981] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 15:59:53,631] {scheduler_job.py:182} INFO - Started process (PID=5669) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:53,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 15:59:53,638] {logging_mixin.py:104} INFO - [2022-03-20 15:59:53,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:53,690] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 15:59:53,738] {logging_mixin.py:104} INFO - [2022-03-20 15:59:53,737] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 15:59:53,780] {logging_mixin.py:104} INFO - [2022-03-20 15:59:53,780] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 15:59:53,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:00:24,373] {scheduler_job.py:182} INFO - Started process (PID=5701) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:24,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:00:24,380] {logging_mixin.py:104} INFO - [2022-03-20 16:00:24,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:24,430] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:24,476] {logging_mixin.py:104} INFO - [2022-03-20 16:00:24,476] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:00:24,519] {logging_mixin.py:104} INFO - [2022-03-20 16:00:24,518] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:00:24,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:00:55,095] {scheduler_job.py:182} INFO - Started process (PID=5733) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:55,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:00:55,101] {logging_mixin.py:104} INFO - [2022-03-20 16:00:55,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:55,150] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:00:55,196] {logging_mixin.py:104} INFO - [2022-03-20 16:00:55,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:00:55,239] {logging_mixin.py:104} INFO - [2022-03-20 16:00:55,238] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:00:55,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:01:25,700] {scheduler_job.py:182} INFO - Started process (PID=5766) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:25,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:01:25,706] {logging_mixin.py:104} INFO - [2022-03-20 16:01:25,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:25,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:25,799] {logging_mixin.py:104} INFO - [2022-03-20 16:01:25,799] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:01:25,842] {logging_mixin.py:104} INFO - [2022-03-20 16:01:25,842] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:01:25,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:01:56,903] {scheduler_job.py:182} INFO - Started process (PID=5791) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:56,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:01:56,910] {logging_mixin.py:104} INFO - [2022-03-20 16:01:56,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:56,956] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:01:56,999] {logging_mixin.py:104} INFO - [2022-03-20 16:01:56,999] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:01:57,040] {logging_mixin.py:104} INFO - [2022-03-20 16:01:57,040] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:01:57,057] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:02:27,192] {scheduler_job.py:182} INFO - Started process (PID=5815) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:27,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:02:27,200] {logging_mixin.py:104} INFO - [2022-03-20 16:02:27,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:27,251] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:27,298] {logging_mixin.py:104} INFO - [2022-03-20 16:02:27,297] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:02:27,338] {logging_mixin.py:104} INFO - [2022-03-20 16:02:27,338] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:02:27,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:02:58,064] {scheduler_job.py:182} INFO - Started process (PID=5847) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:58,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:02:58,072] {logging_mixin.py:104} INFO - [2022-03-20 16:02:58,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:58,123] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:02:58,171] {logging_mixin.py:104} INFO - [2022-03-20 16:02:58,171] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:02:58,213] {logging_mixin.py:104} INFO - [2022-03-20 16:02:58,212] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:02:58,230] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:03:29,070] {scheduler_job.py:182} INFO - Started process (PID=5879) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:29,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:03:29,079] {logging_mixin.py:104} INFO - [2022-03-20 16:03:29,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:29,133] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:29,180] {logging_mixin.py:104} INFO - [2022-03-20 16:03:29,180] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:03:29,224] {logging_mixin.py:104} INFO - [2022-03-20 16:03:29,223] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:03:29,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 16:03:59,885] {scheduler_job.py:182} INFO - Started process (PID=5910) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:59,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:03:59,891] {logging_mixin.py:104} INFO - [2022-03-20 16:03:59,890] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:59,942] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:03:59,991] {logging_mixin.py:104} INFO - [2022-03-20 16:03:59,990] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:04:00,034] {logging_mixin.py:104} INFO - [2022-03-20 16:04:00,033] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:04:00,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:04:30,660] {scheduler_job.py:182} INFO - Started process (PID=5942) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:04:30,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:04:30,666] {logging_mixin.py:104} INFO - [2022-03-20 16:04:30,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:04:30,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:04:30,766] {logging_mixin.py:104} INFO - [2022-03-20 16:04:30,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:04:30,809] {logging_mixin.py:104} INFO - [2022-03-20 16:04:30,808] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:04:30,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:05:01,391] {scheduler_job.py:182} INFO - Started process (PID=5974) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:01,395] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:05:01,400] {logging_mixin.py:104} INFO - [2022-03-20 16:05:01,399] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:01,451] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:01,497] {logging_mixin.py:104} INFO - [2022-03-20 16:05:01,496] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:05:01,539] {logging_mixin.py:104} INFO - [2022-03-20 16:05:01,539] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:05:01,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:05:32,159] {scheduler_job.py:182} INFO - Started process (PID=6007) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:32,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:05:32,166] {logging_mixin.py:104} INFO - [2022-03-20 16:05:32,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:32,218] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:05:32,266] {logging_mixin.py:104} INFO - [2022-03-20 16:05:32,265] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:05:32,308] {logging_mixin.py:104} INFO - [2022-03-20 16:05:32,308] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:05:32,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:06:02,953] {scheduler_job.py:182} INFO - Started process (PID=6039) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:02,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:06:02,961] {logging_mixin.py:104} INFO - [2022-03-20 16:06:02,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:03,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:03,058] {logging_mixin.py:104} INFO - [2022-03-20 16:06:03,057] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:06:03,099] {logging_mixin.py:104} INFO - [2022-03-20 16:06:03,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:06:03,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:06:33,775] {scheduler_job.py:182} INFO - Started process (PID=6071) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:33,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:06:33,786] {logging_mixin.py:104} INFO - [2022-03-20 16:06:33,785] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:33,836] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:06:33,883] {logging_mixin.py:104} INFO - [2022-03-20 16:06:33,883] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:06:33,926] {logging_mixin.py:104} INFO - [2022-03-20 16:06:33,925] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:06:33,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:07:04,616] {scheduler_job.py:182} INFO - Started process (PID=6104) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:04,620] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:07:04,623] {logging_mixin.py:104} INFO - [2022-03-20 16:07:04,622] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:04,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:04,716] {logging_mixin.py:104} INFO - [2022-03-20 16:07:04,715] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:07:04,757] {logging_mixin.py:104} INFO - [2022-03-20 16:07:04,757] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:07:04,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 16:07:35,523] {scheduler_job.py:182} INFO - Started process (PID=6129) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:35,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:07:35,530] {logging_mixin.py:104} INFO - [2022-03-20 16:07:35,530] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:35,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:07:35,624] {logging_mixin.py:104} INFO - [2022-03-20 16:07:35,623] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:07:35,666] {logging_mixin.py:104} INFO - [2022-03-20 16:07:35,666] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:07:35,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 16:08:06,224] {scheduler_job.py:182} INFO - Started process (PID=6153) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:06,228] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:08:06,230] {logging_mixin.py:104} INFO - [2022-03-20 16:08:06,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:06,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:06,326] {logging_mixin.py:104} INFO - [2022-03-20 16:08:06,325] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:08:06,367] {logging_mixin.py:104} INFO - [2022-03-20 16:08:06,367] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:08:06,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 16:08:37,082] {scheduler_job.py:182} INFO - Started process (PID=6184) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:37,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:08:37,089] {logging_mixin.py:104} INFO - [2022-03-20 16:08:37,089] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:37,138] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:08:37,184] {logging_mixin.py:104} INFO - [2022-03-20 16:08:37,184] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:08:37,226] {logging_mixin.py:104} INFO - [2022-03-20 16:08:37,226] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:08:37,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:09:08,064] {scheduler_job.py:182} INFO - Started process (PID=6217) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:08,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:09:08,072] {logging_mixin.py:104} INFO - [2022-03-20 16:09:08,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:08,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:08,168] {logging_mixin.py:104} INFO - [2022-03-20 16:09:08,167] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:09:08,209] {logging_mixin.py:104} INFO - [2022-03-20 16:09:08,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:09:08,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:09:39,068] {scheduler_job.py:182} INFO - Started process (PID=6249) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:39,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:09:39,075] {logging_mixin.py:104} INFO - [2022-03-20 16:09:39,074] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:39,123] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:09:39,171] {logging_mixin.py:104} INFO - [2022-03-20 16:09:39,170] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:09:39,214] {logging_mixin.py:104} INFO - [2022-03-20 16:09:39,214] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:09:39,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:10:10,040] {scheduler_job.py:182} INFO - Started process (PID=6281) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:10,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:10:10,050] {logging_mixin.py:104} INFO - [2022-03-20 16:10:10,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:10,113] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:10,161] {logging_mixin.py:104} INFO - [2022-03-20 16:10:10,160] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:10:10,203] {logging_mixin.py:104} INFO - [2022-03-20 16:10:10,203] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:10:10,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-20 16:10:40,898] {scheduler_job.py:182} INFO - Started process (PID=6313) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:40,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:10:40,906] {logging_mixin.py:104} INFO - [2022-03-20 16:10:40,905] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:40,953] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:10:41,001] {logging_mixin.py:104} INFO - [2022-03-20 16:10:41,000] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:10:41,045] {logging_mixin.py:104} INFO - [2022-03-20 16:10:41,045] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:10:41,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:11:11,703] {scheduler_job.py:182} INFO - Started process (PID=6345) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:11,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:11:11,710] {logging_mixin.py:104} INFO - [2022-03-20 16:11:11,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:11,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:11,806] {logging_mixin.py:104} INFO - [2022-03-20 16:11:11,806] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:11:11,853] {logging_mixin.py:104} INFO - [2022-03-20 16:11:11,853] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:11:11,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:11:42,538] {scheduler_job.py:182} INFO - Started process (PID=6377) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:42,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:11:42,545] {logging_mixin.py:104} INFO - [2022-03-20 16:11:42,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:42,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:11:42,644] {logging_mixin.py:104} INFO - [2022-03-20 16:11:42,644] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:11:42,690] {logging_mixin.py:104} INFO - [2022-03-20 16:11:42,690] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:11:42,706] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:12:13,345] {scheduler_job.py:182} INFO - Started process (PID=6408) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:13,350] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:12:13,355] {logging_mixin.py:104} INFO - [2022-03-20 16:12:13,354] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:13,405] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:13,449] {logging_mixin.py:104} INFO - [2022-03-20 16:12:13,449] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:12:13,491] {logging_mixin.py:104} INFO - [2022-03-20 16:12:13,491] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:12:13,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:12:44,043] {scheduler_job.py:182} INFO - Started process (PID=6442) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:44,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:12:44,050] {logging_mixin.py:104} INFO - [2022-03-20 16:12:44,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:44,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:12:44,148] {logging_mixin.py:104} INFO - [2022-03-20 16:12:44,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:12:44,189] {logging_mixin.py:104} INFO - [2022-03-20 16:12:44,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:12:44,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:13:15,084] {scheduler_job.py:182} INFO - Started process (PID=6467) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:15,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:13:15,090] {logging_mixin.py:104} INFO - [2022-03-20 16:13:15,090] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:15,140] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:15,182] {logging_mixin.py:104} INFO - [2022-03-20 16:13:15,181] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:13:15,223] {logging_mixin.py:104} INFO - [2022-03-20 16:13:15,223] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:13:15,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:13:45,519] {scheduler_job.py:182} INFO - Started process (PID=6494) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:45,524] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:13:45,526] {logging_mixin.py:104} INFO - [2022-03-20 16:13:45,526] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:45,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:13:45,619] {logging_mixin.py:104} INFO - [2022-03-20 16:13:45,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:13:45,660] {logging_mixin.py:104} INFO - [2022-03-20 16:13:45,660] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:13:45,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 16:14:16,187] {scheduler_job.py:182} INFO - Started process (PID=6523) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:16,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:14:16,194] {logging_mixin.py:104} INFO - [2022-03-20 16:14:16,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:16,244] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:16,291] {logging_mixin.py:104} INFO - [2022-03-20 16:14:16,290] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:14:16,332] {logging_mixin.py:104} INFO - [2022-03-20 16:14:16,331] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:14:16,348] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 16:14:47,207] {scheduler_job.py:182} INFO - Started process (PID=6555) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:47,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:14:47,216] {logging_mixin.py:104} INFO - [2022-03-20 16:14:47,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:47,263] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:14:47,308] {logging_mixin.py:104} INFO - [2022-03-20 16:14:47,308] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:14:47,354] {logging_mixin.py:104} INFO - [2022-03-20 16:14:47,354] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:14:47,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:15:17,986] {scheduler_job.py:182} INFO - Started process (PID=6586) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:17,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:15:17,996] {logging_mixin.py:104} INFO - [2022-03-20 16:15:17,995] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:18,044] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:18,093] {logging_mixin.py:104} INFO - [2022-03-20 16:15:18,092] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:15:18,136] {logging_mixin.py:104} INFO - [2022-03-20 16:15:18,135] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:15:18,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:15:48,762] {scheduler_job.py:182} INFO - Started process (PID=6618) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:48,766] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:15:48,769] {logging_mixin.py:104} INFO - [2022-03-20 16:15:48,768] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:48,822] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:15:48,867] {logging_mixin.py:104} INFO - [2022-03-20 16:15:48,866] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:15:48,909] {logging_mixin.py:104} INFO - [2022-03-20 16:15:48,909] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:15:48,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:16:19,609] {scheduler_job.py:182} INFO - Started process (PID=6650) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:19,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:16:19,615] {logging_mixin.py:104} INFO - [2022-03-20 16:16:19,615] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:19,666] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:19,713] {logging_mixin.py:104} INFO - [2022-03-20 16:16:19,712] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:16:19,757] {logging_mixin.py:104} INFO - [2022-03-20 16:16:19,756] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:16:19,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:16:50,385] {scheduler_job.py:182} INFO - Started process (PID=6683) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:50,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:16:50,394] {logging_mixin.py:104} INFO - [2022-03-20 16:16:50,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:50,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:16:50,493] {logging_mixin.py:104} INFO - [2022-03-20 16:16:50,492] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:16:50,535] {logging_mixin.py:104} INFO - [2022-03-20 16:16:50,534] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:16:50,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:17:21,317] {scheduler_job.py:182} INFO - Started process (PID=6715) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:21,322] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:17:21,327] {logging_mixin.py:104} INFO - [2022-03-20 16:17:21,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:21,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:21,425] {logging_mixin.py:104} INFO - [2022-03-20 16:17:21,424] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:17:21,468] {logging_mixin.py:104} INFO - [2022-03-20 16:17:21,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:17:21,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:17:52,095] {scheduler_job.py:182} INFO - Started process (PID=6747) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:52,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:17:52,101] {logging_mixin.py:104} INFO - [2022-03-20 16:17:52,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:52,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:17:52,201] {logging_mixin.py:104} INFO - [2022-03-20 16:17:52,200] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:17:52,246] {logging_mixin.py:104} INFO - [2022-03-20 16:17:52,246] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:17:52,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:18:22,797] {scheduler_job.py:182} INFO - Started process (PID=6780) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:22,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:18:22,803] {logging_mixin.py:104} INFO - [2022-03-20 16:18:22,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:22,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:22,897] {logging_mixin.py:104} INFO - [2022-03-20 16:18:22,896] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:18:22,938] {logging_mixin.py:104} INFO - [2022-03-20 16:18:22,938] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:18:22,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 16:18:53,893] {scheduler_job.py:182} INFO - Started process (PID=6805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:53,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:18:53,899] {logging_mixin.py:104} INFO - [2022-03-20 16:18:53,898] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:53,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:18:53,991] {logging_mixin.py:104} INFO - [2022-03-20 16:18:53,990] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:18:54,031] {logging_mixin.py:104} INFO - [2022-03-20 16:18:54,030] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:18:54,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:19:24,185] {scheduler_job.py:182} INFO - Started process (PID=6832) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:24,189] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:19:24,192] {logging_mixin.py:104} INFO - [2022-03-20 16:19:24,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:24,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:24,278] {logging_mixin.py:104} INFO - [2022-03-20 16:19:24,278] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:19:24,316] {logging_mixin.py:104} INFO - [2022-03-20 16:19:24,315] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:19:24,331] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 16:19:54,456] {scheduler_job.py:182} INFO - Started process (PID=6864) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:54,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:19:54,463] {logging_mixin.py:104} INFO - [2022-03-20 16:19:54,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:54,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:19:54,551] {logging_mixin.py:104} INFO - [2022-03-20 16:19:54,550] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:19:54,590] {logging_mixin.py:104} INFO - [2022-03-20 16:19:54,589] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:19:54,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 16:20:24,718] {scheduler_job.py:182} INFO - Started process (PID=6896) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:24,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:20:24,724] {logging_mixin.py:104} INFO - [2022-03-20 16:20:24,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:24,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:24,812] {logging_mixin.py:104} INFO - [2022-03-20 16:20:24,812] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:20:24,850] {logging_mixin.py:104} INFO - [2022-03-20 16:20:24,849] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:20:24,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 16:20:55,590] {scheduler_job.py:182} INFO - Started process (PID=6925) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:55,594] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:20:55,597] {logging_mixin.py:104} INFO - [2022-03-20 16:20:55,596] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:55,646] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:20:55,691] {logging_mixin.py:104} INFO - [2022-03-20 16:20:55,690] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:20:55,733] {logging_mixin.py:104} INFO - [2022-03-20 16:20:55,732] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:20:55,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:21:26,401] {scheduler_job.py:182} INFO - Started process (PID=6957) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:26,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:21:26,410] {logging_mixin.py:104} INFO - [2022-03-20 16:21:26,410] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:26,457] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:26,507] {logging_mixin.py:104} INFO - [2022-03-20 16:21:26,506] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:21:26,553] {logging_mixin.py:104} INFO - [2022-03-20 16:21:26,552] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:21:26,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 16:21:57,311] {scheduler_job.py:182} INFO - Started process (PID=6988) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:57,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:21:57,317] {logging_mixin.py:104} INFO - [2022-03-20 16:21:57,317] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:57,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:21:57,415] {logging_mixin.py:104} INFO - [2022-03-20 16:21:57,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:21:57,458] {logging_mixin.py:104} INFO - [2022-03-20 16:21:57,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:21:57,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:22:28,259] {scheduler_job.py:182} INFO - Started process (PID=7021) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:28,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:22:28,267] {logging_mixin.py:104} INFO - [2022-03-20 16:22:28,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:28,315] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:28,361] {logging_mixin.py:104} INFO - [2022-03-20 16:22:28,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:22:28,404] {logging_mixin.py:104} INFO - [2022-03-20 16:22:28,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:22:28,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:22:59,083] {scheduler_job.py:182} INFO - Started process (PID=7053) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:59,087] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:22:59,090] {logging_mixin.py:104} INFO - [2022-03-20 16:22:59,090] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:59,140] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:22:59,189] {logging_mixin.py:104} INFO - [2022-03-20 16:22:59,188] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:22:59,230] {logging_mixin.py:104} INFO - [2022-03-20 16:22:59,230] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:22:59,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:23:29,793] {scheduler_job.py:182} INFO - Started process (PID=7086) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:23:29,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:23:29,800] {logging_mixin.py:104} INFO - [2022-03-20 16:23:29,800] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:23:29,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:23:29,892] {logging_mixin.py:104} INFO - [2022-03-20 16:23:29,891] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:23:29,933] {logging_mixin.py:104} INFO - [2022-03-20 16:23:29,933] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:23:29,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 16:24:01,025] {scheduler_job.py:182} INFO - Started process (PID=7111) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:01,029] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:24:01,031] {logging_mixin.py:104} INFO - [2022-03-20 16:24:01,031] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:01,078] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:01,121] {logging_mixin.py:104} INFO - [2022-03-20 16:24:01,121] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:24:01,163] {logging_mixin.py:104} INFO - [2022-03-20 16:24:01,162] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:24:01,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 16:24:31,307] {scheduler_job.py:182} INFO - Started process (PID=7138) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:31,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:24:31,313] {logging_mixin.py:104} INFO - [2022-03-20 16:24:31,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:31,357] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:24:31,397] {logging_mixin.py:104} INFO - [2022-03-20 16:24:31,396] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:24:31,434] {logging_mixin.py:104} INFO - [2022-03-20 16:24:31,433] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:24:31,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 16:25:01,659] {scheduler_job.py:182} INFO - Started process (PID=7170) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:01,662] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:25:01,665] {logging_mixin.py:104} INFO - [2022-03-20 16:25:01,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:01,709] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:01,750] {logging_mixin.py:104} INFO - [2022-03-20 16:25:01,750] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:25:01,792] {logging_mixin.py:104} INFO - [2022-03-20 16:25:01,792] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:25:01,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 16:25:32,027] {scheduler_job.py:182} INFO - Started process (PID=7199) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:32,033] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:25:32,036] {logging_mixin.py:104} INFO - [2022-03-20 16:25:32,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:32,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:25:32,128] {logging_mixin.py:104} INFO - [2022-03-20 16:25:32,128] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:25:32,172] {logging_mixin.py:104} INFO - [2022-03-20 16:25:32,171] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:25:32,189] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:26:02,424] {scheduler_job.py:182} INFO - Started process (PID=7231) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:02,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:26:02,431] {logging_mixin.py:104} INFO - [2022-03-20 16:26:02,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:02,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:02,530] {logging_mixin.py:104} INFO - [2022-03-20 16:26:02,530] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:26:02,572] {logging_mixin.py:104} INFO - [2022-03-20 16:26:02,572] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:26:02,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 16:26:32,957] {scheduler_job.py:182} INFO - Started process (PID=7263) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:32,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:26:32,964] {logging_mixin.py:104} INFO - [2022-03-20 16:26:32,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:33,020] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:26:33,070] {logging_mixin.py:104} INFO - [2022-03-20 16:26:33,070] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:26:33,113] {logging_mixin.py:104} INFO - [2022-03-20 16:26:33,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:26:33,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 16:27:03,606] {scheduler_job.py:182} INFO - Started process (PID=7294) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:03,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:27:03,613] {logging_mixin.py:104} INFO - [2022-03-20 16:27:03,612] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:03,660] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:03,706] {logging_mixin.py:104} INFO - [2022-03-20 16:27:03,706] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:27:03,750] {logging_mixin.py:104} INFO - [2022-03-20 16:27:03,749] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:27:03,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 16:27:34,199] {scheduler_job.py:182} INFO - Started process (PID=7327) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:34,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:27:34,205] {logging_mixin.py:104} INFO - [2022-03-20 16:27:34,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:34,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:27:34,300] {logging_mixin.py:104} INFO - [2022-03-20 16:27:34,299] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:27:34,342] {logging_mixin.py:104} INFO - [2022-03-20 16:27:34,342] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:27:34,360] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 16:28:04,907] {scheduler_job.py:182} INFO - Started process (PID=7360) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:04,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:28:04,913] {logging_mixin.py:104} INFO - [2022-03-20 16:28:04,913] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:04,962] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:05,005] {logging_mixin.py:104} INFO - [2022-03-20 16:28:05,004] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:28:05,047] {logging_mixin.py:104} INFO - [2022-03-20 16:28:05,047] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:28:05,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 16:28:35,418] {scheduler_job.py:182} INFO - Started process (PID=7385) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:35,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:28:35,425] {logging_mixin.py:104} INFO - [2022-03-20 16:28:35,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:35,476] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:28:35,525] {logging_mixin.py:104} INFO - [2022-03-20 16:28:35,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:28:35,580] {logging_mixin.py:104} INFO - [2022-03-20 16:28:35,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:28:35,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.234 seconds
[2022-03-20 16:29:06,193] {scheduler_job.py:182} INFO - Started process (PID=7409) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:06,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:29:06,200] {logging_mixin.py:104} INFO - [2022-03-20 16:29:06,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:06,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:06,297] {logging_mixin.py:104} INFO - [2022-03-20 16:29:06,297] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:29:06,341] {logging_mixin.py:104} INFO - [2022-03-20 16:29:06,340] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:29:06,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:29:36,872] {scheduler_job.py:182} INFO - Started process (PID=7441) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:36,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:29:36,879] {logging_mixin.py:104} INFO - [2022-03-20 16:29:36,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:36,927] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:29:36,975] {logging_mixin.py:104} INFO - [2022-03-20 16:29:36,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:29:37,017] {logging_mixin.py:104} INFO - [2022-03-20 16:29:37,017] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:29:37,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:30:07,514] {scheduler_job.py:182} INFO - Started process (PID=7473) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:07,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:30:07,522] {logging_mixin.py:104} INFO - [2022-03-20 16:30:07,521] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:07,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:07,622] {logging_mixin.py:104} INFO - [2022-03-20 16:30:07,621] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:30:07,664] {logging_mixin.py:104} INFO - [2022-03-20 16:30:07,664] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:30:07,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:30:37,933] {scheduler_job.py:182} INFO - Started process (PID=7505) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:37,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:30:37,941] {logging_mixin.py:104} INFO - [2022-03-20 16:30:37,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:37,992] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:30:38,038] {logging_mixin.py:104} INFO - [2022-03-20 16:30:38,038] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:30:38,081] {logging_mixin.py:104} INFO - [2022-03-20 16:30:38,081] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:30:38,099] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:31:08,441] {scheduler_job.py:182} INFO - Started process (PID=7537) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:08,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:31:08,449] {logging_mixin.py:104} INFO - [2022-03-20 16:31:08,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:08,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:08,547] {logging_mixin.py:104} INFO - [2022-03-20 16:31:08,546] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:31:08,591] {logging_mixin.py:104} INFO - [2022-03-20 16:31:08,590] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:31:08,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 16:31:38,971] {scheduler_job.py:182} INFO - Started process (PID=7568) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:38,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:31:38,978] {logging_mixin.py:104} INFO - [2022-03-20 16:31:38,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:39,027] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:31:39,076] {logging_mixin.py:104} INFO - [2022-03-20 16:31:39,075] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:31:39,120] {logging_mixin.py:104} INFO - [2022-03-20 16:31:39,120] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:31:39,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:32:09,645] {scheduler_job.py:182} INFO - Started process (PID=7601) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:09,649] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:32:09,653] {logging_mixin.py:104} INFO - [2022-03-20 16:32:09,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:09,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:09,753] {logging_mixin.py:104} INFO - [2022-03-20 16:32:09,752] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:32:09,796] {logging_mixin.py:104} INFO - [2022-03-20 16:32:09,796] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:32:09,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:32:41,206] {scheduler_job.py:182} INFO - Started process (PID=7636) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:41,211] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:32:41,213] {logging_mixin.py:104} INFO - [2022-03-20 16:32:41,213] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:41,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:32:41,304] {logging_mixin.py:104} INFO - [2022-03-20 16:32:41,303] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:32:41,344] {logging_mixin.py:104} INFO - [2022-03-20 16:32:41,344] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:32:41,361] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:33:12,956] {scheduler_job.py:182} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:12,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:33:12,962] {logging_mixin.py:104} INFO - [2022-03-20 16:33:12,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:13,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:13,054] {logging_mixin.py:104} INFO - [2022-03-20 16:33:13,054] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:33:13,097] {logging_mixin.py:104} INFO - [2022-03-20 16:33:13,096] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:33:13,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 16:33:43,780] {scheduler_job.py:182} INFO - Started process (PID=7690) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:43,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:33:43,786] {logging_mixin.py:104} INFO - [2022-03-20 16:33:43,786] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:43,835] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:33:43,880] {logging_mixin.py:104} INFO - [2022-03-20 16:33:43,880] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:33:43,923] {logging_mixin.py:104} INFO - [2022-03-20 16:33:43,922] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:33:43,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:34:14,435] {scheduler_job.py:182} INFO - Started process (PID=7718) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:14,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:34:14,443] {logging_mixin.py:104} INFO - [2022-03-20 16:34:14,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:14,492] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:14,537] {logging_mixin.py:104} INFO - [2022-03-20 16:34:14,537] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:34:14,580] {logging_mixin.py:104} INFO - [2022-03-20 16:34:14,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:34:14,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:34:45,018] {scheduler_job.py:182} INFO - Started process (PID=7750) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:45,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:34:45,028] {logging_mixin.py:104} INFO - [2022-03-20 16:34:45,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:45,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:34:45,121] {logging_mixin.py:104} INFO - [2022-03-20 16:34:45,120] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:34:45,167] {logging_mixin.py:104} INFO - [2022-03-20 16:34:45,166] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:34:45,183] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:35:15,618] {scheduler_job.py:182} INFO - Started process (PID=7782) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:15,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:35:15,627] {logging_mixin.py:104} INFO - [2022-03-20 16:35:15,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:15,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:15,723] {logging_mixin.py:104} INFO - [2022-03-20 16:35:15,722] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:35:15,765] {logging_mixin.py:104} INFO - [2022-03-20 16:35:15,765] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:35:15,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:35:46,007] {scheduler_job.py:182} INFO - Started process (PID=7814) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:46,012] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:35:46,014] {logging_mixin.py:104} INFO - [2022-03-20 16:35:46,014] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:46,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:35:46,106] {logging_mixin.py:104} INFO - [2022-03-20 16:35:46,105] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:35:46,145] {logging_mixin.py:104} INFO - [2022-03-20 16:35:46,145] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:35:46,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 16:36:16,746] {scheduler_job.py:182} INFO - Started process (PID=7846) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:16,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:36:16,754] {logging_mixin.py:104} INFO - [2022-03-20 16:36:16,753] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:16,805] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:16,848] {logging_mixin.py:104} INFO - [2022-03-20 16:36:16,848] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:36:16,890] {logging_mixin.py:104} INFO - [2022-03-20 16:36:16,889] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:36:16,907] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:36:47,371] {scheduler_job.py:182} INFO - Started process (PID=7878) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:47,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:36:47,379] {logging_mixin.py:104} INFO - [2022-03-20 16:36:47,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:47,430] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:36:47,474] {logging_mixin.py:104} INFO - [2022-03-20 16:36:47,473] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:36:47,516] {logging_mixin.py:104} INFO - [2022-03-20 16:36:47,515] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:36:47,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 16:37:18,286] {scheduler_job.py:182} INFO - Started process (PID=7910) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:18,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:37:18,293] {logging_mixin.py:104} INFO - [2022-03-20 16:37:18,292] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:18,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:18,385] {logging_mixin.py:104} INFO - [2022-03-20 16:37:18,384] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:37:18,425] {logging_mixin.py:104} INFO - [2022-03-20 16:37:18,424] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:37:18,441] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:37:49,861] {scheduler_job.py:182} INFO - Started process (PID=7940) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:49,865] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:37:49,868] {logging_mixin.py:104} INFO - [2022-03-20 16:37:49,867] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:49,914] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:37:49,959] {logging_mixin.py:104} INFO - [2022-03-20 16:37:49,958] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:37:50,000] {logging_mixin.py:104} INFO - [2022-03-20 16:37:50,000] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:37:50,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:38:20,555] {scheduler_job.py:182} INFO - Started process (PID=7962) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:20,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:38:20,562] {logging_mixin.py:104} INFO - [2022-03-20 16:38:20,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:20,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:20,657] {logging_mixin.py:104} INFO - [2022-03-20 16:38:20,656] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:38:20,698] {logging_mixin.py:104} INFO - [2022-03-20 16:38:20,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:38:20,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:38:51,081] {scheduler_job.py:182} INFO - Started process (PID=7992) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:51,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:38:51,104] {logging_mixin.py:104} INFO - [2022-03-20 16:38:51,103] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:51,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:38:51,215] {logging_mixin.py:104} INFO - [2022-03-20 16:38:51,215] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:38:51,270] {logging_mixin.py:104} INFO - [2022-03-20 16:38:51,270] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:38:51,289] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.214 seconds
[2022-03-20 16:39:21,831] {scheduler_job.py:182} INFO - Started process (PID=8024) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:21,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:39:21,837] {logging_mixin.py:104} INFO - [2022-03-20 16:39:21,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:21,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:21,926] {logging_mixin.py:104} INFO - [2022-03-20 16:39:21,926] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:39:21,965] {logging_mixin.py:104} INFO - [2022-03-20 16:39:21,964] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:39:21,983] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 16:39:52,508] {scheduler_job.py:182} INFO - Started process (PID=8056) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:52,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:39:52,515] {logging_mixin.py:104} INFO - [2022-03-20 16:39:52,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:52,567] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:39:52,614] {logging_mixin.py:104} INFO - [2022-03-20 16:39:52,613] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:39:52,656] {logging_mixin.py:104} INFO - [2022-03-20 16:39:52,656] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:39:52,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 16:40:23,199] {scheduler_job.py:182} INFO - Started process (PID=8088) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:23,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:40:23,209] {logging_mixin.py:104} INFO - [2022-03-20 16:40:23,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:23,257] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:23,300] {logging_mixin.py:104} INFO - [2022-03-20 16:40:23,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:40:23,340] {logging_mixin.py:104} INFO - [2022-03-20 16:40:23,340] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:40:23,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 16:40:53,937] {scheduler_job.py:182} INFO - Started process (PID=8120) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:53,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:40:53,946] {logging_mixin.py:104} INFO - [2022-03-20 16:40:53,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:53,994] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:40:54,038] {logging_mixin.py:104} INFO - [2022-03-20 16:40:54,038] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:40:54,080] {logging_mixin.py:104} INFO - [2022-03-20 16:40:54,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:40:54,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 16:41:24,655] {scheduler_job.py:182} INFO - Started process (PID=8152) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:24,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:41:24,663] {logging_mixin.py:104} INFO - [2022-03-20 16:41:24,663] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:24,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:24,757] {logging_mixin.py:104} INFO - [2022-03-20 16:41:24,757] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:41:24,798] {logging_mixin.py:104} INFO - [2022-03-20 16:41:24,798] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:41:24,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:41:55,398] {scheduler_job.py:182} INFO - Started process (PID=8184) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:55,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:41:55,405] {logging_mixin.py:104} INFO - [2022-03-20 16:41:55,405] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:55,453] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:41:55,496] {logging_mixin.py:104} INFO - [2022-03-20 16:41:55,496] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:41:55,539] {logging_mixin.py:104} INFO - [2022-03-20 16:41:55,539] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:41:55,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 16:42:28,118] {scheduler_job.py:182} INFO - Started process (PID=8214) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:28,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:42:28,125] {logging_mixin.py:104} INFO - [2022-03-20 16:42:28,124] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:28,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:28,222] {logging_mixin.py:104} INFO - [2022-03-20 16:42:28,222] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:42:28,264] {logging_mixin.py:104} INFO - [2022-03-20 16:42:28,264] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:42:28,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:42:58,970] {scheduler_job.py:182} INFO - Started process (PID=8238) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:58,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:42:58,977] {logging_mixin.py:104} INFO - [2022-03-20 16:42:58,977] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:59,025] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:42:59,067] {logging_mixin.py:104} INFO - [2022-03-20 16:42:59,067] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:42:59,109] {logging_mixin.py:104} INFO - [2022-03-20 16:42:59,108] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:42:59,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 16:43:29,809] {scheduler_job.py:182} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:43:29,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:43:29,819] {logging_mixin.py:104} INFO - [2022-03-20 16:43:29,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:43:29,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:43:29,909] {logging_mixin.py:104} INFO - [2022-03-20 16:43:29,908] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:43:29,947] {logging_mixin.py:104} INFO - [2022-03-20 16:43:29,947] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:43:29,962] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 16:44:00,733] {scheduler_job.py:182} INFO - Started process (PID=8298) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:00,738] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:44:00,741] {logging_mixin.py:104} INFO - [2022-03-20 16:44:00,740] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:00,787] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:00,829] {logging_mixin.py:104} INFO - [2022-03-20 16:44:00,828] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:44:00,866] {logging_mixin.py:104} INFO - [2022-03-20 16:44:00,866] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:44:00,882] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 16:44:31,530] {scheduler_job.py:182} INFO - Started process (PID=8330) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:31,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:44:31,538] {logging_mixin.py:104} INFO - [2022-03-20 16:44:31,538] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:31,587] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:44:31,631] {logging_mixin.py:104} INFO - [2022-03-20 16:44:31,631] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:44:31,669] {logging_mixin.py:104} INFO - [2022-03-20 16:44:31,669] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:44:31,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 16:45:02,115] {scheduler_job.py:182} INFO - Started process (PID=8362) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:02,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:45:02,122] {logging_mixin.py:104} INFO - [2022-03-20 16:45:02,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:02,170] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:02,216] {logging_mixin.py:104} INFO - [2022-03-20 16:45:02,216] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:45:02,260] {logging_mixin.py:104} INFO - [2022-03-20 16:45:02,260] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:45:02,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 16:45:32,726] {scheduler_job.py:182} INFO - Started process (PID=8394) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:32,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:45:32,734] {logging_mixin.py:104} INFO - [2022-03-20 16:45:32,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:32,778] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:45:32,824] {logging_mixin.py:104} INFO - [2022-03-20 16:45:32,823] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:45:32,864] {logging_mixin.py:104} INFO - [2022-03-20 16:45:32,864] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:45:32,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 16:46:03,489] {scheduler_job.py:182} INFO - Started process (PID=8426) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:03,494] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:46:03,497] {logging_mixin.py:104} INFO - [2022-03-20 16:46:03,496] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:03,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:03,586] {logging_mixin.py:104} INFO - [2022-03-20 16:46:03,586] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:46:03,625] {logging_mixin.py:104} INFO - [2022-03-20 16:46:03,625] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:46:03,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 16:46:34,112] {scheduler_job.py:182} INFO - Started process (PID=8458) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:34,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:46:34,121] {logging_mixin.py:104} INFO - [2022-03-20 16:46:34,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:34,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:46:34,209] {logging_mixin.py:104} INFO - [2022-03-20 16:46:34,209] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:46:34,248] {logging_mixin.py:104} INFO - [2022-03-20 16:46:34,248] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:46:34,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 16:47:04,672] {scheduler_job.py:182} INFO - Started process (PID=8488) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:04,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:47:04,678] {logging_mixin.py:104} INFO - [2022-03-20 16:47:04,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:04,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:04,767] {logging_mixin.py:104} INFO - [2022-03-20 16:47:04,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:47:04,808] {logging_mixin.py:104} INFO - [2022-03-20 16:47:04,808] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:47:04,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 16:47:35,383] {scheduler_job.py:182} INFO - Started process (PID=8510) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:35,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:47:35,389] {logging_mixin.py:104} INFO - [2022-03-20 16:47:35,389] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:35,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:47:35,484] {logging_mixin.py:104} INFO - [2022-03-20 16:47:35,484] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:47:35,529] {logging_mixin.py:104} INFO - [2022-03-20 16:47:35,529] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:47:35,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 16:48:05,935] {scheduler_job.py:182} INFO - Started process (PID=8540) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:05,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:48:05,941] {logging_mixin.py:104} INFO - [2022-03-20 16:48:05,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:05,985] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:06,028] {logging_mixin.py:104} INFO - [2022-03-20 16:48:06,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:48:06,067] {logging_mixin.py:104} INFO - [2022-03-20 16:48:06,067] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:48:06,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 16:48:36,407] {scheduler_job.py:182} INFO - Started process (PID=8572) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:36,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:48:36,414] {logging_mixin.py:104} INFO - [2022-03-20 16:48:36,414] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:36,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:48:36,514] {logging_mixin.py:104} INFO - [2022-03-20 16:48:36,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:48:36,555] {logging_mixin.py:104} INFO - [2022-03-20 16:48:36,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:48:36,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:49:07,144] {scheduler_job.py:182} INFO - Started process (PID=8604) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:07,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:49:07,152] {logging_mixin.py:104} INFO - [2022-03-20 16:49:07,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:07,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:07,237] {logging_mixin.py:104} INFO - [2022-03-20 16:49:07,237] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:49:07,276] {logging_mixin.py:104} INFO - [2022-03-20 16:49:07,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:49:07,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 16:49:37,824] {scheduler_job.py:182} INFO - Started process (PID=8636) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:37,828] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:49:37,830] {logging_mixin.py:104} INFO - [2022-03-20 16:49:37,830] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:37,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:49:37,917] {logging_mixin.py:104} INFO - [2022-03-20 16:49:37,916] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:49:37,954] {logging_mixin.py:104} INFO - [2022-03-20 16:49:37,953] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:49:37,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 16:50:08,274] {scheduler_job.py:182} INFO - Started process (PID=8668) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:08,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:50:08,282] {logging_mixin.py:104} INFO - [2022-03-20 16:50:08,281] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:08,331] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:08,373] {logging_mixin.py:104} INFO - [2022-03-20 16:50:08,373] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:50:08,410] {logging_mixin.py:104} INFO - [2022-03-20 16:50:08,410] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:50:08,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 16:50:38,927] {scheduler_job.py:182} INFO - Started process (PID=8700) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:38,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:50:38,934] {logging_mixin.py:104} INFO - [2022-03-20 16:50:38,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:38,981] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:50:39,022] {logging_mixin.py:104} INFO - [2022-03-20 16:50:39,022] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:50:39,059] {logging_mixin.py:104} INFO - [2022-03-20 16:50:39,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:50:39,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 16:51:09,590] {scheduler_job.py:182} INFO - Started process (PID=8732) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:09,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:51:09,597] {logging_mixin.py:104} INFO - [2022-03-20 16:51:09,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:09,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:09,684] {logging_mixin.py:104} INFO - [2022-03-20 16:51:09,684] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:51:09,722] {logging_mixin.py:104} INFO - [2022-03-20 16:51:09,721] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:51:09,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 16:51:42,272] {scheduler_job.py:182} INFO - Started process (PID=8762) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:42,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:51:42,278] {logging_mixin.py:104} INFO - [2022-03-20 16:51:42,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:42,329] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:51:42,374] {logging_mixin.py:104} INFO - [2022-03-20 16:51:42,374] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:51:42,416] {logging_mixin.py:104} INFO - [2022-03-20 16:51:42,416] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:51:42,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 16:52:12,875] {scheduler_job.py:182} INFO - Started process (PID=8785) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:12,881] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:52:12,884] {logging_mixin.py:104} INFO - [2022-03-20 16:52:12,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:12,935] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:12,979] {logging_mixin.py:104} INFO - [2022-03-20 16:52:12,978] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:52:13,023] {logging_mixin.py:104} INFO - [2022-03-20 16:52:13,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:52:13,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:52:43,343] {scheduler_job.py:182} INFO - Started process (PID=8814) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:43,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:52:43,350] {logging_mixin.py:104} INFO - [2022-03-20 16:52:43,350] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:43,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:52:43,439] {logging_mixin.py:104} INFO - [2022-03-20 16:52:43,438] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:52:43,477] {logging_mixin.py:104} INFO - [2022-03-20 16:52:43,476] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:52:43,493] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 16:53:13,920] {scheduler_job.py:182} INFO - Started process (PID=8846) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:13,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:53:13,926] {logging_mixin.py:104} INFO - [2022-03-20 16:53:13,926] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:13,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:14,012] {logging_mixin.py:104} INFO - [2022-03-20 16:53:14,011] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:53:14,049] {logging_mixin.py:104} INFO - [2022-03-20 16:53:14,048] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:53:14,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 16:53:44,433] {scheduler_job.py:182} INFO - Started process (PID=8878) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:44,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:53:44,440] {logging_mixin.py:104} INFO - [2022-03-20 16:53:44,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:44,488] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:53:44,530] {logging_mixin.py:104} INFO - [2022-03-20 16:53:44,529] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:53:44,569] {logging_mixin.py:104} INFO - [2022-03-20 16:53:44,569] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:53:44,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 16:54:15,098] {scheduler_job.py:182} INFO - Started process (PID=8910) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:15,102] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:54:15,105] {logging_mixin.py:104} INFO - [2022-03-20 16:54:15,105] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:15,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:15,195] {logging_mixin.py:104} INFO - [2022-03-20 16:54:15,194] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:54:15,232] {logging_mixin.py:104} INFO - [2022-03-20 16:54:15,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:54:15,248] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 16:54:45,612] {scheduler_job.py:182} INFO - Started process (PID=8942) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:45,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:54:45,618] {logging_mixin.py:104} INFO - [2022-03-20 16:54:45,618] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:45,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:54:45,705] {logging_mixin.py:104} INFO - [2022-03-20 16:54:45,704] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:54:45,742] {logging_mixin.py:104} INFO - [2022-03-20 16:54:45,742] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:54:45,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 16:55:16,341] {scheduler_job.py:182} INFO - Started process (PID=8974) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:16,347] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:55:16,350] {logging_mixin.py:104} INFO - [2022-03-20 16:55:16,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:16,396] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:16,437] {logging_mixin.py:104} INFO - [2022-03-20 16:55:16,436] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:55:16,475] {logging_mixin.py:104} INFO - [2022-03-20 16:55:16,475] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:55:16,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 16:55:47,030] {scheduler_job.py:182} INFO - Started process (PID=9006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:47,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:55:47,038] {logging_mixin.py:104} INFO - [2022-03-20 16:55:47,037] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:47,086] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:55:47,128] {logging_mixin.py:104} INFO - [2022-03-20 16:55:47,128] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:55:47,168] {logging_mixin.py:104} INFO - [2022-03-20 16:55:47,167] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:55:47,183] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 16:56:19,805] {scheduler_job.py:182} INFO - Started process (PID=9036) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:19,808] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:56:19,811] {logging_mixin.py:104} INFO - [2022-03-20 16:56:19,810] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:19,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:19,902] {logging_mixin.py:104} INFO - [2022-03-20 16:56:19,902] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:56:19,944] {logging_mixin.py:104} INFO - [2022-03-20 16:56:19,944] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:56:19,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 16:56:50,607] {scheduler_job.py:182} INFO - Started process (PID=9059) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:50,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:56:50,615] {logging_mixin.py:104} INFO - [2022-03-20 16:56:50,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:50,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:56:50,714] {logging_mixin.py:104} INFO - [2022-03-20 16:56:50,714] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:56:50,757] {logging_mixin.py:104} INFO - [2022-03-20 16:56:50,756] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:56:50,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 16:57:21,322] {scheduler_job.py:182} INFO - Started process (PID=9088) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:21,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:57:21,329] {logging_mixin.py:104} INFO - [2022-03-20 16:57:21,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:21,374] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:21,417] {logging_mixin.py:104} INFO - [2022-03-20 16:57:21,416] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:57:21,456] {logging_mixin.py:104} INFO - [2022-03-20 16:57:21,455] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:57:21,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 16:57:52,157] {scheduler_job.py:182} INFO - Started process (PID=9120) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:52,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:57:52,166] {logging_mixin.py:104} INFO - [2022-03-20 16:57:52,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:52,212] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:57:52,255] {logging_mixin.py:104} INFO - [2022-03-20 16:57:52,255] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:57:52,294] {logging_mixin.py:104} INFO - [2022-03-20 16:57:52,293] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:57:52,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 16:58:22,873] {scheduler_job.py:182} INFO - Started process (PID=9152) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:22,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:58:22,881] {logging_mixin.py:104} INFO - [2022-03-20 16:58:22,880] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:22,925] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:22,967] {logging_mixin.py:104} INFO - [2022-03-20 16:58:22,966] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:58:23,004] {logging_mixin.py:104} INFO - [2022-03-20 16:58:23,004] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:58:23,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 16:58:53,668] {scheduler_job.py:182} INFO - Started process (PID=9184) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:53,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:58:53,676] {logging_mixin.py:104} INFO - [2022-03-20 16:58:53,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:53,722] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:58:53,766] {logging_mixin.py:104} INFO - [2022-03-20 16:58:53,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:58:53,806] {logging_mixin.py:104} INFO - [2022-03-20 16:58:53,806] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:58:53,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 16:59:24,445] {scheduler_job.py:182} INFO - Started process (PID=9216) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:24,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:59:24,453] {logging_mixin.py:104} INFO - [2022-03-20 16:59:24,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:24,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:24,543] {logging_mixin.py:104} INFO - [2022-03-20 16:59:24,543] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:59:24,582] {logging_mixin.py:104} INFO - [2022-03-20 16:59:24,582] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:59:24,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 16:59:55,096] {scheduler_job.py:182} INFO - Started process (PID=9248) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:55,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 16:59:55,104] {logging_mixin.py:104} INFO - [2022-03-20 16:59:55,103] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:55,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 16:59:55,195] {logging_mixin.py:104} INFO - [2022-03-20 16:59:55,194] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 16:59:55,233] {logging_mixin.py:104} INFO - [2022-03-20 16:59:55,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 16:59:55,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 17:00:25,740] {scheduler_job.py:182} INFO - Started process (PID=9280) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:25,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:00:25,747] {logging_mixin.py:104} INFO - [2022-03-20 17:00:25,747] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:25,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:25,834] {logging_mixin.py:104} INFO - [2022-03-20 17:00:25,834] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:00:25,872] {logging_mixin.py:104} INFO - [2022-03-20 17:00:25,872] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:00:25,888] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 17:00:57,443] {scheduler_job.py:182} INFO - Started process (PID=9310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:57,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:00:57,450] {logging_mixin.py:104} INFO - [2022-03-20 17:00:57,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:57,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:00:57,544] {logging_mixin.py:104} INFO - [2022-03-20 17:00:57,544] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:00:57,585] {logging_mixin.py:104} INFO - [2022-03-20 17:00:57,585] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:00:57,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:01:28,094] {scheduler_job.py:182} INFO - Started process (PID=9333) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:28,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:01:28,100] {logging_mixin.py:104} INFO - [2022-03-20 17:01:28,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:28,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:28,196] {logging_mixin.py:104} INFO - [2022-03-20 17:01:28,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:01:28,239] {logging_mixin.py:104} INFO - [2022-03-20 17:01:28,239] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:01:28,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:01:58,897] {scheduler_job.py:182} INFO - Started process (PID=9362) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:58,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:01:58,904] {logging_mixin.py:104} INFO - [2022-03-20 17:01:58,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:58,952] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:01:58,994] {logging_mixin.py:104} INFO - [2022-03-20 17:01:58,993] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:01:59,031] {logging_mixin.py:104} INFO - [2022-03-20 17:01:59,031] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:01:59,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 17:02:29,721] {scheduler_job.py:182} INFO - Started process (PID=9394) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:02:29,726] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:02:29,729] {logging_mixin.py:104} INFO - [2022-03-20 17:02:29,728] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:02:29,780] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:02:29,824] {logging_mixin.py:104} INFO - [2022-03-20 17:02:29,823] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:02:29,862] {logging_mixin.py:104} INFO - [2022-03-20 17:02:29,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:02:29,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 17:03:00,638] {scheduler_job.py:182} INFO - Started process (PID=9426) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:00,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:03:00,645] {logging_mixin.py:104} INFO - [2022-03-20 17:03:00,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:00,693] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:00,734] {logging_mixin.py:104} INFO - [2022-03-20 17:03:00,734] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:03:00,772] {logging_mixin.py:104} INFO - [2022-03-20 17:03:00,772] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:03:00,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 17:03:31,440] {scheduler_job.py:182} INFO - Started process (PID=9458) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:31,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:03:31,447] {logging_mixin.py:104} INFO - [2022-03-20 17:03:31,447] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:31,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:03:31,541] {logging_mixin.py:104} INFO - [2022-03-20 17:03:31,540] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:03:31,579] {logging_mixin.py:104} INFO - [2022-03-20 17:03:31,579] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:03:31,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:04:02,068] {scheduler_job.py:182} INFO - Started process (PID=9490) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:02,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:04:02,077] {logging_mixin.py:104} INFO - [2022-03-20 17:04:02,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:02,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:02,170] {logging_mixin.py:104} INFO - [2022-03-20 17:04:02,169] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:04:02,207] {logging_mixin.py:104} INFO - [2022-03-20 17:04:02,206] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:04:02,224] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:04:32,736] {scheduler_job.py:182} INFO - Started process (PID=9522) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:32,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:04:32,743] {logging_mixin.py:104} INFO - [2022-03-20 17:04:32,743] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:32,793] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:04:32,834] {logging_mixin.py:104} INFO - [2022-03-20 17:04:32,834] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:04:32,872] {logging_mixin.py:104} INFO - [2022-03-20 17:04:32,871] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:04:32,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 17:05:03,518] {scheduler_job.py:182} INFO - Started process (PID=9554) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:03,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:05:03,524] {logging_mixin.py:104} INFO - [2022-03-20 17:05:03,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:03,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:03,623] {logging_mixin.py:104} INFO - [2022-03-20 17:05:03,623] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:05:03,665] {logging_mixin.py:104} INFO - [2022-03-20 17:05:03,665] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:05:03,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.209 seconds
[2022-03-20 17:05:34,464] {scheduler_job.py:182} INFO - Started process (PID=9584) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:34,468] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:05:34,471] {logging_mixin.py:104} INFO - [2022-03-20 17:05:34,471] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:34,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:05:34,569] {logging_mixin.py:104} INFO - [2022-03-20 17:05:34,569] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:05:34,612] {logging_mixin.py:104} INFO - [2022-03-20 17:05:34,612] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:05:34,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 17:06:05,364] {scheduler_job.py:182} INFO - Started process (PID=9608) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:05,368] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:06:05,370] {logging_mixin.py:104} INFO - [2022-03-20 17:06:05,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:05,418] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:05,461] {logging_mixin.py:104} INFO - [2022-03-20 17:06:05,461] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:06:05,503] {logging_mixin.py:104} INFO - [2022-03-20 17:06:05,503] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:06:05,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 17:06:36,074] {scheduler_job.py:182} INFO - Started process (PID=9636) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:36,079] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:06:36,082] {logging_mixin.py:104} INFO - [2022-03-20 17:06:36,082] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:36,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:06:36,173] {logging_mixin.py:104} INFO - [2022-03-20 17:06:36,173] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:06:36,212] {logging_mixin.py:104} INFO - [2022-03-20 17:06:36,211] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:06:36,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 17:07:06,871] {scheduler_job.py:182} INFO - Started process (PID=9668) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:06,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:07:06,880] {logging_mixin.py:104} INFO - [2022-03-20 17:07:06,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:06,925] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:06,969] {logging_mixin.py:104} INFO - [2022-03-20 17:07:06,969] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:07:07,008] {logging_mixin.py:104} INFO - [2022-03-20 17:07:07,008] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:07:07,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 17:07:37,796] {scheduler_job.py:182} INFO - Started process (PID=9700) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:37,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:07:37,804] {logging_mixin.py:104} INFO - [2022-03-20 17:07:37,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:37,848] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:07:37,888] {logging_mixin.py:104} INFO - [2022-03-20 17:07:37,888] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:07:37,927] {logging_mixin.py:104} INFO - [2022-03-20 17:07:37,927] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:07:37,944] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 17:08:08,657] {scheduler_job.py:182} INFO - Started process (PID=9732) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:08,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:08:08,664] {logging_mixin.py:104} INFO - [2022-03-20 17:08:08,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:08,711] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:08,751] {logging_mixin.py:104} INFO - [2022-03-20 17:08:08,751] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:08:08,795] {logging_mixin.py:104} INFO - [2022-03-20 17:08:08,794] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:08:08,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:08:39,418] {scheduler_job.py:182} INFO - Started process (PID=9764) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:39,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:08:39,426] {logging_mixin.py:104} INFO - [2022-03-20 17:08:39,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:39,480] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:08:39,527] {logging_mixin.py:104} INFO - [2022-03-20 17:08:39,526] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:08:39,568] {logging_mixin.py:104} INFO - [2022-03-20 17:08:39,567] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:08:39,584] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 17:09:10,130] {scheduler_job.py:182} INFO - Started process (PID=9796) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:10,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:09:10,136] {logging_mixin.py:104} INFO - [2022-03-20 17:09:10,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:10,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:10,221] {logging_mixin.py:104} INFO - [2022-03-20 17:09:10,220] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:09:10,258] {logging_mixin.py:104} INFO - [2022-03-20 17:09:10,258] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:09:10,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 17:09:40,920] {scheduler_job.py:182} INFO - Started process (PID=9828) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:40,925] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:09:40,927] {logging_mixin.py:104} INFO - [2022-03-20 17:09:40,927] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:40,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:09:41,012] {logging_mixin.py:104} INFO - [2022-03-20 17:09:41,011] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:09:41,049] {logging_mixin.py:104} INFO - [2022-03-20 17:09:41,049] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:09:41,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 17:10:11,625] {scheduler_job.py:182} INFO - Started process (PID=9858) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:11,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:10:11,633] {logging_mixin.py:104} INFO - [2022-03-20 17:10:11,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:11,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:11,725] {logging_mixin.py:104} INFO - [2022-03-20 17:10:11,725] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:10:11,766] {logging_mixin.py:104} INFO - [2022-03-20 17:10:11,766] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:10:11,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:10:42,416] {scheduler_job.py:182} INFO - Started process (PID=9882) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:42,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:10:42,423] {logging_mixin.py:104} INFO - [2022-03-20 17:10:42,422] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:42,471] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:10:42,516] {logging_mixin.py:104} INFO - [2022-03-20 17:10:42,515] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:10:42,557] {logging_mixin.py:104} INFO - [2022-03-20 17:10:42,556] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:10:42,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:11:13,347] {scheduler_job.py:182} INFO - Started process (PID=9910) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:13,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:11:13,354] {logging_mixin.py:104} INFO - [2022-03-20 17:11:13,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:13,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:13,443] {logging_mixin.py:104} INFO - [2022-03-20 17:11:13,442] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:11:13,480] {logging_mixin.py:104} INFO - [2022-03-20 17:11:13,480] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:11:13,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 17:11:44,300] {scheduler_job.py:182} INFO - Started process (PID=9942) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:44,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:11:44,308] {logging_mixin.py:104} INFO - [2022-03-20 17:11:44,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:44,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:11:44,398] {logging_mixin.py:104} INFO - [2022-03-20 17:11:44,398] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:11:44,436] {logging_mixin.py:104} INFO - [2022-03-20 17:11:44,436] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:11:44,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 17:12:15,192] {scheduler_job.py:182} INFO - Started process (PID=9974) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:15,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:12:15,199] {logging_mixin.py:104} INFO - [2022-03-20 17:12:15,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:15,245] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:15,285] {logging_mixin.py:104} INFO - [2022-03-20 17:12:15,284] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:12:15,322] {logging_mixin.py:104} INFO - [2022-03-20 17:12:15,322] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:12:15,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 17:12:45,940] {scheduler_job.py:182} INFO - Started process (PID=10006) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:45,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:12:45,948] {logging_mixin.py:104} INFO - [2022-03-20 17:12:45,948] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:45,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:12:46,035] {logging_mixin.py:104} INFO - [2022-03-20 17:12:46,034] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:12:46,075] {logging_mixin.py:104} INFO - [2022-03-20 17:12:46,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:12:46,091] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 17:13:16,746] {scheduler_job.py:182} INFO - Started process (PID=10038) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:16,750] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:13:16,753] {logging_mixin.py:104} INFO - [2022-03-20 17:13:16,753] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:16,800] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:16,843] {logging_mixin.py:104} INFO - [2022-03-20 17:13:16,842] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:13:16,880] {logging_mixin.py:104} INFO - [2022-03-20 17:13:16,880] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:13:16,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 17:13:47,643] {scheduler_job.py:182} INFO - Started process (PID=10070) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:47,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:13:47,651] {logging_mixin.py:104} INFO - [2022-03-20 17:13:47,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:47,699] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:13:47,740] {logging_mixin.py:104} INFO - [2022-03-20 17:13:47,740] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:13:47,778] {logging_mixin.py:104} INFO - [2022-03-20 17:13:47,778] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:13:47,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 17:14:18,481] {scheduler_job.py:182} INFO - Started process (PID=10102) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:18,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:14:18,489] {logging_mixin.py:104} INFO - [2022-03-20 17:14:18,488] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:18,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:18,581] {logging_mixin.py:104} INFO - [2022-03-20 17:14:18,580] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:14:18,621] {logging_mixin.py:104} INFO - [2022-03-20 17:14:18,620] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:14:18,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:14:50,402] {scheduler_job.py:182} INFO - Started process (PID=10132) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:50,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:14:50,408] {logging_mixin.py:104} INFO - [2022-03-20 17:14:50,408] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:50,460] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:14:50,500] {logging_mixin.py:104} INFO - [2022-03-20 17:14:50,500] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:14:50,539] {logging_mixin.py:104} INFO - [2022-03-20 17:14:50,538] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:14:50,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 17:15:21,062] {scheduler_job.py:182} INFO - Started process (PID=10150) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:21,066] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:15:21,069] {logging_mixin.py:104} INFO - [2022-03-20 17:15:21,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:21,121] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:21,165] {logging_mixin.py:104} INFO - [2022-03-20 17:15:21,164] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:15:21,207] {logging_mixin.py:104} INFO - [2022-03-20 17:15:21,207] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:15:21,224] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:15:52,046] {scheduler_job.py:182} INFO - Started process (PID=10178) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:52,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:15:52,055] {logging_mixin.py:104} INFO - [2022-03-20 17:15:52,055] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:52,102] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:15:52,144] {logging_mixin.py:104} INFO - [2022-03-20 17:15:52,143] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:15:52,182] {logging_mixin.py:104} INFO - [2022-03-20 17:15:52,182] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:15:52,198] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-20 17:16:22,822] {scheduler_job.py:182} INFO - Started process (PID=10210) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:22,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:16:22,831] {logging_mixin.py:104} INFO - [2022-03-20 17:16:22,830] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:22,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:22,921] {logging_mixin.py:104} INFO - [2022-03-20 17:16:22,921] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:16:22,959] {logging_mixin.py:104} INFO - [2022-03-20 17:16:22,958] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:16:22,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 17:16:53,553] {scheduler_job.py:182} INFO - Started process (PID=10242) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:53,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:16:53,561] {logging_mixin.py:104} INFO - [2022-03-20 17:16:53,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:53,608] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:16:53,651] {logging_mixin.py:104} INFO - [2022-03-20 17:16:53,650] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:16:53,692] {logging_mixin.py:104} INFO - [2022-03-20 17:16:53,692] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:16:53,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 17:17:24,419] {scheduler_job.py:182} INFO - Started process (PID=10274) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:24,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:17:24,427] {logging_mixin.py:104} INFO - [2022-03-20 17:17:24,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:24,478] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:24,520] {logging_mixin.py:104} INFO - [2022-03-20 17:17:24,519] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:17:24,558] {logging_mixin.py:104} INFO - [2022-03-20 17:17:24,558] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:17:24,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:17:55,400] {scheduler_job.py:182} INFO - Started process (PID=10306) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:55,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:17:55,408] {logging_mixin.py:104} INFO - [2022-03-20 17:17:55,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:55,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:17:55,495] {logging_mixin.py:104} INFO - [2022-03-20 17:17:55,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:17:55,533] {logging_mixin.py:104} INFO - [2022-03-20 17:17:55,532] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:17:55,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 17:18:26,245] {scheduler_job.py:182} INFO - Started process (PID=10338) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:26,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:18:26,255] {logging_mixin.py:104} INFO - [2022-03-20 17:18:26,255] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:26,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:26,348] {logging_mixin.py:104} INFO - [2022-03-20 17:18:26,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:18:26,390] {logging_mixin.py:104} INFO - [2022-03-20 17:18:26,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:18:26,406] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 17:18:57,079] {scheduler_job.py:182} INFO - Started process (PID=10370) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:57,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:18:57,087] {logging_mixin.py:104} INFO - [2022-03-20 17:18:57,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:57,132] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:18:57,176] {logging_mixin.py:104} INFO - [2022-03-20 17:18:57,176] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:18:57,215] {logging_mixin.py:104} INFO - [2022-03-20 17:18:57,214] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:18:57,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 17:19:27,749] {scheduler_job.py:182} INFO - Started process (PID=10400) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:27,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:19:27,756] {logging_mixin.py:104} INFO - [2022-03-20 17:19:27,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:27,808] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:27,855] {logging_mixin.py:104} INFO - [2022-03-20 17:19:27,854] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:19:27,896] {logging_mixin.py:104} INFO - [2022-03-20 17:19:27,895] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:19:27,913] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 17:19:58,664] {scheduler_job.py:182} INFO - Started process (PID=10424) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:58,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:19:58,670] {logging_mixin.py:104} INFO - [2022-03-20 17:19:58,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:58,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:19:58,762] {logging_mixin.py:104} INFO - [2022-03-20 17:19:58,762] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:19:58,802] {logging_mixin.py:104} INFO - [2022-03-20 17:19:58,802] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:19:58,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 17:20:29,554] {scheduler_job.py:182} INFO - Started process (PID=10452) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:20:29,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:20:29,561] {logging_mixin.py:104} INFO - [2022-03-20 17:20:29,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:20:29,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:20:29,647] {logging_mixin.py:104} INFO - [2022-03-20 17:20:29,647] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:20:29,684] {logging_mixin.py:104} INFO - [2022-03-20 17:20:29,684] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:20:29,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 17:21:00,420] {scheduler_job.py:182} INFO - Started process (PID=10484) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:00,425] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:21:00,428] {logging_mixin.py:104} INFO - [2022-03-20 17:21:00,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:00,479] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:00,519] {logging_mixin.py:104} INFO - [2022-03-20 17:21:00,519] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:21:00,557] {logging_mixin.py:104} INFO - [2022-03-20 17:21:00,557] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:21:00,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:21:31,190] {scheduler_job.py:182} INFO - Started process (PID=10516) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:31,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:21:31,197] {logging_mixin.py:104} INFO - [2022-03-20 17:21:31,197] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:31,247] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:21:31,291] {logging_mixin.py:104} INFO - [2022-03-20 17:21:31,291] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:21:31,335] {logging_mixin.py:104} INFO - [2022-03-20 17:21:31,335] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:21:31,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:22:01,562] {scheduler_job.py:182} INFO - Started process (PID=10548) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:01,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:22:01,571] {logging_mixin.py:104} INFO - [2022-03-20 17:22:01,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:01,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:01,663] {logging_mixin.py:104} INFO - [2022-03-20 17:22:01,663] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:22:01,704] {logging_mixin.py:104} INFO - [2022-03-20 17:22:01,703] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:22:01,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:22:32,437] {scheduler_job.py:182} INFO - Started process (PID=10580) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:32,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:22:32,445] {logging_mixin.py:104} INFO - [2022-03-20 17:22:32,444] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:32,494] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:22:32,538] {logging_mixin.py:104} INFO - [2022-03-20 17:22:32,538] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:22:32,579] {logging_mixin.py:104} INFO - [2022-03-20 17:22:32,579] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:22:32,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:23:03,104] {scheduler_job.py:182} INFO - Started process (PID=10612) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:03,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:23:03,112] {logging_mixin.py:104} INFO - [2022-03-20 17:23:03,112] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:03,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:03,198] {logging_mixin.py:104} INFO - [2022-03-20 17:23:03,198] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:23:03,241] {logging_mixin.py:104} INFO - [2022-03-20 17:23:03,241] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:23:03,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 17:23:33,876] {scheduler_job.py:182} INFO - Started process (PID=10644) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:33,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:23:33,883] {logging_mixin.py:104} INFO - [2022-03-20 17:23:33,882] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:33,927] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:23:33,970] {logging_mixin.py:104} INFO - [2022-03-20 17:23:33,969] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:23:34,010] {logging_mixin.py:104} INFO - [2022-03-20 17:23:34,010] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:23:34,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 17:24:05,564] {scheduler_job.py:182} INFO - Started process (PID=10674) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:05,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:24:05,570] {logging_mixin.py:104} INFO - [2022-03-20 17:24:05,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:05,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:05,667] {logging_mixin.py:104} INFO - [2022-03-20 17:24:05,666] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:24:05,708] {logging_mixin.py:104} INFO - [2022-03-20 17:24:05,708] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:24:05,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:24:36,430] {scheduler_job.py:182} INFO - Started process (PID=10698) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:36,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:24:36,436] {logging_mixin.py:104} INFO - [2022-03-20 17:24:36,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:36,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:24:36,527] {logging_mixin.py:104} INFO - [2022-03-20 17:24:36,527] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:24:36,569] {logging_mixin.py:104} INFO - [2022-03-20 17:24:36,569] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:24:36,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:25:07,290] {scheduler_job.py:182} INFO - Started process (PID=10726) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:25:07,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:25:07,299] {logging_mixin.py:104} INFO - [2022-03-20 17:25:07,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:25:07,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:25:07,392] {logging_mixin.py:104} INFO - [2022-03-20 17:25:07,391] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:25:07,431] {logging_mixin.py:104} INFO - [2022-03-20 17:25:07,431] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:25:07,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 17:28:30,045] {scheduler_job.py:182} INFO - Started process (PID=10768) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:28:30,058] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:28:30,068] {logging_mixin.py:104} INFO - [2022-03-20 17:28:30,067] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:28:30,134] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:28:30,186] {logging_mixin.py:104} INFO - [2022-03-20 17:28:30,185] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:28:30,250] {logging_mixin.py:104} INFO - [2022-03-20 17:28:30,249] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:28:30,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.238 seconds
[2022-03-20 17:29:00,553] {scheduler_job.py:182} INFO - Started process (PID=10793) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:00,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:29:00,568] {logging_mixin.py:104} INFO - [2022-03-20 17:29:00,567] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:00,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:00,740] {logging_mixin.py:104} INFO - [2022-03-20 17:29:00,740] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:29:00,793] {logging_mixin.py:104} INFO - [2022-03-20 17:29:00,792] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:29:00,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.287 seconds
[2022-03-20 17:29:31,320] {scheduler_job.py:182} INFO - Started process (PID=10824) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:31,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:29:31,327] {logging_mixin.py:104} INFO - [2022-03-20 17:29:31,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:31,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:29:31,422] {logging_mixin.py:104} INFO - [2022-03-20 17:29:31,421] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:29:31,465] {logging_mixin.py:104} INFO - [2022-03-20 17:29:31,465] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:29:31,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:30:02,066] {scheduler_job.py:182} INFO - Started process (PID=10856) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:02,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:30:02,072] {logging_mixin.py:104} INFO - [2022-03-20 17:30:02,072] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:02,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:02,167] {logging_mixin.py:104} INFO - [2022-03-20 17:30:02,166] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:30:02,209] {logging_mixin.py:104} INFO - [2022-03-20 17:30:02,208] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:30:02,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 17:30:32,879] {scheduler_job.py:182} INFO - Started process (PID=10889) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:32,885] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:30:32,888] {logging_mixin.py:104} INFO - [2022-03-20 17:30:32,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:32,936] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:30:32,982] {logging_mixin.py:104} INFO - [2022-03-20 17:30:32,981] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:30:33,026] {logging_mixin.py:104} INFO - [2022-03-20 17:30:33,025] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:30:33,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 17:31:03,686] {scheduler_job.py:182} INFO - Started process (PID=10921) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:03,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:31:03,695] {logging_mixin.py:104} INFO - [2022-03-20 17:31:03,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:03,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:03,789] {logging_mixin.py:104} INFO - [2022-03-20 17:31:03,789] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:31:03,831] {logging_mixin.py:104} INFO - [2022-03-20 17:31:03,830] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:31:03,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:31:34,462] {scheduler_job.py:182} INFO - Started process (PID=10952) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:34,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:31:34,469] {logging_mixin.py:104} INFO - [2022-03-20 17:31:34,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:34,520] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:31:34,568] {logging_mixin.py:104} INFO - [2022-03-20 17:31:34,567] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:31:34,614] {logging_mixin.py:104} INFO - [2022-03-20 17:31:34,613] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:31:34,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 17:32:05,126] {scheduler_job.py:182} INFO - Started process (PID=10985) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:05,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:32:05,134] {logging_mixin.py:104} INFO - [2022-03-20 17:32:05,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:05,186] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:05,234] {logging_mixin.py:104} INFO - [2022-03-20 17:32:05,233] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:32:05,276] {logging_mixin.py:104} INFO - [2022-03-20 17:32:05,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:32:05,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:32:38,196] {scheduler_job.py:182} INFO - Started process (PID=11018) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:38,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:32:38,203] {logging_mixin.py:104} INFO - [2022-03-20 17:32:38,202] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:38,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:32:38,300] {logging_mixin.py:104} INFO - [2022-03-20 17:32:38,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:32:38,341] {logging_mixin.py:104} INFO - [2022-03-20 17:32:38,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:32:38,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 17:33:08,757] {scheduler_job.py:182} INFO - Started process (PID=11042) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:08,761] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:33:08,763] {logging_mixin.py:104} INFO - [2022-03-20 17:33:08,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:08,813] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:08,862] {logging_mixin.py:104} INFO - [2022-03-20 17:33:08,862] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:33:08,908] {logging_mixin.py:104} INFO - [2022-03-20 17:33:08,907] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:33:08,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:33:39,177] {scheduler_job.py:182} INFO - Started process (PID=11070) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:39,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:33:39,184] {logging_mixin.py:104} INFO - [2022-03-20 17:33:39,183] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:39,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:33:39,269] {logging_mixin.py:104} INFO - [2022-03-20 17:33:39,269] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:33:39,306] {logging_mixin.py:104} INFO - [2022-03-20 17:33:39,306] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:33:39,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 17:34:09,638] {scheduler_job.py:182} INFO - Started process (PID=11093) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:09,643] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:34:09,646] {logging_mixin.py:104} INFO - [2022-03-20 17:34:09,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:09,698] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:09,749] {logging_mixin.py:104} INFO - [2022-03-20 17:34:09,748] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:34:09,791] {logging_mixin.py:104} INFO - [2022-03-20 17:34:09,791] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:34:09,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 17:34:40,368] {scheduler_job.py:182} INFO - Started process (PID=11125) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:40,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:34:40,376] {logging_mixin.py:104} INFO - [2022-03-20 17:34:40,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:40,426] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:34:40,473] {logging_mixin.py:104} INFO - [2022-03-20 17:34:40,472] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:34:40,514] {logging_mixin.py:104} INFO - [2022-03-20 17:34:40,513] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:34:40,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 17:35:11,319] {scheduler_job.py:182} INFO - Started process (PID=11156) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:11,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:35:11,327] {logging_mixin.py:104} INFO - [2022-03-20 17:35:11,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:11,374] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:11,422] {logging_mixin.py:104} INFO - [2022-03-20 17:35:11,422] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:35:11,465] {logging_mixin.py:104} INFO - [2022-03-20 17:35:11,464] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:35:11,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:35:42,084] {scheduler_job.py:182} INFO - Started process (PID=11189) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:42,089] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:35:42,091] {logging_mixin.py:104} INFO - [2022-03-20 17:35:42,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:42,141] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:35:42,189] {logging_mixin.py:104} INFO - [2022-03-20 17:35:42,188] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:35:42,233] {logging_mixin.py:104} INFO - [2022-03-20 17:35:42,233] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:35:42,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 17:36:12,887] {scheduler_job.py:182} INFO - Started process (PID=11221) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:12,892] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:36:12,895] {logging_mixin.py:104} INFO - [2022-03-20 17:36:12,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:12,950] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:12,998] {logging_mixin.py:104} INFO - [2022-03-20 17:36:12,998] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:36:13,043] {logging_mixin.py:104} INFO - [2022-03-20 17:36:13,042] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:36:13,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 17:36:43,536] {scheduler_job.py:182} INFO - Started process (PID=11253) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:43,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:36:43,548] {logging_mixin.py:104} INFO - [2022-03-20 17:36:43,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:43,598] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:36:43,645] {logging_mixin.py:104} INFO - [2022-03-20 17:36:43,645] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:36:43,688] {logging_mixin.py:104} INFO - [2022-03-20 17:36:43,687] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:36:43,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 17:37:15,569] {scheduler_job.py:182} INFO - Started process (PID=11286) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:15,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:37:15,576] {logging_mixin.py:104} INFO - [2022-03-20 17:37:15,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:15,623] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:15,668] {logging_mixin.py:104} INFO - [2022-03-20 17:37:15,667] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:37:15,709] {logging_mixin.py:104} INFO - [2022-03-20 17:37:15,709] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:37:15,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:37:46,165] {scheduler_job.py:182} INFO - Started process (PID=11310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:46,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:37:46,172] {logging_mixin.py:104} INFO - [2022-03-20 17:37:46,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:46,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:37:46,264] {logging_mixin.py:104} INFO - [2022-03-20 17:37:46,263] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:37:46,305] {logging_mixin.py:104} INFO - [2022-03-20 17:37:46,304] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:37:46,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 17:38:17,212] {scheduler_job.py:182} INFO - Started process (PID=11335) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:17,216] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:38:17,219] {logging_mixin.py:104} INFO - [2022-03-20 17:38:17,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:17,269] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:17,316] {logging_mixin.py:104} INFO - [2022-03-20 17:38:17,316] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:38:17,359] {logging_mixin.py:104} INFO - [2022-03-20 17:38:17,358] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:38:17,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 17:38:48,145] {scheduler_job.py:182} INFO - Started process (PID=11366) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:48,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:38:48,152] {logging_mixin.py:104} INFO - [2022-03-20 17:38:48,152] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:48,204] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:38:48,250] {logging_mixin.py:104} INFO - [2022-03-20 17:38:48,249] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:38:48,294] {logging_mixin.py:104} INFO - [2022-03-20 17:38:48,293] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:38:48,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 17:39:18,874] {scheduler_job.py:182} INFO - Started process (PID=11398) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:18,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:39:18,881] {logging_mixin.py:104} INFO - [2022-03-20 17:39:18,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:18,934] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:18,981] {logging_mixin.py:104} INFO - [2022-03-20 17:39:18,981] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:39:19,024] {logging_mixin.py:104} INFO - [2022-03-20 17:39:19,024] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:39:19,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 17:39:49,754] {scheduler_job.py:182} INFO - Started process (PID=11431) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:49,759] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:39:49,762] {logging_mixin.py:104} INFO - [2022-03-20 17:39:49,761] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:49,811] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:39:49,860] {logging_mixin.py:104} INFO - [2022-03-20 17:39:49,859] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:39:49,901] {logging_mixin.py:104} INFO - [2022-03-20 17:39:49,901] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:39:49,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 17:40:20,514] {scheduler_job.py:182} INFO - Started process (PID=11462) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:20,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:40:20,524] {logging_mixin.py:104} INFO - [2022-03-20 17:40:20,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:20,570] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:20,619] {logging_mixin.py:104} INFO - [2022-03-20 17:40:20,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:40:20,660] {logging_mixin.py:104} INFO - [2022-03-20 17:40:20,660] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:40:20,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 17:40:51,206] {scheduler_job.py:182} INFO - Started process (PID=11495) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:51,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:40:51,212] {logging_mixin.py:104} INFO - [2022-03-20 17:40:51,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:51,260] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:40:51,308] {logging_mixin.py:104} INFO - [2022-03-20 17:40:51,307] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:40:51,349] {logging_mixin.py:104} INFO - [2022-03-20 17:40:51,349] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:40:51,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:41:21,836] {scheduler_job.py:182} INFO - Started process (PID=11527) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:21,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:41:21,844] {logging_mixin.py:104} INFO - [2022-03-20 17:41:21,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:21,891] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:21,938] {logging_mixin.py:104} INFO - [2022-03-20 17:41:21,938] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:41:21,980] {logging_mixin.py:104} INFO - [2022-03-20 17:41:21,980] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:41:21,997] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 17:41:52,644] {scheduler_job.py:182} INFO - Started process (PID=11560) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:52,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:41:52,650] {logging_mixin.py:104} INFO - [2022-03-20 17:41:52,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:52,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:41:52,747] {logging_mixin.py:104} INFO - [2022-03-20 17:41:52,747] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:41:52,789] {logging_mixin.py:104} INFO - [2022-03-20 17:41:52,788] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:41:52,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:42:23,389] {scheduler_job.py:182} INFO - Started process (PID=11584) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:23,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:42:23,397] {logging_mixin.py:104} INFO - [2022-03-20 17:42:23,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:23,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:23,487] {logging_mixin.py:104} INFO - [2022-03-20 17:42:23,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:42:23,528] {logging_mixin.py:104} INFO - [2022-03-20 17:42:23,528] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:42:23,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 17:42:53,639] {scheduler_job.py:182} INFO - Started process (PID=11612) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:53,643] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:42:53,645] {logging_mixin.py:104} INFO - [2022-03-20 17:42:53,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:53,689] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:42:53,731] {logging_mixin.py:104} INFO - [2022-03-20 17:42:53,730] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:42:53,770] {logging_mixin.py:104} INFO - [2022-03-20 17:42:53,770] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:42:53,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 17:43:24,310] {scheduler_job.py:182} INFO - Started process (PID=11641) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:24,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:43:24,320] {logging_mixin.py:104} INFO - [2022-03-20 17:43:24,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:24,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:24,418] {logging_mixin.py:104} INFO - [2022-03-20 17:43:24,417] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:43:24,460] {logging_mixin.py:104} INFO - [2022-03-20 17:43:24,459] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:43:24,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:43:55,068] {scheduler_job.py:182} INFO - Started process (PID=11672) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:55,071] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:43:55,074] {logging_mixin.py:104} INFO - [2022-03-20 17:43:55,073] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:55,124] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:43:55,172] {logging_mixin.py:104} INFO - [2022-03-20 17:43:55,171] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:43:55,217] {logging_mixin.py:104} INFO - [2022-03-20 17:43:55,216] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:43:55,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:44:25,838] {scheduler_job.py:182} INFO - Started process (PID=11704) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:44:25,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:44:25,848] {logging_mixin.py:104} INFO - [2022-03-20 17:44:25,847] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:44:25,898] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:44:25,944] {logging_mixin.py:104} INFO - [2022-03-20 17:44:25,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:44:25,986] {logging_mixin.py:104} INFO - [2022-03-20 17:44:25,985] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:44:26,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:46:28,035] {scheduler_job.py:182} INFO - Started process (PID=11736) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:46:28,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:46:28,042] {logging_mixin.py:104} INFO - [2022-03-20 17:46:28,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:46:28,097] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:46:28,152] {logging_mixin.py:104} INFO - [2022-03-20 17:46:28,151] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:46:28,204] {logging_mixin.py:104} INFO - [2022-03-20 17:46:28,203] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:46:28,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.197 seconds
[2022-03-20 17:48:15,965] {scheduler_job.py:182} INFO - Started process (PID=11768) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:15,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:48:15,978] {logging_mixin.py:104} INFO - [2022-03-20 17:48:15,977] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:16,058] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:16,141] {logging_mixin.py:104} INFO - [2022-03-20 17:48:16,140] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:48:16,212] {logging_mixin.py:104} INFO - [2022-03-20 17:48:16,211] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:48:16,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.274 seconds
[2022-03-20 17:48:46,437] {scheduler_job.py:182} INFO - Started process (PID=11787) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:46,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:48:46,443] {logging_mixin.py:104} INFO - [2022-03-20 17:48:46,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:46,490] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:48:46,535] {logging_mixin.py:104} INFO - [2022-03-20 17:48:46,535] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:48:46,580] {logging_mixin.py:104} INFO - [2022-03-20 17:48:46,579] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:48:46,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 17:49:17,232] {scheduler_job.py:182} INFO - Started process (PID=11819) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:17,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:49:17,239] {logging_mixin.py:104} INFO - [2022-03-20 17:49:17,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:17,286] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:17,335] {logging_mixin.py:104} INFO - [2022-03-20 17:49:17,334] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:49:17,377] {logging_mixin.py:104} INFO - [2022-03-20 17:49:17,377] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:49:17,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:49:48,022] {scheduler_job.py:182} INFO - Started process (PID=11850) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:48,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:49:48,028] {logging_mixin.py:104} INFO - [2022-03-20 17:49:48,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:48,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:49:48,126] {logging_mixin.py:104} INFO - [2022-03-20 17:49:48,125] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:49:48,168] {logging_mixin.py:104} INFO - [2022-03-20 17:49:48,167] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:49:48,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 17:50:18,837] {scheduler_job.py:182} INFO - Started process (PID=11882) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:18,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:50:18,843] {logging_mixin.py:104} INFO - [2022-03-20 17:50:18,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:18,894] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:18,942] {logging_mixin.py:104} INFO - [2022-03-20 17:50:18,941] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:50:18,987] {logging_mixin.py:104} INFO - [2022-03-20 17:50:18,987] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:50:19,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:50:49,723] {scheduler_job.py:182} INFO - Started process (PID=11914) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:49,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:50:49,730] {logging_mixin.py:104} INFO - [2022-03-20 17:50:49,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:49,779] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:50:49,825] {logging_mixin.py:104} INFO - [2022-03-20 17:50:49,825] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:50:49,869] {logging_mixin.py:104} INFO - [2022-03-20 17:50:49,868] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:50:49,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:51:20,480] {scheduler_job.py:182} INFO - Started process (PID=11946) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:20,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:51:20,487] {logging_mixin.py:104} INFO - [2022-03-20 17:51:20,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:20,543] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:20,589] {logging_mixin.py:104} INFO - [2022-03-20 17:51:20,589] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:51:20,631] {logging_mixin.py:104} INFO - [2022-03-20 17:51:20,631] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:51:20,648] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 17:51:51,148] {scheduler_job.py:182} INFO - Started process (PID=11978) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:51,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:51:51,154] {logging_mixin.py:104} INFO - [2022-03-20 17:51:51,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:51,202] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:51:51,249] {logging_mixin.py:104} INFO - [2022-03-20 17:51:51,249] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:51:51,293] {logging_mixin.py:104} INFO - [2022-03-20 17:51:51,292] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:51:51,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:52:22,134] {scheduler_job.py:182} INFO - Started process (PID=12004) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:22,138] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:52:22,140] {logging_mixin.py:104} INFO - [2022-03-20 17:52:22,140] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:22,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:22,233] {logging_mixin.py:104} INFO - [2022-03-20 17:52:22,233] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:52:22,275] {logging_mixin.py:104} INFO - [2022-03-20 17:52:22,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:52:22,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 17:52:52,510] {scheduler_job.py:182} INFO - Started process (PID=12028) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:52,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:52:52,516] {logging_mixin.py:104} INFO - [2022-03-20 17:52:52,516] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:52,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:52:52,613] {logging_mixin.py:104} INFO - [2022-03-20 17:52:52,613] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:52:52,655] {logging_mixin.py:104} INFO - [2022-03-20 17:52:52,654] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:52:52,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 17:53:23,316] {scheduler_job.py:182} INFO - Started process (PID=12060) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:23,319] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:53:23,322] {logging_mixin.py:104} INFO - [2022-03-20 17:53:23,322] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:23,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:23,418] {logging_mixin.py:104} INFO - [2022-03-20 17:53:23,417] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:53:23,462] {logging_mixin.py:104} INFO - [2022-03-20 17:53:23,461] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:53:23,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 17:53:54,306] {scheduler_job.py:182} INFO - Started process (PID=12092) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:54,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:53:54,314] {logging_mixin.py:104} INFO - [2022-03-20 17:53:54,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:54,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:53:54,415] {logging_mixin.py:104} INFO - [2022-03-20 17:53:54,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:53:54,460] {logging_mixin.py:104} INFO - [2022-03-20 17:53:54,459] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:53:54,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 17:54:25,115] {scheduler_job.py:182} INFO - Started process (PID=12125) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:25,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:54:25,122] {logging_mixin.py:104} INFO - [2022-03-20 17:54:25,121] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:25,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:25,220] {logging_mixin.py:104} INFO - [2022-03-20 17:54:25,219] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:54:25,261] {logging_mixin.py:104} INFO - [2022-03-20 17:54:25,260] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:54:25,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 17:54:56,047] {scheduler_job.py:182} INFO - Started process (PID=12156) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:56,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:54:56,054] {logging_mixin.py:104} INFO - [2022-03-20 17:54:56,054] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:56,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:54:56,187] {logging_mixin.py:104} INFO - [2022-03-20 17:54:56,187] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:54:56,232] {logging_mixin.py:104} INFO - [2022-03-20 17:54:56,231] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:54:56,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.209 seconds
[2022-03-20 17:55:27,142] {scheduler_job.py:182} INFO - Started process (PID=12188) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:27,147] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:55:27,150] {logging_mixin.py:104} INFO - [2022-03-20 17:55:27,149] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:27,205] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:27,255] {logging_mixin.py:104} INFO - [2022-03-20 17:55:27,255] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:55:27,301] {logging_mixin.py:104} INFO - [2022-03-20 17:55:27,301] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:55:27,320] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 17:55:58,116] {scheduler_job.py:182} INFO - Started process (PID=12220) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:58,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:55:58,123] {logging_mixin.py:104} INFO - [2022-03-20 17:55:58,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:58,174] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:55:58,222] {logging_mixin.py:104} INFO - [2022-03-20 17:55:58,222] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:55:58,268] {logging_mixin.py:104} INFO - [2022-03-20 17:55:58,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:55:58,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 17:56:30,247] {scheduler_job.py:182} INFO - Started process (PID=12256) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:56:30,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:56:30,254] {logging_mixin.py:104} INFO - [2022-03-20 17:56:30,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:56:30,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:56:30,350] {logging_mixin.py:104} INFO - [2022-03-20 17:56:30,349] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:56:30,395] {logging_mixin.py:104} INFO - [2022-03-20 17:56:30,394] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:56:30,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 17:57:01,306] {scheduler_job.py:182} INFO - Started process (PID=12278) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:01,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:57:01,314] {logging_mixin.py:104} INFO - [2022-03-20 17:57:01,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:01,362] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:01,410] {logging_mixin.py:104} INFO - [2022-03-20 17:57:01,409] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:57:01,452] {logging_mixin.py:104} INFO - [2022-03-20 17:57:01,452] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:57:01,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 17:57:31,934] {scheduler_job.py:182} INFO - Started process (PID=12302) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:31,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:57:31,943] {logging_mixin.py:104} INFO - [2022-03-20 17:57:31,942] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:31,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:57:32,046] {logging_mixin.py:104} INFO - [2022-03-20 17:57:32,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:57:32,090] {logging_mixin.py:104} INFO - [2022-03-20 17:57:32,090] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:57:32,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 17:58:02,958] {scheduler_job.py:182} INFO - Started process (PID=12335) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:02,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:58:02,966] {logging_mixin.py:104} INFO - [2022-03-20 17:58:02,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:03,020] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:03,073] {logging_mixin.py:104} INFO - [2022-03-20 17:58:03,072] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:58:03,120] {logging_mixin.py:104} INFO - [2022-03-20 17:58:03,120] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:58:03,140] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.190 seconds
[2022-03-20 17:58:33,937] {scheduler_job.py:182} INFO - Started process (PID=12366) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:33,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:58:33,945] {logging_mixin.py:104} INFO - [2022-03-20 17:58:33,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:33,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:58:34,046] {logging_mixin.py:104} INFO - [2022-03-20 17:58:34,046] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:58:34,092] {logging_mixin.py:104} INFO - [2022-03-20 17:58:34,091] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:58:34,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 17:59:04,672] {scheduler_job.py:182} INFO - Started process (PID=12399) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:04,676] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:59:04,680] {logging_mixin.py:104} INFO - [2022-03-20 17:59:04,679] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:04,736] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:04,785] {logging_mixin.py:104} INFO - [2022-03-20 17:59:04,784] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:59:04,829] {logging_mixin.py:104} INFO - [2022-03-20 17:59:04,828] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:59:04,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 17:59:35,413] {scheduler_job.py:182} INFO - Started process (PID=12430) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:35,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 17:59:35,420] {logging_mixin.py:104} INFO - [2022-03-20 17:59:35,419] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:35,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 17:59:35,517] {logging_mixin.py:104} INFO - [2022-03-20 17:59:35,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 17:59:35,559] {logging_mixin.py:104} INFO - [2022-03-20 17:59:35,559] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 17:59:35,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:00:06,417] {scheduler_job.py:182} INFO - Started process (PID=12463) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:06,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:00:06,426] {logging_mixin.py:104} INFO - [2022-03-20 18:00:06,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:06,478] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:06,525] {logging_mixin.py:104} INFO - [2022-03-20 18:00:06,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:00:06,569] {logging_mixin.py:104} INFO - [2022-03-20 18:00:06,569] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:00:06,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:00:37,474] {scheduler_job.py:182} INFO - Started process (PID=12494) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:37,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:00:37,481] {logging_mixin.py:104} INFO - [2022-03-20 18:00:37,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:37,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:00:37,576] {logging_mixin.py:104} INFO - [2022-03-20 18:00:37,576] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:00:37,620] {logging_mixin.py:104} INFO - [2022-03-20 18:00:37,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:00:37,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:01:10,419] {scheduler_job.py:182} INFO - Started process (PID=12528) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:10,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:01:10,425] {logging_mixin.py:104} INFO - [2022-03-20 18:01:10,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:10,476] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:10,516] {logging_mixin.py:104} INFO - [2022-03-20 18:01:10,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:01:10,554] {logging_mixin.py:104} INFO - [2022-03-20 18:01:10,554] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:01:10,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 18:01:41,566] {scheduler_job.py:182} INFO - Started process (PID=12552) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:41,570] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:01:41,573] {logging_mixin.py:104} INFO - [2022-03-20 18:01:41,572] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:41,623] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:01:41,671] {logging_mixin.py:104} INFO - [2022-03-20 18:01:41,670] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:01:41,718] {logging_mixin.py:104} INFO - [2022-03-20 18:01:41,717] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:01:41,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 18:02:12,283] {scheduler_job.py:182} INFO - Started process (PID=12571) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:12,287] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:02:12,290] {logging_mixin.py:104} INFO - [2022-03-20 18:02:12,289] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:12,341] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:12,388] {logging_mixin.py:104} INFO - [2022-03-20 18:02:12,387] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:02:12,431] {logging_mixin.py:104} INFO - [2022-03-20 18:02:12,430] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:02:12,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:02:42,990] {scheduler_job.py:182} INFO - Started process (PID=12602) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:42,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:02:42,997] {logging_mixin.py:104} INFO - [2022-03-20 18:02:42,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:43,046] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:02:43,093] {logging_mixin.py:104} INFO - [2022-03-20 18:02:43,093] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:02:43,140] {logging_mixin.py:104} INFO - [2022-03-20 18:02:43,139] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:02:43,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:03:13,684] {scheduler_job.py:182} INFO - Started process (PID=12634) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:13,689] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:03:13,691] {logging_mixin.py:104} INFO - [2022-03-20 18:03:13,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:13,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:13,789] {logging_mixin.py:104} INFO - [2022-03-20 18:03:13,788] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:03:13,834] {logging_mixin.py:104} INFO - [2022-03-20 18:03:13,833] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:03:13,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:03:44,648] {scheduler_job.py:182} INFO - Started process (PID=12667) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:44,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:03:44,658] {logging_mixin.py:104} INFO - [2022-03-20 18:03:44,657] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:44,707] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:03:44,754] {logging_mixin.py:104} INFO - [2022-03-20 18:03:44,753] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:03:44,799] {logging_mixin.py:104} INFO - [2022-03-20 18:03:44,798] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:03:44,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:04:15,489] {scheduler_job.py:182} INFO - Started process (PID=12699) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:15,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:04:15,495] {logging_mixin.py:104} INFO - [2022-03-20 18:04:15,495] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:15,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:15,595] {logging_mixin.py:104} INFO - [2022-03-20 18:04:15,594] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:04:15,639] {logging_mixin.py:104} INFO - [2022-03-20 18:04:15,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:04:15,658] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:04:46,675] {scheduler_job.py:182} INFO - Started process (PID=12731) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:46,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:04:46,682] {logging_mixin.py:104} INFO - [2022-03-20 18:04:46,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:46,738] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:04:46,790] {logging_mixin.py:104} INFO - [2022-03-20 18:04:46,789] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:04:46,838] {logging_mixin.py:104} INFO - [2022-03-20 18:04:46,837] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:04:46,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 18:05:17,549] {scheduler_job.py:182} INFO - Started process (PID=12762) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:17,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:05:17,558] {logging_mixin.py:104} INFO - [2022-03-20 18:05:17,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:17,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:17,656] {logging_mixin.py:104} INFO - [2022-03-20 18:05:17,655] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:05:17,698] {logging_mixin.py:104} INFO - [2022-03-20 18:05:17,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:05:17,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:05:49,468] {scheduler_job.py:182} INFO - Started process (PID=12796) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:49,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:05:49,475] {logging_mixin.py:104} INFO - [2022-03-20 18:05:49,475] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:49,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:05:49,577] {logging_mixin.py:104} INFO - [2022-03-20 18:05:49,576] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:05:49,619] {logging_mixin.py:104} INFO - [2022-03-20 18:05:49,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:05:49,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:06:20,609] {scheduler_job.py:182} INFO - Started process (PID=12826) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:20,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:06:20,616] {logging_mixin.py:104} INFO - [2022-03-20 18:06:20,616] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:20,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:20,708] {logging_mixin.py:104} INFO - [2022-03-20 18:06:20,708] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:06:20,751] {logging_mixin.py:104} INFO - [2022-03-20 18:06:20,751] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:06:20,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 18:06:50,870] {scheduler_job.py:182} INFO - Started process (PID=12854) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:50,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:06:50,876] {logging_mixin.py:104} INFO - [2022-03-20 18:06:50,876] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:50,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:06:50,965] {logging_mixin.py:104} INFO - [2022-03-20 18:06:50,965] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:06:51,003] {logging_mixin.py:104} INFO - [2022-03-20 18:06:51,003] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:06:51,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 18:07:21,451] {scheduler_job.py:182} INFO - Started process (PID=12876) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:21,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:07:21,458] {logging_mixin.py:104} INFO - [2022-03-20 18:07:21,458] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:21,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:21,563] {logging_mixin.py:104} INFO - [2022-03-20 18:07:21,563] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:07:21,608] {logging_mixin.py:104} INFO - [2022-03-20 18:07:21,607] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:07:21,625] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 18:07:52,380] {scheduler_job.py:182} INFO - Started process (PID=12909) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:52,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:07:52,388] {logging_mixin.py:104} INFO - [2022-03-20 18:07:52,387] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:52,438] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:07:52,487] {logging_mixin.py:104} INFO - [2022-03-20 18:07:52,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:07:52,529] {logging_mixin.py:104} INFO - [2022-03-20 18:07:52,528] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:07:52,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:08:23,290] {scheduler_job.py:182} INFO - Started process (PID=12941) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:23,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:08:23,296] {logging_mixin.py:104} INFO - [2022-03-20 18:08:23,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:23,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:23,396] {logging_mixin.py:104} INFO - [2022-03-20 18:08:23,395] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:08:23,438] {logging_mixin.py:104} INFO - [2022-03-20 18:08:23,438] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:08:23,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:08:54,194] {scheduler_job.py:182} INFO - Started process (PID=12972) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:54,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:08:54,200] {logging_mixin.py:104} INFO - [2022-03-20 18:08:54,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:54,251] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:08:54,296] {logging_mixin.py:104} INFO - [2022-03-20 18:08:54,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:08:54,340] {logging_mixin.py:104} INFO - [2022-03-20 18:08:54,339] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:08:54,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:09:24,961] {scheduler_job.py:182} INFO - Started process (PID=13004) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:24,966] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:09:24,968] {logging_mixin.py:104} INFO - [2022-03-20 18:09:24,968] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:25,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:25,069] {logging_mixin.py:104} INFO - [2022-03-20 18:09:25,068] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:09:25,113] {logging_mixin.py:104} INFO - [2022-03-20 18:09:25,112] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:09:25,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 18:09:55,851] {scheduler_job.py:182} INFO - Started process (PID=13037) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:55,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:09:55,857] {logging_mixin.py:104} INFO - [2022-03-20 18:09:55,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:55,908] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:09:55,954] {logging_mixin.py:104} INFO - [2022-03-20 18:09:55,954] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:09:55,995] {logging_mixin.py:104} INFO - [2022-03-20 18:09:55,995] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:09:56,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:10:28,974] {scheduler_job.py:182} INFO - Started process (PID=13072) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:10:28,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:10:28,981] {logging_mixin.py:104} INFO - [2022-03-20 18:10:28,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:10:29,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:10:29,077] {logging_mixin.py:104} INFO - [2022-03-20 18:10:29,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:10:29,118] {logging_mixin.py:104} INFO - [2022-03-20 18:10:29,117] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:10:29,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 18:11:00,036] {scheduler_job.py:182} INFO - Started process (PID=13100) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:00,040] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:11:00,042] {logging_mixin.py:104} INFO - [2022-03-20 18:11:00,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:00,089] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:00,133] {logging_mixin.py:104} INFO - [2022-03-20 18:11:00,132] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:11:00,173] {logging_mixin.py:104} INFO - [2022-03-20 18:11:00,172] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:11:00,189] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 18:11:30,290] {scheduler_job.py:182} INFO - Started process (PID=13128) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:30,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:11:30,296] {logging_mixin.py:104} INFO - [2022-03-20 18:11:30,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:30,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:11:30,379] {logging_mixin.py:104} INFO - [2022-03-20 18:11:30,379] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:11:30,416] {logging_mixin.py:104} INFO - [2022-03-20 18:11:30,416] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:11:30,432] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 18:12:00,806] {scheduler_job.py:182} INFO - Started process (PID=13151) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:00,811] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:12:00,814] {logging_mixin.py:104} INFO - [2022-03-20 18:12:00,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:00,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:00,911] {logging_mixin.py:104} INFO - [2022-03-20 18:12:00,911] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:12:00,955] {logging_mixin.py:104} INFO - [2022-03-20 18:12:00,954] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:12:00,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:12:31,590] {scheduler_job.py:182} INFO - Started process (PID=13183) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:31,596] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:12:31,598] {logging_mixin.py:104} INFO - [2022-03-20 18:12:31,598] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:31,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:12:31,696] {logging_mixin.py:104} INFO - [2022-03-20 18:12:31,696] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:12:31,739] {logging_mixin.py:104} INFO - [2022-03-20 18:12:31,738] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:12:31,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:13:02,525] {scheduler_job.py:182} INFO - Started process (PID=13214) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:02,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:13:02,533] {logging_mixin.py:104} INFO - [2022-03-20 18:13:02,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:02,586] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:02,635] {logging_mixin.py:104} INFO - [2022-03-20 18:13:02,635] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:13:02,683] {logging_mixin.py:104} INFO - [2022-03-20 18:13:02,682] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:13:02,702] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 18:13:33,567] {scheduler_job.py:182} INFO - Started process (PID=13247) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:33,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:13:33,574] {logging_mixin.py:104} INFO - [2022-03-20 18:13:33,573] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:33,623] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:13:33,671] {logging_mixin.py:104} INFO - [2022-03-20 18:13:33,670] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:13:33,715] {logging_mixin.py:104} INFO - [2022-03-20 18:13:33,714] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:13:33,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:14:04,270] {scheduler_job.py:182} INFO - Started process (PID=13278) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:04,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:14:04,277] {logging_mixin.py:104} INFO - [2022-03-20 18:14:04,276] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:04,328] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:04,374] {logging_mixin.py:104} INFO - [2022-03-20 18:14:04,373] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:14:04,417] {logging_mixin.py:104} INFO - [2022-03-20 18:14:04,416] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:14:04,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:14:35,072] {scheduler_job.py:182} INFO - Started process (PID=13310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:35,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:14:35,081] {logging_mixin.py:104} INFO - [2022-03-20 18:14:35,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:35,135] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:14:35,187] {logging_mixin.py:104} INFO - [2022-03-20 18:14:35,187] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:14:35,238] {logging_mixin.py:104} INFO - [2022-03-20 18:14:35,237] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:14:35,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-20 18:15:08,340] {scheduler_job.py:182} INFO - Started process (PID=13346) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:08,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:15:08,348] {logging_mixin.py:104} INFO - [2022-03-20 18:15:08,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:08,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:08,440] {logging_mixin.py:104} INFO - [2022-03-20 18:15:08,439] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:15:08,482] {logging_mixin.py:104} INFO - [2022-03-20 18:15:08,482] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:15:08,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 18:15:39,319] {scheduler_job.py:182} INFO - Started process (PID=13374) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:39,323] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:15:39,326] {logging_mixin.py:104} INFO - [2022-03-20 18:15:39,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:39,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:15:39,432] {logging_mixin.py:104} INFO - [2022-03-20 18:15:39,432] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:15:39,475] {logging_mixin.py:104} INFO - [2022-03-20 18:15:39,475] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:15:39,493] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 18:16:09,739] {scheduler_job.py:182} INFO - Started process (PID=13402) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:09,743] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:16:09,745] {logging_mixin.py:104} INFO - [2022-03-20 18:16:09,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:09,791] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:09,833] {logging_mixin.py:104} INFO - [2022-03-20 18:16:09,833] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:16:09,874] {logging_mixin.py:104} INFO - [2022-03-20 18:16:09,874] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:16:09,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 18:16:40,389] {scheduler_job.py:182} INFO - Started process (PID=13424) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:40,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:16:40,396] {logging_mixin.py:104} INFO - [2022-03-20 18:16:40,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:40,449] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:16:40,498] {logging_mixin.py:104} INFO - [2022-03-20 18:16:40,498] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:16:40,545] {logging_mixin.py:104} INFO - [2022-03-20 18:16:40,544] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:16:40,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 18:17:11,094] {scheduler_job.py:182} INFO - Started process (PID=13457) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:11,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:17:11,100] {logging_mixin.py:104} INFO - [2022-03-20 18:17:11,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:11,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:11,199] {logging_mixin.py:104} INFO - [2022-03-20 18:17:11,198] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:17:11,241] {logging_mixin.py:104} INFO - [2022-03-20 18:17:11,240] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:17:11,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:17:41,828] {scheduler_job.py:182} INFO - Started process (PID=13488) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:41,832] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:17:41,835] {logging_mixin.py:104} INFO - [2022-03-20 18:17:41,834] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:41,887] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:17:41,935] {logging_mixin.py:104} INFO - [2022-03-20 18:17:41,934] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:17:41,977] {logging_mixin.py:104} INFO - [2022-03-20 18:17:41,976] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:17:41,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:18:12,798] {scheduler_job.py:182} INFO - Started process (PID=13521) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:12,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:18:12,806] {logging_mixin.py:104} INFO - [2022-03-20 18:18:12,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:12,856] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:12,903] {logging_mixin.py:104} INFO - [2022-03-20 18:18:12,902] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:18:12,946] {logging_mixin.py:104} INFO - [2022-03-20 18:18:12,946] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:18:12,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:18:43,714] {scheduler_job.py:182} INFO - Started process (PID=13553) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:43,719] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:18:43,722] {logging_mixin.py:104} INFO - [2022-03-20 18:18:43,722] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:43,770] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:18:43,815] {logging_mixin.py:104} INFO - [2022-03-20 18:18:43,814] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:18:43,858] {logging_mixin.py:104} INFO - [2022-03-20 18:18:43,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:18:43,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:19:14,476] {scheduler_job.py:182} INFO - Started process (PID=13585) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:14,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:19:14,483] {logging_mixin.py:104} INFO - [2022-03-20 18:19:14,483] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:14,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:14,580] {logging_mixin.py:104} INFO - [2022-03-20 18:19:14,579] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:19:14,623] {logging_mixin.py:104} INFO - [2022-03-20 18:19:14,623] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:19:14,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:19:46,834] {scheduler_job.py:182} INFO - Started process (PID=13618) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:46,838] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:19:46,841] {logging_mixin.py:104} INFO - [2022-03-20 18:19:46,841] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:46,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:19:46,932] {logging_mixin.py:104} INFO - [2022-03-20 18:19:46,931] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:19:46,973] {logging_mixin.py:104} INFO - [2022-03-20 18:19:46,972] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:19:46,990] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 18:20:17,128] {scheduler_job.py:182} INFO - Started process (PID=13642) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:17,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:20:17,134] {logging_mixin.py:104} INFO - [2022-03-20 18:20:17,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:17,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:17,225] {logging_mixin.py:104} INFO - [2022-03-20 18:20:17,224] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:20:17,266] {logging_mixin.py:104} INFO - [2022-03-20 18:20:17,266] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:20:17,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 18:20:47,847] {scheduler_job.py:182} INFO - Started process (PID=13667) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:47,851] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:20:47,854] {logging_mixin.py:104} INFO - [2022-03-20 18:20:47,853] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:47,905] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:20:47,952] {logging_mixin.py:104} INFO - [2022-03-20 18:20:47,952] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:20:47,998] {logging_mixin.py:104} INFO - [2022-03-20 18:20:47,997] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:20:48,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:21:18,419] {scheduler_job.py:182} INFO - Started process (PID=13698) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:18,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:21:18,427] {logging_mixin.py:104} INFO - [2022-03-20 18:21:18,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:18,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:18,525] {logging_mixin.py:104} INFO - [2022-03-20 18:21:18,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:21:18,568] {logging_mixin.py:104} INFO - [2022-03-20 18:21:18,567] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:21:18,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:21:49,150] {scheduler_job.py:182} INFO - Started process (PID=13731) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:49,155] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:21:49,158] {logging_mixin.py:104} INFO - [2022-03-20 18:21:49,158] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:49,209] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:21:49,255] {logging_mixin.py:104} INFO - [2022-03-20 18:21:49,255] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:21:49,297] {logging_mixin.py:104} INFO - [2022-03-20 18:21:49,297] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:21:49,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:22:19,907] {scheduler_job.py:182} INFO - Started process (PID=13763) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:19,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:22:19,914] {logging_mixin.py:104} INFO - [2022-03-20 18:22:19,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:19,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:20,013] {logging_mixin.py:104} INFO - [2022-03-20 18:22:20,012] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:22:20,055] {logging_mixin.py:104} INFO - [2022-03-20 18:22:20,054] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:22:20,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:22:50,584] {scheduler_job.py:182} INFO - Started process (PID=13794) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:50,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:22:50,591] {logging_mixin.py:104} INFO - [2022-03-20 18:22:50,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:50,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:22:50,690] {logging_mixin.py:104} INFO - [2022-03-20 18:22:50,690] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:22:50,734] {logging_mixin.py:104} INFO - [2022-03-20 18:22:50,733] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:22:50,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:23:21,182] {scheduler_job.py:182} INFO - Started process (PID=13826) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:21,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:23:21,191] {logging_mixin.py:104} INFO - [2022-03-20 18:23:21,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:21,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:21,304] {logging_mixin.py:104} INFO - [2022-03-20 18:23:21,303] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:23:21,353] {logging_mixin.py:104} INFO - [2022-03-20 18:23:21,353] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:23:21,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.199 seconds
[2022-03-20 18:23:52,003] {scheduler_job.py:182} INFO - Started process (PID=13858) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:52,007] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:23:52,010] {logging_mixin.py:104} INFO - [2022-03-20 18:23:52,010] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:52,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:23:52,112] {logging_mixin.py:104} INFO - [2022-03-20 18:23:52,112] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:23:52,155] {logging_mixin.py:104} INFO - [2022-03-20 18:23:52,154] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:23:52,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:24:23,904] {scheduler_job.py:182} INFO - Started process (PID=13892) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:23,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:24:23,912] {logging_mixin.py:104} INFO - [2022-03-20 18:24:23,911] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:23,964] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:24,011] {logging_mixin.py:104} INFO - [2022-03-20 18:24:24,011] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:24:24,054] {logging_mixin.py:104} INFO - [2022-03-20 18:24:24,053] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:24:24,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:24:54,452] {scheduler_job.py:182} INFO - Started process (PID=13916) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:54,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:24:54,459] {logging_mixin.py:104} INFO - [2022-03-20 18:24:54,459] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:54,507] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:24:54,555] {logging_mixin.py:104} INFO - [2022-03-20 18:24:54,554] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:24:54,597] {logging_mixin.py:104} INFO - [2022-03-20 18:24:54,596] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:24:54,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 18:25:25,173] {scheduler_job.py:182} INFO - Started process (PID=13941) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:25,178] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:25:25,181] {logging_mixin.py:104} INFO - [2022-03-20 18:25:25,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:25,231] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:25,280] {logging_mixin.py:104} INFO - [2022-03-20 18:25:25,280] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:25:25,322] {logging_mixin.py:104} INFO - [2022-03-20 18:25:25,322] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:25:25,341] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:25:55,927] {scheduler_job.py:182} INFO - Started process (PID=13973) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:55,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:25:55,936] {logging_mixin.py:104} INFO - [2022-03-20 18:25:55,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:55,986] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:25:56,033] {logging_mixin.py:104} INFO - [2022-03-20 18:25:56,032] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:25:56,077] {logging_mixin.py:104} INFO - [2022-03-20 18:25:56,077] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:25:56,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:26:26,682] {scheduler_job.py:182} INFO - Started process (PID=14004) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:26,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:26:26,690] {logging_mixin.py:104} INFO - [2022-03-20 18:26:26,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:26,747] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:26,800] {logging_mixin.py:104} INFO - [2022-03-20 18:26:26,799] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:26:26,846] {logging_mixin.py:104} INFO - [2022-03-20 18:26:26,845] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:26:26,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 18:26:57,355] {scheduler_job.py:182} INFO - Started process (PID=14036) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:57,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:26:57,362] {logging_mixin.py:104} INFO - [2022-03-20 18:26:57,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:57,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:26:57,462] {logging_mixin.py:104} INFO - [2022-03-20 18:26:57,462] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:26:57,506] {logging_mixin.py:104} INFO - [2022-03-20 18:26:57,506] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:26:57,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:27:27,937] {scheduler_job.py:182} INFO - Started process (PID=14068) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:27,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:27:27,946] {logging_mixin.py:104} INFO - [2022-03-20 18:27:27,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:27,998] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:28,049] {logging_mixin.py:104} INFO - [2022-03-20 18:27:28,048] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:27:28,095] {logging_mixin.py:104} INFO - [2022-03-20 18:27:28,094] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:27:28,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 18:27:58,566] {scheduler_job.py:182} INFO - Started process (PID=14100) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:58,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:27:58,576] {logging_mixin.py:104} INFO - [2022-03-20 18:27:58,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:58,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:27:58,671] {logging_mixin.py:104} INFO - [2022-03-20 18:27:58,671] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:27:58,714] {logging_mixin.py:104} INFO - [2022-03-20 18:27:58,713] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:27:58,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 18:28:29,137] {scheduler_job.py:182} INFO - Started process (PID=14132) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:28:29,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:28:29,144] {logging_mixin.py:104} INFO - [2022-03-20 18:28:29,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:28:29,192] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:28:29,240] {logging_mixin.py:104} INFO - [2022-03-20 18:28:29,240] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:28:29,282] {logging_mixin.py:104} INFO - [2022-03-20 18:28:29,282] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:28:29,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:29:01,233] {scheduler_job.py:182} INFO - Started process (PID=14166) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:01,237] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:29:01,240] {logging_mixin.py:104} INFO - [2022-03-20 18:29:01,240] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:01,286] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:01,331] {logging_mixin.py:104} INFO - [2022-03-20 18:29:01,331] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:29:01,373] {logging_mixin.py:104} INFO - [2022-03-20 18:29:01,373] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:29:01,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 18:29:31,650] {scheduler_job.py:182} INFO - Started process (PID=14190) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:31,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:29:31,656] {logging_mixin.py:104} INFO - [2022-03-20 18:29:31,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:31,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:29:31,749] {logging_mixin.py:104} INFO - [2022-03-20 18:29:31,749] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:29:31,791] {logging_mixin.py:104} INFO - [2022-03-20 18:29:31,790] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:29:31,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 18:30:02,535] {scheduler_job.py:182} INFO - Started process (PID=14215) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:02,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:30:02,542] {logging_mixin.py:104} INFO - [2022-03-20 18:30:02,542] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:02,598] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:02,649] {logging_mixin.py:104} INFO - [2022-03-20 18:30:02,648] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:30:02,694] {logging_mixin.py:104} INFO - [2022-03-20 18:30:02,693] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:30:02,712] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 18:30:33,384] {scheduler_job.py:182} INFO - Started process (PID=14246) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:33,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:30:33,394] {logging_mixin.py:104} INFO - [2022-03-20 18:30:33,394] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:33,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:30:33,495] {logging_mixin.py:104} INFO - [2022-03-20 18:30:33,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:30:33,538] {logging_mixin.py:104} INFO - [2022-03-20 18:30:33,537] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:30:33,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 18:31:04,153] {scheduler_job.py:182} INFO - Started process (PID=14279) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:04,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:31:04,162] {logging_mixin.py:104} INFO - [2022-03-20 18:31:04,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:04,212] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:04,281] {logging_mixin.py:104} INFO - [2022-03-20 18:31:04,281] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:31:04,327] {logging_mixin.py:104} INFO - [2022-03-20 18:31:04,327] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:31:04,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.201 seconds
[2022-03-20 18:31:34,842] {scheduler_job.py:182} INFO - Started process (PID=14310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:34,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:31:34,850] {logging_mixin.py:104} INFO - [2022-03-20 18:31:34,850] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:34,907] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:31:34,956] {logging_mixin.py:104} INFO - [2022-03-20 18:31:34,956] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:31:35,001] {logging_mixin.py:104} INFO - [2022-03-20 18:31:35,000] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:31:35,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 18:32:05,490] {scheduler_job.py:182} INFO - Started process (PID=14343) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:05,494] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:32:05,496] {logging_mixin.py:104} INFO - [2022-03-20 18:32:05,496] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:05,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:05,595] {logging_mixin.py:104} INFO - [2022-03-20 18:32:05,595] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:32:05,640] {logging_mixin.py:104} INFO - [2022-03-20 18:32:05,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:32:05,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:32:36,155] {scheduler_job.py:182} INFO - Started process (PID=14374) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:36,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:32:36,162] {logging_mixin.py:104} INFO - [2022-03-20 18:32:36,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:36,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:32:36,263] {logging_mixin.py:104} INFO - [2022-03-20 18:32:36,262] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:32:36,309] {logging_mixin.py:104} INFO - [2022-03-20 18:32:36,308] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:32:36,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 18:33:06,753] {scheduler_job.py:182} INFO - Started process (PID=14406) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:06,756] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:33:06,759] {logging_mixin.py:104} INFO - [2022-03-20 18:33:06,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:06,808] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:06,854] {logging_mixin.py:104} INFO - [2022-03-20 18:33:06,853] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:33:06,896] {logging_mixin.py:104} INFO - [2022-03-20 18:33:06,896] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:33:06,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 18:33:38,670] {scheduler_job.py:182} INFO - Started process (PID=14440) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:38,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:33:38,677] {logging_mixin.py:104} INFO - [2022-03-20 18:33:38,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:38,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:33:38,769] {logging_mixin.py:104} INFO - [2022-03-20 18:33:38,768] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:33:38,811] {logging_mixin.py:104} INFO - [2022-03-20 18:33:38,810] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:33:38,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 18:34:09,232] {scheduler_job.py:182} INFO - Started process (PID=14464) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:09,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:34:09,238] {logging_mixin.py:104} INFO - [2022-03-20 18:34:09,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:09,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:09,330] {logging_mixin.py:104} INFO - [2022-03-20 18:34:09,330] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:34:09,371] {logging_mixin.py:104} INFO - [2022-03-20 18:34:09,371] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:34:09,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 18:34:40,057] {scheduler_job.py:182} INFO - Started process (PID=14488) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:40,061] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:34:40,064] {logging_mixin.py:104} INFO - [2022-03-20 18:34:40,063] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:40,116] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:34:40,168] {logging_mixin.py:104} INFO - [2022-03-20 18:34:40,168] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:34:40,214] {logging_mixin.py:104} INFO - [2022-03-20 18:34:40,214] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:34:40,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 18:35:10,910] {scheduler_job.py:182} INFO - Started process (PID=14520) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:10,917] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:35:10,922] {logging_mixin.py:104} INFO - [2022-03-20 18:35:10,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:10,977] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:11,027] {logging_mixin.py:104} INFO - [2022-03-20 18:35:11,026] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:35:11,071] {logging_mixin.py:104} INFO - [2022-03-20 18:35:11,070] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:35:11,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 18:35:41,709] {scheduler_job.py:182} INFO - Started process (PID=14552) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:41,714] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:35:41,716] {logging_mixin.py:104} INFO - [2022-03-20 18:35:41,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:41,769] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:35:41,818] {logging_mixin.py:104} INFO - [2022-03-20 18:35:41,817] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:35:41,862] {logging_mixin.py:104} INFO - [2022-03-20 18:35:41,861] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:35:41,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 18:36:12,509] {scheduler_job.py:182} INFO - Started process (PID=14585) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:12,515] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:36:12,518] {logging_mixin.py:104} INFO - [2022-03-20 18:36:12,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:12,575] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:12,625] {logging_mixin.py:104} INFO - [2022-03-20 18:36:12,625] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:36:12,671] {logging_mixin.py:104} INFO - [2022-03-20 18:36:12,670] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:36:12,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-20 18:36:43,160] {scheduler_job.py:182} INFO - Started process (PID=14616) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:43,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:36:43,168] {logging_mixin.py:104} INFO - [2022-03-20 18:36:43,167] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:43,218] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:36:43,265] {logging_mixin.py:104} INFO - [2022-03-20 18:36:43,265] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:36:43,310] {logging_mixin.py:104} INFO - [2022-03-20 18:36:43,310] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:36:43,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 18:37:13,968] {scheduler_job.py:182} INFO - Started process (PID=14648) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:13,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:37:13,975] {logging_mixin.py:104} INFO - [2022-03-20 18:37:13,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:14,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:14,071] {logging_mixin.py:104} INFO - [2022-03-20 18:37:14,070] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:37:14,115] {logging_mixin.py:104} INFO - [2022-03-20 18:37:14,114] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:37:14,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:37:44,820] {scheduler_job.py:182} INFO - Started process (PID=14680) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:44,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:37:44,831] {logging_mixin.py:104} INFO - [2022-03-20 18:37:44,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:44,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:37:44,940] {logging_mixin.py:104} INFO - [2022-03-20 18:37:44,939] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:37:44,989] {logging_mixin.py:104} INFO - [2022-03-20 18:37:44,988] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:37:45,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-20 18:38:16,987] {scheduler_job.py:182} INFO - Started process (PID=14714) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:16,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:38:16,994] {logging_mixin.py:104} INFO - [2022-03-20 18:38:16,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:17,042] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:17,092] {logging_mixin.py:104} INFO - [2022-03-20 18:38:17,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:38:17,138] {logging_mixin.py:104} INFO - [2022-03-20 18:38:17,137] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:38:17,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 18:38:47,571] {scheduler_job.py:182} INFO - Started process (PID=14738) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:47,575] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:38:47,578] {logging_mixin.py:104} INFO - [2022-03-20 18:38:47,577] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:47,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:38:47,674] {logging_mixin.py:104} INFO - [2022-03-20 18:38:47,673] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:38:47,717] {logging_mixin.py:104} INFO - [2022-03-20 18:38:47,717] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:38:47,736] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:39:18,214] {scheduler_job.py:182} INFO - Started process (PID=14763) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:18,219] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:39:18,222] {logging_mixin.py:104} INFO - [2022-03-20 18:39:18,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:18,272] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:18,320] {logging_mixin.py:104} INFO - [2022-03-20 18:39:18,319] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:39:18,367] {logging_mixin.py:104} INFO - [2022-03-20 18:39:18,366] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:39:18,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 18:39:48,969] {scheduler_job.py:182} INFO - Started process (PID=14795) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:48,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:39:48,977] {logging_mixin.py:104} INFO - [2022-03-20 18:39:48,976] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:49,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:39:49,078] {logging_mixin.py:104} INFO - [2022-03-20 18:39:49,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:39:49,121] {logging_mixin.py:104} INFO - [2022-03-20 18:39:49,121] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:39:49,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:40:19,617] {scheduler_job.py:182} INFO - Started process (PID=14826) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:19,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:40:19,624] {logging_mixin.py:104} INFO - [2022-03-20 18:40:19,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:19,674] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:19,720] {logging_mixin.py:104} INFO - [2022-03-20 18:40:19,719] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:40:19,764] {logging_mixin.py:104} INFO - [2022-03-20 18:40:19,763] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:40:19,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:40:50,152] {scheduler_job.py:182} INFO - Started process (PID=14859) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:50,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:40:50,159] {logging_mixin.py:104} INFO - [2022-03-20 18:40:50,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:50,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:40:50,260] {logging_mixin.py:104} INFO - [2022-03-20 18:40:50,259] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:40:50,304] {logging_mixin.py:104} INFO - [2022-03-20 18:40:50,304] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:40:50,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 18:41:20,867] {scheduler_job.py:182} INFO - Started process (PID=14890) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:20,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:41:20,875] {logging_mixin.py:104} INFO - [2022-03-20 18:41:20,875] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:20,927] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:20,974] {logging_mixin.py:104} INFO - [2022-03-20 18:41:20,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:41:21,017] {logging_mixin.py:104} INFO - [2022-03-20 18:41:21,017] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:41:21,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 18:41:51,691] {scheduler_job.py:182} INFO - Started process (PID=14922) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:51,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:41:51,699] {logging_mixin.py:104} INFO - [2022-03-20 18:41:51,698] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:51,751] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:41:51,800] {logging_mixin.py:104} INFO - [2022-03-20 18:41:51,799] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:41:51,846] {logging_mixin.py:104} INFO - [2022-03-20 18:41:51,846] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:41:51,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 18:42:22,464] {scheduler_job.py:182} INFO - Started process (PID=14955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:22,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:42:22,472] {logging_mixin.py:104} INFO - [2022-03-20 18:42:22,472] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:22,529] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:22,577] {logging_mixin.py:104} INFO - [2022-03-20 18:42:22,577] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:42:22,624] {logging_mixin.py:104} INFO - [2022-03-20 18:42:22,623] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:42:22,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 18:42:54,594] {scheduler_job.py:182} INFO - Started process (PID=14988) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:54,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:42:54,600] {logging_mixin.py:104} INFO - [2022-03-20 18:42:54,600] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:54,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:42:54,692] {logging_mixin.py:104} INFO - [2022-03-20 18:42:54,692] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:42:54,733] {logging_mixin.py:104} INFO - [2022-03-20 18:42:54,733] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:42:54,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 18:43:25,142] {scheduler_job.py:182} INFO - Started process (PID=15012) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:25,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:43:25,149] {logging_mixin.py:104} INFO - [2022-03-20 18:43:25,149] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:25,201] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:25,247] {logging_mixin.py:104} INFO - [2022-03-20 18:43:25,247] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:43:25,290] {logging_mixin.py:104} INFO - [2022-03-20 18:43:25,289] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:43:25,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 18:43:56,092] {scheduler_job.py:182} INFO - Started process (PID=15036) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:56,096] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:43:56,098] {logging_mixin.py:104} INFO - [2022-03-20 18:43:56,098] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:56,151] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:43:56,198] {logging_mixin.py:104} INFO - [2022-03-20 18:43:56,197] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:43:56,239] {logging_mixin.py:104} INFO - [2022-03-20 18:43:56,239] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:43:56,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:44:26,889] {scheduler_job.py:182} INFO - Started process (PID=15068) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:26,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:44:26,896] {logging_mixin.py:104} INFO - [2022-03-20 18:44:26,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:26,946] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:26,995] {logging_mixin.py:104} INFO - [2022-03-20 18:44:26,994] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:44:27,037] {logging_mixin.py:104} INFO - [2022-03-20 18:44:27,037] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:44:27,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:44:57,646] {scheduler_job.py:182} INFO - Started process (PID=15101) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:57,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:44:57,652] {logging_mixin.py:104} INFO - [2022-03-20 18:44:57,652] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:57,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:44:57,748] {logging_mixin.py:104} INFO - [2022-03-20 18:44:57,748] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:44:57,792] {logging_mixin.py:104} INFO - [2022-03-20 18:44:57,791] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:44:57,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:45:28,497] {scheduler_job.py:182} INFO - Started process (PID=15132) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:28,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:45:28,505] {logging_mixin.py:104} INFO - [2022-03-20 18:45:28,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:28,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:28,610] {logging_mixin.py:104} INFO - [2022-03-20 18:45:28,609] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:45:28,655] {logging_mixin.py:104} INFO - [2022-03-20 18:45:28,654] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:45:28,672] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 18:45:59,254] {scheduler_job.py:182} INFO - Started process (PID=15164) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:59,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:45:59,261] {logging_mixin.py:104} INFO - [2022-03-20 18:45:59,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:59,311] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:45:59,360] {logging_mixin.py:104} INFO - [2022-03-20 18:45:59,359] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:45:59,402] {logging_mixin.py:104} INFO - [2022-03-20 18:45:59,401] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:45:59,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 18:46:30,168] {scheduler_job.py:182} INFO - Started process (PID=15196) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:46:30,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:46:30,174] {logging_mixin.py:104} INFO - [2022-03-20 18:46:30,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:46:30,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:46:30,270] {logging_mixin.py:104} INFO - [2022-03-20 18:46:30,270] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:46:30,312] {logging_mixin.py:104} INFO - [2022-03-20 18:46:30,312] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:46:30,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 18:47:00,997] {scheduler_job.py:182} INFO - Started process (PID=15229) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:01,004] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:47:01,007] {logging_mixin.py:104} INFO - [2022-03-20 18:47:01,007] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:01,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:01,114] {logging_mixin.py:104} INFO - [2022-03-20 18:47:01,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:47:01,162] {logging_mixin.py:104} INFO - [2022-03-20 18:47:01,161] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:47:01,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 18:47:33,006] {scheduler_job.py:182} INFO - Started process (PID=15262) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:33,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:47:33,013] {logging_mixin.py:104} INFO - [2022-03-20 18:47:33,012] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:33,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:47:33,113] {logging_mixin.py:104} INFO - [2022-03-20 18:47:33,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:47:33,156] {logging_mixin.py:104} INFO - [2022-03-20 18:47:33,156] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:47:33,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:48:03,633] {scheduler_job.py:182} INFO - Started process (PID=15286) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:03,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:48:03,640] {logging_mixin.py:104} INFO - [2022-03-20 18:48:03,639] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:03,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:03,738] {logging_mixin.py:104} INFO - [2022-03-20 18:48:03,738] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:48:03,784] {logging_mixin.py:104} INFO - [2022-03-20 18:48:03,784] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:48:03,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 18:48:34,547] {scheduler_job.py:182} INFO - Started process (PID=15310) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:34,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:48:34,556] {logging_mixin.py:104} INFO - [2022-03-20 18:48:34,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:34,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:48:34,653] {logging_mixin.py:104} INFO - [2022-03-20 18:48:34,653] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:48:34,700] {logging_mixin.py:104} INFO - [2022-03-20 18:48:34,700] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:48:34,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 18:49:05,453] {scheduler_job.py:182} INFO - Started process (PID=15343) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:05,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:49:05,459] {logging_mixin.py:104} INFO - [2022-03-20 18:49:05,458] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:05,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:05,564] {logging_mixin.py:104} INFO - [2022-03-20 18:49:05,563] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:49:05,609] {logging_mixin.py:104} INFO - [2022-03-20 18:49:05,608] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:49:05,626] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 18:49:36,311] {scheduler_job.py:182} INFO - Started process (PID=15374) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:36,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:49:36,318] {logging_mixin.py:104} INFO - [2022-03-20 18:49:36,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:36,370] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:49:36,417] {logging_mixin.py:104} INFO - [2022-03-20 18:49:36,417] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:49:36,459] {logging_mixin.py:104} INFO - [2022-03-20 18:49:36,459] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:49:36,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 18:50:07,195] {scheduler_job.py:182} INFO - Started process (PID=15406) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:07,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:50:07,203] {logging_mixin.py:104} INFO - [2022-03-20 18:50:07,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:07,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:07,309] {logging_mixin.py:104} INFO - [2022-03-20 18:50:07,309] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:50:07,354] {logging_mixin.py:104} INFO - [2022-03-20 18:50:07,353] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:50:07,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 18:50:38,143] {scheduler_job.py:182} INFO - Started process (PID=15438) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:38,148] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:50:38,151] {logging_mixin.py:104} INFO - [2022-03-20 18:50:38,151] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:38,207] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:50:38,256] {logging_mixin.py:104} INFO - [2022-03-20 18:50:38,255] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:50:38,299] {logging_mixin.py:104} INFO - [2022-03-20 18:50:38,299] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:50:38,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 18:51:08,947] {scheduler_job.py:182} INFO - Started process (PID=15470) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:08,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:51:08,953] {logging_mixin.py:104} INFO - [2022-03-20 18:51:08,953] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:09,001] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:09,048] {logging_mixin.py:104} INFO - [2022-03-20 18:51:09,047] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:51:09,091] {logging_mixin.py:104} INFO - [2022-03-20 18:51:09,091] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:51:09,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 18:51:39,973] {scheduler_job.py:182} INFO - Started process (PID=15503) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:39,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:51:39,982] {logging_mixin.py:104} INFO - [2022-03-20 18:51:39,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:40,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:51:40,079] {logging_mixin.py:104} INFO - [2022-03-20 18:51:40,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:51:40,121] {logging_mixin.py:104} INFO - [2022-03-20 18:51:40,121] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:51:40,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 18:52:11,899] {scheduler_job.py:182} INFO - Started process (PID=15536) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:11,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:52:11,905] {logging_mixin.py:104} INFO - [2022-03-20 18:52:11,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:11,956] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:12,003] {logging_mixin.py:104} INFO - [2022-03-20 18:52:12,003] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:52:12,045] {logging_mixin.py:104} INFO - [2022-03-20 18:52:12,044] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:52:12,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:52:43,192] {scheduler_job.py:182} INFO - Started process (PID=15566) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:43,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:52:43,199] {logging_mixin.py:104} INFO - [2022-03-20 18:52:43,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:43,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:52:43,301] {logging_mixin.py:104} INFO - [2022-03-20 18:52:43,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:52:43,345] {logging_mixin.py:104} INFO - [2022-03-20 18:52:43,345] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:52:43,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 18:53:13,470] {scheduler_job.py:182} INFO - Started process (PID=15594) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:13,474] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:53:13,477] {logging_mixin.py:104} INFO - [2022-03-20 18:53:13,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:13,525] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:13,568] {logging_mixin.py:104} INFO - [2022-03-20 18:53:13,568] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:53:13,606] {logging_mixin.py:104} INFO - [2022-03-20 18:53:13,606] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:53:13,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 18:53:43,996] {scheduler_job.py:182} INFO - Started process (PID=15617) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:44,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:53:44,003] {logging_mixin.py:104} INFO - [2022-03-20 18:53:44,002] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:44,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:53:44,102] {logging_mixin.py:104} INFO - [2022-03-20 18:53:44,101] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:53:44,143] {logging_mixin.py:104} INFO - [2022-03-20 18:53:44,142] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:53:44,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 18:54:14,762] {scheduler_job.py:182} INFO - Started process (PID=15648) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:14,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:54:14,771] {logging_mixin.py:104} INFO - [2022-03-20 18:54:14,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:14,823] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:14,868] {logging_mixin.py:104} INFO - [2022-03-20 18:54:14,868] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:54:14,914] {logging_mixin.py:104} INFO - [2022-03-20 18:54:14,913] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:54:14,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:54:45,682] {scheduler_job.py:182} INFO - Started process (PID=15681) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:45,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:54:45,689] {logging_mixin.py:104} INFO - [2022-03-20 18:54:45,688] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:45,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:54:45,790] {logging_mixin.py:104} INFO - [2022-03-20 18:54:45,789] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:54:45,833] {logging_mixin.py:104} INFO - [2022-03-20 18:54:45,833] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:54:45,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:55:16,567] {scheduler_job.py:182} INFO - Started process (PID=15713) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:16,572] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:55:16,575] {logging_mixin.py:104} INFO - [2022-03-20 18:55:16,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:16,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:16,685] {logging_mixin.py:104} INFO - [2022-03-20 18:55:16,684] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:55:16,730] {logging_mixin.py:104} INFO - [2022-03-20 18:55:16,729] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:55:16,748] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-20 18:55:47,528] {scheduler_job.py:182} INFO - Started process (PID=15744) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:47,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:55:47,536] {logging_mixin.py:104} INFO - [2022-03-20 18:55:47,536] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:47,591] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:55:47,642] {logging_mixin.py:104} INFO - [2022-03-20 18:55:47,642] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:55:47,690] {logging_mixin.py:104} INFO - [2022-03-20 18:55:47,690] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:55:47,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-20 18:56:18,373] {scheduler_job.py:182} INFO - Started process (PID=15776) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:18,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:56:18,379] {logging_mixin.py:104} INFO - [2022-03-20 18:56:18,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:18,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:18,480] {logging_mixin.py:104} INFO - [2022-03-20 18:56:18,480] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:56:18,526] {logging_mixin.py:104} INFO - [2022-03-20 18:56:18,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:56:18,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 18:56:51,359] {scheduler_job.py:182} INFO - Started process (PID=15808) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:51,363] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:56:51,366] {logging_mixin.py:104} INFO - [2022-03-20 18:56:51,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:51,416] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:56:51,463] {logging_mixin.py:104} INFO - [2022-03-20 18:56:51,462] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:56:51,506] {logging_mixin.py:104} INFO - [2022-03-20 18:56:51,505] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:56:51,522] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:57:22,669] {scheduler_job.py:182} INFO - Started process (PID=15840) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:22,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:57:22,677] {logging_mixin.py:104} INFO - [2022-03-20 18:57:22,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:22,728] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:22,772] {logging_mixin.py:104} INFO - [2022-03-20 18:57:22,771] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:57:22,814] {logging_mixin.py:104} INFO - [2022-03-20 18:57:22,813] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:57:22,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 18:57:52,917] {scheduler_job.py:182} INFO - Started process (PID=15868) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:52,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:57:52,923] {logging_mixin.py:104} INFO - [2022-03-20 18:57:52,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:52,976] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:57:53,027] {logging_mixin.py:104} INFO - [2022-03-20 18:57:53,026] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:57:53,066] {logging_mixin.py:104} INFO - [2022-03-20 18:57:53,066] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:57:53,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 18:58:23,559] {scheduler_job.py:182} INFO - Started process (PID=15890) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:23,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:58:23,567] {logging_mixin.py:104} INFO - [2022-03-20 18:58:23,566] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:23,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:23,665] {logging_mixin.py:104} INFO - [2022-03-20 18:58:23,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:58:23,712] {logging_mixin.py:104} INFO - [2022-03-20 18:58:23,712] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:58:23,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 18:58:54,624] {scheduler_job.py:182} INFO - Started process (PID=15922) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:54,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:58:54,632] {logging_mixin.py:104} INFO - [2022-03-20 18:58:54,631] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:54,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:58:54,730] {logging_mixin.py:104} INFO - [2022-03-20 18:58:54,730] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:58:54,775] {logging_mixin.py:104} INFO - [2022-03-20 18:58:54,774] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:58:54,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 18:59:25,523] {scheduler_job.py:182} INFO - Started process (PID=15955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:25,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:59:25,530] {logging_mixin.py:104} INFO - [2022-03-20 18:59:25,530] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:25,581] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:25,628] {logging_mixin.py:104} INFO - [2022-03-20 18:59:25,628] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:59:25,672] {logging_mixin.py:104} INFO - [2022-03-20 18:59:25,671] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:59:25,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 18:59:56,321] {scheduler_job.py:182} INFO - Started process (PID=15986) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:56,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 18:59:56,328] {logging_mixin.py:104} INFO - [2022-03-20 18:59:56,328] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:56,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 18:59:56,429] {logging_mixin.py:104} INFO - [2022-03-20 18:59:56,428] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 18:59:56,473] {logging_mixin.py:104} INFO - [2022-03-20 18:59:56,473] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 18:59:56,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 19:00:27,129] {scheduler_job.py:182} INFO - Started process (PID=16019) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:27,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:00:27,140] {logging_mixin.py:104} INFO - [2022-03-20 19:00:27,139] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:27,192] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:27,239] {logging_mixin.py:104} INFO - [2022-03-20 19:00:27,239] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:00:27,282] {logging_mixin.py:104} INFO - [2022-03-20 19:00:27,282] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:00:27,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 19:00:58,259] {scheduler_job.py:182} INFO - Started process (PID=16050) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:58,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:00:58,268] {logging_mixin.py:104} INFO - [2022-03-20 19:00:58,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:58,316] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:00:58,363] {logging_mixin.py:104} INFO - [2022-03-20 19:00:58,363] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:00:58,409] {logging_mixin.py:104} INFO - [2022-03-20 19:00:58,409] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:00:58,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:01:31,188] {scheduler_job.py:182} INFO - Started process (PID=16084) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:01:31,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:01:31,194] {logging_mixin.py:104} INFO - [2022-03-20 19:01:31,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:01:31,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:01:31,297] {logging_mixin.py:104} INFO - [2022-03-20 19:01:31,297] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:01:31,341] {logging_mixin.py:104} INFO - [2022-03-20 19:01:31,340] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:01:31,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 19:02:02,347] {scheduler_job.py:182} INFO - Started process (PID=16114) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:02,350] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:02:02,353] {logging_mixin.py:104} INFO - [2022-03-20 19:02:02,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:02,401] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:02,448] {logging_mixin.py:104} INFO - [2022-03-20 19:02:02,448] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:02:02,489] {logging_mixin.py:104} INFO - [2022-03-20 19:02:02,489] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:02:02,506] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 19:02:33,182] {scheduler_job.py:182} INFO - Started process (PID=16138) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:33,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:02:33,190] {logging_mixin.py:104} INFO - [2022-03-20 19:02:33,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:33,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:02:33,295] {logging_mixin.py:104} INFO - [2022-03-20 19:02:33,294] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:02:33,337] {logging_mixin.py:104} INFO - [2022-03-20 19:02:33,336] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:02:33,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 19:03:03,878] {scheduler_job.py:182} INFO - Started process (PID=16171) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:03,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:03:03,887] {logging_mixin.py:104} INFO - [2022-03-20 19:03:03,886] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:03,939] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:03,988] {logging_mixin.py:104} INFO - [2022-03-20 19:03:03,987] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:03:04,034] {logging_mixin.py:104} INFO - [2022-03-20 19:03:04,034] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:03:04,052] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 19:03:34,673] {scheduler_job.py:182} INFO - Started process (PID=16203) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:34,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:03:34,682] {logging_mixin.py:104} INFO - [2022-03-20 19:03:34,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:34,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:03:34,784] {logging_mixin.py:104} INFO - [2022-03-20 19:03:34,784] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:03:34,827] {logging_mixin.py:104} INFO - [2022-03-20 19:03:34,827] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:03:34,843] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 19:04:05,351] {scheduler_job.py:182} INFO - Started process (PID=16235) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:05,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:04:05,358] {logging_mixin.py:104} INFO - [2022-03-20 19:04:05,358] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:05,411] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:05,459] {logging_mixin.py:104} INFO - [2022-03-20 19:04:05,458] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:04:05,503] {logging_mixin.py:104} INFO - [2022-03-20 19:04:05,502] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:04:05,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:04:36,004] {scheduler_job.py:182} INFO - Started process (PID=16266) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:36,008] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:04:36,010] {logging_mixin.py:104} INFO - [2022-03-20 19:04:36,010] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:36,058] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:04:36,104] {logging_mixin.py:104} INFO - [2022-03-20 19:04:36,104] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:04:36,147] {logging_mixin.py:104} INFO - [2022-03-20 19:04:36,146] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:04:36,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 19:05:06,737] {scheduler_job.py:182} INFO - Started process (PID=16298) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:06,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:05:06,748] {logging_mixin.py:104} INFO - [2022-03-20 19:05:06,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:06,804] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:06,858] {logging_mixin.py:104} INFO - [2022-03-20 19:05:06,857] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:05:06,902] {logging_mixin.py:104} INFO - [2022-03-20 19:05:06,902] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:05:06,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.192 seconds
[2022-03-20 19:05:37,480] {scheduler_job.py:182} INFO - Started process (PID=16330) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:37,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:05:37,488] {logging_mixin.py:104} INFO - [2022-03-20 19:05:37,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:37,536] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:05:37,584] {logging_mixin.py:104} INFO - [2022-03-20 19:05:37,583] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:05:37,626] {logging_mixin.py:104} INFO - [2022-03-20 19:05:37,626] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:05:37,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:06:09,829] {scheduler_job.py:182} INFO - Started process (PID=16364) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:09,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:06:09,835] {logging_mixin.py:104} INFO - [2022-03-20 19:06:09,835] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:09,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:09,930] {logging_mixin.py:104} INFO - [2022-03-20 19:06:09,930] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:06:09,974] {logging_mixin.py:104} INFO - [2022-03-20 19:06:09,974] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:06:09,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 19:06:40,415] {scheduler_job.py:182} INFO - Started process (PID=16388) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:40,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:06:40,423] {logging_mixin.py:104} INFO - [2022-03-20 19:06:40,423] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:40,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:06:40,529] {logging_mixin.py:104} INFO - [2022-03-20 19:06:40,528] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:06:40,572] {logging_mixin.py:104} INFO - [2022-03-20 19:06:40,572] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:06:40,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 19:07:11,133] {scheduler_job.py:182} INFO - Started process (PID=16407) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:11,138] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:07:11,140] {logging_mixin.py:104} INFO - [2022-03-20 19:07:11,140] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:11,188] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:11,236] {logging_mixin.py:104} INFO - [2022-03-20 19:07:11,235] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:07:11,277] {logging_mixin.py:104} INFO - [2022-03-20 19:07:11,277] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:07:11,295] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:07:42,038] {scheduler_job.py:182} INFO - Started process (PID=16439) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:42,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:07:42,046] {logging_mixin.py:104} INFO - [2022-03-20 19:07:42,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:42,103] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:07:42,148] {logging_mixin.py:104} INFO - [2022-03-20 19:07:42,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:07:42,194] {logging_mixin.py:104} INFO - [2022-03-20 19:07:42,193] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:07:42,212] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 19:08:12,758] {scheduler_job.py:182} INFO - Started process (PID=16470) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:12,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:08:12,765] {logging_mixin.py:104} INFO - [2022-03-20 19:08:12,765] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:12,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:12,864] {logging_mixin.py:104} INFO - [2022-03-20 19:08:12,864] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:08:12,909] {logging_mixin.py:104} INFO - [2022-03-20 19:08:12,909] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:08:12,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 19:08:43,484] {scheduler_job.py:182} INFO - Started process (PID=16502) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:43,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:08:43,491] {logging_mixin.py:104} INFO - [2022-03-20 19:08:43,491] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:43,544] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:08:43,591] {logging_mixin.py:104} INFO - [2022-03-20 19:08:43,591] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:08:43,635] {logging_mixin.py:104} INFO - [2022-03-20 19:08:43,635] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:08:43,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 19:09:14,302] {scheduler_job.py:182} INFO - Started process (PID=16535) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:14,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:09:14,310] {logging_mixin.py:104} INFO - [2022-03-20 19:09:14,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:14,357] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:14,403] {logging_mixin.py:104} INFO - [2022-03-20 19:09:14,402] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:09:14,445] {logging_mixin.py:104} INFO - [2022-03-20 19:09:14,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:09:14,462] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 19:09:45,136] {scheduler_job.py:182} INFO - Started process (PID=16566) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:45,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:09:45,147] {logging_mixin.py:104} INFO - [2022-03-20 19:09:45,146] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:45,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:09:45,245] {logging_mixin.py:104} INFO - [2022-03-20 19:09:45,244] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:09:45,289] {logging_mixin.py:104} INFO - [2022-03-20 19:09:45,288] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:09:45,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:10:16,015] {scheduler_job.py:182} INFO - Started process (PID=16598) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:16,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:10:16,024] {logging_mixin.py:104} INFO - [2022-03-20 19:10:16,023] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:16,074] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:16,121] {logging_mixin.py:104} INFO - [2022-03-20 19:10:16,120] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:10:16,165] {logging_mixin.py:104} INFO - [2022-03-20 19:10:16,165] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:10:16,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:10:48,179] {scheduler_job.py:182} INFO - Started process (PID=16632) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:48,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:10:48,186] {logging_mixin.py:104} INFO - [2022-03-20 19:10:48,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:48,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:10:48,278] {logging_mixin.py:104} INFO - [2022-03-20 19:10:48,277] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:10:48,321] {logging_mixin.py:104} INFO - [2022-03-20 19:10:48,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:10:48,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 19:11:18,669] {scheduler_job.py:182} INFO - Started process (PID=16656) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:18,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:11:18,675] {logging_mixin.py:104} INFO - [2022-03-20 19:11:18,675] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:18,728] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:18,775] {logging_mixin.py:104} INFO - [2022-03-20 19:11:18,774] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:11:18,816] {logging_mixin.py:104} INFO - [2022-03-20 19:11:18,816] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:11:18,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:11:49,633] {scheduler_job.py:182} INFO - Started process (PID=16681) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:49,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:11:49,642] {logging_mixin.py:104} INFO - [2022-03-20 19:11:49,641] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:49,696] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:11:49,742] {logging_mixin.py:104} INFO - [2022-03-20 19:11:49,741] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:11:49,788] {logging_mixin.py:104} INFO - [2022-03-20 19:11:49,787] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:11:49,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 19:12:20,540] {scheduler_job.py:182} INFO - Started process (PID=16712) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:20,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:12:20,549] {logging_mixin.py:104} INFO - [2022-03-20 19:12:20,548] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:20,599] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:20,647] {logging_mixin.py:104} INFO - [2022-03-20 19:12:20,646] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:12:20,690] {logging_mixin.py:104} INFO - [2022-03-20 19:12:20,689] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:12:20,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:12:51,275] {scheduler_job.py:182} INFO - Started process (PID=16745) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:51,278] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:12:51,281] {logging_mixin.py:104} INFO - [2022-03-20 19:12:51,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:51,334] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:12:51,388] {logging_mixin.py:104} INFO - [2022-03-20 19:12:51,387] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:12:51,437] {logging_mixin.py:104} INFO - [2022-03-20 19:12:51,436] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:12:51,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-20 19:13:22,021] {scheduler_job.py:182} INFO - Started process (PID=16777) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:22,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:13:22,029] {logging_mixin.py:104} INFO - [2022-03-20 19:13:22,029] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:22,080] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:22,127] {logging_mixin.py:104} INFO - [2022-03-20 19:13:22,127] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:13:22,169] {logging_mixin.py:104} INFO - [2022-03-20 19:13:22,169] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:13:22,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 19:13:52,802] {scheduler_job.py:182} INFO - Started process (PID=16808) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:52,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:13:52,807] {logging_mixin.py:104} INFO - [2022-03-20 19:13:52,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:52,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:13:52,903] {logging_mixin.py:104} INFO - [2022-03-20 19:13:52,902] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:13:52,946] {logging_mixin.py:104} INFO - [2022-03-20 19:13:52,945] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:13:52,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:14:23,676] {scheduler_job.py:182} INFO - Started process (PID=16841) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:23,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:14:23,683] {logging_mixin.py:104} INFO - [2022-03-20 19:14:23,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:23,731] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:23,778] {logging_mixin.py:104} INFO - [2022-03-20 19:14:23,777] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:14:23,819] {logging_mixin.py:104} INFO - [2022-03-20 19:14:23,819] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:14:23,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 19:14:54,517] {scheduler_job.py:182} INFO - Started process (PID=16872) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:54,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:14:54,523] {logging_mixin.py:104} INFO - [2022-03-20 19:14:54,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:54,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:14:54,618] {logging_mixin.py:104} INFO - [2022-03-20 19:14:54,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:14:54,664] {logging_mixin.py:104} INFO - [2022-03-20 19:14:54,663] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:14:54,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:15:26,505] {scheduler_job.py:182} INFO - Started process (PID=16906) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:26,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:15:26,513] {logging_mixin.py:104} INFO - [2022-03-20 19:15:26,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:26,560] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:26,605] {logging_mixin.py:104} INFO - [2022-03-20 19:15:26,604] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:15:26,647] {logging_mixin.py:104} INFO - [2022-03-20 19:15:26,647] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:15:26,665] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 19:15:57,097] {scheduler_job.py:182} INFO - Started process (PID=16930) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:57,101] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:15:57,104] {logging_mixin.py:104} INFO - [2022-03-20 19:15:57,104] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:57,156] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:15:57,201] {logging_mixin.py:104} INFO - [2022-03-20 19:15:57,200] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:15:57,241] {logging_mixin.py:104} INFO - [2022-03-20 19:15:57,241] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:15:57,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:16:28,049] {scheduler_job.py:182} INFO - Started process (PID=16955) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:28,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:16:28,057] {logging_mixin.py:104} INFO - [2022-03-20 19:16:28,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:28,108] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:28,167] {logging_mixin.py:104} INFO - [2022-03-20 19:16:28,167] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:16:28,210] {logging_mixin.py:104} INFO - [2022-03-20 19:16:28,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:16:28,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-20 19:16:59,034] {scheduler_job.py:182} INFO - Started process (PID=16986) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:59,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:16:59,041] {logging_mixin.py:104} INFO - [2022-03-20 19:16:59,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:59,094] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:16:59,145] {logging_mixin.py:104} INFO - [2022-03-20 19:16:59,144] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:16:59,192] {logging_mixin.py:104} INFO - [2022-03-20 19:16:59,191] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:16:59,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 19:17:29,795] {scheduler_job.py:182} INFO - Started process (PID=17019) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:17:29,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:17:29,803] {logging_mixin.py:104} INFO - [2022-03-20 19:17:29,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:17:29,856] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:17:29,903] {logging_mixin.py:104} INFO - [2022-03-20 19:17:29,902] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:17:29,947] {logging_mixin.py:104} INFO - [2022-03-20 19:17:29,947] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:17:29,965] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 19:18:00,651] {scheduler_job.py:182} INFO - Started process (PID=17050) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:00,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:18:00,657] {logging_mixin.py:104} INFO - [2022-03-20 19:18:00,657] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:00,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:00,750] {logging_mixin.py:104} INFO - [2022-03-20 19:18:00,750] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:18:00,794] {logging_mixin.py:104} INFO - [2022-03-20 19:18:00,794] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:18:00,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 19:18:31,571] {scheduler_job.py:182} INFO - Started process (PID=17083) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:31,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:18:31,580] {logging_mixin.py:104} INFO - [2022-03-20 19:18:31,580] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:31,628] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:18:31,677] {logging_mixin.py:104} INFO - [2022-03-20 19:18:31,676] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:18:31,721] {logging_mixin.py:104} INFO - [2022-03-20 19:18:31,720] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:18:31,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:19:02,516] {scheduler_job.py:182} INFO - Started process (PID=17115) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:02,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:19:02,527] {logging_mixin.py:104} INFO - [2022-03-20 19:19:02,526] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:02,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:02,625] {logging_mixin.py:104} INFO - [2022-03-20 19:19:02,624] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:19:02,668] {logging_mixin.py:104} INFO - [2022-03-20 19:19:02,668] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:19:02,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:19:33,235] {scheduler_job.py:182} INFO - Started process (PID=17146) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:33,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:19:33,242] {logging_mixin.py:104} INFO - [2022-03-20 19:19:33,242] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:33,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:19:33,344] {logging_mixin.py:104} INFO - [2022-03-20 19:19:33,343] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:19:33,386] {logging_mixin.py:104} INFO - [2022-03-20 19:19:33,386] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:19:33,403] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:20:05,369] {scheduler_job.py:182} INFO - Started process (PID=17180) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:05,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:20:05,376] {logging_mixin.py:104} INFO - [2022-03-20 19:20:05,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:05,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:05,466] {logging_mixin.py:104} INFO - [2022-03-20 19:20:05,466] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:20:05,509] {logging_mixin.py:104} INFO - [2022-03-20 19:20:05,509] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:20:05,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-20 19:20:35,927] {scheduler_job.py:182} INFO - Started process (PID=17204) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:35,930] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:20:35,933] {logging_mixin.py:104} INFO - [2022-03-20 19:20:35,932] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:35,981] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:20:36,028] {logging_mixin.py:104} INFO - [2022-03-20 19:20:36,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:20:36,070] {logging_mixin.py:104} INFO - [2022-03-20 19:20:36,070] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:20:36,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 19:21:06,190] {scheduler_job.py:182} INFO - Started process (PID=17232) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:06,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:21:06,195] {logging_mixin.py:104} INFO - [2022-03-20 19:21:06,195] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:06,244] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:06,286] {logging_mixin.py:104} INFO - [2022-03-20 19:21:06,285] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:21:06,325] {logging_mixin.py:104} INFO - [2022-03-20 19:21:06,324] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:21:06,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 19:21:36,797] {scheduler_job.py:182} INFO - Started process (PID=17260) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:36,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:21:36,804] {logging_mixin.py:104} INFO - [2022-03-20 19:21:36,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:36,857] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:21:36,902] {logging_mixin.py:104} INFO - [2022-03-20 19:21:36,901] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:21:36,946] {logging_mixin.py:104} INFO - [2022-03-20 19:21:36,945] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:21:36,963] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:22:07,716] {scheduler_job.py:182} INFO - Started process (PID=17293) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:07,719] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:22:07,722] {logging_mixin.py:104} INFO - [2022-03-20 19:22:07,722] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:07,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:07,820] {logging_mixin.py:104} INFO - [2022-03-20 19:22:07,820] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:22:07,863] {logging_mixin.py:104} INFO - [2022-03-20 19:22:07,863] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:22:07,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:22:38,394] {scheduler_job.py:182} INFO - Started process (PID=17324) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:38,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:22:38,401] {logging_mixin.py:104} INFO - [2022-03-20 19:22:38,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:38,452] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:22:38,500] {logging_mixin.py:104} INFO - [2022-03-20 19:22:38,499] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:22:38,544] {logging_mixin.py:104} INFO - [2022-03-20 19:22:38,544] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:22:38,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:23:09,323] {scheduler_job.py:182} INFO - Started process (PID=17356) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:09,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:23:09,334] {logging_mixin.py:104} INFO - [2022-03-20 19:23:09,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:09,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:09,435] {logging_mixin.py:104} INFO - [2022-03-20 19:23:09,434] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:23:09,478] {logging_mixin.py:104} INFO - [2022-03-20 19:23:09,478] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:23:09,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 19:23:40,115] {scheduler_job.py:182} INFO - Started process (PID=17389) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:40,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:23:40,122] {logging_mixin.py:104} INFO - [2022-03-20 19:23:40,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:40,173] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:23:40,220] {logging_mixin.py:104} INFO - [2022-03-20 19:23:40,219] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:23:40,263] {logging_mixin.py:104} INFO - [2022-03-20 19:23:40,262] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:23:40,279] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:24:10,895] {scheduler_job.py:182} INFO - Started process (PID=17421) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:10,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:24:10,902] {logging_mixin.py:104} INFO - [2022-03-20 19:24:10,902] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:10,953] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:10,999] {logging_mixin.py:104} INFO - [2022-03-20 19:24:10,998] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:24:11,043] {logging_mixin.py:104} INFO - [2022-03-20 19:24:11,042] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:24:11,060] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:24:43,066] {scheduler_job.py:182} INFO - Started process (PID=17454) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:43,071] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:24:43,073] {logging_mixin.py:104} INFO - [2022-03-20 19:24:43,073] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:43,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:24:43,165] {logging_mixin.py:104} INFO - [2022-03-20 19:24:43,165] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:24:43,206] {logging_mixin.py:104} INFO - [2022-03-20 19:24:43,206] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:24:43,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-20 19:25:13,756] {scheduler_job.py:182} INFO - Started process (PID=17478) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:13,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:25:13,762] {logging_mixin.py:104} INFO - [2022-03-20 19:25:13,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:13,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:13,855] {logging_mixin.py:104} INFO - [2022-03-20 19:25:13,854] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:25:13,895] {logging_mixin.py:104} INFO - [2022-03-20 19:25:13,894] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:25:13,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 19:25:44,624] {scheduler_job.py:182} INFO - Started process (PID=17503) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:44,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:25:44,633] {logging_mixin.py:104} INFO - [2022-03-20 19:25:44,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:44,692] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:25:44,742] {logging_mixin.py:104} INFO - [2022-03-20 19:25:44,741] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:25:44,786] {logging_mixin.py:104} INFO - [2022-03-20 19:25:44,785] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:25:44,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 19:26:15,328] {scheduler_job.py:182} INFO - Started process (PID=17534) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:15,331] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:26:15,334] {logging_mixin.py:104} INFO - [2022-03-20 19:26:15,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:15,388] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:15,435] {logging_mixin.py:104} INFO - [2022-03-20 19:26:15,435] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:26:15,478] {logging_mixin.py:104} INFO - [2022-03-20 19:26:15,478] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:26:15,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 19:26:45,969] {scheduler_job.py:182} INFO - Started process (PID=17566) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:45,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:26:45,976] {logging_mixin.py:104} INFO - [2022-03-20 19:26:45,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:46,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:26:46,080] {logging_mixin.py:104} INFO - [2022-03-20 19:26:46,079] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:26:46,123] {logging_mixin.py:104} INFO - [2022-03-20 19:26:46,123] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:26:46,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 19:27:16,552] {scheduler_job.py:182} INFO - Started process (PID=17598) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:16,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:27:16,559] {logging_mixin.py:104} INFO - [2022-03-20 19:27:16,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:16,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:16,658] {logging_mixin.py:104} INFO - [2022-03-20 19:27:16,657] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:27:16,701] {logging_mixin.py:104} INFO - [2022-03-20 19:27:16,701] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:27:16,718] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:27:47,158] {scheduler_job.py:182} INFO - Started process (PID=17630) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:47,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:27:47,167] {logging_mixin.py:104} INFO - [2022-03-20 19:27:47,166] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:47,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:27:47,265] {logging_mixin.py:104} INFO - [2022-03-20 19:27:47,265] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:27:47,308] {logging_mixin.py:104} INFO - [2022-03-20 19:27:47,307] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:27:47,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-20 19:28:17,764] {scheduler_job.py:182} INFO - Started process (PID=17662) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:17,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:28:17,771] {logging_mixin.py:104} INFO - [2022-03-20 19:28:17,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:17,825] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:17,876] {logging_mixin.py:104} INFO - [2022-03-20 19:28:17,875] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:28:17,921] {logging_mixin.py:104} INFO - [2022-03-20 19:28:17,921] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:28:17,938] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 19:28:48,385] {scheduler_job.py:182} INFO - Started process (PID=17694) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:48,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:28:48,391] {logging_mixin.py:104} INFO - [2022-03-20 19:28:48,391] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:48,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:28:48,487] {logging_mixin.py:104} INFO - [2022-03-20 19:28:48,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:28:48,530] {logging_mixin.py:104} INFO - [2022-03-20 19:28:48,529] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:28:48,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 19:29:19,299] {scheduler_job.py:182} INFO - Started process (PID=17728) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:19,303] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:29:19,305] {logging_mixin.py:104} INFO - [2022-03-20 19:29:19,305] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:19,359] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:19,408] {logging_mixin.py:104} INFO - [2022-03-20 19:29:19,407] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:29:19,450] {logging_mixin.py:104} INFO - [2022-03-20 19:29:19,450] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:29:19,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:29:49,834] {scheduler_job.py:182} INFO - Started process (PID=17752) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:49,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:29:49,840] {logging_mixin.py:104} INFO - [2022-03-20 19:29:49,839] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:49,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:29:49,934] {logging_mixin.py:104} INFO - [2022-03-20 19:29:49,934] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:29:49,977] {logging_mixin.py:104} INFO - [2022-03-20 19:29:49,977] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:29:49,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:30:20,727] {scheduler_job.py:182} INFO - Started process (PID=17776) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:20,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:30:20,736] {logging_mixin.py:104} INFO - [2022-03-20 19:30:20,736] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:20,788] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:20,839] {logging_mixin.py:104} INFO - [2022-03-20 19:30:20,838] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:30:20,885] {logging_mixin.py:104} INFO - [2022-03-20 19:30:20,885] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:30:20,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 19:30:51,526] {scheduler_job.py:182} INFO - Started process (PID=17808) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:51,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:30:51,534] {logging_mixin.py:104} INFO - [2022-03-20 19:30:51,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:51,586] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:30:51,633] {logging_mixin.py:104} INFO - [2022-03-20 19:30:51,633] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:30:51,675] {logging_mixin.py:104} INFO - [2022-03-20 19:30:51,675] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:30:51,694] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:31:22,197] {scheduler_job.py:182} INFO - Started process (PID=17841) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:22,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:31:22,204] {logging_mixin.py:104} INFO - [2022-03-20 19:31:22,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:22,256] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:22,306] {logging_mixin.py:104} INFO - [2022-03-20 19:31:22,305] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:31:22,353] {logging_mixin.py:104} INFO - [2022-03-20 19:31:22,353] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:31:22,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 19:31:52,922] {scheduler_job.py:182} INFO - Started process (PID=17872) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:52,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:31:52,931] {logging_mixin.py:104} INFO - [2022-03-20 19:31:52,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:52,988] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:31:53,036] {logging_mixin.py:104} INFO - [2022-03-20 19:31:53,036] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:31:53,083] {logging_mixin.py:104} INFO - [2022-03-20 19:31:53,082] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:31:53,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 19:32:23,726] {scheduler_job.py:182} INFO - Started process (PID=17904) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:23,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:32:23,732] {logging_mixin.py:104} INFO - [2022-03-20 19:32:23,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:23,784] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:23,831] {logging_mixin.py:104} INFO - [2022-03-20 19:32:23,831] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:32:23,874] {logging_mixin.py:104} INFO - [2022-03-20 19:32:23,874] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:32:23,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:32:54,540] {scheduler_job.py:182} INFO - Started process (PID=17936) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:54,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:32:54,548] {logging_mixin.py:104} INFO - [2022-03-20 19:32:54,547] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:54,599] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:32:54,645] {logging_mixin.py:104} INFO - [2022-03-20 19:32:54,644] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:32:54,686] {logging_mixin.py:104} INFO - [2022-03-20 19:32:54,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:32:54,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:33:25,389] {scheduler_job.py:182} INFO - Started process (PID=17968) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:25,395] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:33:25,398] {logging_mixin.py:104} INFO - [2022-03-20 19:33:25,397] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:25,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:25,492] {logging_mixin.py:104} INFO - [2022-03-20 19:33:25,491] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:33:25,535] {logging_mixin.py:104} INFO - [2022-03-20 19:33:25,535] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:33:25,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:33:57,513] {scheduler_job.py:182} INFO - Started process (PID=18002) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:57,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:33:57,519] {logging_mixin.py:104} INFO - [2022-03-20 19:33:57,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:57,571] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:33:57,617] {logging_mixin.py:104} INFO - [2022-03-20 19:33:57,617] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:33:57,660] {logging_mixin.py:104} INFO - [2022-03-20 19:33:57,659] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:33:57,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:34:28,065] {scheduler_job.py:182} INFO - Started process (PID=18026) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:28,068] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:34:28,071] {logging_mixin.py:104} INFO - [2022-03-20 19:34:28,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:28,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:28,166] {logging_mixin.py:104} INFO - [2022-03-20 19:34:28,166] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:34:28,226] {logging_mixin.py:104} INFO - [2022-03-20 19:34:28,226] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:34:28,245] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-20 19:34:58,755] {scheduler_job.py:182} INFO - Started process (PID=18050) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:58,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:34:58,762] {logging_mixin.py:104} INFO - [2022-03-20 19:34:58,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:58,817] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:34:58,864] {logging_mixin.py:104} INFO - [2022-03-20 19:34:58,863] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:34:58,908] {logging_mixin.py:104} INFO - [2022-03-20 19:34:58,908] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:34:58,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 19:35:29,603] {scheduler_job.py:182} INFO - Started process (PID=18082) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:35:29,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:35:29,611] {logging_mixin.py:104} INFO - [2022-03-20 19:35:29,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:35:29,661] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:35:29,710] {logging_mixin.py:104} INFO - [2022-03-20 19:35:29,710] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:35:29,755] {logging_mixin.py:104} INFO - [2022-03-20 19:35:29,755] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:35:29,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 19:36:00,512] {scheduler_job.py:182} INFO - Started process (PID=18115) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:00,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:36:00,522] {logging_mixin.py:104} INFO - [2022-03-20 19:36:00,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:00,585] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:00,635] {logging_mixin.py:104} INFO - [2022-03-20 19:36:00,634] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:36:00,682] {logging_mixin.py:104} INFO - [2022-03-20 19:36:00,681] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:36:00,699] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-20 19:36:31,264] {scheduler_job.py:182} INFO - Started process (PID=18146) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:31,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:36:31,271] {logging_mixin.py:104} INFO - [2022-03-20 19:36:31,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:31,326] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:36:31,374] {logging_mixin.py:104} INFO - [2022-03-20 19:36:31,374] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:36:31,419] {logging_mixin.py:104} INFO - [2022-03-20 19:36:31,419] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:36:31,437] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 19:37:01,913] {scheduler_job.py:182} INFO - Started process (PID=18178) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:01,917] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:37:01,919] {logging_mixin.py:104} INFO - [2022-03-20 19:37:01,919] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:01,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:02,014] {logging_mixin.py:104} INFO - [2022-03-20 19:37:02,014] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:37:02,059] {logging_mixin.py:104} INFO - [2022-03-20 19:37:02,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:37:02,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:37:32,536] {scheduler_job.py:182} INFO - Started process (PID=18210) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:32,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:37:32,544] {logging_mixin.py:104} INFO - [2022-03-20 19:37:32,543] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:32,594] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:37:32,643] {logging_mixin.py:104} INFO - [2022-03-20 19:37:32,643] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:37:32,687] {logging_mixin.py:104} INFO - [2022-03-20 19:37:32,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:37:32,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:38:03,073] {scheduler_job.py:182} INFO - Started process (PID=18243) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:03,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:38:03,080] {logging_mixin.py:104} INFO - [2022-03-20 19:38:03,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:03,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:03,178] {logging_mixin.py:104} INFO - [2022-03-20 19:38:03,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:38:03,221] {logging_mixin.py:104} INFO - [2022-03-20 19:38:03,221] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:38:03,238] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:38:35,238] {scheduler_job.py:182} INFO - Started process (PID=18276) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:35,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:38:35,246] {logging_mixin.py:104} INFO - [2022-03-20 19:38:35,245] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:35,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:38:35,346] {logging_mixin.py:104} INFO - [2022-03-20 19:38:35,345] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:38:35,388] {logging_mixin.py:104} INFO - [2022-03-20 19:38:35,388] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:38:35,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:39:05,640] {scheduler_job.py:182} INFO - Started process (PID=18300) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:05,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:39:05,646] {logging_mixin.py:104} INFO - [2022-03-20 19:39:05,646] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:05,698] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:05,742] {logging_mixin.py:104} INFO - [2022-03-20 19:39:05,742] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:39:05,783] {logging_mixin.py:104} INFO - [2022-03-20 19:39:05,783] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:39:05,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:39:35,960] {scheduler_job.py:182} INFO - Started process (PID=18328) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:35,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:39:35,967] {logging_mixin.py:104} INFO - [2022-03-20 19:39:35,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:36,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:39:36,057] {logging_mixin.py:104} INFO - [2022-03-20 19:39:36,057] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:39:36,099] {logging_mixin.py:104} INFO - [2022-03-20 19:39:36,098] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:39:36,116] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 19:40:06,304] {scheduler_job.py:182} INFO - Started process (PID=18360) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:06,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:40:06,310] {logging_mixin.py:104} INFO - [2022-03-20 19:40:06,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:06,357] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:06,404] {logging_mixin.py:104} INFO - [2022-03-20 19:40:06,404] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:40:06,445] {logging_mixin.py:104} INFO - [2022-03-20 19:40:06,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:40:06,464] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 19:40:36,987] {scheduler_job.py:182} INFO - Started process (PID=18388) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:36,992] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:40:36,995] {logging_mixin.py:104} INFO - [2022-03-20 19:40:36,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:37,050] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:40:37,100] {logging_mixin.py:104} INFO - [2022-03-20 19:40:37,100] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:40:37,144] {logging_mixin.py:104} INFO - [2022-03-20 19:40:37,144] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:40:37,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 19:41:07,694] {scheduler_job.py:182} INFO - Started process (PID=18420) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:07,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:41:07,703] {logging_mixin.py:104} INFO - [2022-03-20 19:41:07,702] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:07,755] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:07,805] {logging_mixin.py:104} INFO - [2022-03-20 19:41:07,805] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:41:07,851] {logging_mixin.py:104} INFO - [2022-03-20 19:41:07,850] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:41:07,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 19:41:38,380] {scheduler_job.py:182} INFO - Started process (PID=18452) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:38,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:41:38,386] {logging_mixin.py:104} INFO - [2022-03-20 19:41:38,386] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:38,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:41:38,483] {logging_mixin.py:104} INFO - [2022-03-20 19:41:38,482] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:41:38,524] {logging_mixin.py:104} INFO - [2022-03-20 19:41:38,524] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:41:38,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:42:08,982] {scheduler_job.py:182} INFO - Started process (PID=18484) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:08,985] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:42:08,988] {logging_mixin.py:104} INFO - [2022-03-20 19:42:08,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:09,039] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:09,086] {logging_mixin.py:104} INFO - [2022-03-20 19:42:09,085] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:42:09,129] {logging_mixin.py:104} INFO - [2022-03-20 19:42:09,128] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:42:09,146] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:42:39,575] {scheduler_job.py:182} INFO - Started process (PID=18516) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:39,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:42:39,583] {logging_mixin.py:104} INFO - [2022-03-20 19:42:39,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:39,633] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:42:39,680] {logging_mixin.py:104} INFO - [2022-03-20 19:42:39,680] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:42:39,723] {logging_mixin.py:104} INFO - [2022-03-20 19:42:39,722] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:42:39,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 19:43:11,445] {scheduler_job.py:182} INFO - Started process (PID=18550) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:11,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:43:11,452] {logging_mixin.py:104} INFO - [2022-03-20 19:43:11,451] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:11,500] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:11,547] {logging_mixin.py:104} INFO - [2022-03-20 19:43:11,546] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:43:11,590] {logging_mixin.py:104} INFO - [2022-03-20 19:43:11,589] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:43:11,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:43:41,791] {scheduler_job.py:182} INFO - Started process (PID=18574) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:41,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:43:41,798] {logging_mixin.py:104} INFO - [2022-03-20 19:43:41,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:41,845] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:43:41,891] {logging_mixin.py:104} INFO - [2022-03-20 19:43:41,890] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:43:41,934] {logging_mixin.py:104} INFO - [2022-03-20 19:43:41,933] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:43:41,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 19:44:12,220] {scheduler_job.py:182} INFO - Started process (PID=18602) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:12,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:44:12,227] {logging_mixin.py:104} INFO - [2022-03-20 19:44:12,227] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:12,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:12,324] {logging_mixin.py:104} INFO - [2022-03-20 19:44:12,324] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:44:12,366] {logging_mixin.py:104} INFO - [2022-03-20 19:44:12,365] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:44:12,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 19:44:42,656] {scheduler_job.py:182} INFO - Started process (PID=18631) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:42,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:44:42,665] {logging_mixin.py:104} INFO - [2022-03-20 19:44:42,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:42,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:44:42,767] {logging_mixin.py:104} INFO - [2022-03-20 19:44:42,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:44:42,811] {logging_mixin.py:104} INFO - [2022-03-20 19:44:42,811] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:44:42,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-20 19:45:13,310] {scheduler_job.py:182} INFO - Started process (PID=18662) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:13,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:45:13,320] {logging_mixin.py:104} INFO - [2022-03-20 19:45:13,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:13,369] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:13,416] {logging_mixin.py:104} INFO - [2022-03-20 19:45:13,416] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:45:13,459] {logging_mixin.py:104} INFO - [2022-03-20 19:45:13,459] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:45:13,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:45:44,072] {scheduler_job.py:182} INFO - Started process (PID=18695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:44,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:45:44,082] {logging_mixin.py:104} INFO - [2022-03-20 19:45:44,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:44,133] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:45:44,182] {logging_mixin.py:104} INFO - [2022-03-20 19:45:44,182] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:45:44,225] {logging_mixin.py:104} INFO - [2022-03-20 19:45:44,225] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:45:44,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 19:46:14,769] {scheduler_job.py:182} INFO - Started process (PID=18726) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:14,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:46:14,777] {logging_mixin.py:104} INFO - [2022-03-20 19:46:14,777] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:14,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:14,879] {logging_mixin.py:104} INFO - [2022-03-20 19:46:14,878] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:46:14,923] {logging_mixin.py:104} INFO - [2022-03-20 19:46:14,923] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:46:14,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 19:46:45,495] {scheduler_job.py:182} INFO - Started process (PID=18759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:45,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:46:45,501] {logging_mixin.py:104} INFO - [2022-03-20 19:46:45,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:45,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:46:45,598] {logging_mixin.py:104} INFO - [2022-03-20 19:46:45,597] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:46:45,640] {logging_mixin.py:104} INFO - [2022-03-20 19:46:45,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:46:45,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-20 19:47:16,187] {scheduler_job.py:182} INFO - Started process (PID=18790) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:16,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:47:16,193] {logging_mixin.py:104} INFO - [2022-03-20 19:47:16,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:16,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:16,290] {logging_mixin.py:104} INFO - [2022-03-20 19:47:16,289] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:47:16,334] {logging_mixin.py:104} INFO - [2022-03-20 19:47:16,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:47:16,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-20 19:47:47,244] {scheduler_job.py:182} INFO - Started process (PID=18817) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:47,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:47:47,251] {logging_mixin.py:104} INFO - [2022-03-20 19:47:47,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:47,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:47:47,352] {logging_mixin.py:104} INFO - [2022-03-20 19:47:47,352] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:47:47,399] {logging_mixin.py:104} INFO - [2022-03-20 19:47:47,399] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:47:47,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-20 19:48:17,828] {scheduler_job.py:182} INFO - Started process (PID=18840) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:17,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:48:17,837] {logging_mixin.py:104} INFO - [2022-03-20 19:48:17,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:17,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:17,934] {logging_mixin.py:104} INFO - [2022-03-20 19:48:17,933] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:48:17,976] {logging_mixin.py:104} INFO - [2022-03-20 19:48:17,976] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:48:17,993] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:48:48,573] {scheduler_job.py:182} INFO - Started process (PID=18873) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:48,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:48:48,580] {logging_mixin.py:104} INFO - [2022-03-20 19:48:48,580] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:48,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:48:48,687] {logging_mixin.py:104} INFO - [2022-03-20 19:48:48,686] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:48:48,734] {logging_mixin.py:104} INFO - [2022-03-20 19:48:48,733] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:48:48,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-20 19:49:19,151] {scheduler_job.py:182} INFO - Started process (PID=18904) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:19,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:49:19,161] {logging_mixin.py:104} INFO - [2022-03-20 19:49:19,161] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:19,212] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:19,262] {logging_mixin.py:104} INFO - [2022-03-20 19:49:19,262] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:49:19,305] {logging_mixin.py:104} INFO - [2022-03-20 19:49:19,305] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:49:19,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-20 19:49:49,682] {scheduler_job.py:182} INFO - Started process (PID=18936) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:49,688] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:49:49,693] {logging_mixin.py:104} INFO - [2022-03-20 19:49:49,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:49,747] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:49:49,795] {logging_mixin.py:104} INFO - [2022-03-20 19:49:49,795] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:49:49,839] {logging_mixin.py:104} INFO - [2022-03-20 19:49:49,838] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:49:49,857] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 19:50:20,319] {scheduler_job.py:182} INFO - Started process (PID=18969) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:20,323] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:50:20,326] {logging_mixin.py:104} INFO - [2022-03-20 19:50:20,325] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:20,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:20,425] {logging_mixin.py:104} INFO - [2022-03-20 19:50:20,425] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:50:20,470] {logging_mixin.py:104} INFO - [2022-03-20 19:50:20,469] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:50:20,486] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 19:50:50,889] {scheduler_job.py:182} INFO - Started process (PID=19000) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:50,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:50:50,896] {logging_mixin.py:104} INFO - [2022-03-20 19:50:50,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:50,946] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:50:50,993] {logging_mixin.py:104} INFO - [2022-03-20 19:50:50,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:50:51,037] {logging_mixin.py:104} INFO - [2022-03-20 19:50:51,036] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:50:51,053] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-20 19:51:21,457] {scheduler_job.py:182} INFO - Started process (PID=19033) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:21,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:51:21,467] {logging_mixin.py:104} INFO - [2022-03-20 19:51:21,467] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:21,518] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:21,565] {logging_mixin.py:104} INFO - [2022-03-20 19:51:21,565] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:51:21,611] {logging_mixin.py:104} INFO - [2022-03-20 19:51:21,610] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:51:21,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-20 19:51:52,348] {scheduler_job.py:182} INFO - Started process (PID=19066) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:52,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:51:52,354] {logging_mixin.py:104} INFO - [2022-03-20 19:51:52,354] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:52,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:51:52,449] {logging_mixin.py:104} INFO - [2022-03-20 19:51:52,449] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:51:52,492] {logging_mixin.py:104} INFO - [2022-03-20 19:51:52,492] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:51:52,510] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-20 19:52:22,958] {scheduler_job.py:182} INFO - Started process (PID=19090) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:22,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:52:22,966] {logging_mixin.py:104} INFO - [2022-03-20 19:52:22,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:23,023] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:23,075] {logging_mixin.py:104} INFO - [2022-03-20 19:52:23,074] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:52:23,123] {logging_mixin.py:104} INFO - [2022-03-20 19:52:23,122] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:52:23,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.192 seconds
[2022-03-20 19:52:53,571] {scheduler_job.py:182} INFO - Started process (PID=19114) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:53,576] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:52:53,579] {logging_mixin.py:104} INFO - [2022-03-20 19:52:53,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:53,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:52:53,687] {logging_mixin.py:104} INFO - [2022-03-20 19:52:53,687] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:52:53,736] {logging_mixin.py:104} INFO - [2022-03-20 19:52:53,735] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:52:53,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-20 19:53:24,408] {scheduler_job.py:182} INFO - Started process (PID=19146) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:24,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:53:24,417] {logging_mixin.py:104} INFO - [2022-03-20 19:53:24,416] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:24,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:24,542] {logging_mixin.py:104} INFO - [2022-03-20 19:53:24,540] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:53:24,597] {logging_mixin.py:104} INFO - [2022-03-20 19:53:24,596] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:53:24,618] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.218 seconds
[2022-03-20 19:53:54,684] {scheduler_job.py:182} INFO - Started process (PID=19176) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:54,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:53:54,694] {logging_mixin.py:104} INFO - [2022-03-20 19:53:54,693] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:54,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:53:54,798] {logging_mixin.py:104} INFO - [2022-03-20 19:53:54,797] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:53:54,845] {logging_mixin.py:104} INFO - [2022-03-20 19:53:54,844] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:53:54,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-20 19:54:25,770] {scheduler_job.py:182} INFO - Started process (PID=19211) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:25,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:54:25,778] {logging_mixin.py:104} INFO - [2022-03-20 19:54:25,777] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:25,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:25,876] {logging_mixin.py:104} INFO - [2022-03-20 19:54:25,875] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:54:25,921] {logging_mixin.py:104} INFO - [2022-03-20 19:54:25,921] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:54:25,939] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-20 19:54:56,517] {scheduler_job.py:182} INFO - Started process (PID=19243) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:56,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:54:56,524] {logging_mixin.py:104} INFO - [2022-03-20 19:54:56,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:56,571] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:54:56,621] {logging_mixin.py:104} INFO - [2022-03-20 19:54:56,621] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:54:56,664] {logging_mixin.py:104} INFO - [2022-03-20 19:54:56,664] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:54:56,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:55:27,173] {scheduler_job.py:182} INFO - Started process (PID=19275) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:27,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:55:27,180] {logging_mixin.py:104} INFO - [2022-03-20 19:55:27,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:27,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:27,282] {logging_mixin.py:104} INFO - [2022-03-20 19:55:27,281] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:55:27,326] {logging_mixin.py:104} INFO - [2022-03-20 19:55:27,326] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:55:27,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 19:55:57,761] {scheduler_job.py:182} INFO - Started process (PID=19306) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:57,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:55:57,770] {logging_mixin.py:104} INFO - [2022-03-20 19:55:57,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:57,822] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:55:57,871] {logging_mixin.py:104} INFO - [2022-03-20 19:55:57,870] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:55:57,913] {logging_mixin.py:104} INFO - [2022-03-20 19:55:57,913] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:55:57,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 19:56:30,069] {scheduler_job.py:182} INFO - Started process (PID=19340) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:56:30,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:56:30,076] {logging_mixin.py:104} INFO - [2022-03-20 19:56:30,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:56:30,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:56:30,174] {logging_mixin.py:104} INFO - [2022-03-20 19:56:30,174] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:56:30,217] {logging_mixin.py:104} INFO - [2022-03-20 19:56:30,216] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:56:30,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 19:57:02,485] {scheduler_job.py:182} INFO - Started process (PID=19370) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:02,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:57:02,494] {logging_mixin.py:104} INFO - [2022-03-20 19:57:02,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:02,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:02,603] {logging_mixin.py:104} INFO - [2022-03-20 19:57:02,602] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:57:02,646] {logging_mixin.py:104} INFO - [2022-03-20 19:57:02,645] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:57:02,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 19:57:33,088] {scheduler_job.py:182} INFO - Started process (PID=19388) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:33,092] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:57:33,095] {logging_mixin.py:104} INFO - [2022-03-20 19:57:33,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:33,154] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:57:33,213] {logging_mixin.py:104} INFO - [2022-03-20 19:57:33,212] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:57:33,267] {logging_mixin.py:104} INFO - [2022-03-20 19:57:33,266] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:57:33,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.211 seconds
[2022-03-20 19:58:04,201] {scheduler_job.py:182} INFO - Started process (PID=19420) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:04,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:58:04,210] {logging_mixin.py:104} INFO - [2022-03-20 19:58:04,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:04,265] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:04,320] {logging_mixin.py:104} INFO - [2022-03-20 19:58:04,320] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:58:04,369] {logging_mixin.py:104} INFO - [2022-03-20 19:58:04,369] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:58:04,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-20 19:58:35,012] {scheduler_job.py:182} INFO - Started process (PID=19452) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:35,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:58:35,020] {logging_mixin.py:104} INFO - [2022-03-20 19:58:35,020] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:35,077] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:58:35,130] {logging_mixin.py:104} INFO - [2022-03-20 19:58:35,130] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:58:35,179] {logging_mixin.py:104} INFO - [2022-03-20 19:58:35,178] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:58:35,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-20 19:59:05,836] {scheduler_job.py:182} INFO - Started process (PID=19484) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:05,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:59:05,844] {logging_mixin.py:104} INFO - [2022-03-20 19:59:05,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:05,899] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:05,947] {logging_mixin.py:104} INFO - [2022-03-20 19:59:05,946] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:59:05,991] {logging_mixin.py:104} INFO - [2022-03-20 19:59:05,991] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:59:06,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 19:59:36,557] {scheduler_job.py:182} INFO - Started process (PID=19516) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:36,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 19:59:36,564] {logging_mixin.py:104} INFO - [2022-03-20 19:59:36,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:36,618] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 19:59:36,665] {logging_mixin.py:104} INFO - [2022-03-20 19:59:36,664] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 19:59:36,709] {logging_mixin.py:104} INFO - [2022-03-20 19:59:36,709] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 19:59:36,725] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-20 20:00:07,312] {scheduler_job.py:182} INFO - Started process (PID=19549) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:07,319] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:00:07,321] {logging_mixin.py:104} INFO - [2022-03-20 20:00:07,321] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:07,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:07,435] {logging_mixin.py:104} INFO - [2022-03-20 20:00:07,435] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:00:07,483] {logging_mixin.py:104} INFO - [2022-03-20 20:00:07,483] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:00:07,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-20 20:00:38,302] {scheduler_job.py:182} INFO - Started process (PID=19581) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:38,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:00:38,311] {logging_mixin.py:104} INFO - [2022-03-20 20:00:38,310] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:38,364] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:00:38,416] {logging_mixin.py:104} INFO - [2022-03-20 20:00:38,415] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:00:38,463] {logging_mixin.py:104} INFO - [2022-03-20 20:00:38,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:00:38,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 20:01:10,377] {scheduler_job.py:182} INFO - Started process (PID=19614) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:10,380] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:01:10,383] {logging_mixin.py:104} INFO - [2022-03-20 20:01:10,382] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:10,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:10,482] {logging_mixin.py:104} INFO - [2022-03-20 20:01:10,481] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:01:10,523] {logging_mixin.py:104} INFO - [2022-03-20 20:01:10,523] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:01:10,543] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-20 20:01:40,972] {scheduler_job.py:182} INFO - Started process (PID=19638) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:40,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:01:40,978] {logging_mixin.py:104} INFO - [2022-03-20 20:01:40,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:41,027] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:01:41,072] {logging_mixin.py:104} INFO - [2022-03-20 20:01:41,072] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:01:41,118] {logging_mixin.py:104} INFO - [2022-03-20 20:01:41,118] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:01:41,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 20:02:11,245] {scheduler_job.py:182} INFO - Started process (PID=19662) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:11,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:02:11,251] {logging_mixin.py:104} INFO - [2022-03-20 20:02:11,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:11,309] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:11,361] {logging_mixin.py:104} INFO - [2022-03-20 20:02:11,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:02:11,406] {logging_mixin.py:104} INFO - [2022-03-20 20:02:11,406] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:02:11,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-20 20:02:42,050] {scheduler_job.py:182} INFO - Started process (PID=19695) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:42,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:02:42,057] {logging_mixin.py:104} INFO - [2022-03-20 20:02:42,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:42,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:02:42,162] {logging_mixin.py:104} INFO - [2022-03-20 20:02:42,162] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:02:42,208] {logging_mixin.py:104} INFO - [2022-03-20 20:02:42,207] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:02:42,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 20:03:13,032] {scheduler_job.py:182} INFO - Started process (PID=19727) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:13,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:03:13,040] {logging_mixin.py:104} INFO - [2022-03-20 20:03:13,039] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:13,095] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:13,150] {logging_mixin.py:104} INFO - [2022-03-20 20:03:13,150] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:03:13,198] {logging_mixin.py:104} INFO - [2022-03-20 20:03:13,198] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:03:13,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-20 20:03:44,201] {scheduler_job.py:182} INFO - Started process (PID=19759) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:44,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:03:44,208] {logging_mixin.py:104} INFO - [2022-03-20 20:03:44,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:44,269] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:03:44,323] {logging_mixin.py:104} INFO - [2022-03-20 20:03:44,322] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:03:44,373] {logging_mixin.py:104} INFO - [2022-03-20 20:03:44,373] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:03:44,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.200 seconds
[2022-03-20 20:05:02,018] {scheduler_job.py:182} INFO - Started process (PID=19805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:02,022] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:05:02,025] {logging_mixin.py:104} INFO - [2022-03-20 20:05:02,025] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:02,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:02,112] {logging_mixin.py:104} INFO - [2022-03-20 20:05:02,112] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:05:02,156] {logging_mixin.py:104} INFO - [2022-03-20 20:05:02,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:05:02,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 20:05:32,630] {scheduler_job.py:182} INFO - Started process (PID=19823) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:32,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:05:32,638] {logging_mixin.py:104} INFO - [2022-03-20 20:05:32,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:32,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:05:32,723] {logging_mixin.py:104} INFO - [2022-03-20 20:05:32,723] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:05:32,760] {logging_mixin.py:104} INFO - [2022-03-20 20:05:32,760] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:05:32,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 20:06:03,638] {scheduler_job.py:182} INFO - Started process (PID=19856) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:03,643] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:06:03,646] {logging_mixin.py:104} INFO - [2022-03-20 20:06:03,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:03,684] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:03,734] {logging_mixin.py:104} INFO - [2022-03-20 20:06:03,733] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:06:03,773] {logging_mixin.py:104} INFO - [2022-03-20 20:06:03,773] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:06:03,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 20:06:34,445] {scheduler_job.py:182} INFO - Started process (PID=19887) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:34,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:06:34,452] {logging_mixin.py:104} INFO - [2022-03-20 20:06:34,451] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:34,493] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:06:34,544] {logging_mixin.py:104} INFO - [2022-03-20 20:06:34,543] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:06:34,586] {logging_mixin.py:104} INFO - [2022-03-20 20:06:34,586] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:06:34,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-20 20:07:05,434] {scheduler_job.py:182} INFO - Started process (PID=19920) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:05,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:07:05,442] {logging_mixin.py:104} INFO - [2022-03-20 20:07:05,441] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:05,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:05,527] {logging_mixin.py:104} INFO - [2022-03-20 20:07:05,527] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:07:05,561] {logging_mixin.py:104} INFO - [2022-03-20 20:07:05,561] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:07:05,579] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:07:36,205] {scheduler_job.py:182} INFO - Started process (PID=19951) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:36,210] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:07:36,212] {logging_mixin.py:104} INFO - [2022-03-20 20:07:36,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:36,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:07:36,296] {logging_mixin.py:104} INFO - [2022-03-20 20:07:36,295] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:07:36,330] {logging_mixin.py:104} INFO - [2022-03-20 20:07:36,330] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:07:36,347] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:08:06,903] {scheduler_job.py:182} INFO - Started process (PID=19983) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:06,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:08:06,910] {logging_mixin.py:104} INFO - [2022-03-20 20:08:06,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:06,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:07,002] {logging_mixin.py:104} INFO - [2022-03-20 20:08:07,002] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:08:07,037] {logging_mixin.py:104} INFO - [2022-03-20 20:08:07,037] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:08:07,055] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 20:08:37,733] {scheduler_job.py:182} INFO - Started process (PID=20016) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:37,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:08:37,740] {logging_mixin.py:104} INFO - [2022-03-20 20:08:37,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:37,779] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:08:37,825] {logging_mixin.py:104} INFO - [2022-03-20 20:08:37,824] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:08:37,858] {logging_mixin.py:104} INFO - [2022-03-20 20:08:37,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:08:37,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:09:09,761] {scheduler_job.py:182} INFO - Started process (PID=20049) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:09,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:09:09,768] {logging_mixin.py:104} INFO - [2022-03-20 20:09:09,767] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:09,805] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:09,848] {logging_mixin.py:104} INFO - [2022-03-20 20:09:09,848] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:09:09,881] {logging_mixin.py:104} INFO - [2022-03-20 20:09:09,880] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:09:09,898] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:09:40,238] {scheduler_job.py:182} INFO - Started process (PID=20073) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:40,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:09:40,246] {logging_mixin.py:104} INFO - [2022-03-20 20:09:40,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:40,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:09:40,329] {logging_mixin.py:104} INFO - [2022-03-20 20:09:40,329] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:09:40,362] {logging_mixin.py:104} INFO - [2022-03-20 20:09:40,361] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:09:40,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:10:11,233] {scheduler_job.py:182} INFO - Started process (PID=20098) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:11,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:10:11,239] {logging_mixin.py:104} INFO - [2022-03-20 20:10:11,239] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:11,279] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:11,326] {logging_mixin.py:104} INFO - [2022-03-20 20:10:11,326] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:10:11,360] {logging_mixin.py:104} INFO - [2022-03-20 20:10:11,359] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:10:11,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:10:42,208] {scheduler_job.py:182} INFO - Started process (PID=20130) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:42,212] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:10:42,215] {logging_mixin.py:104} INFO - [2022-03-20 20:10:42,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:42,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:10:42,298] {logging_mixin.py:104} INFO - [2022-03-20 20:10:42,297] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:10:42,332] {logging_mixin.py:104} INFO - [2022-03-20 20:10:42,332] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:10:42,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:11:13,032] {scheduler_job.py:182} INFO - Started process (PID=20161) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:13,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:11:13,040] {logging_mixin.py:104} INFO - [2022-03-20 20:11:13,039] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:13,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:13,123] {logging_mixin.py:104} INFO - [2022-03-20 20:11:13,122] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:11:13,158] {logging_mixin.py:104} INFO - [2022-03-20 20:11:13,157] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:11:13,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:11:43,813] {scheduler_job.py:182} INFO - Started process (PID=20194) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:43,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:11:43,820] {logging_mixin.py:104} INFO - [2022-03-20 20:11:43,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:43,854] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:11:43,896] {logging_mixin.py:104} INFO - [2022-03-20 20:11:43,896] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:11:43,930] {logging_mixin.py:104} INFO - [2022-03-20 20:11:43,930] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:11:43,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 20:12:14,586] {scheduler_job.py:182} INFO - Started process (PID=20225) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:14,591] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:12:14,594] {logging_mixin.py:104} INFO - [2022-03-20 20:12:14,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:14,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:14,676] {logging_mixin.py:104} INFO - [2022-03-20 20:12:14,675] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:12:14,712] {logging_mixin.py:104} INFO - [2022-03-20 20:12:14,711] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:12:14,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:12:45,224] {scheduler_job.py:182} INFO - Started process (PID=20257) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:45,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:12:45,231] {logging_mixin.py:104} INFO - [2022-03-20 20:12:45,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:45,266] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:12:45,312] {logging_mixin.py:104} INFO - [2022-03-20 20:12:45,312] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:12:45,347] {logging_mixin.py:104} INFO - [2022-03-20 20:12:45,347] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:12:45,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 20:13:15,914] {scheduler_job.py:182} INFO - Started process (PID=20290) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:15,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:13:15,922] {logging_mixin.py:104} INFO - [2022-03-20 20:13:15,922] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:15,962] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:16,007] {logging_mixin.py:104} INFO - [2022-03-20 20:13:16,007] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:13:16,041] {logging_mixin.py:104} INFO - [2022-03-20 20:13:16,041] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:13:16,058] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 20:13:46,839] {scheduler_job.py:182} INFO - Started process (PID=20323) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:46,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:13:46,847] {logging_mixin.py:104} INFO - [2022-03-20 20:13:46,846] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:46,881] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:13:46,928] {logging_mixin.py:104} INFO - [2022-03-20 20:13:46,928] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:13:46,963] {logging_mixin.py:104} INFO - [2022-03-20 20:13:46,962] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:13:46,981] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:14:17,342] {scheduler_job.py:182} INFO - Started process (PID=20347) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:17,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:14:17,348] {logging_mixin.py:104} INFO - [2022-03-20 20:14:17,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:17,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:17,426] {logging_mixin.py:104} INFO - [2022-03-20 20:14:17,425] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:14:17,458] {logging_mixin.py:104} INFO - [2022-03-20 20:14:17,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:14:17,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 20:14:48,180] {scheduler_job.py:182} INFO - Started process (PID=20372) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:48,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:14:48,187] {logging_mixin.py:104} INFO - [2022-03-20 20:14:48,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:48,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:14:48,273] {logging_mixin.py:104} INFO - [2022-03-20 20:14:48,273] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:14:48,307] {logging_mixin.py:104} INFO - [2022-03-20 20:14:48,306] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:14:48,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:15:19,040] {scheduler_job.py:182} INFO - Started process (PID=20403) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:19,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:15:19,047] {logging_mixin.py:104} INFO - [2022-03-20 20:15:19,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:19,083] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:19,128] {logging_mixin.py:104} INFO - [2022-03-20 20:15:19,128] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:15:19,163] {logging_mixin.py:104} INFO - [2022-03-20 20:15:19,162] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:15:19,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:15:49,764] {scheduler_job.py:182} INFO - Started process (PID=20436) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:49,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:15:49,773] {logging_mixin.py:104} INFO - [2022-03-20 20:15:49,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:49,815] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:15:49,860] {logging_mixin.py:104} INFO - [2022-03-20 20:15:49,860] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:15:49,893] {logging_mixin.py:104} INFO - [2022-03-20 20:15:49,893] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:15:49,910] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 20:16:20,499] {scheduler_job.py:182} INFO - Started process (PID=20467) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:20,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:16:20,507] {logging_mixin.py:104} INFO - [2022-03-20 20:16:20,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:20,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:20,586] {logging_mixin.py:104} INFO - [2022-03-20 20:16:20,586] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:16:20,619] {logging_mixin.py:104} INFO - [2022-03-20 20:16:20,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:16:20,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:16:51,195] {scheduler_job.py:182} INFO - Started process (PID=20499) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:51,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:16:51,203] {logging_mixin.py:104} INFO - [2022-03-20 20:16:51,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:51,240] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:16:51,286] {logging_mixin.py:104} INFO - [2022-03-20 20:16:51,285] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:16:51,320] {logging_mixin.py:104} INFO - [2022-03-20 20:16:51,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:16:51,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 20:17:21,895] {scheduler_job.py:182} INFO - Started process (PID=20531) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:21,900] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:17:21,905] {logging_mixin.py:104} INFO - [2022-03-20 20:17:21,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:21,940] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:21,986] {logging_mixin.py:104} INFO - [2022-03-20 20:17:21,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:17:22,021] {logging_mixin.py:104} INFO - [2022-03-20 20:17:22,020] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:17:22,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:17:52,573] {scheduler_job.py:182} INFO - Started process (PID=20563) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:52,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:17:52,579] {logging_mixin.py:104} INFO - [2022-03-20 20:17:52,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:52,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:17:52,661] {logging_mixin.py:104} INFO - [2022-03-20 20:17:52,660] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:17:52,695] {logging_mixin.py:104} INFO - [2022-03-20 20:17:52,695] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:17:52,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:18:24,429] {scheduler_job.py:182} INFO - Started process (PID=20597) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:24,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:18:24,436] {logging_mixin.py:104} INFO - [2022-03-20 20:18:24,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:24,471] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:24,513] {logging_mixin.py:104} INFO - [2022-03-20 20:18:24,512] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:18:24,546] {logging_mixin.py:104} INFO - [2022-03-20 20:18:24,546] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:18:24,563] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 20:18:54,942] {scheduler_job.py:182} INFO - Started process (PID=20621) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:54,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:18:54,949] {logging_mixin.py:104} INFO - [2022-03-20 20:18:54,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:54,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:18:55,027] {logging_mixin.py:104} INFO - [2022-03-20 20:18:55,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:18:55,060] {logging_mixin.py:104} INFO - [2022-03-20 20:18:55,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:18:55,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 20:19:25,771] {scheduler_job.py:182} INFO - Started process (PID=20645) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:25,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:19:25,778] {logging_mixin.py:104} INFO - [2022-03-20 20:19:25,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:25,814] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:25,858] {logging_mixin.py:104} INFO - [2022-03-20 20:19:25,858] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:19:25,891] {logging_mixin.py:104} INFO - [2022-03-20 20:19:25,890] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:19:25,908] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:19:56,461] {scheduler_job.py:182} INFO - Started process (PID=20678) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:56,465] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:19:56,468] {logging_mixin.py:104} INFO - [2022-03-20 20:19:56,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:56,504] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:19:56,552] {logging_mixin.py:104} INFO - [2022-03-20 20:19:56,551] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:19:56,588] {logging_mixin.py:104} INFO - [2022-03-20 20:19:56,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:19:56,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:20:27,309] {scheduler_job.py:182} INFO - Started process (PID=20709) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:27,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:20:27,314] {logging_mixin.py:104} INFO - [2022-03-20 20:20:27,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:27,352] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:27,397] {logging_mixin.py:104} INFO - [2022-03-20 20:20:27,397] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:20:27,433] {logging_mixin.py:104} INFO - [2022-03-20 20:20:27,432] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:20:27,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:20:57,915] {scheduler_job.py:182} INFO - Started process (PID=20742) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:57,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:20:57,921] {logging_mixin.py:104} INFO - [2022-03-20 20:20:57,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:57,958] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:20:58,002] {logging_mixin.py:104} INFO - [2022-03-20 20:20:58,002] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:20:58,036] {logging_mixin.py:104} INFO - [2022-03-20 20:20:58,035] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:20:58,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:21:28,506] {scheduler_job.py:182} INFO - Started process (PID=20773) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:28,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:21:28,513] {logging_mixin.py:104} INFO - [2022-03-20 20:21:28,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:28,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:28,609] {logging_mixin.py:104} INFO - [2022-03-20 20:21:28,609] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:21:28,645] {logging_mixin.py:104} INFO - [2022-03-20 20:21:28,644] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:21:28,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-20 20:21:59,200] {scheduler_job.py:182} INFO - Started process (PID=20805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:59,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:21:59,207] {logging_mixin.py:104} INFO - [2022-03-20 20:21:59,207] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:59,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:21:59,283] {logging_mixin.py:104} INFO - [2022-03-20 20:21:59,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:21:59,316] {logging_mixin.py:104} INFO - [2022-03-20 20:21:59,315] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:21:59,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 20:22:29,882] {scheduler_job.py:182} INFO - Started process (PID=20837) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:22:29,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:22:29,890] {logging_mixin.py:104} INFO - [2022-03-20 20:22:29,890] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:22:29,924] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:22:29,968] {logging_mixin.py:104} INFO - [2022-03-20 20:22:29,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:22:30,002] {logging_mixin.py:104} INFO - [2022-03-20 20:22:30,002] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:22:30,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 20:23:01,663] {scheduler_job.py:182} INFO - Started process (PID=20871) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:01,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:23:01,669] {logging_mixin.py:104} INFO - [2022-03-20 20:23:01,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:01,703] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:01,747] {logging_mixin.py:104} INFO - [2022-03-20 20:23:01,746] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:23:01,779] {logging_mixin.py:104} INFO - [2022-03-20 20:23:01,779] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:23:01,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 20:23:32,358] {scheduler_job.py:182} INFO - Started process (PID=20895) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:32,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:23:32,365] {logging_mixin.py:104} INFO - [2022-03-20 20:23:32,364] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:32,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:23:32,442] {logging_mixin.py:104} INFO - [2022-03-20 20:23:32,442] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:23:32,474] {logging_mixin.py:104} INFO - [2022-03-20 20:23:32,474] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:23:32,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 20:24:03,200] {scheduler_job.py:182} INFO - Started process (PID=20919) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:03,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:24:03,207] {logging_mixin.py:104} INFO - [2022-03-20 20:24:03,206] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:03,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:03,287] {logging_mixin.py:104} INFO - [2022-03-20 20:24:03,286] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:24:03,320] {logging_mixin.py:104} INFO - [2022-03-20 20:24:03,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:24:03,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:24:33,872] {scheduler_job.py:182} INFO - Started process (PID=20952) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:33,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:24:33,879] {logging_mixin.py:104} INFO - [2022-03-20 20:24:33,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:33,911] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:24:33,954] {logging_mixin.py:104} INFO - [2022-03-20 20:24:33,954] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:24:33,987] {logging_mixin.py:104} INFO - [2022-03-20 20:24:33,986] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:24:34,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 20:25:04,690] {scheduler_job.py:182} INFO - Started process (PID=20983) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:04,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:25:04,699] {logging_mixin.py:104} INFO - [2022-03-20 20:25:04,699] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:04,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:04,779] {logging_mixin.py:104} INFO - [2022-03-20 20:25:04,778] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:25:04,813] {logging_mixin.py:104} INFO - [2022-03-20 20:25:04,812] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:25:04,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:25:35,475] {scheduler_job.py:182} INFO - Started process (PID=21016) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:35,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:25:35,483] {logging_mixin.py:104} INFO - [2022-03-20 20:25:35,482] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:35,518] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:25:35,567] {logging_mixin.py:104} INFO - [2022-03-20 20:25:35,567] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:25:35,602] {logging_mixin.py:104} INFO - [2022-03-20 20:25:35,602] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:25:35,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 20:26:06,067] {scheduler_job.py:182} INFO - Started process (PID=21047) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:06,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:26:06,075] {logging_mixin.py:104} INFO - [2022-03-20 20:26:06,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:06,109] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:06,155] {logging_mixin.py:104} INFO - [2022-03-20 20:26:06,154] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:26:06,188] {logging_mixin.py:104} INFO - [2022-03-20 20:26:06,188] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:26:06,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:26:36,663] {scheduler_job.py:182} INFO - Started process (PID=21080) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:36,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:26:36,673] {logging_mixin.py:104} INFO - [2022-03-20 20:26:36,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:36,706] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:26:36,752] {logging_mixin.py:104} INFO - [2022-03-20 20:26:36,751] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:26:36,785] {logging_mixin.py:104} INFO - [2022-03-20 20:26:36,785] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:26:36,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:27:07,194] {scheduler_job.py:182} INFO - Started process (PID=21111) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:07,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:27:07,201] {logging_mixin.py:104} INFO - [2022-03-20 20:27:07,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:07,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:07,283] {logging_mixin.py:104} INFO - [2022-03-20 20:27:07,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:27:07,317] {logging_mixin.py:104} INFO - [2022-03-20 20:27:07,317] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:27:07,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:27:39,039] {scheduler_job.py:182} INFO - Started process (PID=21145) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:39,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:27:39,045] {logging_mixin.py:104} INFO - [2022-03-20 20:27:39,045] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:39,082] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:27:39,126] {logging_mixin.py:104} INFO - [2022-03-20 20:27:39,126] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:27:39,159] {logging_mixin.py:104} INFO - [2022-03-20 20:27:39,159] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:27:39,177] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:28:09,765] {scheduler_job.py:182} INFO - Started process (PID=21169) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:09,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:28:09,772] {logging_mixin.py:104} INFO - [2022-03-20 20:28:09,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:09,807] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:09,852] {logging_mixin.py:104} INFO - [2022-03-20 20:28:09,851] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:28:09,886] {logging_mixin.py:104} INFO - [2022-03-20 20:28:09,886] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:28:09,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:28:40,132] {scheduler_job.py:182} INFO - Started process (PID=21194) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:40,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:28:40,139] {logging_mixin.py:104} INFO - [2022-03-20 20:28:40,139] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:40,174] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:28:40,220] {logging_mixin.py:104} INFO - [2022-03-20 20:28:40,220] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:28:40,257] {logging_mixin.py:104} INFO - [2022-03-20 20:28:40,256] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:28:40,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 20:29:10,796] {scheduler_job.py:182} INFO - Started process (PID=21225) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:10,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:29:10,804] {logging_mixin.py:104} INFO - [2022-03-20 20:29:10,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:10,838] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:10,884] {logging_mixin.py:104} INFO - [2022-03-20 20:29:10,883] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:29:10,921] {logging_mixin.py:104} INFO - [2022-03-20 20:29:10,920] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:29:10,939] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:29:41,504] {scheduler_job.py:182} INFO - Started process (PID=21257) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:41,509] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:29:41,512] {logging_mixin.py:104} INFO - [2022-03-20 20:29:41,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:41,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:29:41,593] {logging_mixin.py:104} INFO - [2022-03-20 20:29:41,593] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:29:41,629] {logging_mixin.py:104} INFO - [2022-03-20 20:29:41,628] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:29:41,647] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:30:12,383] {scheduler_job.py:182} INFO - Started process (PID=21289) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:12,388] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:30:12,392] {logging_mixin.py:104} INFO - [2022-03-20 20:30:12,391] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:12,427] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:12,472] {logging_mixin.py:104} INFO - [2022-03-20 20:30:12,472] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:30:12,505] {logging_mixin.py:104} INFO - [2022-03-20 20:30:12,504] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:30:12,521] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 20:30:43,338] {scheduler_job.py:182} INFO - Started process (PID=21321) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:43,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:30:43,345] {logging_mixin.py:104} INFO - [2022-03-20 20:30:43,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:43,378] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:30:43,426] {logging_mixin.py:104} INFO - [2022-03-20 20:30:43,426] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:30:43,461] {logging_mixin.py:104} INFO - [2022-03-20 20:30:43,460] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:30:43,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:31:14,192] {scheduler_job.py:182} INFO - Started process (PID=21353) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:14,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:31:14,200] {logging_mixin.py:104} INFO - [2022-03-20 20:31:14,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:14,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:14,286] {logging_mixin.py:104} INFO - [2022-03-20 20:31:14,286] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:31:14,324] {logging_mixin.py:104} INFO - [2022-03-20 20:31:14,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:31:14,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 20:31:44,922] {scheduler_job.py:182} INFO - Started process (PID=21385) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:44,927] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:31:44,931] {logging_mixin.py:104} INFO - [2022-03-20 20:31:44,930] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:44,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:31:45,012] {logging_mixin.py:104} INFO - [2022-03-20 20:31:45,011] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:31:45,046] {logging_mixin.py:104} INFO - [2022-03-20 20:31:45,046] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:31:45,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:32:17,720] {scheduler_job.py:182} INFO - Started process (PID=21419) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:17,724] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:32:17,726] {logging_mixin.py:104} INFO - [2022-03-20 20:32:17,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:17,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:17,807] {logging_mixin.py:104} INFO - [2022-03-20 20:32:17,807] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:32:17,842] {logging_mixin.py:104} INFO - [2022-03-20 20:32:17,841] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:32:17,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:32:48,987] {scheduler_job.py:182} INFO - Started process (PID=21449) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:48,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:32:48,994] {logging_mixin.py:104} INFO - [2022-03-20 20:32:48,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:49,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:32:49,077] {logging_mixin.py:104} INFO - [2022-03-20 20:32:49,076] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:32:49,110] {logging_mixin.py:104} INFO - [2022-03-20 20:32:49,110] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:32:49,127] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:33:19,725] {scheduler_job.py:182} INFO - Started process (PID=21467) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:19,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:33:19,732] {logging_mixin.py:104} INFO - [2022-03-20 20:33:19,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:19,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:19,812] {logging_mixin.py:104} INFO - [2022-03-20 20:33:19,811] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:33:19,845] {logging_mixin.py:104} INFO - [2022-03-20 20:33:19,845] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:33:19,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:33:50,417] {scheduler_job.py:182} INFO - Started process (PID=21499) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:50,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:33:50,425] {logging_mixin.py:104} INFO - [2022-03-20 20:33:50,424] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:50,465] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:33:50,512] {logging_mixin.py:104} INFO - [2022-03-20 20:33:50,512] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:33:50,547] {logging_mixin.py:104} INFO - [2022-03-20 20:33:50,547] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:33:50,565] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 20:34:21,107] {scheduler_job.py:182} INFO - Started process (PID=21531) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:21,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:34:21,114] {logging_mixin.py:104} INFO - [2022-03-20 20:34:21,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:21,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:21,193] {logging_mixin.py:104} INFO - [2022-03-20 20:34:21,192] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:34:21,225] {logging_mixin.py:104} INFO - [2022-03-20 20:34:21,224] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:34:21,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 20:34:51,665] {scheduler_job.py:182} INFO - Started process (PID=21564) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:51,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:34:51,672] {logging_mixin.py:104} INFO - [2022-03-20 20:34:51,671] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:51,710] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:34:51,757] {logging_mixin.py:104} INFO - [2022-03-20 20:34:51,757] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:34:51,793] {logging_mixin.py:104} INFO - [2022-03-20 20:34:51,792] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:34:51,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 20:35:22,286] {scheduler_job.py:182} INFO - Started process (PID=21596) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:22,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:35:22,292] {logging_mixin.py:104} INFO - [2022-03-20 20:35:22,292] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:22,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:22,375] {logging_mixin.py:104} INFO - [2022-03-20 20:35:22,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:35:22,410] {logging_mixin.py:104} INFO - [2022-03-20 20:35:22,409] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:35:22,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:35:52,937] {scheduler_job.py:182} INFO - Started process (PID=21627) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:52,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:35:52,944] {logging_mixin.py:104} INFO - [2022-03-20 20:35:52,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:52,978] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:35:53,021] {logging_mixin.py:104} INFO - [2022-03-20 20:35:53,020] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:35:53,055] {logging_mixin.py:104} INFO - [2022-03-20 20:35:53,054] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:35:53,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.141 seconds
[2022-03-20 20:36:23,517] {scheduler_job.py:182} INFO - Started process (PID=21659) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:23,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:36:23,524] {logging_mixin.py:104} INFO - [2022-03-20 20:36:23,524] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:23,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:23,601] {logging_mixin.py:104} INFO - [2022-03-20 20:36:23,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:36:23,637] {logging_mixin.py:104} INFO - [2022-03-20 20:36:23,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:36:23,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:36:55,527] {scheduler_job.py:182} INFO - Started process (PID=21693) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:55,531] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:36:55,533] {logging_mixin.py:104} INFO - [2022-03-20 20:36:55,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:55,567] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:36:55,610] {logging_mixin.py:104} INFO - [2022-03-20 20:36:55,610] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:36:55,642] {logging_mixin.py:104} INFO - [2022-03-20 20:36:55,642] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:36:55,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 20:37:26,043] {scheduler_job.py:182} INFO - Started process (PID=21717) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:26,048] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:37:26,051] {logging_mixin.py:104} INFO - [2022-03-20 20:37:26,050] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:26,084] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:26,126] {logging_mixin.py:104} INFO - [2022-03-20 20:37:26,126] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:37:26,158] {logging_mixin.py:104} INFO - [2022-03-20 20:37:26,158] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:37:26,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 20:37:56,976] {scheduler_job.py:182} INFO - Started process (PID=21741) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:56,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:37:56,983] {logging_mixin.py:104} INFO - [2022-03-20 20:37:56,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:57,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:37:57,066] {logging_mixin.py:104} INFO - [2022-03-20 20:37:57,066] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:37:57,101] {logging_mixin.py:104} INFO - [2022-03-20 20:37:57,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:37:57,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:38:27,810] {scheduler_job.py:182} INFO - Started process (PID=21773) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:27,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:38:27,817] {logging_mixin.py:104} INFO - [2022-03-20 20:38:27,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:27,850] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:27,896] {logging_mixin.py:104} INFO - [2022-03-20 20:38:27,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:38:27,931] {logging_mixin.py:104} INFO - [2022-03-20 20:38:27,930] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:38:27,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:38:58,504] {scheduler_job.py:182} INFO - Started process (PID=21805) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:58,509] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:38:58,513] {logging_mixin.py:104} INFO - [2022-03-20 20:38:58,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:58,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:38:58,598] {logging_mixin.py:104} INFO - [2022-03-20 20:38:58,598] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:38:58,635] {logging_mixin.py:104} INFO - [2022-03-20 20:38:58,634] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:38:58,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 20:39:29,261] {scheduler_job.py:182} INFO - Started process (PID=21838) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:39:29,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:39:29,272] {logging_mixin.py:104} INFO - [2022-03-20 20:39:29,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:39:29,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:39:29,376] {logging_mixin.py:104} INFO - [2022-03-20 20:39:29,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:39:29,417] {logging_mixin.py:104} INFO - [2022-03-20 20:39:29,416] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:39:29,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-20 20:40:00,039] {scheduler_job.py:182} INFO - Started process (PID=21869) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:00,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:40:00,047] {logging_mixin.py:104} INFO - [2022-03-20 20:40:00,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:00,086] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:00,136] {logging_mixin.py:104} INFO - [2022-03-20 20:40:00,136] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:40:00,173] {logging_mixin.py:104} INFO - [2022-03-20 20:40:00,172] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:40:00,191] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 20:40:30,997] {scheduler_job.py:182} INFO - Started process (PID=21902) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:31,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:40:31,005] {logging_mixin.py:104} INFO - [2022-03-20 20:40:31,005] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:31,045] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:40:31,093] {logging_mixin.py:104} INFO - [2022-03-20 20:40:31,092] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:40:31,129] {logging_mixin.py:104} INFO - [2022-03-20 20:40:31,128] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:40:31,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 20:41:01,633] {scheduler_job.py:182} INFO - Started process (PID=21933) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:01,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:41:01,639] {logging_mixin.py:104} INFO - [2022-03-20 20:41:01,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:01,673] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:01,718] {logging_mixin.py:104} INFO - [2022-03-20 20:41:01,718] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:41:01,753] {logging_mixin.py:104} INFO - [2022-03-20 20:41:01,753] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:41:01,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:41:33,588] {scheduler_job.py:182} INFO - Started process (PID=21967) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:33,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:41:33,595] {logging_mixin.py:104} INFO - [2022-03-20 20:41:33,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:33,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:41:33,676] {logging_mixin.py:104} INFO - [2022-03-20 20:41:33,675] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:41:33,713] {logging_mixin.py:104} INFO - [2022-03-20 20:41:33,713] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:41:33,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:42:04,070] {scheduler_job.py:182} INFO - Started process (PID=21991) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:04,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:42:04,076] {logging_mixin.py:104} INFO - [2022-03-20 20:42:04,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:04,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:04,154] {logging_mixin.py:104} INFO - [2022-03-20 20:42:04,154] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:42:04,188] {logging_mixin.py:104} INFO - [2022-03-20 20:42:04,188] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:42:04,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 20:42:34,655] {scheduler_job.py:182} INFO - Started process (PID=22015) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:34,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:42:34,662] {logging_mixin.py:104} INFO - [2022-03-20 20:42:34,662] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:34,703] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:42:34,749] {logging_mixin.py:104} INFO - [2022-03-20 20:42:34,749] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:42:34,781] {logging_mixin.py:104} INFO - [2022-03-20 20:42:34,781] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:42:34,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:43:05,164] {scheduler_job.py:182} INFO - Started process (PID=22047) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:05,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:43:05,171] {logging_mixin.py:104} INFO - [2022-03-20 20:43:05,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:05,205] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:05,252] {logging_mixin.py:104} INFO - [2022-03-20 20:43:05,252] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:43:05,286] {logging_mixin.py:104} INFO - [2022-03-20 20:43:05,286] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:43:05,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 20:43:35,695] {scheduler_job.py:182} INFO - Started process (PID=22080) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:35,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:43:35,703] {logging_mixin.py:104} INFO - [2022-03-20 20:43:35,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:35,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:43:35,790] {logging_mixin.py:104} INFO - [2022-03-20 20:43:35,789] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:43:35,824] {logging_mixin.py:104} INFO - [2022-03-20 20:43:35,824] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:43:35,842] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-20 20:44:06,308] {scheduler_job.py:182} INFO - Started process (PID=22112) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:06,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:44:06,315] {logging_mixin.py:104} INFO - [2022-03-20 20:44:06,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:06,355] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:06,402] {logging_mixin.py:104} INFO - [2022-03-20 20:44:06,402] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:44:06,439] {logging_mixin.py:104} INFO - [2022-03-20 20:44:06,439] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:44:06,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 20:44:36,996] {scheduler_job.py:182} INFO - Started process (PID=22143) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:37,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:44:37,003] {logging_mixin.py:104} INFO - [2022-03-20 20:44:37,003] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:37,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:44:37,082] {logging_mixin.py:104} INFO - [2022-03-20 20:44:37,082] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:44:37,115] {logging_mixin.py:104} INFO - [2022-03-20 20:44:37,115] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:44:37,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 20:45:07,699] {scheduler_job.py:182} INFO - Started process (PID=22175) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:07,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:45:07,705] {logging_mixin.py:104} INFO - [2022-03-20 20:45:07,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:07,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:07,783] {logging_mixin.py:104} INFO - [2022-03-20 20:45:07,783] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:45:07,816] {logging_mixin.py:104} INFO - [2022-03-20 20:45:07,815] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:45:07,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 20:45:38,427] {scheduler_job.py:182} INFO - Started process (PID=22207) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:38,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:45:38,436] {logging_mixin.py:104} INFO - [2022-03-20 20:45:38,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:38,479] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:45:38,531] {logging_mixin.py:104} INFO - [2022-03-20 20:45:38,531] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:45:38,567] {logging_mixin.py:104} INFO - [2022-03-20 20:45:38,567] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:45:38,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-20 20:46:10,965] {scheduler_job.py:182} INFO - Started process (PID=22241) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:10,972] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:46:10,974] {logging_mixin.py:104} INFO - [2022-03-20 20:46:10,974] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:11,010] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:11,064] {logging_mixin.py:104} INFO - [2022-03-20 20:46:11,064] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:46:11,100] {logging_mixin.py:104} INFO - [2022-03-20 20:46:11,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:46:11,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-20 20:46:41,357] {scheduler_job.py:182} INFO - Started process (PID=22265) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:41,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:46:41,364] {logging_mixin.py:104} INFO - [2022-03-20 20:46:41,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:41,399] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:46:41,446] {logging_mixin.py:104} INFO - [2022-03-20 20:46:41,446] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:46:41,485] {logging_mixin.py:104} INFO - [2022-03-20 20:46:41,484] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:46:41,503] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 20:47:12,180] {scheduler_job.py:182} INFO - Started process (PID=22289) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:12,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:47:12,188] {logging_mixin.py:104} INFO - [2022-03-20 20:47:12,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:12,227] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:12,274] {logging_mixin.py:104} INFO - [2022-03-20 20:47:12,273] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:47:12,308] {logging_mixin.py:104} INFO - [2022-03-20 20:47:12,308] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:47:12,326] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 20:47:42,969] {scheduler_job.py:182} INFO - Started process (PID=22321) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:42,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:47:42,976] {logging_mixin.py:104} INFO - [2022-03-20 20:47:42,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:43,012] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:47:43,059] {logging_mixin.py:104} INFO - [2022-03-20 20:47:43,059] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:47:43,094] {logging_mixin.py:104} INFO - [2022-03-20 20:47:43,093] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:47:43,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:48:13,784] {scheduler_job.py:182} INFO - Started process (PID=22354) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:13,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:48:13,792] {logging_mixin.py:104} INFO - [2022-03-20 20:48:13,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:13,829] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:13,874] {logging_mixin.py:104} INFO - [2022-03-20 20:48:13,873] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:48:13,907] {logging_mixin.py:104} INFO - [2022-03-20 20:48:13,907] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:48:13,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:48:44,577] {scheduler_job.py:182} INFO - Started process (PID=22386) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:44,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:48:44,584] {logging_mixin.py:104} INFO - [2022-03-20 20:48:44,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:44,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:48:44,670] {logging_mixin.py:104} INFO - [2022-03-20 20:48:44,670] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:48:44,706] {logging_mixin.py:104} INFO - [2022-03-20 20:48:44,705] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:48:44,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 20:49:15,427] {scheduler_job.py:182} INFO - Started process (PID=22417) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:15,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:49:15,435] {logging_mixin.py:104} INFO - [2022-03-20 20:49:15,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:15,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:15,519] {logging_mixin.py:104} INFO - [2022-03-20 20:49:15,518] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:49:15,553] {logging_mixin.py:104} INFO - [2022-03-20 20:49:15,553] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:49:15,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 20:49:46,189] {scheduler_job.py:182} INFO - Started process (PID=22449) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:46,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:49:46,196] {logging_mixin.py:104} INFO - [2022-03-20 20:49:46,196] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:46,229] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:49:46,276] {logging_mixin.py:104} INFO - [2022-03-20 20:49:46,275] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:49:46,311] {logging_mixin.py:104} INFO - [2022-03-20 20:49:46,310] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:49:46,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:50:16,832] {scheduler_job.py:182} INFO - Started process (PID=22482) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:16,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:50:16,838] {logging_mixin.py:104} INFO - [2022-03-20 20:50:16,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:16,874] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:16,919] {logging_mixin.py:104} INFO - [2022-03-20 20:50:16,918] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:50:16,979] {logging_mixin.py:104} INFO - [2022-03-20 20:50:16,978] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:50:16,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-20 20:50:48,877] {scheduler_job.py:182} INFO - Started process (PID=22515) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:48,881] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:50:48,884] {logging_mixin.py:104} INFO - [2022-03-20 20:50:48,883] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:48,919] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:50:48,963] {logging_mixin.py:104} INFO - [2022-03-20 20:50:48,962] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:50:48,996] {logging_mixin.py:104} INFO - [2022-03-20 20:50:48,995] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:50:49,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.142 seconds
[2022-03-20 20:51:19,616] {scheduler_job.py:182} INFO - Started process (PID=22539) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:19,620] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:51:19,623] {logging_mixin.py:104} INFO - [2022-03-20 20:51:19,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:19,659] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:19,704] {logging_mixin.py:104} INFO - [2022-03-20 20:51:19,703] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:51:19,737] {logging_mixin.py:104} INFO - [2022-03-20 20:51:19,736] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:51:19,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 20:51:49,920] {scheduler_job.py:182} INFO - Started process (PID=22563) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:49,925] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:51:49,928] {logging_mixin.py:104} INFO - [2022-03-20 20:51:49,928] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:49,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:51:50,023] {logging_mixin.py:104} INFO - [2022-03-20 20:51:50,022] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:51:50,056] {logging_mixin.py:104} INFO - [2022-03-20 20:51:50,056] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:51:50,073] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-20 20:52:20,724] {scheduler_job.py:182} INFO - Started process (PID=22595) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:20,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:52:20,733] {logging_mixin.py:104} INFO - [2022-03-20 20:52:20,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:20,768] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:20,813] {logging_mixin.py:104} INFO - [2022-03-20 20:52:20,812] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:52:20,850] {logging_mixin.py:104} INFO - [2022-03-20 20:52:20,849] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:52:20,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 20:52:51,562] {scheduler_job.py:182} INFO - Started process (PID=22627) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:51,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:52:51,568] {logging_mixin.py:104} INFO - [2022-03-20 20:52:51,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:51,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:52:51,651] {logging_mixin.py:104} INFO - [2022-03-20 20:52:51,650] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:52:51,685] {logging_mixin.py:104} INFO - [2022-03-20 20:52:51,685] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:52:51,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:53:22,306] {scheduler_job.py:182} INFO - Started process (PID=22659) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:22,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:53:22,314] {logging_mixin.py:104} INFO - [2022-03-20 20:53:22,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:22,351] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:22,397] {logging_mixin.py:104} INFO - [2022-03-20 20:53:22,396] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:53:22,431] {logging_mixin.py:104} INFO - [2022-03-20 20:53:22,430] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:53:22,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:53:52,957] {scheduler_job.py:182} INFO - Started process (PID=22692) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:52,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:53:52,964] {logging_mixin.py:104} INFO - [2022-03-20 20:53:52,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:52,998] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:53:53,042] {logging_mixin.py:104} INFO - [2022-03-20 20:53:53,042] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:53:53,076] {logging_mixin.py:104} INFO - [2022-03-20 20:53:53,076] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:53:53,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:54:23,649] {scheduler_job.py:182} INFO - Started process (PID=22723) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:23,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:54:23,656] {logging_mixin.py:104} INFO - [2022-03-20 20:54:23,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:23,692] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:23,739] {logging_mixin.py:104} INFO - [2022-03-20 20:54:23,738] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:54:23,772] {logging_mixin.py:104} INFO - [2022-03-20 20:54:23,771] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:54:23,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 20:54:54,406] {scheduler_job.py:182} INFO - Started process (PID=22756) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:54,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:54:54,412] {logging_mixin.py:104} INFO - [2022-03-20 20:54:54,412] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:54,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:54:54,491] {logging_mixin.py:104} INFO - [2022-03-20 20:54:54,491] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:54:54,526] {logging_mixin.py:104} INFO - [2022-03-20 20:54:54,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:54:54,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 20:55:27,276] {scheduler_job.py:182} INFO - Started process (PID=22789) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:27,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:55:27,283] {logging_mixin.py:104} INFO - [2022-03-20 20:55:27,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:27,316] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:27,362] {logging_mixin.py:104} INFO - [2022-03-20 20:55:27,361] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:55:27,396] {logging_mixin.py:104} INFO - [2022-03-20 20:55:27,396] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:55:27,413] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 20:55:58,545] {scheduler_job.py:182} INFO - Started process (PID=22819) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:58,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:55:58,552] {logging_mixin.py:104} INFO - [2022-03-20 20:55:58,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:58,588] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:55:58,632] {logging_mixin.py:104} INFO - [2022-03-20 20:55:58,632] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:55:58,665] {logging_mixin.py:104} INFO - [2022-03-20 20:55:58,664] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:55:58,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 20:56:28,851] {scheduler_job.py:182} INFO - Started process (PID=22845) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:28,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:56:28,858] {logging_mixin.py:104} INFO - [2022-03-20 20:56:28,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:28,894] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:28,935] {logging_mixin.py:104} INFO - [2022-03-20 20:56:28,935] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:56:28,966] {logging_mixin.py:104} INFO - [2022-03-20 20:56:28,965] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:56:28,983] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 20:56:59,436] {scheduler_job.py:182} INFO - Started process (PID=22870) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:59,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:56:59,447] {logging_mixin.py:104} INFO - [2022-03-20 20:56:59,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:59,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:56:59,533] {logging_mixin.py:104} INFO - [2022-03-20 20:56:59,532] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:56:59,569] {logging_mixin.py:104} INFO - [2022-03-20 20:56:59,568] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:56:59,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 20:57:30,235] {scheduler_job.py:182} INFO - Started process (PID=22901) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:57:30,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:57:30,242] {logging_mixin.py:104} INFO - [2022-03-20 20:57:30,241] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:57:30,281] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:57:30,329] {logging_mixin.py:104} INFO - [2022-03-20 20:57:30,328] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:57:30,363] {logging_mixin.py:104} INFO - [2022-03-20 20:57:30,362] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:57:30,382] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 20:58:00,976] {scheduler_job.py:182} INFO - Started process (PID=22934) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:00,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:58:00,985] {logging_mixin.py:104} INFO - [2022-03-20 20:58:00,985] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:01,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:01,069] {logging_mixin.py:104} INFO - [2022-03-20 20:58:01,069] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:58:01,105] {logging_mixin.py:104} INFO - [2022-03-20 20:58:01,104] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:58:01,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-20 20:58:31,842] {scheduler_job.py:182} INFO - Started process (PID=22966) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:31,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:58:31,849] {logging_mixin.py:104} INFO - [2022-03-20 20:58:31,849] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:31,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:58:31,931] {logging_mixin.py:104} INFO - [2022-03-20 20:58:31,930] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:58:31,965] {logging_mixin.py:104} INFO - [2022-03-20 20:58:31,965] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:58:31,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 20:59:02,677] {scheduler_job.py:182} INFO - Started process (PID=22997) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:02,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:59:02,688] {logging_mixin.py:104} INFO - [2022-03-20 20:59:02,687] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:02,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:02,777] {logging_mixin.py:104} INFO - [2022-03-20 20:59:02,777] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:59:02,810] {logging_mixin.py:104} INFO - [2022-03-20 20:59:02,810] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:59:02,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 20:59:33,387] {scheduler_job.py:182} INFO - Started process (PID=23029) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:33,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 20:59:33,394] {logging_mixin.py:104} INFO - [2022-03-20 20:59:33,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:33,429] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 20:59:33,475] {logging_mixin.py:104} INFO - [2022-03-20 20:59:33,474] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 20:59:33,508] {logging_mixin.py:104} INFO - [2022-03-20 20:59:33,508] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 20:59:33,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 21:00:06,254] {scheduler_job.py:182} INFO - Started process (PID=23063) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:06,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:00:06,262] {logging_mixin.py:104} INFO - [2022-03-20 21:00:06,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:06,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:06,344] {logging_mixin.py:104} INFO - [2022-03-20 21:00:06,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:00:06,377] {logging_mixin.py:104} INFO - [2022-03-20 21:00:06,376] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:00:06,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 21:00:37,454] {scheduler_job.py:182} INFO - Started process (PID=23093) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:37,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:00:37,461] {logging_mixin.py:104} INFO - [2022-03-20 21:00:37,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:37,497] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:00:37,542] {logging_mixin.py:104} INFO - [2022-03-20 21:00:37,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:00:37,576] {logging_mixin.py:104} INFO - [2022-03-20 21:00:37,576] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:00:37,594] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 21:01:07,728] {scheduler_job.py:182} INFO - Started process (PID=23119) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:07,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:01:07,736] {logging_mixin.py:104} INFO - [2022-03-20 21:01:07,736] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:07,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:07,811] {logging_mixin.py:104} INFO - [2022-03-20 21:01:07,811] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:01:07,842] {logging_mixin.py:104} INFO - [2022-03-20 21:01:07,842] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:01:07,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 21:01:38,436] {scheduler_job.py:182} INFO - Started process (PID=23143) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:38,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:01:38,442] {logging_mixin.py:104} INFO - [2022-03-20 21:01:38,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:38,478] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:01:38,524] {logging_mixin.py:104} INFO - [2022-03-20 21:01:38,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:01:38,558] {logging_mixin.py:104} INFO - [2022-03-20 21:01:38,558] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:01:38,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 21:02:09,320] {scheduler_job.py:182} INFO - Started process (PID=23175) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:09,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:02:09,326] {logging_mixin.py:104} INFO - [2022-03-20 21:02:09,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:09,360] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:09,404] {logging_mixin.py:104} INFO - [2022-03-20 21:02:09,404] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:02:09,438] {logging_mixin.py:104} INFO - [2022-03-20 21:02:09,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:02:09,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.140 seconds
[2022-03-20 21:02:40,139] {scheduler_job.py:182} INFO - Started process (PID=23207) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:40,142] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:02:40,144] {logging_mixin.py:104} INFO - [2022-03-20 21:02:40,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:40,181] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:02:40,228] {logging_mixin.py:104} INFO - [2022-03-20 21:02:40,227] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:02:40,265] {logging_mixin.py:104} INFO - [2022-03-20 21:02:40,264] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:02:40,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:03:10,841] {scheduler_job.py:182} INFO - Started process (PID=23239) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:10,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:03:10,849] {logging_mixin.py:104} INFO - [2022-03-20 21:03:10,848] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:10,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:10,929] {logging_mixin.py:104} INFO - [2022-03-20 21:03:10,928] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:03:10,966] {logging_mixin.py:104} INFO - [2022-03-20 21:03:10,965] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:03:10,985] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:03:41,653] {scheduler_job.py:182} INFO - Started process (PID=23272) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:41,656] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:03:41,659] {logging_mixin.py:104} INFO - [2022-03-20 21:03:41,658] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:41,695] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:03:41,743] {logging_mixin.py:104} INFO - [2022-03-20 21:03:41,742] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:03:41,777] {logging_mixin.py:104} INFO - [2022-03-20 21:03:41,776] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:03:41,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 21:04:12,593] {scheduler_job.py:182} INFO - Started process (PID=23304) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:12,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:04:12,600] {logging_mixin.py:104} INFO - [2022-03-20 21:04:12,600] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:12,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:12,684] {logging_mixin.py:104} INFO - [2022-03-20 21:04:12,684] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:04:12,719] {logging_mixin.py:104} INFO - [2022-03-20 21:04:12,719] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:04:12,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 21:04:44,394] {scheduler_job.py:182} INFO - Started process (PID=23337) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:44,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:04:44,401] {logging_mixin.py:104} INFO - [2022-03-20 21:04:44,400] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:44,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:04:44,491] {logging_mixin.py:104} INFO - [2022-03-20 21:04:44,490] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:04:44,526] {logging_mixin.py:104} INFO - [2022-03-20 21:04:44,525] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:04:44,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 21:05:15,728] {scheduler_job.py:182} INFO - Started process (PID=23367) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:15,732] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:05:15,734] {logging_mixin.py:104} INFO - [2022-03-20 21:05:15,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:15,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:15,810] {logging_mixin.py:104} INFO - [2022-03-20 21:05:15,809] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:05:15,842] {logging_mixin.py:104} INFO - [2022-03-20 21:05:15,842] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:05:15,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.138 seconds
[2022-03-20 21:05:46,030] {scheduler_job.py:182} INFO - Started process (PID=23393) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:46,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:05:46,037] {logging_mixin.py:104} INFO - [2022-03-20 21:05:46,036] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:46,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:05:46,111] {logging_mixin.py:104} INFO - [2022-03-20 21:05:46,111] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:05:46,141] {logging_mixin.py:104} INFO - [2022-03-20 21:05:46,141] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:05:46,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.135 seconds
[2022-03-20 21:06:16,735] {scheduler_job.py:182} INFO - Started process (PID=23417) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:16,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:06:16,743] {logging_mixin.py:104} INFO - [2022-03-20 21:06:16,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:16,779] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:16,827] {logging_mixin.py:104} INFO - [2022-03-20 21:06:16,827] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:06:16,862] {logging_mixin.py:104} INFO - [2022-03-20 21:06:16,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:06:16,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 21:06:47,536] {scheduler_job.py:182} INFO - Started process (PID=23449) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:47,542] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:06:47,544] {logging_mixin.py:104} INFO - [2022-03-20 21:06:47,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:47,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:06:47,623] {logging_mixin.py:104} INFO - [2022-03-20 21:06:47,622] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:06:47,657] {logging_mixin.py:104} INFO - [2022-03-20 21:06:47,656] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:06:47,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 21:07:18,400] {scheduler_job.py:182} INFO - Started process (PID=23481) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:18,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:07:18,407] {logging_mixin.py:104} INFO - [2022-03-20 21:07:18,406] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:18,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:18,486] {logging_mixin.py:104} INFO - [2022-03-20 21:07:18,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:07:18,519] {logging_mixin.py:104} INFO - [2022-03-20 21:07:18,518] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:07:18,535] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 21:07:49,095] {scheduler_job.py:182} INFO - Started process (PID=23514) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:49,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:07:49,104] {logging_mixin.py:104} INFO - [2022-03-20 21:07:49,104] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:49,140] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:07:49,188] {logging_mixin.py:104} INFO - [2022-03-20 21:07:49,187] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:07:49,226] {logging_mixin.py:104} INFO - [2022-03-20 21:07:49,226] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:07:49,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-20 21:08:19,897] {scheduler_job.py:182} INFO - Started process (PID=23545) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:19,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:08:19,904] {logging_mixin.py:104} INFO - [2022-03-20 21:08:19,904] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:19,942] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:19,989] {logging_mixin.py:104} INFO - [2022-03-20 21:08:19,988] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:08:20,024] {logging_mixin.py:104} INFO - [2022-03-20 21:08:20,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:08:20,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 21:08:50,570] {scheduler_job.py:182} INFO - Started process (PID=23578) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:50,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:08:50,579] {logging_mixin.py:104} INFO - [2022-03-20 21:08:50,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:50,617] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:08:50,662] {logging_mixin.py:104} INFO - [2022-03-20 21:08:50,661] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:08:50,696] {logging_mixin.py:104} INFO - [2022-03-20 21:08:50,696] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:08:50,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 21:09:23,276] {scheduler_job.py:182} INFO - Started process (PID=23611) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:23,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:09:23,283] {logging_mixin.py:104} INFO - [2022-03-20 21:09:23,283] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:23,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:23,368] {logging_mixin.py:104} INFO - [2022-03-20 21:09:23,368] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:09:23,401] {logging_mixin.py:104} INFO - [2022-03-20 21:09:23,401] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:09:23,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 21:09:54,375] {scheduler_job.py:182} INFO - Started process (PID=23641) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:54,380] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:09:54,383] {logging_mixin.py:104} INFO - [2022-03-20 21:09:54,383] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:54,417] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:09:54,461] {logging_mixin.py:104} INFO - [2022-03-20 21:09:54,461] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:09:54,495] {logging_mixin.py:104} INFO - [2022-03-20 21:09:54,495] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:09:54,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 21:10:24,643] {scheduler_job.py:182} INFO - Started process (PID=23659) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:24,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:10:24,650] {logging_mixin.py:104} INFO - [2022-03-20 21:10:24,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:24,682] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:24,728] {logging_mixin.py:104} INFO - [2022-03-20 21:10:24,727] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:10:24,763] {logging_mixin.py:104} INFO - [2022-03-20 21:10:24,762] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:10:24,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 21:10:55,425] {scheduler_job.py:182} INFO - Started process (PID=23692) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:55,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:10:55,432] {logging_mixin.py:104} INFO - [2022-03-20 21:10:55,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:55,467] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:10:55,516] {logging_mixin.py:104} INFO - [2022-03-20 21:10:55,515] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:10:55,550] {logging_mixin.py:104} INFO - [2022-03-20 21:10:55,550] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:10:55,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:11:26,214] {scheduler_job.py:182} INFO - Started process (PID=23723) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:26,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:11:26,220] {logging_mixin.py:104} INFO - [2022-03-20 21:11:26,220] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:26,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:26,301] {logging_mixin.py:104} INFO - [2022-03-20 21:11:26,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:11:26,335] {logging_mixin.py:104} INFO - [2022-03-20 21:11:26,335] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:11:26,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 21:11:57,095] {scheduler_job.py:182} INFO - Started process (PID=23756) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:57,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:11:57,102] {logging_mixin.py:104} INFO - [2022-03-20 21:11:57,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:57,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:11:57,183] {logging_mixin.py:104} INFO - [2022-03-20 21:11:57,183] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:11:57,218] {logging_mixin.py:104} INFO - [2022-03-20 21:11:57,218] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:11:57,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 21:12:27,729] {scheduler_job.py:182} INFO - Started process (PID=23788) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:27,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:12:27,739] {logging_mixin.py:104} INFO - [2022-03-20 21:12:27,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:27,773] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:27,823] {logging_mixin.py:104} INFO - [2022-03-20 21:12:27,822] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:12:27,857] {logging_mixin.py:104} INFO - [2022-03-20 21:12:27,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:12:27,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 21:12:58,541] {scheduler_job.py:182} INFO - Started process (PID=23819) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:58,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:12:58,553] {logging_mixin.py:104} INFO - [2022-03-20 21:12:58,552] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:58,587] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:12:58,633] {logging_mixin.py:104} INFO - [2022-03-20 21:12:58,632] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:12:58,666] {logging_mixin.py:104} INFO - [2022-03-20 21:12:58,666] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:12:58,684] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:13:29,242] {scheduler_job.py:182} INFO - Started process (PID=23851) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:13:29,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:13:29,251] {logging_mixin.py:104} INFO - [2022-03-20 21:13:29,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:13:29,287] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:13:29,333] {logging_mixin.py:104} INFO - [2022-03-20 21:13:29,332] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:13:29,366] {logging_mixin.py:104} INFO - [2022-03-20 21:13:29,365] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:13:29,383] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:14:02,057] {scheduler_job.py:182} INFO - Started process (PID=23885) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:02,061] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:14:02,064] {logging_mixin.py:104} INFO - [2022-03-20 21:14:02,064] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:02,100] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:02,145] {logging_mixin.py:104} INFO - [2022-03-20 21:14:02,144] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:14:02,178] {logging_mixin.py:104} INFO - [2022-03-20 21:14:02,178] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:14:02,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 21:14:33,342] {scheduler_job.py:182} INFO - Started process (PID=23915) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:33,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:14:33,349] {logging_mixin.py:104} INFO - [2022-03-20 21:14:33,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:33,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:14:33,434] {logging_mixin.py:104} INFO - [2022-03-20 21:14:33,434] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:14:33,468] {logging_mixin.py:104} INFO - [2022-03-20 21:14:33,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:14:33,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 21:15:04,013] {scheduler_job.py:182} INFO - Started process (PID=23933) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:04,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:15:04,020] {logging_mixin.py:104} INFO - [2022-03-20 21:15:04,020] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:04,060] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:04,108] {logging_mixin.py:104} INFO - [2022-03-20 21:15:04,108] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:15:04,144] {logging_mixin.py:104} INFO - [2022-03-20 21:15:04,144] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:15:04,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 21:15:34,777] {scheduler_job.py:182} INFO - Started process (PID=23965) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:34,781] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:15:34,783] {logging_mixin.py:104} INFO - [2022-03-20 21:15:34,783] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:34,820] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:15:34,866] {logging_mixin.py:104} INFO - [2022-03-20 21:15:34,866] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:15:34,899] {logging_mixin.py:104} INFO - [2022-03-20 21:15:34,899] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:15:34,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.147 seconds
[2022-03-20 21:16:05,582] {scheduler_job.py:182} INFO - Started process (PID=23997) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:05,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:16:05,590] {logging_mixin.py:104} INFO - [2022-03-20 21:16:05,589] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:05,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:05,671] {logging_mixin.py:104} INFO - [2022-03-20 21:16:05,670] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:16:05,707] {logging_mixin.py:104} INFO - [2022-03-20 21:16:05,707] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:16:05,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.149 seconds
[2022-03-20 21:16:36,420] {scheduler_job.py:182} INFO - Started process (PID=24030) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:36,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:16:36,428] {logging_mixin.py:104} INFO - [2022-03-20 21:16:36,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:36,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:16:36,507] {logging_mixin.py:104} INFO - [2022-03-20 21:16:36,507] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:16:36,543] {logging_mixin.py:104} INFO - [2022-03-20 21:16:36,542] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:16:36,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.148 seconds
[2022-03-20 21:17:07,204] {scheduler_job.py:182} INFO - Started process (PID=24061) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:07,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:17:07,211] {logging_mixin.py:104} INFO - [2022-03-20 21:17:07,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:07,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:07,296] {logging_mixin.py:104} INFO - [2022-03-20 21:17:07,295] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:17:07,332] {logging_mixin.py:104} INFO - [2022-03-20 21:17:07,331] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:17:07,350] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-20 21:17:37,837] {scheduler_job.py:182} INFO - Started process (PID=24094) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:37,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:17:37,845] {logging_mixin.py:104} INFO - [2022-03-20 21:17:37,845] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:37,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:17:37,928] {logging_mixin.py:104} INFO - [2022-03-20 21:17:37,928] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:17:37,963] {logging_mixin.py:104} INFO - [2022-03-20 21:17:37,962] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:17:37,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:18:08,416] {scheduler_job.py:182} INFO - Started process (PID=24125) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:08,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:18:08,424] {logging_mixin.py:104} INFO - [2022-03-20 21:18:08,423] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:08,458] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:08,506] {logging_mixin.py:104} INFO - [2022-03-20 21:18:08,506] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:18:08,542] {logging_mixin.py:104} INFO - [2022-03-20 21:18:08,541] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:18:08,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 21:18:40,246] {scheduler_job.py:182} INFO - Started process (PID=24159) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:40,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:18:40,251] {logging_mixin.py:104} INFO - [2022-03-20 21:18:40,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:40,283] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:18:40,327] {logging_mixin.py:104} INFO - [2022-03-20 21:18:40,327] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:18:40,359] {logging_mixin.py:104} INFO - [2022-03-20 21:18:40,359] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:18:40,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 21:19:10,955] {scheduler_job.py:182} INFO - Started process (PID=24183) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:10,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:19:10,962] {logging_mixin.py:104} INFO - [2022-03-20 21:19:10,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:10,998] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:11,043] {logging_mixin.py:104} INFO - [2022-03-20 21:19:11,043] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:19:11,075] {logging_mixin.py:104} INFO - [2022-03-20 21:19:11,075] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:19:11,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 21:19:41,745] {scheduler_job.py:182} INFO - Started process (PID=24207) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:41,750] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:19:41,755] {logging_mixin.py:104} INFO - [2022-03-20 21:19:41,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:41,802] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:19:41,858] {logging_mixin.py:104} INFO - [2022-03-20 21:19:41,858] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:19:41,900] {logging_mixin.py:104} INFO - [2022-03-20 21:19:41,900] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:19:41,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-20 21:20:12,776] {scheduler_job.py:182} INFO - Started process (PID=24239) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:12,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:20:12,786] {logging_mixin.py:104} INFO - [2022-03-20 21:20:12,786] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:12,827] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:12,873] {logging_mixin.py:104} INFO - [2022-03-20 21:20:12,872] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:20:12,908] {logging_mixin.py:104} INFO - [2022-03-20 21:20:12,908] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:20:12,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-20 21:20:43,437] {scheduler_job.py:182} INFO - Started process (PID=24270) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:43,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:20:43,444] {logging_mixin.py:104} INFO - [2022-03-20 21:20:43,443] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:43,487] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:20:43,534] {logging_mixin.py:104} INFO - [2022-03-20 21:20:43,534] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:20:43,570] {logging_mixin.py:104} INFO - [2022-03-20 21:20:43,570] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:20:43,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-20 21:21:14,217] {scheduler_job.py:182} INFO - Started process (PID=24303) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:14,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:21:14,224] {logging_mixin.py:104} INFO - [2022-03-20 21:21:14,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:14,263] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:14,310] {logging_mixin.py:104} INFO - [2022-03-20 21:21:14,310] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:21:14,344] {logging_mixin.py:104} INFO - [2022-03-20 21:21:14,343] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:21:14,362] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-20 21:21:44,976] {scheduler_job.py:182} INFO - Started process (PID=24335) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:44,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:21:44,985] {logging_mixin.py:104} INFO - [2022-03-20 21:21:44,984] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:45,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:21:45,068] {logging_mixin.py:104} INFO - [2022-03-20 21:21:45,068] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:21:45,102] {logging_mixin.py:104} INFO - [2022-03-20 21:21:45,102] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:21:45,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-20 21:22:15,665] {scheduler_job.py:182} INFO - Started process (PID=24368) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:15,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:22:15,672] {logging_mixin.py:104} INFO - [2022-03-20 21:22:15,671] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:15,707] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:15,752] {logging_mixin.py:104} INFO - [2022-03-20 21:22:15,752] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:22:15,785] {logging_mixin.py:104} INFO - [2022-03-20 21:22:15,785] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:22:15,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.145 seconds
[2022-03-20 21:22:46,460] {scheduler_job.py:182} INFO - Started process (PID=24400) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:46,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:22:46,469] {logging_mixin.py:104} INFO - [2022-03-20 21:22:46,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:46,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:22:46,563] {logging_mixin.py:104} INFO - [2022-03-20 21:22:46,562] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:22:46,606] {logging_mixin.py:104} INFO - [2022-03-20 21:22:46,606] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:22:46,626] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-20 21:23:18,702] {scheduler_job.py:182} INFO - Started process (PID=24433) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:18,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:23:18,708] {logging_mixin.py:104} INFO - [2022-03-20 21:23:18,707] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:18,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:18,783] {logging_mixin.py:104} INFO - [2022-03-20 21:23:18,783] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:23:18,815] {logging_mixin.py:104} INFO - [2022-03-20 21:23:18,815] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:23:18,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.137 seconds
[2022-03-20 21:23:49,128] {scheduler_job.py:182} INFO - Started process (PID=24457) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:49,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:23:49,134] {logging_mixin.py:104} INFO - [2022-03-20 21:23:49,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:49,167] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:23:49,212] {logging_mixin.py:104} INFO - [2022-03-20 21:23:49,212] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:23:49,247] {logging_mixin.py:104} INFO - [2022-03-20 21:23:49,246] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:23:49,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.143 seconds
[2022-03-20 21:24:19,697] {scheduler_job.py:182} INFO - Started process (PID=24482) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:19,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:24:19,706] {logging_mixin.py:104} INFO - [2022-03-20 21:24:19,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:19,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:19,785] {logging_mixin.py:104} INFO - [2022-03-20 21:24:19,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:24:19,821] {logging_mixin.py:104} INFO - [2022-03-20 21:24:19,821] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:24:19,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:24:50,337] {scheduler_job.py:182} INFO - Started process (PID=24513) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:50,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:24:50,346] {logging_mixin.py:104} INFO - [2022-03-20 21:24:50,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:50,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:24:50,429] {logging_mixin.py:104} INFO - [2022-03-20 21:24:50,428] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:24:50,463] {logging_mixin.py:104} INFO - [2022-03-20 21:24:50,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:24:50,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:25:21,034] {scheduler_job.py:182} INFO - Started process (PID=24546) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:21,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:25:21,041] {logging_mixin.py:104} INFO - [2022-03-20 21:25:21,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:21,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:21,123] {logging_mixin.py:104} INFO - [2022-03-20 21:25:21,122] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:25:21,156] {logging_mixin.py:104} INFO - [2022-03-20 21:25:21,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:25:21,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.146 seconds
[2022-03-20 21:25:51,563] {scheduler_job.py:182} INFO - Started process (PID=24578) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:51,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:25:51,570] {logging_mixin.py:104} INFO - [2022-03-20 21:25:51,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:51,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:25:51,653] {logging_mixin.py:104} INFO - [2022-03-20 21:25:51,653] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:25:51,689] {logging_mixin.py:104} INFO - [2022-03-20 21:25:51,689] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:25:51,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 21:26:22,104] {scheduler_job.py:182} INFO - Started process (PID=24609) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:22,109] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:26:22,111] {logging_mixin.py:104} INFO - [2022-03-20 21:26:22,111] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:22,146] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:22,195] {logging_mixin.py:104} INFO - [2022-03-20 21:26:22,194] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:26:22,231] {logging_mixin.py:104} INFO - [2022-03-20 21:26:22,231] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:26:22,248] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-20 21:26:52,634] {scheduler_job.py:182} INFO - Started process (PID=24641) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:52,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:26:52,642] {logging_mixin.py:104} INFO - [2022-03-20 21:26:52,641] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:52,677] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:26:52,721] {logging_mixin.py:104} INFO - [2022-03-20 21:26:52,720] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:26:52,757] {logging_mixin.py:104} INFO - [2022-03-20 21:26:52,757] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:26:52,776] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.150 seconds
[2022-03-20 21:27:23,516] {scheduler_job.py:182} INFO - Started process (PID=24673) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 21:27:23,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 21:27:23,523] {logging_mixin.py:104} INFO - [2022-03-20 21:27:23,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 21:27:23,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 21:27:23,604] {logging_mixin.py:104} INFO - [2022-03-20 21:27:23,603] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 21:27:23,637] {logging_mixin.py:104} INFO - [2022-03-20 21:27:23,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 21:27:23,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.144 seconds
[2022-03-20 22:02:18,070] {scheduler_job.py:182} INFO - Started process (PID=24705) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 22:02:18,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 22:02:18,078] {logging_mixin.py:104} INFO - [2022-03-20 22:02:18,078] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 22:02:18,119] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 22:02:18,168] {logging_mixin.py:104} INFO - [2022-03-20 22:02:18,168] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 22:02:18,210] {logging_mixin.py:104} INFO - [2022-03-20 22:02:18,210] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 22:02:18,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-20 23:07:02,545] {scheduler_job.py:182} INFO - Started process (PID=24737) to work on /opt/airflow/dags/spark_job.py
[2022-03-20 23:07:02,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-20 23:07:02,553] {logging_mixin.py:104} INFO - [2022-03-20 23:07:02,552] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-20 23:07:02,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-20 23:07:02,651] {logging_mixin.py:104} INFO - [2022-03-20 23:07:02,651] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-20 23:07:02,720] {logging_mixin.py:104} INFO - [2022-03-20 23:07:02,719] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-19 00:00:00+00:00
[2022-03-20 23:07:02,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.212 seconds
