[2022-03-18 00:00:27,776] {scheduler_job.py:182} INFO - Started process (PID=14138) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:27,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:00:27,782] {logging_mixin.py:104} INFO - [2022-03-18 00:00:27,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:27,799] {logging_mixin.py:104} INFO - [2022-03-18 00:00:27,794] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:00:27,802] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:27,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:00:58,280] {scheduler_job.py:182} INFO - Started process (PID=14168) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:58,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:00:58,289] {logging_mixin.py:104} INFO - [2022-03-18 00:00:58,288] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:58,306] {logging_mixin.py:104} INFO - [2022-03-18 00:00:58,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:00:58,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:00:58,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:01:30,118] {scheduler_job.py:182} INFO - Started process (PID=14200) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:01:30,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:01:30,124] {logging_mixin.py:104} INFO - [2022-03-18 00:01:30,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:01:30,141] {logging_mixin.py:104} INFO - [2022-03-18 00:01:30,136] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:01:30,144] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:01:30,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:02:00,930] {scheduler_job.py:182} INFO - Started process (PID=14222) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:00,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:02:00,939] {logging_mixin.py:104} INFO - [2022-03-18 00:02:00,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:00,961] {logging_mixin.py:104} INFO - [2022-03-18 00:02:00,955] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:02:00,967] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:01,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 00:02:31,547] {scheduler_job.py:182} INFO - Started process (PID=14252) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:31,552] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:02:31,555] {logging_mixin.py:104} INFO - [2022-03-18 00:02:31,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:31,576] {logging_mixin.py:104} INFO - [2022-03-18 00:02:31,572] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:02:31,580] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:02:31,607] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:03:02,110] {scheduler_job.py:182} INFO - Started process (PID=14284) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:02,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:03:02,118] {logging_mixin.py:104} INFO - [2022-03-18 00:03:02,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:02,138] {logging_mixin.py:104} INFO - [2022-03-18 00:03:02,132] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:03:02,142] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:02,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.072 seconds
[2022-03-18 00:03:32,892] {scheduler_job.py:182} INFO - Started process (PID=14316) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:32,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:03:32,899] {logging_mixin.py:104} INFO - [2022-03-18 00:03:32,899] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:32,916] {logging_mixin.py:104} INFO - [2022-03-18 00:03:32,911] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:03:32,919] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:03:32,946] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:04:03,562] {scheduler_job.py:182} INFO - Started process (PID=14348) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:03,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:04:03,570] {logging_mixin.py:104} INFO - [2022-03-18 00:04:03,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:03,588] {logging_mixin.py:104} INFO - [2022-03-18 00:04:03,583] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:04:03,591] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:03,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:04:34,194] {scheduler_job.py:182} INFO - Started process (PID=14380) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:34,199] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:04:34,201] {logging_mixin.py:104} INFO - [2022-03-18 00:04:34,201] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:34,217] {logging_mixin.py:104} INFO - [2022-03-18 00:04:34,213] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:04:34,221] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:04:34,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:05:05,282] {scheduler_job.py:182} INFO - Started process (PID=14412) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:05,288] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:05:05,291] {logging_mixin.py:104} INFO - [2022-03-18 00:05:05,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:05,308] {logging_mixin.py:104} INFO - [2022-03-18 00:05:05,304] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:05:05,312] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:05,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:05:35,964] {scheduler_job.py:182} INFO - Started process (PID=14442) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:35,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:05:35,971] {logging_mixin.py:104} INFO - [2022-03-18 00:05:35,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:35,989] {logging_mixin.py:104} INFO - [2022-03-18 00:05:35,983] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:05:35,993] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:05:36,024] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:06:07,732] {scheduler_job.py:182} INFO - Started process (PID=14474) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:07,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:06:07,739] {logging_mixin.py:104} INFO - [2022-03-18 00:06:07,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:07,757] {logging_mixin.py:104} INFO - [2022-03-18 00:06:07,752] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:06:07,762] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:07,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:06:38,666] {scheduler_job.py:182} INFO - Started process (PID=14497) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:38,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:06:38,674] {logging_mixin.py:104} INFO - [2022-03-18 00:06:38,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:38,691] {logging_mixin.py:104} INFO - [2022-03-18 00:06:38,686] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:06:38,695] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:06:38,723] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:07:09,305] {scheduler_job.py:182} INFO - Started process (PID=14526) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:09,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:07:09,312] {logging_mixin.py:104} INFO - [2022-03-18 00:07:09,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:09,330] {logging_mixin.py:104} INFO - [2022-03-18 00:07:09,325] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:07:09,333] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:09,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 00:07:39,942] {scheduler_job.py:182} INFO - Started process (PID=14558) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:39,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:07:39,950] {logging_mixin.py:104} INFO - [2022-03-18 00:07:39,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:39,967] {logging_mixin.py:104} INFO - [2022-03-18 00:07:39,962] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:07:39,971] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:07:39,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:08:10,542] {scheduler_job.py:182} INFO - Started process (PID=14590) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:10,548] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:08:10,551] {logging_mixin.py:104} INFO - [2022-03-18 00:08:10,550] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:10,567] {logging_mixin.py:104} INFO - [2022-03-18 00:08:10,563] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:08:10,571] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:10,599] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:08:41,270] {scheduler_job.py:182} INFO - Started process (PID=14622) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:41,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:08:41,278] {logging_mixin.py:104} INFO - [2022-03-18 00:08:41,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:41,297] {logging_mixin.py:104} INFO - [2022-03-18 00:08:41,292] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:08:41,301] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:08:41,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:09:11,975] {scheduler_job.py:182} INFO - Started process (PID=14654) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:11,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:09:11,983] {logging_mixin.py:104} INFO - [2022-03-18 00:09:11,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:12,000] {logging_mixin.py:104} INFO - [2022-03-18 00:09:11,995] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:09:12,003] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:12,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:09:42,679] {scheduler_job.py:182} INFO - Started process (PID=14686) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:42,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:09:42,689] {logging_mixin.py:104} INFO - [2022-03-18 00:09:42,689] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:42,706] {logging_mixin.py:104} INFO - [2022-03-18 00:09:42,701] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:09:42,710] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:09:42,736] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:10:13,388] {scheduler_job.py:182} INFO - Started process (PID=14716) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:13,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:10:13,394] {logging_mixin.py:104} INFO - [2022-03-18 00:10:13,394] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:13,411] {logging_mixin.py:104} INFO - [2022-03-18 00:10:13,407] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:10:13,416] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:13,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:10:46,272] {scheduler_job.py:182} INFO - Started process (PID=14748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:46,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:10:46,279] {logging_mixin.py:104} INFO - [2022-03-18 00:10:46,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:46,297] {logging_mixin.py:104} INFO - [2022-03-18 00:10:46,292] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:10:46,301] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:10:46,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:11:17,179] {scheduler_job.py:182} INFO - Started process (PID=14770) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:17,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:11:17,186] {logging_mixin.py:104} INFO - [2022-03-18 00:11:17,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:17,203] {logging_mixin.py:104} INFO - [2022-03-18 00:11:17,198] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:11:17,207] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:17,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:11:47,887] {scheduler_job.py:182} INFO - Started process (PID=14800) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:47,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:11:47,894] {logging_mixin.py:104} INFO - [2022-03-18 00:11:47,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:47,910] {logging_mixin.py:104} INFO - [2022-03-18 00:11:47,906] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:11:47,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:11:47,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:12:18,630] {scheduler_job.py:182} INFO - Started process (PID=14832) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:18,634] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:12:18,637] {logging_mixin.py:104} INFO - [2022-03-18 00:12:18,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:18,655] {logging_mixin.py:104} INFO - [2022-03-18 00:12:18,651] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:12:18,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:18,688] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:12:49,425] {scheduler_job.py:182} INFO - Started process (PID=14864) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:49,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:12:49,435] {logging_mixin.py:104} INFO - [2022-03-18 00:12:49,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:49,453] {logging_mixin.py:104} INFO - [2022-03-18 00:12:49,448] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:12:49,457] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:12:49,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:13:20,136] {scheduler_job.py:182} INFO - Started process (PID=14896) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:20,140] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:13:20,143] {logging_mixin.py:104} INFO - [2022-03-18 00:13:20,143] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:20,162] {logging_mixin.py:104} INFO - [2022-03-18 00:13:20,157] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:13:20,166] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:20,194] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:13:50,845] {scheduler_job.py:182} INFO - Started process (PID=14928) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:50,849] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:13:50,851] {logging_mixin.py:104} INFO - [2022-03-18 00:13:50,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:50,868] {logging_mixin.py:104} INFO - [2022-03-18 00:13:50,863] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:13:50,872] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:13:50,898] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:14:21,360] {scheduler_job.py:182} INFO - Started process (PID=14960) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:21,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:14:21,367] {logging_mixin.py:104} INFO - [2022-03-18 00:14:21,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:21,383] {logging_mixin.py:104} INFO - [2022-03-18 00:14:21,379] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:14:21,387] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:21,413] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.059 seconds
[2022-03-18 00:14:51,973] {scheduler_job.py:182} INFO - Started process (PID=14990) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:51,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:14:51,980] {logging_mixin.py:104} INFO - [2022-03-18 00:14:51,979] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:51,995] {logging_mixin.py:104} INFO - [2022-03-18 00:14:51,991] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:14:51,999] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:14:52,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:15:24,779] {scheduler_job.py:182} INFO - Started process (PID=15022) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:24,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:15:24,785] {logging_mixin.py:104} INFO - [2022-03-18 00:15:24,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:24,803] {logging_mixin.py:104} INFO - [2022-03-18 00:15:24,798] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:15:24,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:24,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:15:55,532] {scheduler_job.py:182} INFO - Started process (PID=15044) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:55,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:15:55,541] {logging_mixin.py:104} INFO - [2022-03-18 00:15:55,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:55,559] {logging_mixin.py:104} INFO - [2022-03-18 00:15:55,554] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:15:55,562] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:15:55,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:16:26,129] {scheduler_job.py:182} INFO - Started process (PID=15074) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:26,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:16:26,137] {logging_mixin.py:104} INFO - [2022-03-18 00:16:26,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:26,155] {logging_mixin.py:104} INFO - [2022-03-18 00:16:26,150] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:16:26,158] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:26,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:16:56,975] {scheduler_job.py:182} INFO - Started process (PID=15106) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:56,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:16:56,983] {logging_mixin.py:104} INFO - [2022-03-18 00:16:56,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:56,998] {logging_mixin.py:104} INFO - [2022-03-18 00:16:56,994] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:16:57,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:16:57,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:17:27,870] {scheduler_job.py:182} INFO - Started process (PID=15138) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:27,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:17:27,878] {logging_mixin.py:104} INFO - [2022-03-18 00:17:27,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:27,895] {logging_mixin.py:104} INFO - [2022-03-18 00:17:27,891] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:17:27,899] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:27,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:17:58,776] {scheduler_job.py:182} INFO - Started process (PID=15170) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:58,781] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:17:58,784] {logging_mixin.py:104} INFO - [2022-03-18 00:17:58,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:58,801] {logging_mixin.py:104} INFO - [2022-03-18 00:17:58,796] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:17:58,805] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:17:58,834] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:18:29,440] {scheduler_job.py:182} INFO - Started process (PID=15202) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:29,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:18:29,447] {logging_mixin.py:104} INFO - [2022-03-18 00:18:29,447] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:29,467] {logging_mixin.py:104} INFO - [2022-03-18 00:18:29,463] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:18:29,470] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:29,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:18:59,915] {scheduler_job.py:182} INFO - Started process (PID=15234) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:59,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:18:59,924] {logging_mixin.py:104} INFO - [2022-03-18 00:18:59,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:59,940] {logging_mixin.py:104} INFO - [2022-03-18 00:18:59,936] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:18:59,944] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:18:59,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:19:30,599] {scheduler_job.py:182} INFO - Started process (PID=15264) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:19:30,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:19:30,606] {logging_mixin.py:104} INFO - [2022-03-18 00:19:30,606] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:19:30,624] {logging_mixin.py:104} INFO - [2022-03-18 00:19:30,618] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:19:30,628] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:19:30,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:20:03,478] {scheduler_job.py:182} INFO - Started process (PID=15296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:03,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:20:03,484] {logging_mixin.py:104} INFO - [2022-03-18 00:20:03,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:03,502] {logging_mixin.py:104} INFO - [2022-03-18 00:20:03,496] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:20:03,505] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:03,534] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 00:20:34,343] {scheduler_job.py:182} INFO - Started process (PID=15319) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:34,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:20:34,352] {logging_mixin.py:104} INFO - [2022-03-18 00:20:34,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:34,371] {logging_mixin.py:104} INFO - [2022-03-18 00:20:34,367] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:20:34,375] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:20:34,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:21:05,144] {scheduler_job.py:182} INFO - Started process (PID=15348) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:05,148] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:21:05,151] {logging_mixin.py:104} INFO - [2022-03-18 00:21:05,150] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:05,169] {logging_mixin.py:104} INFO - [2022-03-18 00:21:05,164] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:21:05,172] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:05,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:21:36,073] {scheduler_job.py:182} INFO - Started process (PID=15380) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:36,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:21:36,081] {logging_mixin.py:104} INFO - [2022-03-18 00:21:36,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:36,102] {logging_mixin.py:104} INFO - [2022-03-18 00:21:36,097] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:21:36,106] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:21:36,133] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:22:06,788] {scheduler_job.py:182} INFO - Started process (PID=15412) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:06,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:22:06,799] {logging_mixin.py:104} INFO - [2022-03-18 00:22:06,799] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:06,816] {logging_mixin.py:104} INFO - [2022-03-18 00:22:06,811] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:22:06,820] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:06,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:22:37,535] {scheduler_job.py:182} INFO - Started process (PID=15444) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:37,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:22:37,542] {logging_mixin.py:104} INFO - [2022-03-18 00:22:37,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:37,559] {logging_mixin.py:104} INFO - [2022-03-18 00:22:37,554] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:22:37,563] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:22:37,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:23:08,110] {scheduler_job.py:182} INFO - Started process (PID=15476) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:08,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:23:08,116] {logging_mixin.py:104} INFO - [2022-03-18 00:23:08,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:08,133] {logging_mixin.py:104} INFO - [2022-03-18 00:23:08,127] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:23:08,136] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:08,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:23:38,613] {scheduler_job.py:182} INFO - Started process (PID=15508) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:38,617] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:23:38,620] {logging_mixin.py:104} INFO - [2022-03-18 00:23:38,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:38,637] {logging_mixin.py:104} INFO - [2022-03-18 00:23:38,632] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:23:38,641] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:23:38,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:24:09,375] {scheduler_job.py:182} INFO - Started process (PID=15538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:09,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:24:09,381] {logging_mixin.py:104} INFO - [2022-03-18 00:24:09,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:09,399] {logging_mixin.py:104} INFO - [2022-03-18 00:24:09,394] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:24:09,403] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:09,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 00:24:42,166] {scheduler_job.py:182} INFO - Started process (PID=15570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:42,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:24:42,172] {logging_mixin.py:104} INFO - [2022-03-18 00:24:42,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:42,189] {logging_mixin.py:104} INFO - [2022-03-18 00:24:42,185] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:24:42,193] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:24:42,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:25:13,129] {scheduler_job.py:182} INFO - Started process (PID=15592) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:13,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:25:13,135] {logging_mixin.py:104} INFO - [2022-03-18 00:25:13,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:13,155] {logging_mixin.py:104} INFO - [2022-03-18 00:25:13,149] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:25:13,159] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:13,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.098 seconds
[2022-03-18 00:25:43,864] {scheduler_job.py:182} INFO - Started process (PID=15622) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:43,868] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:25:43,872] {logging_mixin.py:104} INFO - [2022-03-18 00:25:43,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:43,892] {logging_mixin.py:104} INFO - [2022-03-18 00:25:43,887] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:25:43,897] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:25:43,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:26:14,613] {scheduler_job.py:182} INFO - Started process (PID=15654) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:14,617] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:26:14,619] {logging_mixin.py:104} INFO - [2022-03-18 00:26:14,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:14,636] {logging_mixin.py:104} INFO - [2022-03-18 00:26:14,631] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:26:14,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:14,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:26:45,296] {scheduler_job.py:182} INFO - Started process (PID=15686) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:45,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:26:45,303] {logging_mixin.py:104} INFO - [2022-03-18 00:26:45,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:45,319] {logging_mixin.py:104} INFO - [2022-03-18 00:26:45,314] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:26:45,322] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:26:45,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.059 seconds
[2022-03-18 00:27:16,045] {scheduler_job.py:182} INFO - Started process (PID=15718) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:16,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:27:16,051] {logging_mixin.py:104} INFO - [2022-03-18 00:27:16,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:16,068] {logging_mixin.py:104} INFO - [2022-03-18 00:27:16,063] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:27:16,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:16,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.058 seconds
[2022-03-18 00:27:46,558] {scheduler_job.py:182} INFO - Started process (PID=15750) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:46,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:27:46,565] {logging_mixin.py:104} INFO - [2022-03-18 00:27:46,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:46,582] {logging_mixin.py:104} INFO - [2022-03-18 00:27:46,577] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:27:46,585] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:27:46,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:28:16,902] {scheduler_job.py:182} INFO - Started process (PID=15782) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:16,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:28:16,910] {logging_mixin.py:104} INFO - [2022-03-18 00:28:16,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:16,926] {logging_mixin.py:104} INFO - [2022-03-18 00:28:16,921] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:28:16,930] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:16,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 00:28:47,630] {scheduler_job.py:182} INFO - Started process (PID=15812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:47,634] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:28:47,636] {logging_mixin.py:104} INFO - [2022-03-18 00:28:47,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:47,652] {logging_mixin.py:104} INFO - [2022-03-18 00:28:47,648] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:28:47,656] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:28:47,688] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:29:20,288] {scheduler_job.py:182} INFO - Started process (PID=15844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:20,292] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:29:20,295] {logging_mixin.py:104} INFO - [2022-03-18 00:29:20,294] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:20,311] {logging_mixin.py:104} INFO - [2022-03-18 00:29:20,306] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:29:20,314] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:20,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:29:51,073] {scheduler_job.py:182} INFO - Started process (PID=15866) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:51,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:29:51,081] {logging_mixin.py:104} INFO - [2022-03-18 00:29:51,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:51,098] {logging_mixin.py:104} INFO - [2022-03-18 00:29:51,093] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:29:51,101] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:29:51,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:30:21,622] {scheduler_job.py:182} INFO - Started process (PID=15896) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:21,627] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:30:21,629] {logging_mixin.py:104} INFO - [2022-03-18 00:30:21,629] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:21,647] {logging_mixin.py:104} INFO - [2022-03-18 00:30:21,641] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:30:21,650] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:21,676] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:30:52,437] {scheduler_job.py:182} INFO - Started process (PID=15928) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:52,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:30:52,445] {logging_mixin.py:104} INFO - [2022-03-18 00:30:52,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:52,462] {logging_mixin.py:104} INFO - [2022-03-18 00:30:52,457] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:30:52,465] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:30:52,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:31:23,130] {scheduler_job.py:182} INFO - Started process (PID=15960) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:23,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:31:23,137] {logging_mixin.py:104} INFO - [2022-03-18 00:31:23,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:23,155] {logging_mixin.py:104} INFO - [2022-03-18 00:31:23,150] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:31:23,159] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:23,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:31:53,753] {scheduler_job.py:182} INFO - Started process (PID=15992) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:53,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:31:53,761] {logging_mixin.py:104} INFO - [2022-03-18 00:31:53,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:53,779] {logging_mixin.py:104} INFO - [2022-03-18 00:31:53,774] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:31:53,783] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:31:53,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:32:24,408] {scheduler_job.py:182} INFO - Started process (PID=16024) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:24,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:32:24,415] {logging_mixin.py:104} INFO - [2022-03-18 00:32:24,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:24,431] {logging_mixin.py:104} INFO - [2022-03-18 00:32:24,426] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:32:24,434] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:24,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:32:55,483] {scheduler_job.py:182} INFO - Started process (PID=16056) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:55,487] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:32:55,491] {logging_mixin.py:104} INFO - [2022-03-18 00:32:55,491] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:55,521] {logging_mixin.py:104} INFO - [2022-03-18 00:32:55,513] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:32:55,527] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:32:55,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 00:33:26,113] {scheduler_job.py:182} INFO - Started process (PID=16088) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:26,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:33:26,121] {logging_mixin.py:104} INFO - [2022-03-18 00:33:26,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:26,140] {logging_mixin.py:104} INFO - [2022-03-18 00:33:26,135] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:33:26,143] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:26,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 00:33:56,694] {scheduler_job.py:182} INFO - Started process (PID=16118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:56,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:33:56,701] {logging_mixin.py:104} INFO - [2022-03-18 00:33:56,701] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:56,717] {logging_mixin.py:104} INFO - [2022-03-18 00:33:56,713] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:33:56,721] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:33:56,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:34:27,510] {scheduler_job.py:182} INFO - Started process (PID=16140) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:27,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:34:27,516] {logging_mixin.py:104} INFO - [2022-03-18 00:34:27,516] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:27,536] {logging_mixin.py:104} INFO - [2022-03-18 00:34:27,531] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:34:27,541] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:27,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:34:57,990] {scheduler_job.py:182} INFO - Started process (PID=16170) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:57,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:34:57,997] {logging_mixin.py:104} INFO - [2022-03-18 00:34:57,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:58,015] {logging_mixin.py:104} INFO - [2022-03-18 00:34:58,010] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:34:58,019] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:34:58,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:35:28,590] {scheduler_job.py:182} INFO - Started process (PID=16202) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:28,595] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:35:28,598] {logging_mixin.py:104} INFO - [2022-03-18 00:35:28,598] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:28,615] {logging_mixin.py:104} INFO - [2022-03-18 00:35:28,610] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:35:28,618] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:28,646] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:35:59,080] {scheduler_job.py:182} INFO - Started process (PID=16234) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:59,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:35:59,088] {logging_mixin.py:104} INFO - [2022-03-18 00:35:59,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:59,105] {logging_mixin.py:104} INFO - [2022-03-18 00:35:59,101] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:35:59,109] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:35:59,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:36:29,700] {scheduler_job.py:182} INFO - Started process (PID=16266) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:36:29,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:36:29,708] {logging_mixin.py:104} INFO - [2022-03-18 00:36:29,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:36:29,728] {logging_mixin.py:104} INFO - [2022-03-18 00:36:29,722] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:36:29,731] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:36:29,758] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:37:00,251] {scheduler_job.py:182} INFO - Started process (PID=16298) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:00,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:37:00,260] {logging_mixin.py:104} INFO - [2022-03-18 00:37:00,260] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:00,277] {logging_mixin.py:104} INFO - [2022-03-18 00:37:00,272] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:37:00,280] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:00,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:37:30,798] {scheduler_job.py:182} INFO - Started process (PID=16330) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:30,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:37:30,807] {logging_mixin.py:104} INFO - [2022-03-18 00:37:30,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:30,824] {logging_mixin.py:104} INFO - [2022-03-18 00:37:30,819] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:37:30,828] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:37:30,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:38:01,481] {scheduler_job.py:182} INFO - Started process (PID=16360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:01,484] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:38:01,488] {logging_mixin.py:104} INFO - [2022-03-18 00:38:01,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:01,507] {logging_mixin.py:104} INFO - [2022-03-18 00:38:01,501] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:38:01,511] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:01,541] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:38:34,250] {scheduler_job.py:182} INFO - Started process (PID=16392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:34,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:38:34,256] {logging_mixin.py:104} INFO - [2022-03-18 00:38:34,256] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:34,274] {logging_mixin.py:104} INFO - [2022-03-18 00:38:34,269] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:38:34,277] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:38:34,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:39:05,184] {scheduler_job.py:182} INFO - Started process (PID=16414) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:05,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:39:05,191] {logging_mixin.py:104} INFO - [2022-03-18 00:39:05,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:05,210] {logging_mixin.py:104} INFO - [2022-03-18 00:39:05,205] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:39:05,214] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:05,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.069 seconds
[2022-03-18 00:39:35,884] {scheduler_job.py:182} INFO - Started process (PID=16444) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:35,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:39:35,891] {logging_mixin.py:104} INFO - [2022-03-18 00:39:35,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:35,911] {logging_mixin.py:104} INFO - [2022-03-18 00:39:35,907] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:39:35,915] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:39:35,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:40:06,743] {scheduler_job.py:182} INFO - Started process (PID=16476) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:06,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:40:06,751] {logging_mixin.py:104} INFO - [2022-03-18 00:40:06,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:06,769] {logging_mixin.py:104} INFO - [2022-03-18 00:40:06,765] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:40:06,772] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:06,800] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:40:37,573] {scheduler_job.py:182} INFO - Started process (PID=16508) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:37,576] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:40:37,579] {logging_mixin.py:104} INFO - [2022-03-18 00:40:37,578] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:37,595] {logging_mixin.py:104} INFO - [2022-03-18 00:40:37,590] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:40:37,599] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:40:37,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:41:08,356] {scheduler_job.py:182} INFO - Started process (PID=16540) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:08,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:41:08,363] {logging_mixin.py:104} INFO - [2022-03-18 00:41:08,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:08,380] {logging_mixin.py:104} INFO - [2022-03-18 00:41:08,375] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:41:08,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:08,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:41:38,921] {scheduler_job.py:182} INFO - Started process (PID=16572) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:38,925] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:41:38,928] {logging_mixin.py:104} INFO - [2022-03-18 00:41:38,928] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:38,946] {logging_mixin.py:104} INFO - [2022-03-18 00:41:38,941] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:41:38,949] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:41:38,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:42:09,313] {scheduler_job.py:182} INFO - Started process (PID=16604) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:09,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:42:09,319] {logging_mixin.py:104} INFO - [2022-03-18 00:42:09,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:09,337] {logging_mixin.py:104} INFO - [2022-03-18 00:42:09,331] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:42:09,340] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:09,365] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.059 seconds
[2022-03-18 00:42:39,932] {scheduler_job.py:182} INFO - Started process (PID=16634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:39,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:42:39,941] {logging_mixin.py:104} INFO - [2022-03-18 00:42:39,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:39,960] {logging_mixin.py:104} INFO - [2022-03-18 00:42:39,954] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:42:39,964] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:42:39,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:43:12,638] {scheduler_job.py:182} INFO - Started process (PID=16666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:12,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:43:12,645] {logging_mixin.py:104} INFO - [2022-03-18 00:43:12,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:12,662] {logging_mixin.py:104} INFO - [2022-03-18 00:43:12,658] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:43:12,667] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:12,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:43:43,554] {scheduler_job.py:182} INFO - Started process (PID=16688) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:43,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:43:43,561] {logging_mixin.py:104} INFO - [2022-03-18 00:43:43,560] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:43,578] {logging_mixin.py:104} INFO - [2022-03-18 00:43:43,574] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:43:43,582] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:43:43,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:44:14,338] {scheduler_job.py:182} INFO - Started process (PID=16718) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:14,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:44:14,344] {logging_mixin.py:104} INFO - [2022-03-18 00:44:14,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:14,360] {logging_mixin.py:104} INFO - [2022-03-18 00:44:14,355] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:44:14,363] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:14,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:44:45,196] {scheduler_job.py:182} INFO - Started process (PID=16750) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:45,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:44:45,203] {logging_mixin.py:104} INFO - [2022-03-18 00:44:45,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:45,220] {logging_mixin.py:104} INFO - [2022-03-18 00:44:45,216] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:44:45,224] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:44:45,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:45:15,983] {scheduler_job.py:182} INFO - Started process (PID=16782) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:15,988] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:45:15,991] {logging_mixin.py:104} INFO - [2022-03-18 00:45:15,991] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:16,009] {logging_mixin.py:104} INFO - [2022-03-18 00:45:16,004] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:45:16,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:16,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:45:46,695] {scheduler_job.py:182} INFO - Started process (PID=16814) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:46,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:45:46,705] {logging_mixin.py:104} INFO - [2022-03-18 00:45:46,704] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:46,722] {logging_mixin.py:104} INFO - [2022-03-18 00:45:46,717] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:45:46,726] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:45:46,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.069 seconds
[2022-03-18 00:46:17,333] {scheduler_job.py:182} INFO - Started process (PID=16846) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:17,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:46:17,341] {logging_mixin.py:104} INFO - [2022-03-18 00:46:17,340] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:17,360] {logging_mixin.py:104} INFO - [2022-03-18 00:46:17,355] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:46:17,363] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:17,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:46:47,825] {scheduler_job.py:182} INFO - Started process (PID=16878) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:47,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:46:47,832] {logging_mixin.py:104} INFO - [2022-03-18 00:46:47,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:47,850] {logging_mixin.py:104} INFO - [2022-03-18 00:46:47,845] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:46:47,853] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:46:47,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:47:18,501] {scheduler_job.py:182} INFO - Started process (PID=16908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:18,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:47:18,508] {logging_mixin.py:104} INFO - [2022-03-18 00:47:18,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:18,525] {logging_mixin.py:104} INFO - [2022-03-18 00:47:18,520] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:47:18,528] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:18,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:47:51,433] {scheduler_job.py:182} INFO - Started process (PID=16940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:51,437] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:47:51,439] {logging_mixin.py:104} INFO - [2022-03-18 00:47:51,439] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:51,456] {logging_mixin.py:104} INFO - [2022-03-18 00:47:51,452] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:47:51,459] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:47:51,490] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:48:22,293] {scheduler_job.py:182} INFO - Started process (PID=16963) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:22,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:48:22,300] {logging_mixin.py:104} INFO - [2022-03-18 00:48:22,300] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:22,321] {logging_mixin.py:104} INFO - [2022-03-18 00:48:22,314] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:48:22,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:22,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:48:53,126] {scheduler_job.py:182} INFO - Started process (PID=16992) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:53,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:48:53,134] {logging_mixin.py:104} INFO - [2022-03-18 00:48:53,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:53,150] {logging_mixin.py:104} INFO - [2022-03-18 00:48:53,145] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:48:53,153] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:48:53,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:49:23,877] {scheduler_job.py:182} INFO - Started process (PID=17024) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:23,881] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:49:23,884] {logging_mixin.py:104} INFO - [2022-03-18 00:49:23,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:23,902] {logging_mixin.py:104} INFO - [2022-03-18 00:49:23,897] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:49:23,906] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:23,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:49:54,631] {scheduler_job.py:182} INFO - Started process (PID=17056) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:54,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:49:54,638] {logging_mixin.py:104} INFO - [2022-03-18 00:49:54,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:54,656] {logging_mixin.py:104} INFO - [2022-03-18 00:49:54,651] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:49:54,660] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:49:54,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:50:25,312] {scheduler_job.py:182} INFO - Started process (PID=17088) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:25,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:50:25,319] {logging_mixin.py:104} INFO - [2022-03-18 00:50:25,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:25,338] {logging_mixin.py:104} INFO - [2022-03-18 00:50:25,333] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:50:25,341] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:25,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:50:55,952] {scheduler_job.py:182} INFO - Started process (PID=17120) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:55,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:50:55,959] {logging_mixin.py:104} INFO - [2022-03-18 00:50:55,959] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:55,976] {logging_mixin.py:104} INFO - [2022-03-18 00:50:55,971] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:50:55,980] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:50:56,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:51:26,720] {scheduler_job.py:182} INFO - Started process (PID=17152) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:26,725] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:51:26,727] {logging_mixin.py:104} INFO - [2022-03-18 00:51:26,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:26,745] {logging_mixin.py:104} INFO - [2022-03-18 00:51:26,741] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:51:26,748] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:26,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.058 seconds
[2022-03-18 00:51:57,556] {scheduler_job.py:182} INFO - Started process (PID=17184) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:57,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:51:57,564] {logging_mixin.py:104} INFO - [2022-03-18 00:51:57,564] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:57,581] {logging_mixin.py:104} INFO - [2022-03-18 00:51:57,575] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:51:57,584] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:51:57,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:52:30,489] {scheduler_job.py:182} INFO - Started process (PID=17214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:52:30,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:52:30,495] {logging_mixin.py:104} INFO - [2022-03-18 00:52:30,495] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:52:30,514] {logging_mixin.py:104} INFO - [2022-03-18 00:52:30,509] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:52:30,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:52:30,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:53:01,295] {scheduler_job.py:182} INFO - Started process (PID=17236) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:01,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:53:01,302] {logging_mixin.py:104} INFO - [2022-03-18 00:53:01,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:01,321] {logging_mixin.py:104} INFO - [2022-03-18 00:53:01,316] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:53:01,325] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:01,356] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 00:53:32,081] {scheduler_job.py:182} INFO - Started process (PID=17266) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:32,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:53:32,088] {logging_mixin.py:104} INFO - [2022-03-18 00:53:32,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:32,106] {logging_mixin.py:104} INFO - [2022-03-18 00:53:32,101] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:53:32,109] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:53:32,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:54:03,020] {scheduler_job.py:182} INFO - Started process (PID=17298) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:03,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:54:03,028] {logging_mixin.py:104} INFO - [2022-03-18 00:54:03,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:03,046] {logging_mixin.py:104} INFO - [2022-03-18 00:54:03,041] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:54:03,049] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:03,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:54:33,779] {scheduler_job.py:182} INFO - Started process (PID=17330) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:33,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:54:33,787] {logging_mixin.py:104} INFO - [2022-03-18 00:54:33,787] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:33,806] {logging_mixin.py:104} INFO - [2022-03-18 00:54:33,801] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:54:33,811] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:54:33,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 00:55:04,612] {scheduler_job.py:182} INFO - Started process (PID=17362) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:04,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:55:04,621] {logging_mixin.py:104} INFO - [2022-03-18 00:55:04,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:04,637] {logging_mixin.py:104} INFO - [2022-03-18 00:55:04,633] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:55:04,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:04,665] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 00:55:35,332] {scheduler_job.py:182} INFO - Started process (PID=17394) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:35,336] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:55:35,338] {logging_mixin.py:104} INFO - [2022-03-18 00:55:35,338] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:35,356] {logging_mixin.py:104} INFO - [2022-03-18 00:55:35,352] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:55:35,359] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:55:35,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:56:05,526] {scheduler_job.py:182} INFO - Started process (PID=17426) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:05,530] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:56:05,533] {logging_mixin.py:104} INFO - [2022-03-18 00:56:05,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:05,550] {logging_mixin.py:104} INFO - [2022-03-18 00:56:05,545] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:56:05,554] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:05,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:56:36,281] {scheduler_job.py:182} INFO - Started process (PID=17458) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:36,286] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:56:36,289] {logging_mixin.py:104} INFO - [2022-03-18 00:56:36,288] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:36,306] {logging_mixin.py:104} INFO - [2022-03-18 00:56:36,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:56:36,309] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:56:36,336] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 00:57:09,989] {scheduler_job.py:182} INFO - Started process (PID=17488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:09,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:57:09,996] {logging_mixin.py:104} INFO - [2022-03-18 00:57:09,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:10,013] {logging_mixin.py:104} INFO - [2022-03-18 00:57:10,009] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:57:10,017] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:10,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 00:57:43,937] {scheduler_job.py:182} INFO - Started process (PID=17520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:43,941] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:57:43,944] {logging_mixin.py:104} INFO - [2022-03-18 00:57:43,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:43,962] {logging_mixin.py:104} INFO - [2022-03-18 00:57:43,957] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:57:43,966] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:57:43,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 00:58:14,975] {scheduler_job.py:182} INFO - Started process (PID=17543) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:14,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:58:14,983] {logging_mixin.py:104} INFO - [2022-03-18 00:58:14,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:15,001] {logging_mixin.py:104} INFO - [2022-03-18 00:58:14,995] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:58:15,005] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:15,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.071 seconds
[2022-03-18 00:58:45,778] {scheduler_job.py:182} INFO - Started process (PID=17572) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:45,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:58:45,785] {logging_mixin.py:104} INFO - [2022-03-18 00:58:45,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:45,801] {logging_mixin.py:104} INFO - [2022-03-18 00:58:45,796] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:58:45,804] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:58:45,831] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 00:59:16,658] {scheduler_job.py:182} INFO - Started process (PID=17604) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:16,663] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:59:16,666] {logging_mixin.py:104} INFO - [2022-03-18 00:59:16,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:16,684] {logging_mixin.py:104} INFO - [2022-03-18 00:59:16,679] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:59:16,688] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:16,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 00:59:47,568] {scheduler_job.py:182} INFO - Started process (PID=17636) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:47,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 00:59:47,576] {logging_mixin.py:104} INFO - [2022-03-18 00:59:47,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:47,592] {logging_mixin.py:104} INFO - [2022-03-18 00:59:47,588] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 00:59:47,596] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 00:59:47,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:00:18,377] {scheduler_job.py:182} INFO - Started process (PID=17668) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:18,382] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:00:18,385] {logging_mixin.py:104} INFO - [2022-03-18 01:00:18,384] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:18,403] {logging_mixin.py:104} INFO - [2022-03-18 01:00:18,398] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:00:18,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:18,436] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:00:48,902] {scheduler_job.py:182} INFO - Started process (PID=17700) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:48,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:00:48,911] {logging_mixin.py:104} INFO - [2022-03-18 01:00:48,911] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:48,930] {logging_mixin.py:104} INFO - [2022-03-18 01:00:48,925] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:00:48,934] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:00:48,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 01:01:19,585] {scheduler_job.py:182} INFO - Started process (PID=17732) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:19,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:01:19,594] {logging_mixin.py:104} INFO - [2022-03-18 01:01:19,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:19,609] {logging_mixin.py:104} INFO - [2022-03-18 01:01:19,605] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:01:19,613] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:19,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 01:01:50,351] {scheduler_job.py:182} INFO - Started process (PID=17764) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:50,356] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:01:50,359] {logging_mixin.py:104} INFO - [2022-03-18 01:01:50,358] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:50,376] {logging_mixin.py:104} INFO - [2022-03-18 01:01:50,371] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:01:50,379] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:01:50,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:02:23,130] {scheduler_job.py:182} INFO - Started process (PID=17794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:23,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:02:23,136] {logging_mixin.py:104} INFO - [2022-03-18 01:02:23,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:23,154] {logging_mixin.py:104} INFO - [2022-03-18 01:02:23,149] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:02:23,158] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:23,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:02:54,089] {scheduler_job.py:182} INFO - Started process (PID=17817) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:54,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:02:54,096] {logging_mixin.py:104} INFO - [2022-03-18 01:02:54,095] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:54,113] {logging_mixin.py:104} INFO - [2022-03-18 01:02:54,108] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:02:54,116] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:02:54,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:03:24,878] {scheduler_job.py:182} INFO - Started process (PID=17846) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:24,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:03:24,885] {logging_mixin.py:104} INFO - [2022-03-18 01:03:24,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:24,903] {logging_mixin.py:104} INFO - [2022-03-18 01:03:24,898] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:03:24,907] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:24,934] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:03:55,730] {scheduler_job.py:182} INFO - Started process (PID=17878) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:55,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:03:55,738] {logging_mixin.py:104} INFO - [2022-03-18 01:03:55,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:55,756] {logging_mixin.py:104} INFO - [2022-03-18 01:03:55,752] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:03:55,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:03:55,788] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 01:04:26,506] {scheduler_job.py:182} INFO - Started process (PID=17910) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:26,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:04:26,513] {logging_mixin.py:104} INFO - [2022-03-18 01:04:26,513] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:26,532] {logging_mixin.py:104} INFO - [2022-03-18 01:04:26,526] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:04:26,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:26,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:04:57,164] {scheduler_job.py:182} INFO - Started process (PID=17942) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:57,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:04:57,172] {logging_mixin.py:104} INFO - [2022-03-18 01:04:57,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:57,190] {logging_mixin.py:104} INFO - [2022-03-18 01:04:57,185] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:04:57,193] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:04:57,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:05:27,698] {scheduler_job.py:182} INFO - Started process (PID=17974) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:27,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:05:27,705] {logging_mixin.py:104} INFO - [2022-03-18 01:05:27,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:27,722] {logging_mixin.py:104} INFO - [2022-03-18 01:05:27,717] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:05:27,726] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:27,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 01:05:58,398] {scheduler_job.py:182} INFO - Started process (PID=18006) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:58,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:05:58,405] {logging_mixin.py:104} INFO - [2022-03-18 01:05:58,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:58,422] {logging_mixin.py:104} INFO - [2022-03-18 01:05:58,417] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:05:58,426] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:05:58,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:06:29,392] {scheduler_job.py:182} INFO - Started process (PID=18038) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:06:29,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:06:29,400] {logging_mixin.py:104} INFO - [2022-03-18 01:06:29,400] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:06:29,420] {logging_mixin.py:104} INFO - [2022-03-18 01:06:29,415] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:06:29,424] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:06:29,452] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.069 seconds
[2022-03-18 01:07:02,427] {scheduler_job.py:182} INFO - Started process (PID=18068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:02,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:07:02,435] {logging_mixin.py:104} INFO - [2022-03-18 01:07:02,435] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:02,451] {logging_mixin.py:104} INFO - [2022-03-18 01:07:02,447] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:07:02,456] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:02,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:07:33,278] {scheduler_job.py:182} INFO - Started process (PID=18090) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:33,281] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:07:33,284] {logging_mixin.py:104} INFO - [2022-03-18 01:07:33,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:33,301] {logging_mixin.py:104} INFO - [2022-03-18 01:07:33,296] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:07:33,304] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:07:33,333] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:08:04,108] {scheduler_job.py:182} INFO - Started process (PID=18120) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:04,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:08:04,115] {logging_mixin.py:104} INFO - [2022-03-18 01:08:04,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:04,133] {logging_mixin.py:104} INFO - [2022-03-18 01:08:04,128] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:08:04,137] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:04,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:08:34,908] {scheduler_job.py:182} INFO - Started process (PID=18152) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:34,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:08:34,915] {logging_mixin.py:104} INFO - [2022-03-18 01:08:34,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:34,932] {logging_mixin.py:104} INFO - [2022-03-18 01:08:34,927] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:08:34,937] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:08:34,965] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:09:05,803] {scheduler_job.py:182} INFO - Started process (PID=18184) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:05,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:09:05,810] {logging_mixin.py:104} INFO - [2022-03-18 01:09:05,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:05,827] {logging_mixin.py:104} INFO - [2022-03-18 01:09:05,822] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:09:05,830] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:05,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 01:09:36,637] {scheduler_job.py:182} INFO - Started process (PID=18216) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:36,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:09:36,646] {logging_mixin.py:104} INFO - [2022-03-18 01:09:36,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:36,666] {logging_mixin.py:104} INFO - [2022-03-18 01:09:36,660] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:09:36,670] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:09:36,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 01:10:06,811] {scheduler_job.py:182} INFO - Started process (PID=18248) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:06,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:10:06,819] {logging_mixin.py:104} INFO - [2022-03-18 01:10:06,819] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:06,837] {logging_mixin.py:104} INFO - [2022-03-18 01:10:06,832] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:10:06,841] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:06,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:10:37,665] {scheduler_job.py:182} INFO - Started process (PID=18280) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:37,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:10:37,672] {logging_mixin.py:104} INFO - [2022-03-18 01:10:37,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:37,690] {logging_mixin.py:104} INFO - [2022-03-18 01:10:37,686] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:10:37,694] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:10:37,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:11:08,664] {scheduler_job.py:182} INFO - Started process (PID=18312) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:08,668] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:11:08,671] {logging_mixin.py:104} INFO - [2022-03-18 01:11:08,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:08,688] {logging_mixin.py:104} INFO - [2022-03-18 01:11:08,683] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:11:08,691] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:08,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:11:41,493] {scheduler_job.py:182} INFO - Started process (PID=18342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:41,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:11:41,500] {logging_mixin.py:104} INFO - [2022-03-18 01:11:41,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:41,517] {logging_mixin.py:104} INFO - [2022-03-18 01:11:41,512] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:11:41,522] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:11:41,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:12:12,365] {scheduler_job.py:182} INFO - Started process (PID=18365) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:12,369] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:12:12,371] {logging_mixin.py:104} INFO - [2022-03-18 01:12:12,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:12,388] {logging_mixin.py:104} INFO - [2022-03-18 01:12:12,383] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:12:12,392] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:12,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:12:43,252] {scheduler_job.py:182} INFO - Started process (PID=18394) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:43,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:12:43,259] {logging_mixin.py:104} INFO - [2022-03-18 01:12:43,259] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:43,279] {logging_mixin.py:104} INFO - [2022-03-18 01:12:43,273] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:12:43,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:12:43,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:13:14,027] {scheduler_job.py:182} INFO - Started process (PID=18426) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:14,033] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:13:14,036] {logging_mixin.py:104} INFO - [2022-03-18 01:13:14,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:14,052] {logging_mixin.py:104} INFO - [2022-03-18 01:13:14,048] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:13:14,057] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:14,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:13:44,829] {scheduler_job.py:182} INFO - Started process (PID=18458) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:44,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:13:44,837] {logging_mixin.py:104} INFO - [2022-03-18 01:13:44,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:44,853] {logging_mixin.py:104} INFO - [2022-03-18 01:13:44,849] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:13:44,856] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:13:44,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:14:15,552] {scheduler_job.py:182} INFO - Started process (PID=18490) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:15,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:14:15,560] {logging_mixin.py:104} INFO - [2022-03-18 01:14:15,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:15,579] {logging_mixin.py:104} INFO - [2022-03-18 01:14:15,574] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:14:15,583] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:15,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.069 seconds
[2022-03-18 01:14:46,076] {scheduler_job.py:182} INFO - Started process (PID=18522) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:46,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:14:46,083] {logging_mixin.py:104} INFO - [2022-03-18 01:14:46,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:46,100] {logging_mixin.py:104} INFO - [2022-03-18 01:14:46,096] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:14:46,104] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:14:46,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:15:16,832] {scheduler_job.py:182} INFO - Started process (PID=18554) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:16,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:15:16,840] {logging_mixin.py:104} INFO - [2022-03-18 01:15:16,839] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:16,858] {logging_mixin.py:104} INFO - [2022-03-18 01:15:16,853] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:15:16,862] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:16,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.067 seconds
[2022-03-18 01:15:47,763] {scheduler_job.py:182} INFO - Started process (PID=18586) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:47,768] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:15:47,771] {logging_mixin.py:104} INFO - [2022-03-18 01:15:47,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:47,790] {logging_mixin.py:104} INFO - [2022-03-18 01:15:47,785] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:15:47,793] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:15:47,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:16:19,750] {scheduler_job.py:182} INFO - Started process (PID=18616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:19,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:16:19,756] {logging_mixin.py:104} INFO - [2022-03-18 01:16:19,756] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:19,776] {logging_mixin.py:104} INFO - [2022-03-18 01:16:19,771] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:16:19,781] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:19,808] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:16:50,549] {scheduler_job.py:182} INFO - Started process (PID=18638) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:50,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:16:50,555] {logging_mixin.py:104} INFO - [2022-03-18 01:16:50,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:50,572] {logging_mixin.py:104} INFO - [2022-03-18 01:16:50,568] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:16:50,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:16:50,606] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:17:21,212] {scheduler_job.py:182} INFO - Started process (PID=18668) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:21,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:17:21,218] {logging_mixin.py:104} INFO - [2022-03-18 01:17:21,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:21,235] {logging_mixin.py:104} INFO - [2022-03-18 01:17:21,230] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:17:21,240] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:21,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:17:51,875] {scheduler_job.py:182} INFO - Started process (PID=18700) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:51,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:17:51,881] {logging_mixin.py:104} INFO - [2022-03-18 01:17:51,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:51,899] {logging_mixin.py:104} INFO - [2022-03-18 01:17:51,894] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:17:51,903] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:17:51,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:18:22,553] {scheduler_job.py:182} INFO - Started process (PID=18732) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:22,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:18:22,558] {logging_mixin.py:104} INFO - [2022-03-18 01:18:22,558] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:22,575] {logging_mixin.py:104} INFO - [2022-03-18 01:18:22,571] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:18:22,579] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:22,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.058 seconds
[2022-03-18 01:18:53,254] {scheduler_job.py:182} INFO - Started process (PID=18764) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:53,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:18:53,262] {logging_mixin.py:104} INFO - [2022-03-18 01:18:53,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:53,278] {logging_mixin.py:104} INFO - [2022-03-18 01:18:53,273] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:18:53,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:18:53,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:19:24,255] {scheduler_job.py:182} INFO - Started process (PID=18796) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:24,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:19:24,261] {logging_mixin.py:104} INFO - [2022-03-18 01:19:24,260] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:24,277] {logging_mixin.py:104} INFO - [2022-03-18 01:19:24,272] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:19:24,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:24,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:19:55,011] {scheduler_job.py:182} INFO - Started process (PID=18828) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:55,014] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:19:55,017] {logging_mixin.py:104} INFO - [2022-03-18 01:19:55,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:55,033] {logging_mixin.py:104} INFO - [2022-03-18 01:19:55,028] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:19:55,037] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:19:55,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:20:25,745] {scheduler_job.py:182} INFO - Started process (PID=18860) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:25,749] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:20:25,751] {logging_mixin.py:104} INFO - [2022-03-18 01:20:25,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:25,766] {logging_mixin.py:104} INFO - [2022-03-18 01:20:25,762] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:20:25,770] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:25,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.059 seconds
[2022-03-18 01:20:57,404] {scheduler_job.py:182} INFO - Started process (PID=18890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:57,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:20:57,410] {logging_mixin.py:104} INFO - [2022-03-18 01:20:57,410] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:57,426] {logging_mixin.py:104} INFO - [2022-03-18 01:20:57,422] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:20:57,431] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:20:57,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:21:28,452] {scheduler_job.py:182} INFO - Started process (PID=18914) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:28,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:21:28,458] {logging_mixin.py:104} INFO - [2022-03-18 01:21:28,458] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:28,478] {logging_mixin.py:104} INFO - [2022-03-18 01:21:28,473] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:21:28,481] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:28,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:21:59,413] {scheduler_job.py:182} INFO - Started process (PID=18942) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:59,418] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:21:59,421] {logging_mixin.py:104} INFO - [2022-03-18 01:21:59,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:59,437] {logging_mixin.py:104} INFO - [2022-03-18 01:21:59,432] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:21:59,440] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:21:59,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:22:30,031] {scheduler_job.py:182} INFO - Started process (PID=18974) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:22:30,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:22:30,037] {logging_mixin.py:104} INFO - [2022-03-18 01:22:30,037] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:22:30,056] {logging_mixin.py:104} INFO - [2022-03-18 01:22:30,051] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:22:30,062] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:22:30,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:23:00,650] {scheduler_job.py:182} INFO - Started process (PID=19006) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:00,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:23:00,657] {logging_mixin.py:104} INFO - [2022-03-18 01:23:00,657] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:00,675] {logging_mixin.py:104} INFO - [2022-03-18 01:23:00,670] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:23:00,679] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:00,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:23:31,245] {scheduler_job.py:182} INFO - Started process (PID=19038) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:31,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:23:31,252] {logging_mixin.py:104} INFO - [2022-03-18 01:23:31,252] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:31,270] {logging_mixin.py:104} INFO - [2022-03-18 01:23:31,265] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:23:31,273] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:23:31,301] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:24:02,224] {scheduler_job.py:182} INFO - Started process (PID=19070) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:02,228] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:24:02,230] {logging_mixin.py:104} INFO - [2022-03-18 01:24:02,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:02,246] {logging_mixin.py:104} INFO - [2022-03-18 01:24:02,242] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:24:02,250] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:02,279] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:24:32,784] {scheduler_job.py:182} INFO - Started process (PID=19102) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:32,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:24:32,791] {logging_mixin.py:104} INFO - [2022-03-18 01:24:32,790] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:32,809] {logging_mixin.py:104} INFO - [2022-03-18 01:24:32,805] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:24:32,812] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:24:32,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:25:03,441] {scheduler_job.py:182} INFO - Started process (PID=19134) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:03,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:25:03,450] {logging_mixin.py:104} INFO - [2022-03-18 01:25:03,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:03,468] {logging_mixin.py:104} INFO - [2022-03-18 01:25:03,463] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:25:03,472] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:03,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:25:33,927] {scheduler_job.py:182} INFO - Started process (PID=19164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:33,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:25:33,933] {logging_mixin.py:104} INFO - [2022-03-18 01:25:33,933] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:33,949] {logging_mixin.py:104} INFO - [2022-03-18 01:25:33,944] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:25:33,953] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:25:33,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:26:04,732] {scheduler_job.py:182} INFO - Started process (PID=19188) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:04,735] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:26:04,738] {logging_mixin.py:104} INFO - [2022-03-18 01:26:04,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:04,755] {logging_mixin.py:104} INFO - [2022-03-18 01:26:04,751] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:26:04,759] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:04,788] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:26:35,315] {scheduler_job.py:182} INFO - Started process (PID=19216) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:35,319] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:26:35,322] {logging_mixin.py:104} INFO - [2022-03-18 01:26:35,321] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:35,337] {logging_mixin.py:104} INFO - [2022-03-18 01:26:35,333] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:26:35,340] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:26:35,366] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.059 seconds
[2022-03-18 01:27:05,976] {scheduler_job.py:182} INFO - Started process (PID=19248) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:05,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:27:05,983] {logging_mixin.py:104} INFO - [2022-03-18 01:27:05,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:06,002] {logging_mixin.py:104} INFO - [2022-03-18 01:27:05,996] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:27:06,006] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:06,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 01:27:36,557] {scheduler_job.py:182} INFO - Started process (PID=19280) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:36,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:27:36,565] {logging_mixin.py:104} INFO - [2022-03-18 01:27:36,564] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:36,580] {logging_mixin.py:104} INFO - [2022-03-18 01:27:36,576] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:27:36,584] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:27:36,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.058 seconds
[2022-03-18 01:28:07,208] {scheduler_job.py:182} INFO - Started process (PID=19312) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:07,211] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:28:07,213] {logging_mixin.py:104} INFO - [2022-03-18 01:28:07,213] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:07,230] {logging_mixin.py:104} INFO - [2022-03-18 01:28:07,225] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:28:07,234] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:07,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:28:38,171] {scheduler_job.py:182} INFO - Started process (PID=19344) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:38,176] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:28:38,180] {logging_mixin.py:104} INFO - [2022-03-18 01:28:38,179] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:38,197] {logging_mixin.py:104} INFO - [2022-03-18 01:28:38,192] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:28:38,202] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:28:38,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:29:08,928] {scheduler_job.py:182} INFO - Started process (PID=19376) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:08,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:29:08,935] {logging_mixin.py:104} INFO - [2022-03-18 01:29:08,935] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:08,952] {logging_mixin.py:104} INFO - [2022-03-18 01:29:08,947] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:29:08,956] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:08,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:29:39,611] {scheduler_job.py:182} INFO - Started process (PID=19408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:39,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:29:39,619] {logging_mixin.py:104} INFO - [2022-03-18 01:29:39,618] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:39,638] {logging_mixin.py:104} INFO - [2022-03-18 01:29:39,633] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:29:39,642] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:29:39,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.068 seconds
[2022-03-18 01:30:10,311] {scheduler_job.py:182} INFO - Started process (PID=19438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:10,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:30:10,317] {logging_mixin.py:104} INFO - [2022-03-18 01:30:10,317] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:10,336] {logging_mixin.py:104} INFO - [2022-03-18 01:30:10,329] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:30:10,341] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:10,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:30:41,141] {scheduler_job.py:182} INFO - Started process (PID=19461) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:41,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:30:41,154] {logging_mixin.py:104} INFO - [2022-03-18 01:30:41,153] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:41,174] {logging_mixin.py:104} INFO - [2022-03-18 01:30:41,168] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:30:41,178] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:30:41,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 01:31:12,042] {scheduler_job.py:182} INFO - Started process (PID=19490) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:12,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:31:12,048] {logging_mixin.py:104} INFO - [2022-03-18 01:31:12,048] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:12,066] {logging_mixin.py:104} INFO - [2022-03-18 01:31:12,061] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:31:12,070] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:12,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 01:31:42,620] {scheduler_job.py:182} INFO - Started process (PID=19522) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:42,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:31:42,628] {logging_mixin.py:104} INFO - [2022-03-18 01:31:42,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:42,646] {logging_mixin.py:104} INFO - [2022-03-18 01:31:42,641] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:31:42,651] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:31:42,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.065 seconds
[2022-03-18 01:32:13,301] {scheduler_job.py:182} INFO - Started process (PID=19554) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:13,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:32:13,309] {logging_mixin.py:104} INFO - [2022-03-18 01:32:13,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:13,327] {logging_mixin.py:104} INFO - [2022-03-18 01:32:13,322] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:32:13,331] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:13,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:32:43,681] {scheduler_job.py:182} INFO - Started process (PID=19586) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:43,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:32:43,687] {logging_mixin.py:104} INFO - [2022-03-18 01:32:43,687] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:43,703] {logging_mixin.py:104} INFO - [2022-03-18 01:32:43,699] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:32:43,707] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:32:43,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.057 seconds
[2022-03-18 01:33:13,871] {scheduler_job.py:182} INFO - Started process (PID=19618) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:13,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:33:13,879] {logging_mixin.py:104} INFO - [2022-03-18 01:33:13,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:13,896] {logging_mixin.py:104} INFO - [2022-03-18 01:33:13,892] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:33:13,901] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:13,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:33:44,483] {scheduler_job.py:182} INFO - Started process (PID=19650) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:44,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:33:44,490] {logging_mixin.py:104} INFO - [2022-03-18 01:33:44,490] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:44,508] {logging_mixin.py:104} INFO - [2022-03-18 01:33:44,503] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:33:44,511] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:33:44,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:34:15,043] {scheduler_job.py:182} INFO - Started process (PID=19680) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:15,048] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:34:15,051] {logging_mixin.py:104} INFO - [2022-03-18 01:34:15,050] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:15,067] {logging_mixin.py:104} INFO - [2022-03-18 01:34:15,063] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:34:15,072] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:15,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:34:45,667] {scheduler_job.py:182} INFO - Started process (PID=19705) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:45,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:34:45,676] {logging_mixin.py:104} INFO - [2022-03-18 01:34:45,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:45,694] {logging_mixin.py:104} INFO - [2022-03-18 01:34:45,689] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:34:45,699] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:34:45,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.069 seconds
[2022-03-18 01:35:16,259] {scheduler_job.py:182} INFO - Started process (PID=19732) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:16,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:35:16,266] {logging_mixin.py:104} INFO - [2022-03-18 01:35:16,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:16,282] {logging_mixin.py:104} INFO - [2022-03-18 01:35:16,278] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:35:16,287] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:16,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.063 seconds
[2022-03-18 01:35:46,789] {scheduler_job.py:182} INFO - Started process (PID=19764) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:46,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:35:46,795] {logging_mixin.py:104} INFO - [2022-03-18 01:35:46,795] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:46,811] {logging_mixin.py:104} INFO - [2022-03-18 01:35:46,806] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:35:46,814] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:35:46,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.058 seconds
[2022-03-18 01:36:41,186] {scheduler_job.py:182} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:36:41,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:36:41,194] {logging_mixin.py:104} INFO - [2022-03-18 01:36:41,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:36:41,222] {logging_mixin.py:104} INFO - [2022-03-18 01:36:41,217] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:36:41,227] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:36:41,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 01:37:11,811] {scheduler_job.py:182} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:11,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:37:11,817] {logging_mixin.py:104} INFO - [2022-03-18 01:37:11,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:11,836] {logging_mixin.py:104} INFO - [2022-03-18 01:37:11,830] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:37:11,840] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:11,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:37:42,008] {scheduler_job.py:182} INFO - Started process (PID=276) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:42,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:37:42,018] {logging_mixin.py:104} INFO - [2022-03-18 01:37:42,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:42,043] {logging_mixin.py:104} INFO - [2022-03-18 01:37:42,037] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:37:42,047] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:37:42,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 01:38:12,146] {scheduler_job.py:182} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:12,151] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:38:12,154] {logging_mixin.py:104} INFO - [2022-03-18 01:38:12,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:12,172] {logging_mixin.py:104} INFO - [2022-03-18 01:38:12,166] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:38:12,179] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:12,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 01:38:42,422] {scheduler_job.py:182} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:42,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:38:42,431] {logging_mixin.py:104} INFO - [2022-03-18 01:38:42,430] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:42,449] {logging_mixin.py:104} INFO - [2022-03-18 01:38:42,445] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:38:42,454] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:38:42,488] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.073 seconds
[2022-03-18 01:39:13,255] {scheduler_job.py:182} INFO - Started process (PID=372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:13,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:39:13,262] {logging_mixin.py:104} INFO - [2022-03-18 01:39:13,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:13,282] {logging_mixin.py:104} INFO - [2022-03-18 01:39:13,277] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:39:13,286] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:13,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.064 seconds
[2022-03-18 01:39:47,118] {scheduler_job.py:182} INFO - Started process (PID=402) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:47,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:39:47,125] {logging_mixin.py:104} INFO - [2022-03-18 01:39:47,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:47,142] {logging_mixin.py:104} INFO - [2022-03-18 01:39:47,138] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:39:47,147] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:39:47,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.062 seconds
[2022-03-18 01:40:17,801] {scheduler_job.py:182} INFO - Started process (PID=422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:17,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:40:17,809] {logging_mixin.py:104} INFO - [2022-03-18 01:40:17,808] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:17,828] {logging_mixin.py:104} INFO - [2022-03-18 01:40:17,822] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:40:17,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:17,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.066 seconds
[2022-03-18 01:40:48,837] {scheduler_job.py:182} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:48,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:40:48,843] {logging_mixin.py:104} INFO - [2022-03-18 01:40:48,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:48,861] {logging_mixin.py:104} INFO - [2022-03-18 01:40:48,856] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:40:48,864] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:40:48,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.060 seconds
[2022-03-18 01:41:19,667] {scheduler_job.py:182} INFO - Started process (PID=486) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:19,672] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:41:19,675] {logging_mixin.py:104} INFO - [2022-03-18 01:41:19,674] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:19,693] {logging_mixin.py:104} INFO - [2022-03-18 01:41:19,688] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:41:19,698] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:19,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.072 seconds
[2022-03-18 01:41:50,836] {scheduler_job.py:182} INFO - Started process (PID=518) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:50,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:41:50,842] {logging_mixin.py:104} INFO - [2022-03-18 01:41:50,842] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:50,860] {logging_mixin.py:104} INFO - [2022-03-18 01:41:50,855] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 4, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache'
[2022-03-18 01:41:50,863] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:41:50,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.061 seconds
[2022-03-18 01:46:18,502] {scheduler_job.py:182} INFO - Started process (PID=215) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:18,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:46:18,510] {logging_mixin.py:104} INFO - [2022-03-18 01:46:18,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:18,567] {logging_mixin.py:104} INFO - [2022-03-18 01:46:18,562] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:46:18,571] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:18,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.108 seconds
[2022-03-18 01:46:49,102] {scheduler_job.py:182} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:49,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:46:49,110] {logging_mixin.py:104} INFO - [2022-03-18 01:46:49,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:49,147] {logging_mixin.py:104} INFO - [2022-03-18 01:46:49,143] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:46:49,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:46:49,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 01:47:19,333] {scheduler_job.py:182} INFO - Started process (PID=276) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:19,337] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:47:19,340] {logging_mixin.py:104} INFO - [2022-03-18 01:47:19,339] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:19,381] {logging_mixin.py:104} INFO - [2022-03-18 01:47:19,376] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:47:19,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:19,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 01:47:49,524] {scheduler_job.py:182} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:49,528] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:47:49,530] {logging_mixin.py:104} INFO - [2022-03-18 01:47:49,530] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:49,569] {logging_mixin.py:104} INFO - [2022-03-18 01:47:49,564] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:47:49,573] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:47:49,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 01:48:19,746] {scheduler_job.py:182} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:19,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:48:19,755] {logging_mixin.py:104} INFO - [2022-03-18 01:48:19,754] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:19,799] {logging_mixin.py:104} INFO - [2022-03-18 01:48:19,793] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:48:19,803] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:19,834] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.095 seconds
[2022-03-18 01:48:50,490] {scheduler_job.py:182} INFO - Started process (PID=372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:50,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:48:50,496] {logging_mixin.py:104} INFO - [2022-03-18 01:48:50,496] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:50,534] {logging_mixin.py:104} INFO - [2022-03-18 01:48:50,529] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:48:50,538] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:48:50,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 01:49:24,355] {scheduler_job.py:182} INFO - Started process (PID=402) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:24,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:49:24,362] {logging_mixin.py:104} INFO - [2022-03-18 01:49:24,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:24,396] {logging_mixin.py:104} INFO - [2022-03-18 01:49:24,391] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:49:24,400] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:24,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 01:49:55,013] {scheduler_job.py:182} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:55,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:49:55,020] {logging_mixin.py:104} INFO - [2022-03-18 01:49:55,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:55,064] {logging_mixin.py:104} INFO - [2022-03-18 01:49:55,058] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:49:55,068] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:49:55,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.095 seconds
[2022-03-18 01:50:25,942] {scheduler_job.py:182} INFO - Started process (PID=442) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:25,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:50:25,951] {logging_mixin.py:104} INFO - [2022-03-18 01:50:25,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:26,006] {logging_mixin.py:104} INFO - [2022-03-18 01:50:26,001] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:50:26,009] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:26,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.104 seconds
[2022-03-18 01:50:56,762] {scheduler_job.py:182} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:56,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:50:56,771] {logging_mixin.py:104} INFO - [2022-03-18 01:50:56,770] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:56,806] {logging_mixin.py:104} INFO - [2022-03-18 01:50:56,802] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:50:56,810] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:50:56,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 01:51:27,479] {scheduler_job.py:182} INFO - Started process (PID=506) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:27,484] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:51:27,487] {logging_mixin.py:104} INFO - [2022-03-18 01:51:27,486] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:27,521] {logging_mixin.py:104} INFO - [2022-03-18 01:51:27,516] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:51:27,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:27,552] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 01:51:58,249] {scheduler_job.py:182} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:58,253] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:51:58,256] {logging_mixin.py:104} INFO - [2022-03-18 01:51:58,256] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:58,288] {logging_mixin.py:104} INFO - [2022-03-18 01:51:58,283] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:51:58,292] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:51:58,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 01:52:29,165] {scheduler_job.py:182} INFO - Started process (PID=570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:52:29,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:52:29,172] {logging_mixin.py:104} INFO - [2022-03-18 01:52:29,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:52:29,203] {logging_mixin.py:104} INFO - [2022-03-18 01:52:29,199] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:52:29,207] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:52:29,234] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 01:52:59,931] {scheduler_job.py:182} INFO - Started process (PID=602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:52:59,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:52:59,938] {logging_mixin.py:104} INFO - [2022-03-18 01:52:59,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:52:59,972] {logging_mixin.py:104} INFO - [2022-03-18 01:52:59,967] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:52:59,976] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:53:00,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 01:53:30,766] {scheduler_job.py:182} INFO - Started process (PID=634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:53:30,771] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:53:30,773] {logging_mixin.py:104} INFO - [2022-03-18 01:53:30,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:53:30,808] {logging_mixin.py:104} INFO - [2022-03-18 01:53:30,802] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:53:30,812] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:53:30,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 01:54:03,489] {scheduler_job.py:182} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:03,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:54:03,496] {logging_mixin.py:104} INFO - [2022-03-18 01:54:03,496] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:03,529] {logging_mixin.py:104} INFO - [2022-03-18 01:54:03,524] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:54:03,533] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:03,559] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 01:54:34,040] {scheduler_job.py:182} INFO - Started process (PID=674) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:34,045] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:54:34,047] {logging_mixin.py:104} INFO - [2022-03-18 01:54:34,047] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:34,085] {logging_mixin.py:104} INFO - [2022-03-18 01:54:34,080] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:54:34,090] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:54:34,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 01:55:04,961] {scheduler_job.py:182} INFO - Started process (PID=704) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:04,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:55:04,970] {logging_mixin.py:104} INFO - [2022-03-18 01:55:04,970] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:05,003] {logging_mixin.py:104} INFO - [2022-03-18 01:55:04,998] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:55:05,008] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:05,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 01:55:35,717] {scheduler_job.py:182} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:35,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:55:35,726] {logging_mixin.py:104} INFO - [2022-03-18 01:55:35,726] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:35,761] {logging_mixin.py:104} INFO - [2022-03-18 01:55:35,756] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:55:35,765] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:55:35,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 01:56:06,536] {scheduler_job.py:182} INFO - Started process (PID=768) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:06,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:56:06,544] {logging_mixin.py:104} INFO - [2022-03-18 01:56:06,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:06,580] {logging_mixin.py:104} INFO - [2022-03-18 01:56:06,575] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:56:06,583] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:06,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 01:56:37,396] {scheduler_job.py:182} INFO - Started process (PID=800) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:37,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:56:37,404] {logging_mixin.py:104} INFO - [2022-03-18 01:56:37,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:37,437] {logging_mixin.py:104} INFO - [2022-03-18 01:56:37,432] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:56:37,441] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:56:37,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 01:57:08,216] {scheduler_job.py:182} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:08,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:57:08,223] {logging_mixin.py:104} INFO - [2022-03-18 01:57:08,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:08,258] {logging_mixin.py:104} INFO - [2022-03-18 01:57:08,252] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:57:08,262] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:08,290] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 01:57:38,975] {scheduler_job.py:182} INFO - Started process (PID=864) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:38,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:57:38,982] {logging_mixin.py:104} INFO - [2022-03-18 01:57:38,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:39,014] {logging_mixin.py:104} INFO - [2022-03-18 01:57:39,010] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:57:39,018] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:57:39,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 01:58:09,695] {scheduler_job.py:182} INFO - Started process (PID=896) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:09,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:58:09,702] {logging_mixin.py:104} INFO - [2022-03-18 01:58:09,701] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:09,732] {logging_mixin.py:104} INFO - [2022-03-18 01:58:09,727] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:58:09,736] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:09,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 01:58:42,433] {scheduler_job.py:182} INFO - Started process (PID=926) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:42,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:58:42,439] {logging_mixin.py:104} INFO - [2022-03-18 01:58:42,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:42,474] {logging_mixin.py:104} INFO - [2022-03-18 01:58:42,470] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:58:42,478] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:58:42,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 01:59:13,183] {scheduler_job.py:182} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:13,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:59:13,190] {logging_mixin.py:104} INFO - [2022-03-18 01:59:13,189] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:13,225] {logging_mixin.py:104} INFO - [2022-03-18 01:59:13,220] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:59:13,229] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:13,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 01:59:44,125] {scheduler_job.py:182} INFO - Started process (PID=966) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:44,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 01:59:44,133] {logging_mixin.py:104} INFO - [2022-03-18 01:59:44,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:44,165] {logging_mixin.py:104} INFO - [2022-03-18 01:59:44,161] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 01:59:44,169] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 01:59:44,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:00:14,966] {scheduler_job.py:182} INFO - Started process (PID=998) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:14,972] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:00:14,974] {logging_mixin.py:104} INFO - [2022-03-18 02:00:14,974] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:15,007] {logging_mixin.py:104} INFO - [2022-03-18 02:00:15,002] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:00:15,013] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:15,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:00:45,751] {scheduler_job.py:182} INFO - Started process (PID=1030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:45,755] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:00:45,759] {logging_mixin.py:104} INFO - [2022-03-18 02:00:45,758] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:45,793] {logging_mixin.py:104} INFO - [2022-03-18 02:00:45,788] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:00:45,797] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:00:45,823] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:01:16,442] {scheduler_job.py:182} INFO - Started process (PID=1062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:16,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:01:16,450] {logging_mixin.py:104} INFO - [2022-03-18 02:01:16,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:16,481] {logging_mixin.py:104} INFO - [2022-03-18 02:01:16,477] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:01:16,485] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:16,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:01:47,342] {scheduler_job.py:182} INFO - Started process (PID=1094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:47,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:01:47,348] {logging_mixin.py:104} INFO - [2022-03-18 02:01:47,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:47,381] {logging_mixin.py:104} INFO - [2022-03-18 02:01:47,377] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:01:47,385] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:01:47,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:02:18,260] {scheduler_job.py:182} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:18,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:02:18,267] {logging_mixin.py:104} INFO - [2022-03-18 02:02:18,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:18,306] {logging_mixin.py:104} INFO - [2022-03-18 02:02:18,300] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:02:18,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:18,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 02:02:48,394] {scheduler_job.py:182} INFO - Started process (PID=1158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:48,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:02:48,400] {logging_mixin.py:104} INFO - [2022-03-18 02:02:48,399] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:48,433] {logging_mixin.py:104} INFO - [2022-03-18 02:02:48,428] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:02:48,437] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:02:48,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:03:22,116] {scheduler_job.py:182} INFO - Started process (PID=1188) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:22,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:03:22,124] {logging_mixin.py:104} INFO - [2022-03-18 02:03:22,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:22,158] {logging_mixin.py:104} INFO - [2022-03-18 02:03:22,153] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:03:22,162] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:22,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:03:52,808] {scheduler_job.py:182} INFO - Started process (PID=1199) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:52,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:03:52,818] {logging_mixin.py:104} INFO - [2022-03-18 02:03:52,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:52,850] {logging_mixin.py:104} INFO - [2022-03-18 02:03:52,845] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:03:52,854] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:03:52,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:04:23,744] {scheduler_job.py:182} INFO - Started process (PID=1228) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:23,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:04:23,751] {logging_mixin.py:104} INFO - [2022-03-18 02:04:23,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:23,786] {logging_mixin.py:104} INFO - [2022-03-18 02:04:23,780] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:04:23,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:23,816] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:04:54,542] {scheduler_job.py:182} INFO - Started process (PID=1260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:54,548] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:04:54,551] {logging_mixin.py:104} INFO - [2022-03-18 02:04:54,550] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:54,585] {logging_mixin.py:104} INFO - [2022-03-18 02:04:54,580] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:04:54,588] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:04:54,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:05:25,243] {scheduler_job.py:182} INFO - Started process (PID=1292) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:25,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:05:25,252] {logging_mixin.py:104} INFO - [2022-03-18 02:05:25,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:25,286] {logging_mixin.py:104} INFO - [2022-03-18 02:05:25,280] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:05:25,290] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:25,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:05:56,039] {scheduler_job.py:182} INFO - Started process (PID=1324) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:56,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:05:56,046] {logging_mixin.py:104} INFO - [2022-03-18 02:05:56,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:56,082] {logging_mixin.py:104} INFO - [2022-03-18 02:05:56,077] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:05:56,085] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:05:56,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:06:26,865] {scheduler_job.py:182} INFO - Started process (PID=1356) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:26,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:06:26,872] {logging_mixin.py:104} INFO - [2022-03-18 02:06:26,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:26,904] {logging_mixin.py:104} INFO - [2022-03-18 02:06:26,899] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:06:26,907] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:26,935] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:06:57,611] {scheduler_job.py:182} INFO - Started process (PID=1388) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:57,615] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:06:57,617] {logging_mixin.py:104} INFO - [2022-03-18 02:06:57,617] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:57,649] {logging_mixin.py:104} INFO - [2022-03-18 02:06:57,644] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:06:57,653] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:06:57,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:07:28,316] {scheduler_job.py:182} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:07:28,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:07:28,324] {logging_mixin.py:104} INFO - [2022-03-18 02:07:28,323] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:07:28,357] {logging_mixin.py:104} INFO - [2022-03-18 02:07:28,353] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:07:28,362] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:07:28,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:08:01,427] {scheduler_job.py:182} INFO - Started process (PID=1452) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:01,431] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:08:01,433] {logging_mixin.py:104} INFO - [2022-03-18 02:08:01,433] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:01,465] {logging_mixin.py:104} INFO - [2022-03-18 02:08:01,460] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:08:01,469] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:01,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 02:08:32,005] {scheduler_job.py:182} INFO - Started process (PID=1461) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:32,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:08:32,012] {logging_mixin.py:104} INFO - [2022-03-18 02:08:32,012] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:32,050] {logging_mixin.py:104} INFO - [2022-03-18 02:08:32,044] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:08:32,055] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:08:32,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 02:09:02,768] {scheduler_job.py:182} INFO - Started process (PID=1490) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:02,771] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:09:02,774] {logging_mixin.py:104} INFO - [2022-03-18 02:09:02,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:02,807] {logging_mixin.py:104} INFO - [2022-03-18 02:09:02,802] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:09:02,811] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:02,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:09:33,526] {scheduler_job.py:182} INFO - Started process (PID=1522) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:33,531] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:09:33,533] {logging_mixin.py:104} INFO - [2022-03-18 02:09:33,533] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:33,565] {logging_mixin.py:104} INFO - [2022-03-18 02:09:33,560] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:09:33,569] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:09:33,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:10:04,230] {scheduler_job.py:182} INFO - Started process (PID=1554) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:04,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:10:04,238] {logging_mixin.py:104} INFO - [2022-03-18 02:10:04,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:04,271] {logging_mixin.py:104} INFO - [2022-03-18 02:10:04,267] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:10:04,275] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:04,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:10:35,058] {scheduler_job.py:182} INFO - Started process (PID=1586) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:35,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:10:35,066] {logging_mixin.py:104} INFO - [2022-03-18 02:10:35,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:35,098] {logging_mixin.py:104} INFO - [2022-03-18 02:10:35,093] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:10:35,102] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:10:35,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:11:05,912] {scheduler_job.py:182} INFO - Started process (PID=1618) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:05,917] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:11:05,920] {logging_mixin.py:104} INFO - [2022-03-18 02:11:05,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:05,958] {logging_mixin.py:104} INFO - [2022-03-18 02:11:05,952] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:11:05,961] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:05,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 02:11:36,885] {scheduler_job.py:182} INFO - Started process (PID=1650) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:36,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:11:36,893] {logging_mixin.py:104} INFO - [2022-03-18 02:11:36,892] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:36,930] {logging_mixin.py:104} INFO - [2022-03-18 02:11:36,924] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:11:36,935] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:11:36,962] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 02:12:07,367] {scheduler_job.py:182} INFO - Started process (PID=1682) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:07,374] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:12:07,377] {logging_mixin.py:104} INFO - [2022-03-18 02:12:07,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:07,408] {logging_mixin.py:104} INFO - [2022-03-18 02:12:07,403] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:12:07,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:07,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:12:39,168] {scheduler_job.py:182} INFO - Started process (PID=1712) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:39,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:12:39,175] {logging_mixin.py:104} INFO - [2022-03-18 02:12:39,174] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:39,210] {logging_mixin.py:104} INFO - [2022-03-18 02:12:39,205] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:12:39,213] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:12:39,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:13:09,948] {scheduler_job.py:182} INFO - Started process (PID=1735) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:09,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:13:09,957] {logging_mixin.py:104} INFO - [2022-03-18 02:13:09,957] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:09,992] {logging_mixin.py:104} INFO - [2022-03-18 02:13:09,987] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:13:09,996] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:10,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:13:40,596] {scheduler_job.py:182} INFO - Started process (PID=1764) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:40,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:13:40,604] {logging_mixin.py:104} INFO - [2022-03-18 02:13:40,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:40,640] {logging_mixin.py:104} INFO - [2022-03-18 02:13:40,635] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:13:40,651] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:13:40,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.091 seconds
[2022-03-18 02:14:11,243] {scheduler_job.py:182} INFO - Started process (PID=1796) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:11,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:14:11,248] {logging_mixin.py:104} INFO - [2022-03-18 02:14:11,248] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:11,278] {logging_mixin.py:104} INFO - [2022-03-18 02:14:11,274] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:14:11,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:11,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.071 seconds
[2022-03-18 02:14:42,070] {scheduler_job.py:182} INFO - Started process (PID=1828) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:42,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:14:42,077] {logging_mixin.py:104} INFO - [2022-03-18 02:14:42,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:42,110] {logging_mixin.py:104} INFO - [2022-03-18 02:14:42,105] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:14:42,114] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:14:42,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:15:12,633] {scheduler_job.py:182} INFO - Started process (PID=1860) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:12,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:15:12,641] {logging_mixin.py:104} INFO - [2022-03-18 02:15:12,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:12,672] {logging_mixin.py:104} INFO - [2022-03-18 02:15:12,667] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:15:12,677] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:12,703] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:15:43,401] {scheduler_job.py:182} INFO - Started process (PID=1892) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:43,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:15:43,408] {logging_mixin.py:104} INFO - [2022-03-18 02:15:43,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:43,440] {logging_mixin.py:104} INFO - [2022-03-18 02:15:43,435] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:15:43,443] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:15:43,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:16:14,158] {scheduler_job.py:182} INFO - Started process (PID=1924) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:14,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:16:14,166] {logging_mixin.py:104} INFO - [2022-03-18 02:16:14,166] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:14,199] {logging_mixin.py:104} INFO - [2022-03-18 02:16:14,195] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:16:14,203] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:14,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:16:44,297] {scheduler_job.py:182} INFO - Started process (PID=1956) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:44,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:16:44,302] {logging_mixin.py:104} INFO - [2022-03-18 02:16:44,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:44,336] {logging_mixin.py:104} INFO - [2022-03-18 02:16:44,331] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:16:44,341] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:16:44,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:17:16,916] {scheduler_job.py:182} INFO - Started process (PID=1986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:16,920] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:17:16,922] {logging_mixin.py:104} INFO - [2022-03-18 02:17:16,922] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:16,957] {logging_mixin.py:104} INFO - [2022-03-18 02:17:16,952] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:17:16,961] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:16,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:17:47,828] {scheduler_job.py:182} INFO - Started process (PID=2009) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:47,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:17:47,837] {logging_mixin.py:104} INFO - [2022-03-18 02:17:47,836] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:47,871] {logging_mixin.py:104} INFO - [2022-03-18 02:17:47,865] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:17:47,875] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:17:47,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:18:18,486] {scheduler_job.py:182} INFO - Started process (PID=2038) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:18,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:18:18,495] {logging_mixin.py:104} INFO - [2022-03-18 02:18:18,494] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:18,527] {logging_mixin.py:104} INFO - [2022-03-18 02:18:18,522] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:18:18,531] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:18,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:18:49,229] {scheduler_job.py:182} INFO - Started process (PID=2070) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:49,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:18:49,237] {logging_mixin.py:104} INFO - [2022-03-18 02:18:49,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:49,268] {logging_mixin.py:104} INFO - [2022-03-18 02:18:49,264] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:18:49,273] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:18:49,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:19:20,075] {scheduler_job.py:182} INFO - Started process (PID=2102) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:20,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:19:20,083] {logging_mixin.py:104} INFO - [2022-03-18 02:19:20,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:20,116] {logging_mixin.py:104} INFO - [2022-03-18 02:19:20,111] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:19:20,120] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:20,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.096 seconds
[2022-03-18 02:19:50,866] {scheduler_job.py:182} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:50,870] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:19:50,873] {logging_mixin.py:104} INFO - [2022-03-18 02:19:50,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:50,909] {logging_mixin.py:104} INFO - [2022-03-18 02:19:50,904] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:19:50,912] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:19:50,938] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:20:21,628] {scheduler_job.py:182} INFO - Started process (PID=2166) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:21,632] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:20:21,636] {logging_mixin.py:104} INFO - [2022-03-18 02:20:21,636] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:21,668] {logging_mixin.py:104} INFO - [2022-03-18 02:20:21,663] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:20:21,671] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:21,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.098 seconds
[2022-03-18 02:20:52,281] {scheduler_job.py:182} INFO - Started process (PID=2198) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:52,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:20:52,289] {logging_mixin.py:104} INFO - [2022-03-18 02:20:52,289] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:52,324] {logging_mixin.py:104} INFO - [2022-03-18 02:20:52,319] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:20:52,328] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:20:52,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:21:23,356] {scheduler_job.py:182} INFO - Started process (PID=2230) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:23,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:21:23,364] {logging_mixin.py:104} INFO - [2022-03-18 02:21:23,363] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:23,399] {logging_mixin.py:104} INFO - [2022-03-18 02:21:23,393] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:21:23,402] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:23,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:21:55,207] {scheduler_job.py:182} INFO - Started process (PID=2260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:55,210] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:21:55,213] {logging_mixin.py:104} INFO - [2022-03-18 02:21:55,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:55,249] {logging_mixin.py:104} INFO - [2022-03-18 02:21:55,244] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:21:55,254] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:21:55,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:22:26,159] {scheduler_job.py:182} INFO - Started process (PID=2283) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:26,166] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:22:26,170] {logging_mixin.py:104} INFO - [2022-03-18 02:22:26,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:26,203] {logging_mixin.py:104} INFO - [2022-03-18 02:22:26,198] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:22:26,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:26,237] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 02:22:56,820] {scheduler_job.py:182} INFO - Started process (PID=2312) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:56,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:22:56,827] {logging_mixin.py:104} INFO - [2022-03-18 02:22:56,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:56,860] {logging_mixin.py:104} INFO - [2022-03-18 02:22:56,855] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:22:56,864] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:22:56,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:23:27,423] {scheduler_job.py:182} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:27,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:23:27,430] {logging_mixin.py:104} INFO - [2022-03-18 02:23:27,430] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:27,464] {logging_mixin.py:104} INFO - [2022-03-18 02:23:27,459] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:23:27,469] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:27,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:23:58,192] {scheduler_job.py:182} INFO - Started process (PID=2376) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:58,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:23:58,200] {logging_mixin.py:104} INFO - [2022-03-18 02:23:58,200] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:58,233] {logging_mixin.py:104} INFO - [2022-03-18 02:23:58,228] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:23:58,237] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:23:58,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:24:28,779] {scheduler_job.py:182} INFO - Started process (PID=2408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:28,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:24:28,785] {logging_mixin.py:104} INFO - [2022-03-18 02:24:28,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:28,815] {logging_mixin.py:104} INFO - [2022-03-18 02:24:28,811] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:24:28,819] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:28,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.073 seconds
[2022-03-18 02:24:59,508] {scheduler_job.py:182} INFO - Started process (PID=2440) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:59,511] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:24:59,514] {logging_mixin.py:104} INFO - [2022-03-18 02:24:59,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:59,549] {logging_mixin.py:104} INFO - [2022-03-18 02:24:59,544] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:24:59,552] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:24:59,579] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:25:30,138] {scheduler_job.py:182} INFO - Started process (PID=2472) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:25:30,142] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:25:30,145] {logging_mixin.py:104} INFO - [2022-03-18 02:25:30,145] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:25:30,181] {logging_mixin.py:104} INFO - [2022-03-18 02:25:30,177] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:25:30,185] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:25:30,212] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:26:00,693] {scheduler_job.py:182} INFO - Started process (PID=2504) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:00,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:26:00,700] {logging_mixin.py:104} INFO - [2022-03-18 02:26:00,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:00,735] {logging_mixin.py:104} INFO - [2022-03-18 02:26:00,730] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:26:00,739] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:00,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:26:33,585] {scheduler_job.py:182} INFO - Started process (PID=2534) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:33,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:26:33,591] {logging_mixin.py:104} INFO - [2022-03-18 02:26:33,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:33,626] {logging_mixin.py:104} INFO - [2022-03-18 02:26:33,621] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:26:33,630] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:26:33,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:27:04,399] {scheduler_job.py:182} INFO - Started process (PID=2557) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:04,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:27:04,407] {logging_mixin.py:104} INFO - [2022-03-18 02:27:04,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:04,440] {logging_mixin.py:104} INFO - [2022-03-18 02:27:04,435] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:27:04,444] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:04,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:27:35,163] {scheduler_job.py:182} INFO - Started process (PID=2586) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:35,168] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:27:35,171] {logging_mixin.py:104} INFO - [2022-03-18 02:27:35,170] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:35,204] {logging_mixin.py:104} INFO - [2022-03-18 02:27:35,199] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:27:35,208] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:27:35,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:28:05,966] {scheduler_job.py:182} INFO - Started process (PID=2618) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:05,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:28:05,972] {logging_mixin.py:104} INFO - [2022-03-18 02:28:05,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:06,008] {logging_mixin.py:104} INFO - [2022-03-18 02:28:06,003] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:28:06,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:06,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:28:36,757] {scheduler_job.py:182} INFO - Started process (PID=2650) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:36,761] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:28:36,763] {logging_mixin.py:104} INFO - [2022-03-18 02:28:36,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:36,796] {logging_mixin.py:104} INFO - [2022-03-18 02:28:36,791] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:28:36,801] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:28:36,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:29:07,488] {scheduler_job.py:182} INFO - Started process (PID=2682) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:07,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:29:07,495] {logging_mixin.py:104} INFO - [2022-03-18 02:29:07,495] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:07,531] {logging_mixin.py:104} INFO - [2022-03-18 02:29:07,526] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:29:07,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:07,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:29:38,305] {scheduler_job.py:182} INFO - Started process (PID=2714) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:38,308] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:29:38,311] {logging_mixin.py:104} INFO - [2022-03-18 02:29:38,310] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:38,345] {logging_mixin.py:104} INFO - [2022-03-18 02:29:38,340] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:29:38,349] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:29:38,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:30:08,958] {scheduler_job.py:182} INFO - Started process (PID=2746) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:08,964] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:30:08,967] {logging_mixin.py:104} INFO - [2022-03-18 02:30:08,967] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:09,002] {logging_mixin.py:104} INFO - [2022-03-18 02:30:08,997] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:30:09,007] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:09,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:30:39,165] {scheduler_job.py:182} INFO - Started process (PID=2778) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:39,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:30:39,173] {logging_mixin.py:104} INFO - [2022-03-18 02:30:39,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:39,208] {logging_mixin.py:104} INFO - [2022-03-18 02:30:39,204] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:30:39,212] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:30:39,239] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:31:11,882] {scheduler_job.py:182} INFO - Started process (PID=2808) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:11,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:31:11,888] {logging_mixin.py:104} INFO - [2022-03-18 02:31:11,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:11,921] {logging_mixin.py:104} INFO - [2022-03-18 02:31:11,916] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:31:11,925] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:11,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:31:42,949] {scheduler_job.py:182} INFO - Started process (PID=2832) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:42,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:31:42,955] {logging_mixin.py:104} INFO - [2022-03-18 02:31:42,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:42,988] {logging_mixin.py:104} INFO - [2022-03-18 02:31:42,984] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:31:42,993] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:31:43,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:32:13,893] {scheduler_job.py:182} INFO - Started process (PID=2860) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:13,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:32:13,900] {logging_mixin.py:104} INFO - [2022-03-18 02:32:13,900] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:13,935] {logging_mixin.py:104} INFO - [2022-03-18 02:32:13,930] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:32:13,938] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:13,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:32:44,430] {scheduler_job.py:182} INFO - Started process (PID=2892) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:44,435] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:32:44,438] {logging_mixin.py:104} INFO - [2022-03-18 02:32:44,438] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:44,471] {logging_mixin.py:104} INFO - [2022-03-18 02:32:44,466] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:32:44,477] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:32:44,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:33:14,964] {scheduler_job.py:182} INFO - Started process (PID=2924) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:14,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:33:14,972] {logging_mixin.py:104} INFO - [2022-03-18 02:33:14,972] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:15,007] {logging_mixin.py:104} INFO - [2022-03-18 02:33:15,002] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:33:15,011] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:15,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 02:33:45,527] {scheduler_job.py:182} INFO - Started process (PID=2956) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:45,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:33:45,535] {logging_mixin.py:104} INFO - [2022-03-18 02:33:45,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:45,572] {logging_mixin.py:104} INFO - [2022-03-18 02:33:45,567] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:33:45,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:33:45,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:34:16,224] {scheduler_job.py:182} INFO - Started process (PID=2988) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:16,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:34:16,234] {logging_mixin.py:104} INFO - [2022-03-18 02:34:16,234] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:16,274] {logging_mixin.py:104} INFO - [2022-03-18 02:34:16,269] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:34:16,278] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:16,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.097 seconds
[2022-03-18 02:34:46,797] {scheduler_job.py:182} INFO - Started process (PID=3020) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:46,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:34:46,806] {logging_mixin.py:104} INFO - [2022-03-18 02:34:46,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:46,847] {logging_mixin.py:104} INFO - [2022-03-18 02:34:46,841] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:34:46,850] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:34:46,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.089 seconds
[2022-03-18 02:35:17,208] {scheduler_job.py:182} INFO - Started process (PID=3052) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:17,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:35:17,217] {logging_mixin.py:104} INFO - [2022-03-18 02:35:17,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:17,252] {logging_mixin.py:104} INFO - [2022-03-18 02:35:17,246] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:35:17,255] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:17,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:35:47,687] {scheduler_job.py:182} INFO - Started process (PID=3082) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:47,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:35:47,695] {logging_mixin.py:104} INFO - [2022-03-18 02:35:47,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:47,729] {logging_mixin.py:104} INFO - [2022-03-18 02:35:47,723] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:35:47,732] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:35:47,762] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:36:18,539] {scheduler_job.py:182} INFO - Started process (PID=3105) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:18,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:36:18,546] {logging_mixin.py:104} INFO - [2022-03-18 02:36:18,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:18,579] {logging_mixin.py:104} INFO - [2022-03-18 02:36:18,574] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:36:18,583] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:18,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:36:49,168] {scheduler_job.py:182} INFO - Started process (PID=3134) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:49,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:36:49,175] {logging_mixin.py:104} INFO - [2022-03-18 02:36:49,174] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:49,208] {logging_mixin.py:104} INFO - [2022-03-18 02:36:49,203] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:36:49,212] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:36:49,238] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:37:19,761] {scheduler_job.py:182} INFO - Started process (PID=3166) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:19,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:37:19,767] {logging_mixin.py:104} INFO - [2022-03-18 02:37:19,767] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:19,801] {logging_mixin.py:104} INFO - [2022-03-18 02:37:19,796] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:37:19,805] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:19,853] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.099 seconds
[2022-03-18 02:37:50,411] {scheduler_job.py:182} INFO - Started process (PID=3198) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:50,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:37:50,418] {logging_mixin.py:104} INFO - [2022-03-18 02:37:50,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:50,452] {logging_mixin.py:104} INFO - [2022-03-18 02:37:50,447] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:37:50,456] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:37:50,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:38:21,029] {scheduler_job.py:182} INFO - Started process (PID=3230) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:21,033] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:38:21,035] {logging_mixin.py:104} INFO - [2022-03-18 02:38:21,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:21,066] {logging_mixin.py:104} INFO - [2022-03-18 02:38:21,062] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:38:21,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:21,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.072 seconds
[2022-03-18 02:38:51,531] {scheduler_job.py:182} INFO - Started process (PID=3262) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:51,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:38:51,538] {logging_mixin.py:104} INFO - [2022-03-18 02:38:51,537] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:51,572] {logging_mixin.py:104} INFO - [2022-03-18 02:38:51,567] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:38:51,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:38:51,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:39:22,080] {scheduler_job.py:182} INFO - Started process (PID=3294) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:22,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:39:22,087] {logging_mixin.py:104} INFO - [2022-03-18 02:39:22,087] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:22,124] {logging_mixin.py:104} INFO - [2022-03-18 02:39:22,119] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:39:22,128] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:22,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:39:52,658] {scheduler_job.py:182} INFO - Started process (PID=3326) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:52,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:39:52,668] {logging_mixin.py:104} INFO - [2022-03-18 02:39:52,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:52,706] {logging_mixin.py:104} INFO - [2022-03-18 02:39:52,700] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:39:52,709] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:39:52,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 02:40:25,502] {scheduler_job.py:182} INFO - Started process (PID=3356) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:25,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:40:25,508] {logging_mixin.py:104} INFO - [2022-03-18 02:40:25,508] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:25,545] {logging_mixin.py:104} INFO - [2022-03-18 02:40:25,540] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:40:25,549] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:25,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:40:56,396] {scheduler_job.py:182} INFO - Started process (PID=3379) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:56,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:40:56,403] {logging_mixin.py:104} INFO - [2022-03-18 02:40:56,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:56,435] {logging_mixin.py:104} INFO - [2022-03-18 02:40:56,431] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:40:56,440] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:40:56,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:41:27,147] {scheduler_job.py:182} INFO - Started process (PID=3408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:27,153] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:41:27,155] {logging_mixin.py:104} INFO - [2022-03-18 02:41:27,155] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:27,189] {logging_mixin.py:104} INFO - [2022-03-18 02:41:27,184] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:41:27,194] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:27,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:41:58,071] {scheduler_job.py:182} INFO - Started process (PID=3440) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:58,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:41:58,081] {logging_mixin.py:104} INFO - [2022-03-18 02:41:58,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:58,115] {logging_mixin.py:104} INFO - [2022-03-18 02:41:58,109] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:41:58,119] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:41:58,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 02:42:28,676] {scheduler_job.py:182} INFO - Started process (PID=3472) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:28,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:42:28,684] {logging_mixin.py:104} INFO - [2022-03-18 02:42:28,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:28,716] {logging_mixin.py:104} INFO - [2022-03-18 02:42:28,712] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:42:28,720] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:28,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:42:59,338] {scheduler_job.py:182} INFO - Started process (PID=3504) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:59,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:42:59,346] {logging_mixin.py:104} INFO - [2022-03-18 02:42:59,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:59,381] {logging_mixin.py:104} INFO - [2022-03-18 02:42:59,375] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:42:59,385] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:42:59,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:43:30,033] {scheduler_job.py:182} INFO - Started process (PID=3536) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:43:30,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:43:30,039] {logging_mixin.py:104} INFO - [2022-03-18 02:43:30,039] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:43:30,073] {logging_mixin.py:104} INFO - [2022-03-18 02:43:30,068] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:43:30,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:43:30,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:44:00,621] {scheduler_job.py:182} INFO - Started process (PID=3568) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:00,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:44:00,628] {logging_mixin.py:104} INFO - [2022-03-18 02:44:00,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:00,660] {logging_mixin.py:104} INFO - [2022-03-18 02:44:00,655] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:44:00,664] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:00,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:44:31,701] {scheduler_job.py:182} INFO - Started process (PID=3600) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:31,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:44:31,709] {logging_mixin.py:104} INFO - [2022-03-18 02:44:31,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:31,745] {logging_mixin.py:104} INFO - [2022-03-18 02:44:31,739] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:44:31,749] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:44:31,775] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:45:02,316] {scheduler_job.py:182} INFO - Started process (PID=3630) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:02,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:45:02,323] {logging_mixin.py:104} INFO - [2022-03-18 02:45:02,323] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:02,357] {logging_mixin.py:104} INFO - [2022-03-18 02:45:02,353] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:45:02,362] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:02,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:45:33,295] {scheduler_job.py:182} INFO - Started process (PID=3653) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:33,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:45:33,302] {logging_mixin.py:104} INFO - [2022-03-18 02:45:33,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:33,340] {logging_mixin.py:104} INFO - [2022-03-18 02:45:33,334] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:45:33,343] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:45:33,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 02:46:03,938] {scheduler_job.py:182} INFO - Started process (PID=3682) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:03,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:46:03,946] {logging_mixin.py:104} INFO - [2022-03-18 02:46:03,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:03,980] {logging_mixin.py:104} INFO - [2022-03-18 02:46:03,975] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:46:03,985] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:04,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:46:34,629] {scheduler_job.py:182} INFO - Started process (PID=3714) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:34,634] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:46:34,637] {logging_mixin.py:104} INFO - [2022-03-18 02:46:34,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:34,670] {logging_mixin.py:104} INFO - [2022-03-18 02:46:34,666] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:46:34,674] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:46:34,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:47:05,319] {scheduler_job.py:182} INFO - Started process (PID=3746) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:05,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:47:05,327] {logging_mixin.py:104} INFO - [2022-03-18 02:47:05,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:05,362] {logging_mixin.py:104} INFO - [2022-03-18 02:47:05,357] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:47:05,367] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:05,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:47:36,007] {scheduler_job.py:182} INFO - Started process (PID=3778) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:36,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:47:36,016] {logging_mixin.py:104} INFO - [2022-03-18 02:47:36,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:36,049] {logging_mixin.py:104} INFO - [2022-03-18 02:47:36,044] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:47:36,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:47:36,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:48:06,629] {scheduler_job.py:182} INFO - Started process (PID=3810) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:06,634] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:48:06,637] {logging_mixin.py:104} INFO - [2022-03-18 02:48:06,637] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:06,670] {logging_mixin.py:104} INFO - [2022-03-18 02:48:06,665] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:48:06,673] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:06,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:48:37,124] {scheduler_job.py:182} INFO - Started process (PID=3842) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:37,128] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:48:37,130] {logging_mixin.py:104} INFO - [2022-03-18 02:48:37,130] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:37,162] {logging_mixin.py:104} INFO - [2022-03-18 02:48:37,157] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:48:37,166] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:48:37,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.073 seconds
[2022-03-18 02:49:07,477] {scheduler_job.py:182} INFO - Started process (PID=3872) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:07,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:49:07,484] {logging_mixin.py:104} INFO - [2022-03-18 02:49:07,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:07,518] {logging_mixin.py:104} INFO - [2022-03-18 02:49:07,514] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:49:07,522] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:07,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:49:40,247] {scheduler_job.py:182} INFO - Started process (PID=3904) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:40,251] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:49:40,254] {logging_mixin.py:104} INFO - [2022-03-18 02:49:40,253] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:40,290] {logging_mixin.py:104} INFO - [2022-03-18 02:49:40,285] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:49:40,294] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:49:40,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:50:11,275] {scheduler_job.py:182} INFO - Started process (PID=3927) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:11,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:50:11,282] {logging_mixin.py:104} INFO - [2022-03-18 02:50:11,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:11,317] {logging_mixin.py:104} INFO - [2022-03-18 02:50:11,312] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:50:11,320] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:11,348] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:50:42,093] {scheduler_job.py:182} INFO - Started process (PID=3956) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:42,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:50:42,101] {logging_mixin.py:104} INFO - [2022-03-18 02:50:42,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:42,136] {logging_mixin.py:104} INFO - [2022-03-18 02:50:42,131] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:50:42,140] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:50:42,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 02:51:12,747] {scheduler_job.py:182} INFO - Started process (PID=3988) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:12,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:51:12,754] {logging_mixin.py:104} INFO - [2022-03-18 02:51:12,754] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:12,787] {logging_mixin.py:104} INFO - [2022-03-18 02:51:12,782] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:51:12,791] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:12,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 02:51:43,425] {scheduler_job.py:182} INFO - Started process (PID=4020) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:43,430] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:51:43,433] {logging_mixin.py:104} INFO - [2022-03-18 02:51:43,432] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:43,465] {logging_mixin.py:104} INFO - [2022-03-18 02:51:43,461] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:51:43,470] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:51:43,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 02:52:14,101] {scheduler_job.py:182} INFO - Started process (PID=4052) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:14,105] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:52:14,108] {logging_mixin.py:104} INFO - [2022-03-18 02:52:14,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:14,145] {logging_mixin.py:104} INFO - [2022-03-18 02:52:14,140] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:52:14,149] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:14,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:52:44,851] {scheduler_job.py:182} INFO - Started process (PID=4084) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:44,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:52:44,858] {logging_mixin.py:104} INFO - [2022-03-18 02:52:44,857] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:44,893] {logging_mixin.py:104} INFO - [2022-03-18 02:52:44,888] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:52:44,897] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:52:44,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:53:15,539] {scheduler_job.py:182} INFO - Started process (PID=4116) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:15,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:53:15,546] {logging_mixin.py:104} INFO - [2022-03-18 02:53:15,546] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:15,578] {logging_mixin.py:104} INFO - [2022-03-18 02:53:15,573] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:53:15,582] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:15,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:53:46,656] {scheduler_job.py:182} INFO - Started process (PID=4148) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:46,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:53:46,664] {logging_mixin.py:104} INFO - [2022-03-18 02:53:46,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:46,697] {logging_mixin.py:104} INFO - [2022-03-18 02:53:46,692] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:53:46,701] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:53:46,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:54:17,273] {scheduler_job.py:182} INFO - Started process (PID=4178) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:17,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:54:17,279] {logging_mixin.py:104} INFO - [2022-03-18 02:54:17,279] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:17,312] {logging_mixin.py:104} INFO - [2022-03-18 02:54:17,306] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:54:17,315] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:17,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 02:54:48,268] {scheduler_job.py:182} INFO - Started process (PID=4201) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:48,274] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:54:48,277] {logging_mixin.py:104} INFO - [2022-03-18 02:54:48,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:48,312] {logging_mixin.py:104} INFO - [2022-03-18 02:54:48,307] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:54:48,315] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:54:48,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 02:55:18,957] {scheduler_job.py:182} INFO - Started process (PID=4230) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:18,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:55:18,965] {logging_mixin.py:104} INFO - [2022-03-18 02:55:18,964] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:18,999] {logging_mixin.py:104} INFO - [2022-03-18 02:55:18,994] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:55:19,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:19,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:55:49,599] {scheduler_job.py:182} INFO - Started process (PID=4262) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:49,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:55:49,607] {logging_mixin.py:104} INFO - [2022-03-18 02:55:49,606] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:49,640] {logging_mixin.py:104} INFO - [2022-03-18 02:55:49,636] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:55:49,644] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:55:49,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:56:20,158] {scheduler_job.py:182} INFO - Started process (PID=4294) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:20,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:56:20,165] {logging_mixin.py:104} INFO - [2022-03-18 02:56:20,165] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:20,199] {logging_mixin.py:104} INFO - [2022-03-18 02:56:20,194] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:56:20,203] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:20,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 02:56:50,702] {scheduler_job.py:182} INFO - Started process (PID=4326) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:50,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:56:50,708] {logging_mixin.py:104} INFO - [2022-03-18 02:56:50,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:50,742] {logging_mixin.py:104} INFO - [2022-03-18 02:56:50,737] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:56:50,746] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:56:50,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:57:21,318] {scheduler_job.py:182} INFO - Started process (PID=4358) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:21,323] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:57:21,325] {logging_mixin.py:104} INFO - [2022-03-18 02:57:21,325] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:21,358] {logging_mixin.py:104} INFO - [2022-03-18 02:57:21,353] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:57:21,362] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:21,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 02:57:51,908] {scheduler_job.py:182} INFO - Started process (PID=4390) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:51,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:57:51,916] {logging_mixin.py:104} INFO - [2022-03-18 02:57:51,916] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:51,950] {logging_mixin.py:104} INFO - [2022-03-18 02:57:51,945] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:57:51,953] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:57:51,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:58:23,025] {scheduler_job.py:182} INFO - Started process (PID=4422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:23,030] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:58:23,033] {logging_mixin.py:104} INFO - [2022-03-18 02:58:23,032] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:23,066] {logging_mixin.py:104} INFO - [2022-03-18 02:58:23,061] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:58:23,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:23,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 02:58:54,598] {scheduler_job.py:182} INFO - Started process (PID=4452) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:54,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:58:54,604] {logging_mixin.py:104} INFO - [2022-03-18 02:58:54,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:54,641] {logging_mixin.py:104} INFO - [2022-03-18 02:58:54,636] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:58:54,644] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:58:54,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 02:59:25,460] {scheduler_job.py:182} INFO - Started process (PID=4475) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:25,470] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:59:25,473] {logging_mixin.py:104} INFO - [2022-03-18 02:59:25,473] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:25,508] {logging_mixin.py:104} INFO - [2022-03-18 02:59:25,503] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:59:25,512] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:25,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 02:59:55,911] {scheduler_job.py:182} INFO - Started process (PID=4504) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:55,915] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 02:59:55,918] {logging_mixin.py:104} INFO - [2022-03-18 02:59:55,918] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:55,951] {logging_mixin.py:104} INFO - [2022-03-18 02:59:55,946] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 02:59:55,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 02:59:55,983] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:00:26,618] {scheduler_job.py:182} INFO - Started process (PID=4536) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:26,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:00:26,624] {logging_mixin.py:104} INFO - [2022-03-18 03:00:26,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:26,654] {logging_mixin.py:104} INFO - [2022-03-18 03:00:26,650] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:00:26,663] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:26,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 03:00:57,149] {scheduler_job.py:182} INFO - Started process (PID=4568) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:57,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:00:57,154] {logging_mixin.py:104} INFO - [2022-03-18 03:00:57,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:57,187] {logging_mixin.py:104} INFO - [2022-03-18 03:00:57,182] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:00:57,191] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:00:57,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:01:27,825] {scheduler_job.py:182} INFO - Started process (PID=4600) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:27,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:01:27,831] {logging_mixin.py:104} INFO - [2022-03-18 03:01:27,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:27,862] {logging_mixin.py:104} INFO - [2022-03-18 03:01:27,858] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:01:27,866] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:27,893] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:01:58,331] {scheduler_job.py:182} INFO - Started process (PID=4632) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:58,335] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:01:58,337] {logging_mixin.py:104} INFO - [2022-03-18 03:01:58,337] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:58,369] {logging_mixin.py:104} INFO - [2022-03-18 03:01:58,364] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:01:58,373] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:01:58,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:02:28,821] {scheduler_job.py:182} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:28,828] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:02:28,831] {logging_mixin.py:104} INFO - [2022-03-18 03:02:28,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:28,870] {logging_mixin.py:104} INFO - [2022-03-18 03:02:28,864] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:02:28,874] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:28,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.089 seconds
[2022-03-18 03:02:59,405] {scheduler_job.py:182} INFO - Started process (PID=4696) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:59,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:02:59,412] {logging_mixin.py:104} INFO - [2022-03-18 03:02:59,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:59,445] {logging_mixin.py:104} INFO - [2022-03-18 03:02:59,440] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:02:59,449] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:02:59,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:03:32,113] {scheduler_job.py:182} INFO - Started process (PID=4726) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:03:32,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:03:32,121] {logging_mixin.py:104} INFO - [2022-03-18 03:03:32,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:03:32,157] {logging_mixin.py:104} INFO - [2022-03-18 03:03:32,152] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:03:32,161] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:03:32,189] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:04:02,994] {scheduler_job.py:182} INFO - Started process (PID=4749) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:02,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:04:03,001] {logging_mixin.py:104} INFO - [2022-03-18 03:04:03,000] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:03,035] {logging_mixin.py:104} INFO - [2022-03-18 03:04:03,030] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:04:03,039] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:03,067] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:04:33,714] {scheduler_job.py:182} INFO - Started process (PID=4778) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:33,718] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:04:33,721] {logging_mixin.py:104} INFO - [2022-03-18 03:04:33,721] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:33,754] {logging_mixin.py:104} INFO - [2022-03-18 03:04:33,749] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:04:33,757] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:04:33,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:05:04,516] {scheduler_job.py:182} INFO - Started process (PID=4810) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:04,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:05:04,523] {logging_mixin.py:104} INFO - [2022-03-18 03:05:04,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:04,555] {logging_mixin.py:104} INFO - [2022-03-18 03:05:04,551] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:05:04,561] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:04,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:05:35,119] {scheduler_job.py:182} INFO - Started process (PID=4842) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:35,125] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:05:35,128] {logging_mixin.py:104} INFO - [2022-03-18 03:05:35,127] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:35,160] {logging_mixin.py:104} INFO - [2022-03-18 03:05:35,155] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:05:35,164] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:05:35,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:06:05,865] {scheduler_job.py:182} INFO - Started process (PID=4874) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:05,870] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:06:05,873] {logging_mixin.py:104} INFO - [2022-03-18 03:06:05,872] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:05,905] {logging_mixin.py:104} INFO - [2022-03-18 03:06:05,901] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:06:05,910] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:05,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:06:36,681] {scheduler_job.py:182} INFO - Started process (PID=4906) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:36,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:06:36,689] {logging_mixin.py:104} INFO - [2022-03-18 03:06:36,688] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:36,721] {logging_mixin.py:104} INFO - [2022-03-18 03:06:36,717] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:06:36,727] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:06:36,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:07:07,321] {scheduler_job.py:182} INFO - Started process (PID=4938) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:07,326] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:07:07,329] {logging_mixin.py:104} INFO - [2022-03-18 03:07:07,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:07,362] {logging_mixin.py:104} INFO - [2022-03-18 03:07:07,357] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:07:07,365] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:07,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:07:37,607] {scheduler_job.py:182} INFO - Started process (PID=4970) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:37,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:07:37,615] {logging_mixin.py:104} INFO - [2022-03-18 03:07:37,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:37,650] {logging_mixin.py:104} INFO - [2022-03-18 03:07:37,645] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:07:37,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:07:37,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 03:08:10,286] {scheduler_job.py:182} INFO - Started process (PID=5000) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:10,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:08:10,293] {logging_mixin.py:104} INFO - [2022-03-18 03:08:10,293] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:10,324] {logging_mixin.py:104} INFO - [2022-03-18 03:08:10,320] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:08:10,329] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:10,356] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:08:41,257] {scheduler_job.py:182} INFO - Started process (PID=5023) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:41,261] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:08:41,264] {logging_mixin.py:104} INFO - [2022-03-18 03:08:41,264] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:41,301] {logging_mixin.py:104} INFO - [2022-03-18 03:08:41,296] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:08:41,308] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:08:41,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.088 seconds
[2022-03-18 03:09:11,997] {scheduler_job.py:182} INFO - Started process (PID=5052) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:12,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:09:12,003] {logging_mixin.py:104} INFO - [2022-03-18 03:09:12,003] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:12,036] {logging_mixin.py:104} INFO - [2022-03-18 03:09:12,031] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:09:12,040] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:12,066] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:09:42,695] {scheduler_job.py:182} INFO - Started process (PID=5084) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:42,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:09:42,701] {logging_mixin.py:104} INFO - [2022-03-18 03:09:42,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:42,732] {logging_mixin.py:104} INFO - [2022-03-18 03:09:42,728] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:09:42,736] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:09:42,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:10:13,271] {scheduler_job.py:182} INFO - Started process (PID=5116) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:13,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:10:13,277] {logging_mixin.py:104} INFO - [2022-03-18 03:10:13,277] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:13,309] {logging_mixin.py:104} INFO - [2022-03-18 03:10:13,305] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:10:13,313] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:13,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:10:44,036] {scheduler_job.py:182} INFO - Started process (PID=5148) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:44,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:10:44,042] {logging_mixin.py:104} INFO - [2022-03-18 03:10:44,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:44,073] {logging_mixin.py:104} INFO - [2022-03-18 03:10:44,069] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:10:44,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:10:44,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:11:14,645] {scheduler_job.py:182} INFO - Started process (PID=5180) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:14,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:11:14,652] {logging_mixin.py:104} INFO - [2022-03-18 03:11:14,651] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:14,682] {logging_mixin.py:104} INFO - [2022-03-18 03:11:14,677] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:11:14,686] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:14,712] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:11:45,256] {scheduler_job.py:182} INFO - Started process (PID=5212) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:45,261] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:11:45,263] {logging_mixin.py:104} INFO - [2022-03-18 03:11:45,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:45,294] {logging_mixin.py:104} INFO - [2022-03-18 03:11:45,289] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:11:45,298] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:11:45,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:12:15,726] {scheduler_job.py:182} INFO - Started process (PID=5244) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:15,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:12:15,732] {logging_mixin.py:104} INFO - [2022-03-18 03:12:15,731] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:15,763] {logging_mixin.py:104} INFO - [2022-03-18 03:12:15,759] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:12:15,767] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:15,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:12:48,321] {scheduler_job.py:182} INFO - Started process (PID=5274) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:48,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:12:48,327] {logging_mixin.py:104} INFO - [2022-03-18 03:12:48,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:48,362] {logging_mixin.py:104} INFO - [2022-03-18 03:12:48,358] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:12:48,366] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:12:48,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:13:19,211] {scheduler_job.py:182} INFO - Started process (PID=5297) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:19,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:13:19,218] {logging_mixin.py:104} INFO - [2022-03-18 03:13:19,217] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:19,255] {logging_mixin.py:104} INFO - [2022-03-18 03:13:19,250] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:13:19,259] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:19,287] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:13:49,920] {scheduler_job.py:182} INFO - Started process (PID=5326) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:49,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:13:49,945] {logging_mixin.py:104} INFO - [2022-03-18 03:13:49,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:49,978] {logging_mixin.py:104} INFO - [2022-03-18 03:13:49,973] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:13:49,982] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:13:50,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.095 seconds
[2022-03-18 03:14:20,663] {scheduler_job.py:182} INFO - Started process (PID=5358) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:20,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:14:20,674] {logging_mixin.py:104} INFO - [2022-03-18 03:14:20,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:20,708] {logging_mixin.py:104} INFO - [2022-03-18 03:14:20,703] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:14:20,712] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:20,736] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:14:51,291] {scheduler_job.py:182} INFO - Started process (PID=5390) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:51,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:14:51,300] {logging_mixin.py:104} INFO - [2022-03-18 03:14:51,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:51,333] {logging_mixin.py:104} INFO - [2022-03-18 03:14:51,327] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:14:51,338] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:14:51,365] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:15:22,107] {scheduler_job.py:182} INFO - Started process (PID=5422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:22,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:15:22,119] {logging_mixin.py:104} INFO - [2022-03-18 03:15:22,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:22,153] {logging_mixin.py:104} INFO - [2022-03-18 03:15:22,148] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:15:22,157] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:22,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 03:15:52,848] {scheduler_job.py:182} INFO - Started process (PID=5454) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:52,851] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:15:52,854] {logging_mixin.py:104} INFO - [2022-03-18 03:15:52,853] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:52,884] {logging_mixin.py:104} INFO - [2022-03-18 03:15:52,880] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:15:52,889] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:15:52,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.073 seconds
[2022-03-18 03:16:23,503] {scheduler_job.py:182} INFO - Started process (PID=5486) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:23,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:16:23,509] {logging_mixin.py:104} INFO - [2022-03-18 03:16:23,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:23,540] {logging_mixin.py:104} INFO - [2022-03-18 03:16:23,535] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:16:23,544] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:23,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:16:53,679] {scheduler_job.py:182} INFO - Started process (PID=5518) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:53,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:16:53,686] {logging_mixin.py:104} INFO - [2022-03-18 03:16:53,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:53,722] {logging_mixin.py:104} INFO - [2022-03-18 03:16:53,717] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:16:53,725] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:16:53,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:17:26,289] {scheduler_job.py:182} INFO - Started process (PID=5548) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:26,293] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:17:26,296] {logging_mixin.py:104} INFO - [2022-03-18 03:17:26,295] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:26,330] {logging_mixin.py:104} INFO - [2022-03-18 03:17:26,325] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:17:26,335] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:26,363] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:17:57,152] {scheduler_job.py:182} INFO - Started process (PID=5571) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:57,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:17:57,159] {logging_mixin.py:104} INFO - [2022-03-18 03:17:57,158] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:57,194] {logging_mixin.py:104} INFO - [2022-03-18 03:17:57,189] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:17:57,198] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:17:57,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:18:27,841] {scheduler_job.py:182} INFO - Started process (PID=5600) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:27,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:18:27,849] {logging_mixin.py:104} INFO - [2022-03-18 03:18:27,848] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:27,880] {logging_mixin.py:104} INFO - [2022-03-18 03:18:27,875] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:18:27,884] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:27,909] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:18:58,542] {scheduler_job.py:182} INFO - Started process (PID=5632) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:58,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:18:58,549] {logging_mixin.py:104} INFO - [2022-03-18 03:18:58,548] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:58,584] {logging_mixin.py:104} INFO - [2022-03-18 03:18:58,578] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:18:58,587] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:18:58,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:19:29,408] {scheduler_job.py:182} INFO - Started process (PID=5664) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:19:29,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:19:29,415] {logging_mixin.py:104} INFO - [2022-03-18 03:19:29,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:19:29,449] {logging_mixin.py:104} INFO - [2022-03-18 03:19:29,445] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:19:29,453] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:19:29,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:20:00,171] {scheduler_job.py:182} INFO - Started process (PID=5696) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:00,176] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:20:00,180] {logging_mixin.py:104} INFO - [2022-03-18 03:20:00,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:00,215] {logging_mixin.py:104} INFO - [2022-03-18 03:20:00,210] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:20:00,219] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:00,245] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:20:31,035] {scheduler_job.py:182} INFO - Started process (PID=5728) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:31,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:20:31,042] {logging_mixin.py:104} INFO - [2022-03-18 03:20:31,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:31,074] {logging_mixin.py:104} INFO - [2022-03-18 03:20:31,070] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:20:31,078] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:20:31,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 03:21:01,659] {scheduler_job.py:182} INFO - Started process (PID=5760) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:01,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:21:01,667] {logging_mixin.py:104} INFO - [2022-03-18 03:21:01,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:01,699] {logging_mixin.py:104} INFO - [2022-03-18 03:21:01,694] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:21:01,702] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:01,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:21:31,826] {scheduler_job.py:182} INFO - Started process (PID=5792) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:31,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:21:31,833] {logging_mixin.py:104} INFO - [2022-03-18 03:21:31,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:31,866] {logging_mixin.py:104} INFO - [2022-03-18 03:21:31,861] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:21:31,871] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:21:31,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:22:03,458] {scheduler_job.py:182} INFO - Started process (PID=5822) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:03,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:22:03,464] {logging_mixin.py:104} INFO - [2022-03-18 03:22:03,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:03,498] {logging_mixin.py:104} INFO - [2022-03-18 03:22:03,493] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:22:03,502] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:03,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:22:34,287] {scheduler_job.py:182} INFO - Started process (PID=5845) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:34,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:22:34,295] {logging_mixin.py:104} INFO - [2022-03-18 03:22:34,294] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:34,332] {logging_mixin.py:104} INFO - [2022-03-18 03:22:34,327] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:22:34,336] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:22:34,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 03:23:04,906] {scheduler_job.py:182} INFO - Started process (PID=5874) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:04,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:23:04,914] {logging_mixin.py:104} INFO - [2022-03-18 03:23:04,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:04,947] {logging_mixin.py:104} INFO - [2022-03-18 03:23:04,942] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:23:04,951] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:04,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:23:35,562] {scheduler_job.py:182} INFO - Started process (PID=5906) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:35,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:23:35,569] {logging_mixin.py:104} INFO - [2022-03-18 03:23:35,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:35,604] {logging_mixin.py:104} INFO - [2022-03-18 03:23:35,599] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:23:35,607] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:23:35,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:24:06,427] {scheduler_job.py:182} INFO - Started process (PID=5938) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:06,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:24:06,436] {logging_mixin.py:104} INFO - [2022-03-18 03:24:06,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:06,467] {logging_mixin.py:104} INFO - [2022-03-18 03:24:06,463] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:24:06,471] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:06,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:24:36,959] {scheduler_job.py:182} INFO - Started process (PID=5970) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:36,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:24:36,966] {logging_mixin.py:104} INFO - [2022-03-18 03:24:36,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:37,000] {logging_mixin.py:104} INFO - [2022-03-18 03:24:36,995] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:24:37,004] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:24:37,031] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:25:07,564] {scheduler_job.py:182} INFO - Started process (PID=6002) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:07,570] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:25:07,574] {logging_mixin.py:104} INFO - [2022-03-18 03:25:07,573] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:07,607] {logging_mixin.py:104} INFO - [2022-03-18 03:25:07,603] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:25:07,612] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:07,639] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:25:38,106] {scheduler_job.py:182} INFO - Started process (PID=6034) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:38,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:25:38,113] {logging_mixin.py:104} INFO - [2022-03-18 03:25:38,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:38,148] {logging_mixin.py:104} INFO - [2022-03-18 03:25:38,144] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:25:38,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:25:38,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:26:08,321] {scheduler_job.py:182} INFO - Started process (PID=6064) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:08,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:26:08,329] {logging_mixin.py:104} INFO - [2022-03-18 03:26:08,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:08,361] {logging_mixin.py:104} INFO - [2022-03-18 03:26:08,357] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:26:08,365] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:08,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:26:39,108] {scheduler_job.py:182} INFO - Started process (PID=6093) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:39,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:26:39,114] {logging_mixin.py:104} INFO - [2022-03-18 03:26:39,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:39,148] {logging_mixin.py:104} INFO - [2022-03-18 03:26:39,143] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:26:39,152] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:26:39,181] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:27:09,777] {scheduler_job.py:182} INFO - Started process (PID=6119) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:09,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:27:09,785] {logging_mixin.py:104} INFO - [2022-03-18 03:27:09,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:09,820] {logging_mixin.py:104} INFO - [2022-03-18 03:27:09,815] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:27:09,824] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:09,853] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 03:27:40,571] {scheduler_job.py:182} INFO - Started process (PID=6148) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:40,576] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:27:40,579] {logging_mixin.py:104} INFO - [2022-03-18 03:27:40,579] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:40,615] {logging_mixin.py:104} INFO - [2022-03-18 03:27:40,610] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:27:40,618] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:27:40,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:28:11,017] {scheduler_job.py:182} INFO - Started process (PID=6180) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:11,022] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:28:11,025] {logging_mixin.py:104} INFO - [2022-03-18 03:28:11,025] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:11,058] {logging_mixin.py:104} INFO - [2022-03-18 03:28:11,053] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:28:11,062] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:11,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:28:41,202] {scheduler_job.py:182} INFO - Started process (PID=6212) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:41,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:28:41,208] {logging_mixin.py:104} INFO - [2022-03-18 03:28:41,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:41,242] {logging_mixin.py:104} INFO - [2022-03-18 03:28:41,237] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:28:41,246] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:28:41,273] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:29:11,366] {scheduler_job.py:182} INFO - Started process (PID=6244) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:11,371] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:29:11,373] {logging_mixin.py:104} INFO - [2022-03-18 03:29:11,373] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:11,404] {logging_mixin.py:104} INFO - [2022-03-18 03:29:11,399] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:29:11,408] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:11,437] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:29:42,056] {scheduler_job.py:182} INFO - Started process (PID=6276) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:42,059] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:29:42,062] {logging_mixin.py:104} INFO - [2022-03-18 03:29:42,061] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:42,094] {logging_mixin.py:104} INFO - [2022-03-18 03:29:42,090] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:29:42,099] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:29:42,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:30:12,360] {scheduler_job.py:182} INFO - Started process (PID=6308) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:12,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:30:12,368] {logging_mixin.py:104} INFO - [2022-03-18 03:30:12,368] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:12,402] {logging_mixin.py:104} INFO - [2022-03-18 03:30:12,397] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:30:12,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:12,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:30:42,791] {scheduler_job.py:182} INFO - Started process (PID=6340) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:42,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:30:42,798] {logging_mixin.py:104} INFO - [2022-03-18 03:30:42,798] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:42,831] {logging_mixin.py:104} INFO - [2022-03-18 03:30:42,827] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:30:42,836] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:30:42,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:31:13,530] {scheduler_job.py:182} INFO - Started process (PID=6370) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:13,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:31:13,536] {logging_mixin.py:104} INFO - [2022-03-18 03:31:13,535] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:13,573] {logging_mixin.py:104} INFO - [2022-03-18 03:31:13,567] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:31:13,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:13,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:31:44,051] {scheduler_job.py:182} INFO - Started process (PID=6394) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:44,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:31:44,058] {logging_mixin.py:104} INFO - [2022-03-18 03:31:44,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:44,091] {logging_mixin.py:104} INFO - [2022-03-18 03:31:44,087] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:31:44,096] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:31:44,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:32:14,902] {scheduler_job.py:182} INFO - Started process (PID=6422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:14,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:32:14,909] {logging_mixin.py:104} INFO - [2022-03-18 03:32:14,908] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:14,951] {logging_mixin.py:104} INFO - [2022-03-18 03:32:14,946] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:32:14,954] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:14,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 03:32:45,408] {scheduler_job.py:182} INFO - Started process (PID=6454) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:45,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:32:45,416] {logging_mixin.py:104} INFO - [2022-03-18 03:32:45,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:45,453] {logging_mixin.py:104} INFO - [2022-03-18 03:32:45,448] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:32:45,457] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:32:45,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:33:16,112] {scheduler_job.py:182} INFO - Started process (PID=6486) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:16,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:33:16,117] {logging_mixin.py:104} INFO - [2022-03-18 03:33:16,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:16,152] {logging_mixin.py:104} INFO - [2022-03-18 03:33:16,147] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:33:16,156] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:16,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:33:46,543] {scheduler_job.py:182} INFO - Started process (PID=6518) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:46,548] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:33:46,551] {logging_mixin.py:104} INFO - [2022-03-18 03:33:46,550] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:46,586] {logging_mixin.py:104} INFO - [2022-03-18 03:33:46,581] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:33:46,590] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:33:46,618] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 03:34:16,736] {scheduler_job.py:182} INFO - Started process (PID=6550) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:16,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:34:16,743] {logging_mixin.py:104} INFO - [2022-03-18 03:34:16,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:16,777] {logging_mixin.py:104} INFO - [2022-03-18 03:34:16,772] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:34:16,781] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:16,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:34:47,406] {scheduler_job.py:182} INFO - Started process (PID=6582) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:47,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:34:47,415] {logging_mixin.py:104} INFO - [2022-03-18 03:34:47,414] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:47,447] {logging_mixin.py:104} INFO - [2022-03-18 03:34:47,441] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:34:47,452] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:34:47,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:35:17,619] {scheduler_job.py:182} INFO - Started process (PID=6614) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:17,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:35:17,625] {logging_mixin.py:104} INFO - [2022-03-18 03:35:17,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:17,656] {logging_mixin.py:104} INFO - [2022-03-18 03:35:17,652] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:35:17,661] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:17,688] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:35:48,029] {scheduler_job.py:182} INFO - Started process (PID=6644) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:48,033] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:35:48,036] {logging_mixin.py:104} INFO - [2022-03-18 03:35:48,035] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:48,070] {logging_mixin.py:104} INFO - [2022-03-18 03:35:48,066] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:35:48,076] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:35:48,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:36:18,786] {scheduler_job.py:182} INFO - Started process (PID=6669) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:18,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:36:18,793] {logging_mixin.py:104} INFO - [2022-03-18 03:36:18,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:18,828] {logging_mixin.py:104} INFO - [2022-03-18 03:36:18,823] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:36:18,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:18,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:36:49,282] {scheduler_job.py:182} INFO - Started process (PID=6696) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:49,286] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:36:49,289] {logging_mixin.py:104} INFO - [2022-03-18 03:36:49,288] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:49,321] {logging_mixin.py:104} INFO - [2022-03-18 03:36:49,316] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:36:49,325] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:36:49,350] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:37:20,077] {scheduler_job.py:182} INFO - Started process (PID=6728) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:20,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:37:20,083] {logging_mixin.py:104} INFO - [2022-03-18 03:37:20,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:20,116] {logging_mixin.py:104} INFO - [2022-03-18 03:37:20,112] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:37:20,120] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:20,146] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:37:50,340] {scheduler_job.py:182} INFO - Started process (PID=6760) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:50,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:37:50,352] {logging_mixin.py:104} INFO - [2022-03-18 03:37:50,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:50,391] {logging_mixin.py:104} INFO - [2022-03-18 03:37:50,384] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:37:50,396] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:37:50,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.097 seconds
[2022-03-18 03:38:21,187] {scheduler_job.py:182} INFO - Started process (PID=6792) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:21,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:38:21,193] {logging_mixin.py:104} INFO - [2022-03-18 03:38:21,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:21,225] {logging_mixin.py:104} INFO - [2022-03-18 03:38:21,220] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:38:21,228] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:21,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:38:51,588] {scheduler_job.py:182} INFO - Started process (PID=6824) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:51,594] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:38:51,597] {logging_mixin.py:104} INFO - [2022-03-18 03:38:51,597] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:51,639] {logging_mixin.py:104} INFO - [2022-03-18 03:38:51,633] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:38:51,642] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:38:51,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.091 seconds
[2022-03-18 03:39:22,278] {scheduler_job.py:182} INFO - Started process (PID=6856) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:22,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:39:22,285] {logging_mixin.py:104} INFO - [2022-03-18 03:39:22,285] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:22,323] {logging_mixin.py:104} INFO - [2022-03-18 03:39:22,317] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:39:22,327] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:22,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:39:52,569] {scheduler_job.py:182} INFO - Started process (PID=6888) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:52,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:39:52,577] {logging_mixin.py:104} INFO - [2022-03-18 03:39:52,577] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:52,609] {logging_mixin.py:104} INFO - [2022-03-18 03:39:52,604] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:39:52,613] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:39:52,639] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:40:22,943] {scheduler_job.py:182} INFO - Started process (PID=6918) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:22,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:40:22,950] {logging_mixin.py:104} INFO - [2022-03-18 03:40:22,949] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:22,987] {logging_mixin.py:104} INFO - [2022-03-18 03:40:22,981] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:40:22,991] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:23,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:40:53,690] {scheduler_job.py:182} INFO - Started process (PID=6943) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:53,695] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:40:53,698] {logging_mixin.py:104} INFO - [2022-03-18 03:40:53,698] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:53,733] {logging_mixin.py:104} INFO - [2022-03-18 03:40:53,727] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:40:53,737] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:40:53,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.099 seconds
[2022-03-18 03:41:24,125] {scheduler_job.py:182} INFO - Started process (PID=6970) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:24,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:41:24,132] {logging_mixin.py:104} INFO - [2022-03-18 03:41:24,131] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:24,166] {logging_mixin.py:104} INFO - [2022-03-18 03:41:24,161] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:41:24,170] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:24,197] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:41:54,913] {scheduler_job.py:182} INFO - Started process (PID=7002) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:54,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:41:54,921] {logging_mixin.py:104} INFO - [2022-03-18 03:41:54,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:54,954] {logging_mixin.py:104} INFO - [2022-03-18 03:41:54,950] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:41:54,958] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:41:54,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:42:25,800] {scheduler_job.py:182} INFO - Started process (PID=7034) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:25,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:42:25,808] {logging_mixin.py:104} INFO - [2022-03-18 03:42:25,808] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:25,849] {logging_mixin.py:104} INFO - [2022-03-18 03:42:25,844] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:42:25,853] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:25,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.089 seconds
[2022-03-18 03:42:56,577] {scheduler_job.py:182} INFO - Started process (PID=7066) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:56,580] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:42:56,583] {logging_mixin.py:104} INFO - [2022-03-18 03:42:56,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:56,615] {logging_mixin.py:104} INFO - [2022-03-18 03:42:56,610] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:42:56,620] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:42:56,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 03:43:26,897] {scheduler_job.py:182} INFO - Started process (PID=7098) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:26,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:43:26,906] {logging_mixin.py:104} INFO - [2022-03-18 03:43:26,906] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:26,941] {logging_mixin.py:104} INFO - [2022-03-18 03:43:26,936] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:43:26,945] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:26,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 03:43:57,757] {scheduler_job.py:182} INFO - Started process (PID=7130) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:57,761] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:43:57,763] {logging_mixin.py:104} INFO - [2022-03-18 03:43:57,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:57,793] {logging_mixin.py:104} INFO - [2022-03-18 03:43:57,789] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:43:57,797] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:43:57,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 03:44:28,281] {scheduler_job.py:182} INFO - Started process (PID=7162) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:28,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:44:28,286] {logging_mixin.py:104} INFO - [2022-03-18 03:44:28,286] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:28,321] {logging_mixin.py:104} INFO - [2022-03-18 03:44:28,316] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:44:28,326] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:28,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 03:44:58,679] {scheduler_job.py:182} INFO - Started process (PID=7194) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:58,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:44:58,688] {logging_mixin.py:104} INFO - [2022-03-18 03:44:58,688] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:58,729] {logging_mixin.py:104} INFO - [2022-03-18 03:44:58,723] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:44:58,734] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:44:58,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.090 seconds
[2022-03-18 03:45:29,073] {scheduler_job.py:182} INFO - Started process (PID=7224) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:45:29,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:45:29,080] {logging_mixin.py:104} INFO - [2022-03-18 03:45:29,080] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:45:29,115] {logging_mixin.py:104} INFO - [2022-03-18 03:45:29,110] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:45:29,118] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:45:29,147] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:46:00,031] {scheduler_job.py:182} INFO - Started process (PID=7249) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:00,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:46:00,039] {logging_mixin.py:104} INFO - [2022-03-18 03:46:00,038] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:00,080] {logging_mixin.py:104} INFO - [2022-03-18 03:46:00,075] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:46:00,084] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:00,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.089 seconds
[2022-03-18 03:46:30,468] {scheduler_job.py:182} INFO - Started process (PID=7276) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:30,474] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:46:30,479] {logging_mixin.py:104} INFO - [2022-03-18 03:46:30,478] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:30,524] {logging_mixin.py:104} INFO - [2022-03-18 03:46:30,517] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:46:30,530] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:46:30,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.100 seconds
[2022-03-18 03:47:00,634] {scheduler_job.py:182} INFO - Started process (PID=7308) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:00,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:47:00,641] {logging_mixin.py:104} INFO - [2022-03-18 03:47:00,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:00,675] {logging_mixin.py:104} INFO - [2022-03-18 03:47:00,670] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:47:00,679] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:00,706] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:47:31,298] {scheduler_job.py:182} INFO - Started process (PID=7340) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:31,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:47:31,304] {logging_mixin.py:104} INFO - [2022-03-18 03:47:31,303] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:31,337] {logging_mixin.py:104} INFO - [2022-03-18 03:47:31,332] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:47:31,341] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:47:31,368] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:48:01,529] {scheduler_job.py:182} INFO - Started process (PID=7372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:01,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:48:01,536] {logging_mixin.py:104} INFO - [2022-03-18 03:48:01,536] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:01,573] {logging_mixin.py:104} INFO - [2022-03-18 03:48:01,568] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:48:01,577] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:01,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:48:32,217] {scheduler_job.py:182} INFO - Started process (PID=7404) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:32,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:48:32,223] {logging_mixin.py:104} INFO - [2022-03-18 03:48:32,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:32,254] {logging_mixin.py:104} INFO - [2022-03-18 03:48:32,250] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:48:32,257] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:48:32,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.072 seconds
[2022-03-18 03:49:02,551] {scheduler_job.py:182} INFO - Started process (PID=7436) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:02,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:49:02,558] {logging_mixin.py:104} INFO - [2022-03-18 03:49:02,558] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:02,591] {logging_mixin.py:104} INFO - [2022-03-18 03:49:02,586] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:49:02,595] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:02,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:49:32,913] {scheduler_job.py:182} INFO - Started process (PID=7468) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:32,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:49:32,921] {logging_mixin.py:104} INFO - [2022-03-18 03:49:32,920] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:32,956] {logging_mixin.py:104} INFO - [2022-03-18 03:49:32,951] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:49:32,961] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:49:32,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 03:50:03,264] {scheduler_job.py:182} INFO - Started process (PID=7498) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:03,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:50:03,271] {logging_mixin.py:104} INFO - [2022-03-18 03:50:03,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:03,306] {logging_mixin.py:104} INFO - [2022-03-18 03:50:03,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:50:03,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:03,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:50:34,140] {scheduler_job.py:182} INFO - Started process (PID=7522) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:34,144] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:50:34,146] {logging_mixin.py:104} INFO - [2022-03-18 03:50:34,146] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:34,179] {logging_mixin.py:104} INFO - [2022-03-18 03:50:34,175] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:50:34,183] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:50:34,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:51:04,697] {scheduler_job.py:182} INFO - Started process (PID=7550) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:04,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:51:04,704] {logging_mixin.py:104} INFO - [2022-03-18 03:51:04,704] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:04,738] {logging_mixin.py:104} INFO - [2022-03-18 03:51:04,733] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:51:04,742] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:04,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:51:35,339] {scheduler_job.py:182} INFO - Started process (PID=7582) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:35,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:51:35,347] {logging_mixin.py:104} INFO - [2022-03-18 03:51:35,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:35,380] {logging_mixin.py:104} INFO - [2022-03-18 03:51:35,375] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:51:35,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:51:35,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:52:05,699] {scheduler_job.py:182} INFO - Started process (PID=7614) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:05,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:52:05,705] {logging_mixin.py:104} INFO - [2022-03-18 03:52:05,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:05,738] {logging_mixin.py:104} INFO - [2022-03-18 03:52:05,734] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:52:05,743] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:05,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:52:36,116] {scheduler_job.py:182} INFO - Started process (PID=7646) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:36,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:52:36,126] {logging_mixin.py:104} INFO - [2022-03-18 03:52:36,125] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:36,160] {logging_mixin.py:104} INFO - [2022-03-18 03:52:36,156] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:52:36,164] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:52:36,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 03:53:06,551] {scheduler_job.py:182} INFO - Started process (PID=7678) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:06,556] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:53:06,560] {logging_mixin.py:104} INFO - [2022-03-18 03:53:06,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:06,592] {logging_mixin.py:104} INFO - [2022-03-18 03:53:06,587] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:53:06,595] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:06,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:53:36,966] {scheduler_job.py:182} INFO - Started process (PID=7710) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:36,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:53:36,974] {logging_mixin.py:104} INFO - [2022-03-18 03:53:36,973] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:37,006] {logging_mixin.py:104} INFO - [2022-03-18 03:53:37,002] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:53:37,010] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:53:37,035] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:54:07,409] {scheduler_job.py:182} INFO - Started process (PID=7740) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:07,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:54:07,415] {logging_mixin.py:104} INFO - [2022-03-18 03:54:07,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:07,452] {logging_mixin.py:104} INFO - [2022-03-18 03:54:07,447] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:54:07,455] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:07,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:54:38,870] {scheduler_job.py:182} INFO - Started process (PID=7772) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:38,873] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:54:38,877] {logging_mixin.py:104} INFO - [2022-03-18 03:54:38,876] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:38,910] {logging_mixin.py:104} INFO - [2022-03-18 03:54:38,905] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:54:38,913] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:54:38,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 03:55:09,721] {scheduler_job.py:182} INFO - Started process (PID=7796) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:09,725] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:55:09,727] {logging_mixin.py:104} INFO - [2022-03-18 03:55:09,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:09,762] {logging_mixin.py:104} INFO - [2022-03-18 03:55:09,758] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:55:09,766] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:09,794] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:55:39,973] {scheduler_job.py:182} INFO - Started process (PID=7824) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:39,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:55:39,982] {logging_mixin.py:104} INFO - [2022-03-18 03:55:39,981] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:40,013] {logging_mixin.py:104} INFO - [2022-03-18 03:55:40,008] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:55:40,017] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:55:40,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:56:10,784] {scheduler_job.py:182} INFO - Started process (PID=7856) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:10,789] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:56:10,792] {logging_mixin.py:104} INFO - [2022-03-18 03:56:10,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:10,826] {logging_mixin.py:104} INFO - [2022-03-18 03:56:10,820] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:56:10,831] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:10,857] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 03:56:41,644] {scheduler_job.py:182} INFO - Started process (PID=7888) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:41,649] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:56:41,652] {logging_mixin.py:104} INFO - [2022-03-18 03:56:41,651] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:41,685] {logging_mixin.py:104} INFO - [2022-03-18 03:56:41,680] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:56:41,689] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:56:41,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 03:57:11,839] {scheduler_job.py:182} INFO - Started process (PID=7920) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:11,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:57:11,847] {logging_mixin.py:104} INFO - [2022-03-18 03:57:11,847] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:11,883] {logging_mixin.py:104} INFO - [2022-03-18 03:57:11,878] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:57:11,887] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:11,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 03:57:42,450] {scheduler_job.py:182} INFO - Started process (PID=7952) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:42,454] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:57:42,457] {logging_mixin.py:104} INFO - [2022-03-18 03:57:42,456] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:42,489] {logging_mixin.py:104} INFO - [2022-03-18 03:57:42,484] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:57:42,493] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:57:42,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 03:58:12,796] {scheduler_job.py:182} INFO - Started process (PID=7984) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:12,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:58:12,804] {logging_mixin.py:104} INFO - [2022-03-18 03:58:12,803] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:12,835] {logging_mixin.py:104} INFO - [2022-03-18 03:58:12,830] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:58:12,839] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:12,863] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 03:58:42,955] {scheduler_job.py:182} INFO - Started process (PID=8016) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:42,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:58:42,964] {logging_mixin.py:104} INFO - [2022-03-18 03:58:42,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:43,002] {logging_mixin.py:104} INFO - [2022-03-18 03:58:42,997] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:58:43,006] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:58:43,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 03:59:13,266] {scheduler_job.py:182} INFO - Started process (PID=8046) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:13,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:59:13,272] {logging_mixin.py:104} INFO - [2022-03-18 03:59:13,271] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:13,307] {logging_mixin.py:104} INFO - [2022-03-18 03:59:13,301] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:59:13,311] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:13,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 03:59:43,658] {scheduler_job.py:182} INFO - Started process (PID=8071) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:43,662] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 03:59:43,665] {logging_mixin.py:104} INFO - [2022-03-18 03:59:43,665] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:43,699] {logging_mixin.py:104} INFO - [2022-03-18 03:59:43,694] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 03:59:43,703] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 03:59:43,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 04:00:14,357] {scheduler_job.py:182} INFO - Started process (PID=8098) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:14,363] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:00:14,366] {logging_mixin.py:104} INFO - [2022-03-18 04:00:14,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:14,399] {logging_mixin.py:104} INFO - [2022-03-18 04:00:14,394] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:00:14,403] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:14,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 04:00:44,841] {scheduler_job.py:182} INFO - Started process (PID=8130) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:44,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:00:44,849] {logging_mixin.py:104} INFO - [2022-03-18 04:00:44,849] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:44,884] {logging_mixin.py:104} INFO - [2022-03-18 04:00:44,879] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:00:44,888] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:00:44,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 04:01:15,097] {scheduler_job.py:182} INFO - Started process (PID=8162) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:15,102] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:01:15,105] {logging_mixin.py:104} INFO - [2022-03-18 04:01:15,105] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:15,138] {logging_mixin.py:104} INFO - [2022-03-18 04:01:15,133] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:01:15,142] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:15,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:01:45,396] {scheduler_job.py:182} INFO - Started process (PID=8194) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:45,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:01:45,403] {logging_mixin.py:104} INFO - [2022-03-18 04:01:45,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:45,436] {logging_mixin.py:104} INFO - [2022-03-18 04:01:45,431] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:01:45,440] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:01:45,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:02:15,731] {scheduler_job.py:182} INFO - Started process (PID=8226) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:15,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:02:15,739] {logging_mixin.py:104} INFO - [2022-03-18 04:02:15,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:15,770] {logging_mixin.py:104} INFO - [2022-03-18 04:02:15,766] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:02:15,774] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:15,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:02:46,080] {scheduler_job.py:182} INFO - Started process (PID=8258) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:46,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:02:46,088] {logging_mixin.py:104} INFO - [2022-03-18 04:02:46,088] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:46,122] {logging_mixin.py:104} INFO - [2022-03-18 04:02:46,118] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:02:46,126] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:02:46,154] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 04:03:16,938] {scheduler_job.py:182} INFO - Started process (PID=8290) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:16,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:03:16,945] {logging_mixin.py:104} INFO - [2022-03-18 04:03:16,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:16,979] {logging_mixin.py:104} INFO - [2022-03-18 04:03:16,974] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:03:16,983] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:17,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 04:03:47,249] {scheduler_job.py:182} INFO - Started process (PID=8320) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:47,253] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:03:47,256] {logging_mixin.py:104} INFO - [2022-03-18 04:03:47,256] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:47,291] {logging_mixin.py:104} INFO - [2022-03-18 04:03:47,286] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:03:47,295] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:03:47,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:04:18,166] {scheduler_job.py:182} INFO - Started process (PID=8345) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:18,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:04:18,173] {logging_mixin.py:104} INFO - [2022-03-18 04:04:18,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:18,207] {logging_mixin.py:104} INFO - [2022-03-18 04:04:18,203] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:04:18,212] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:18,239] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 04:04:48,683] {scheduler_job.py:182} INFO - Started process (PID=8372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:48,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:04:48,692] {logging_mixin.py:104} INFO - [2022-03-18 04:04:48,692] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:48,723] {logging_mixin.py:104} INFO - [2022-03-18 04:04:48,718] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:04:48,726] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:04:48,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 04:05:19,085] {scheduler_job.py:182} INFO - Started process (PID=8404) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:19,090] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:05:19,093] {logging_mixin.py:104} INFO - [2022-03-18 04:05:19,093] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:19,127] {logging_mixin.py:104} INFO - [2022-03-18 04:05:19,123] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:05:19,131] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:19,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.083 seconds
[2022-03-18 04:05:49,607] {scheduler_job.py:182} INFO - Started process (PID=8436) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:49,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:05:49,614] {logging_mixin.py:104} INFO - [2022-03-18 04:05:49,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:49,646] {logging_mixin.py:104} INFO - [2022-03-18 04:05:49,641] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:05:49,650] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:05:49,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:06:20,156] {scheduler_job.py:182} INFO - Started process (PID=8468) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:20,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:06:20,163] {logging_mixin.py:104} INFO - [2022-03-18 04:06:20,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:20,195] {logging_mixin.py:104} INFO - [2022-03-18 04:06:20,190] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:06:20,199] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:20,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.075 seconds
[2022-03-18 04:06:50,874] {scheduler_job.py:182} INFO - Started process (PID=8500) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:50,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:06:50,881] {logging_mixin.py:104} INFO - [2022-03-18 04:06:50,880] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:50,914] {logging_mixin.py:104} INFO - [2022-03-18 04:06:50,909] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:06:50,918] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:06:50,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:07:21,493] {scheduler_job.py:182} INFO - Started process (PID=8532) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:21,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:07:21,500] {logging_mixin.py:104} INFO - [2022-03-18 04:07:21,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:21,535] {logging_mixin.py:104} INFO - [2022-03-18 04:07:21,530] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:07:21,539] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:21,565] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 04:07:51,999] {scheduler_job.py:182} INFO - Started process (PID=8564) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:52,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:07:52,005] {logging_mixin.py:104} INFO - [2022-03-18 04:07:52,005] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:52,036] {logging_mixin.py:104} INFO - [2022-03-18 04:07:52,032] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:07:52,040] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:07:52,067] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 04:08:22,497] {scheduler_job.py:182} INFO - Started process (PID=8594) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:22,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:08:22,504] {logging_mixin.py:104} INFO - [2022-03-18 04:08:22,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:22,540] {logging_mixin.py:104} INFO - [2022-03-18 04:08:22,535] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:08:22,544] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:22,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 04:08:53,337] {scheduler_job.py:182} INFO - Started process (PID=8617) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:53,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:08:53,344] {logging_mixin.py:104} INFO - [2022-03-18 04:08:53,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:53,380] {logging_mixin.py:104} INFO - [2022-03-18 04:08:53,375] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:08:53,385] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:08:53,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 04:09:23,878] {scheduler_job.py:182} INFO - Started process (PID=8646) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:23,883] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:09:23,886] {logging_mixin.py:104} INFO - [2022-03-18 04:09:23,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:23,924] {logging_mixin.py:104} INFO - [2022-03-18 04:09:23,919] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:09:23,927] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:23,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 04:09:54,561] {scheduler_job.py:182} INFO - Started process (PID=8678) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:54,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:09:54,570] {logging_mixin.py:104} INFO - [2022-03-18 04:09:54,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:54,609] {logging_mixin.py:104} INFO - [2022-03-18 04:09:54,604] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:09:54,613] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:09:54,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.090 seconds
[2022-03-18 04:10:25,134] {scheduler_job.py:182} INFO - Started process (PID=8710) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:25,138] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:10:25,141] {logging_mixin.py:104} INFO - [2022-03-18 04:10:25,141] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:25,174] {logging_mixin.py:104} INFO - [2022-03-18 04:10:25,169] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:10:25,179] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:25,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:10:55,724] {scheduler_job.py:182} INFO - Started process (PID=8742) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:55,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:10:55,731] {logging_mixin.py:104} INFO - [2022-03-18 04:10:55,731] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:55,763] {logging_mixin.py:104} INFO - [2022-03-18 04:10:55,758] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:10:55,768] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:10:55,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 04:11:26,373] {scheduler_job.py:182} INFO - Started process (PID=8774) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:26,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:11:26,380] {logging_mixin.py:104} INFO - [2022-03-18 04:11:26,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:26,417] {logging_mixin.py:104} INFO - [2022-03-18 04:11:26,411] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:11:26,421] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:26,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 04:11:57,073] {scheduler_job.py:182} INFO - Started process (PID=8806) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:57,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:11:57,081] {logging_mixin.py:104} INFO - [2022-03-18 04:11:57,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:57,113] {logging_mixin.py:104} INFO - [2022-03-18 04:11:57,108] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:11:57,117] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:11:57,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:12:27,430] {scheduler_job.py:182} INFO - Started process (PID=8836) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:27,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:12:27,437] {logging_mixin.py:104} INFO - [2022-03-18 04:12:27,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:27,471] {logging_mixin.py:104} INFO - [2022-03-18 04:12:27,466] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:12:27,476] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:27,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 04:12:58,146] {scheduler_job.py:182} INFO - Started process (PID=8861) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:58,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:12:58,154] {logging_mixin.py:104} INFO - [2022-03-18 04:12:58,154] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:58,191] {logging_mixin.py:104} INFO - [2022-03-18 04:12:58,186] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:12:58,195] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:12:58,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.089 seconds
[2022-03-18 04:13:28,803] {scheduler_job.py:182} INFO - Started process (PID=8888) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:28,808] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:13:28,811] {logging_mixin.py:104} INFO - [2022-03-18 04:13:28,810] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:28,843] {logging_mixin.py:104} INFO - [2022-03-18 04:13:28,838] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:13:28,846] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:28,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.074 seconds
[2022-03-18 04:13:59,244] {scheduler_job.py:182} INFO - Started process (PID=8920) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:59,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:13:59,251] {logging_mixin.py:104} INFO - [2022-03-18 04:13:59,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:59,289] {logging_mixin.py:104} INFO - [2022-03-18 04:13:59,284] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:13:59,294] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:13:59,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.087 seconds
[2022-03-18 04:14:29,678] {scheduler_job.py:182} INFO - Started process (PID=8952) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:14:29,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:14:29,685] {logging_mixin.py:104} INFO - [2022-03-18 04:14:29,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:14:29,720] {logging_mixin.py:104} INFO - [2022-03-18 04:14:29,715] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:14:29,723] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:14:29,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 04:15:00,033] {scheduler_job.py:182} INFO - Started process (PID=8984) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:00,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:15:00,041] {logging_mixin.py:104} INFO - [2022-03-18 04:15:00,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:00,076] {logging_mixin.py:104} INFO - [2022-03-18 04:15:00,071] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:15:00,079] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:00,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 04:15:30,397] {scheduler_job.py:182} INFO - Started process (PID=9016) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:30,403] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:15:30,406] {logging_mixin.py:104} INFO - [2022-03-18 04:15:30,406] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:30,442] {logging_mixin.py:104} INFO - [2022-03-18 04:15:30,436] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 25, in <module>
    default_args=args,
NameError: name 'args' is not defined
[2022-03-18 04:15:30,446] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:15:30,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.085 seconds
[2022-03-18 04:16:00,762] {scheduler_job.py:182} INFO - Started process (PID=9048) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:00,767] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:16:00,771] {logging_mixin.py:104} INFO - [2022-03-18 04:16:00,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:00,819] {logging_mixin.py:104} INFO - [2022-03-18 04:16:00,814] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:16:00,824] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:00,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.097 seconds
[2022-03-18 04:16:31,012] {scheduler_job.py:182} INFO - Started process (PID=9080) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:31,018] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:16:31,021] {logging_mixin.py:104} INFO - [2022-03-18 04:16:31,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:31,056] {logging_mixin.py:104} INFO - [2022-03-18 04:16:31,051] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:16:31,061] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:16:31,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.086 seconds
[2022-03-18 04:17:01,306] {scheduler_job.py:182} INFO - Started process (PID=9110) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:01,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:17:01,311] {logging_mixin.py:104} INFO - [2022-03-18 04:17:01,311] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:01,347] {logging_mixin.py:104} INFO - [2022-03-18 04:17:01,342] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:17:01,351] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:01,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:17:31,976] {scheduler_job.py:182} INFO - Started process (PID=9134) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:31,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:17:31,983] {logging_mixin.py:104} INFO - [2022-03-18 04:17:31,982] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:32,018] {logging_mixin.py:104} INFO - [2022-03-18 04:17:32,012] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:17:32,022] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:17:32,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:18:02,231] {scheduler_job.py:182} INFO - Started process (PID=9162) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:02,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:18:02,238] {logging_mixin.py:104} INFO - [2022-03-18 04:18:02,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:02,272] {logging_mixin.py:104} INFO - [2022-03-18 04:18:02,267] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:18:02,276] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:02,302] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.079 seconds
[2022-03-18 04:18:32,569] {scheduler_job.py:182} INFO - Started process (PID=9194) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:32,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:18:32,577] {logging_mixin.py:104} INFO - [2022-03-18 04:18:32,576] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:32,613] {logging_mixin.py:104} INFO - [2022-03-18 04:18:32,608] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:18:32,617] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:18:32,642] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.082 seconds
[2022-03-18 04:19:02,819] {scheduler_job.py:182} INFO - Started process (PID=9226) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:02,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:19:02,826] {logging_mixin.py:104} INFO - [2022-03-18 04:19:02,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:02,857] {logging_mixin.py:104} INFO - [2022-03-18 04:19:02,852] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:19:02,862] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:02,888] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.076 seconds
[2022-03-18 04:19:33,241] {scheduler_job.py:182} INFO - Started process (PID=9258) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:33,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:19:33,251] {logging_mixin.py:104} INFO - [2022-03-18 04:19:33,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:33,293] {logging_mixin.py:104} INFO - [2022-03-18 04:19:33,287] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:19:33,297] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:19:33,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.094 seconds
[2022-03-18 04:20:03,672] {scheduler_job.py:182} INFO - Started process (PID=9290) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:03,678] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:20:03,681] {logging_mixin.py:104} INFO - [2022-03-18 04:20:03,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:03,714] {logging_mixin.py:104} INFO - [2022-03-18 04:20:03,710] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:20:03,718] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:03,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.080 seconds
[2022-03-18 04:20:34,009] {scheduler_job.py:182} INFO - Started process (PID=9322) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:34,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:20:34,015] {logging_mixin.py:104} INFO - [2022-03-18 04:20:34,015] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:34,048] {logging_mixin.py:104} INFO - [2022-03-18 04:20:34,043] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:20:34,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:20:34,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:21:04,303] {scheduler_job.py:182} INFO - Started process (PID=9352) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:04,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:21:04,310] {logging_mixin.py:104} INFO - [2022-03-18 04:21:04,310] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:04,343] {logging_mixin.py:104} INFO - [2022-03-18 04:21:04,338] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:21:04,347] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:04,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:21:34,965] {scheduler_job.py:182} INFO - Started process (PID=9377) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:34,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:21:34,972] {logging_mixin.py:104} INFO - [2022-03-18 04:21:34,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:35,006] {logging_mixin.py:104} INFO - [2022-03-18 04:21:35,001] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:21:35,010] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:21:35,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.077 seconds
[2022-03-18 04:22:05,744] {scheduler_job.py:182} INFO - Started process (PID=9406) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:05,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:22:05,751] {logging_mixin.py:104} INFO - [2022-03-18 04:22:05,751] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:05,784] {logging_mixin.py:104} INFO - [2022-03-18 04:22:05,779] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:22:05,788] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:05,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.078 seconds
[2022-03-18 04:22:36,011] {scheduler_job.py:182} INFO - Started process (PID=9436) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:36,018] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:22:36,021] {logging_mixin.py:104} INFO - [2022-03-18 04:22:36,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:36,057] {logging_mixin.py:104} INFO - [2022-03-18 04:22:36,052] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:22:36,060] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:22:36,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.084 seconds
[2022-03-18 04:23:06,360] {scheduler_job.py:182} INFO - Started process (PID=9468) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:06,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:23:06,369] {logging_mixin.py:104} INFO - [2022-03-18 04:23:06,368] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:06,402] {logging_mixin.py:104} INFO - [2022-03-18 04:23:06,398] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:23:06,406] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:06,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.081 seconds
[2022-03-18 04:23:37,126] {scheduler_job.py:182} INFO - Started process (PID=9500) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:37,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:23:37,133] {logging_mixin.py:104} INFO - [2022-03-18 04:23:37,133] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:37,187] {logging_mixin.py:104} INFO - [2022-03-18 04:23:37,181] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:23:37,190] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:23:37,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.103 seconds
[2022-03-18 04:24:07,707] {scheduler_job.py:182} INFO - Started process (PID=9532) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:07,714] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:24:07,717] {logging_mixin.py:104} INFO - [2022-03-18 04:24:07,716] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:07,755] {logging_mixin.py:104} INFO - [2022-03-18 04:24:07,750] {dagbag.py:305} ERROR - Failed to import: /opt/airflow/dags/spark_job.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 302, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job.py", line 30, in <module>
    start_date = airflow.utils.dates.days_ago(1)
NameError: name 'airflow' is not defined
[2022-03-18 04:24:07,760] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:07,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.093 seconds
[2022-03-18 04:24:38,066] {scheduler_job.py:182} INFO - Started process (PID=9564) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:38,071] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:24:38,075] {logging_mixin.py:104} INFO - [2022-03-18 04:24:38,074] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:38,156] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:24:38,221] {logging_mixin.py:104} INFO - [2022-03-18 04:24:38,221] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:24:38,254] {logging_mixin.py:104} INFO - [2022-03-18 04:24:38,254] {dag.py:1837} INFO - Creating ORM DAG for sparkoperator_demo
[2022-03-18 04:24:38,274] {logging_mixin.py:104} INFO - [2022-03-18 04:24:38,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:24:38,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.270 seconds
[2022-03-18 04:25:08,759] {scheduler_job.py:182} INFO - Started process (PID=9596) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:08,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:25:08,768] {logging_mixin.py:104} INFO - [2022-03-18 04:25:08,768] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:08,818] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:08,861] {logging_mixin.py:104} INFO - [2022-03-18 04:25:08,861] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:25:08,899] {logging_mixin.py:104} INFO - [2022-03-18 04:25:08,899] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:25:08,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 04:25:39,301] {scheduler_job.py:182} INFO - Started process (PID=9626) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:39,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:25:39,308] {logging_mixin.py:104} INFO - [2022-03-18 04:25:39,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:39,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:25:39,405] {logging_mixin.py:104} INFO - [2022-03-18 04:25:39,405] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:25:39,450] {logging_mixin.py:104} INFO - [2022-03-18 04:25:39,450] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:25:39,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 04:26:10,038] {scheduler_job.py:182} INFO - Started process (PID=9650) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:10,042] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:26:10,045] {logging_mixin.py:104} INFO - [2022-03-18 04:26:10,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:10,094] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:10,140] {logging_mixin.py:104} INFO - [2022-03-18 04:26:10,140] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:26:10,182] {logging_mixin.py:104} INFO - [2022-03-18 04:26:10,182] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:26:10,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 04:26:40,951] {scheduler_job.py:182} INFO - Started process (PID=9678) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:40,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:26:40,960] {logging_mixin.py:104} INFO - [2022-03-18 04:26:40,959] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:41,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:26:41,061] {logging_mixin.py:104} INFO - [2022-03-18 04:26:41,060] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:26:41,107] {logging_mixin.py:104} INFO - [2022-03-18 04:26:41,106] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:26:41,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 04:27:11,605] {scheduler_job.py:182} INFO - Started process (PID=9710) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:11,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:27:11,613] {logging_mixin.py:104} INFO - [2022-03-18 04:27:11,613] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:11,663] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:11,708] {logging_mixin.py:104} INFO - [2022-03-18 04:27:11,708] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:27:11,750] {logging_mixin.py:104} INFO - [2022-03-18 04:27:11,749] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:27:11,768] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 04:27:42,381] {scheduler_job.py:182} INFO - Started process (PID=9742) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:42,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:27:42,388] {logging_mixin.py:104} INFO - [2022-03-18 04:27:42,387] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:42,438] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:27:42,496] {logging_mixin.py:104} INFO - [2022-03-18 04:27:42,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:27:42,537] {logging_mixin.py:104} INFO - [2022-03-18 04:27:42,536] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:27:42,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 04:28:12,892] {scheduler_job.py:182} INFO - Started process (PID=9774) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:12,898] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:28:12,902] {logging_mixin.py:104} INFO - [2022-03-18 04:28:12,901] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:12,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:12,992] {logging_mixin.py:104} INFO - [2022-03-18 04:28:12,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:28:13,033] {logging_mixin.py:104} INFO - [2022-03-18 04:28:13,032] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:28:13,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 04:28:43,462] {scheduler_job.py:182} INFO - Started process (PID=9806) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:43,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:28:43,469] {logging_mixin.py:104} INFO - [2022-03-18 04:28:43,469] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:43,516] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:28:43,559] {logging_mixin.py:104} INFO - [2022-03-18 04:28:43,558] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:28:43,598] {logging_mixin.py:104} INFO - [2022-03-18 04:28:43,597] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:28:43,614] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 04:29:14,051] {scheduler_job.py:182} INFO - Started process (PID=9838) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:14,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:29:14,058] {logging_mixin.py:104} INFO - [2022-03-18 04:29:14,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:14,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:14,142] {logging_mixin.py:104} INFO - [2022-03-18 04:29:14,142] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:29:14,181] {logging_mixin.py:104} INFO - [2022-03-18 04:29:14,180] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:29:14,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-18 04:29:44,887] {scheduler_job.py:182} INFO - Started process (PID=9870) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:44,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:29:44,896] {logging_mixin.py:104} INFO - [2022-03-18 04:29:44,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:44,943] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:29:44,986] {logging_mixin.py:104} INFO - [2022-03-18 04:29:44,986] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:29:45,025] {logging_mixin.py:104} INFO - [2022-03-18 04:29:45,025] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:29:45,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 04:30:15,635] {scheduler_job.py:182} INFO - Started process (PID=9900) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:15,640] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:30:15,644] {logging_mixin.py:104} INFO - [2022-03-18 04:30:15,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:15,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:15,811] {logging_mixin.py:104} INFO - [2022-03-18 04:30:15,811] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:30:15,941] {logging_mixin.py:104} INFO - [2022-03-18 04:30:15,941] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:30:15,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.352 seconds
[2022-03-18 04:30:46,487] {scheduler_job.py:182} INFO - Started process (PID=9924) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:46,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:30:46,494] {logging_mixin.py:104} INFO - [2022-03-18 04:30:46,494] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:46,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:30:46,591] {logging_mixin.py:104} INFO - [2022-03-18 04:30:46,590] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:30:46,635] {logging_mixin.py:104} INFO - [2022-03-18 04:30:46,634] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:30:46,651] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 04:31:17,239] {scheduler_job.py:182} INFO - Started process (PID=9952) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:17,245] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:31:17,249] {logging_mixin.py:104} INFO - [2022-03-18 04:31:17,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:17,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:17,344] {logging_mixin.py:104} INFO - [2022-03-18 04:31:17,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:31:17,383] {logging_mixin.py:104} INFO - [2022-03-18 04:31:17,382] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:31:17,398] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 04:31:47,977] {scheduler_job.py:182} INFO - Started process (PID=9984) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:47,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:31:47,985] {logging_mixin.py:104} INFO - [2022-03-18 04:31:47,985] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:48,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:31:48,087] {logging_mixin.py:104} INFO - [2022-03-18 04:31:48,087] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:31:48,133] {logging_mixin.py:104} INFO - [2022-03-18 04:31:48,132] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:31:48,150] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 04:32:18,731] {scheduler_job.py:182} INFO - Started process (PID=10016) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:18,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:32:18,739] {logging_mixin.py:104} INFO - [2022-03-18 04:32:18,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:18,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:18,835] {logging_mixin.py:104} INFO - [2022-03-18 04:32:18,835] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:32:18,874] {logging_mixin.py:104} INFO - [2022-03-18 04:32:18,873] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:32:18,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 04:32:49,568] {scheduler_job.py:182} INFO - Started process (PID=10048) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:49,573] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:32:49,576] {logging_mixin.py:104} INFO - [2022-03-18 04:32:49,576] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:49,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:32:49,671] {logging_mixin.py:104} INFO - [2022-03-18 04:32:49,670] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:32:49,709] {logging_mixin.py:104} INFO - [2022-03-18 04:32:49,709] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:32:49,725] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 04:33:20,348] {scheduler_job.py:182} INFO - Started process (PID=10080) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:20,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:33:20,358] {logging_mixin.py:104} INFO - [2022-03-18 04:33:20,357] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:20,418] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:20,465] {logging_mixin.py:104} INFO - [2022-03-18 04:33:20,464] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:33:20,509] {logging_mixin.py:104} INFO - [2022-03-18 04:33:20,509] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:33:20,526] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-18 04:33:51,120] {scheduler_job.py:182} INFO - Started process (PID=10112) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:51,126] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:33:51,130] {logging_mixin.py:104} INFO - [2022-03-18 04:33:51,129] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:51,184] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:33:51,231] {logging_mixin.py:104} INFO - [2022-03-18 04:33:51,230] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:33:51,274] {logging_mixin.py:104} INFO - [2022-03-18 04:33:51,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:33:51,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 04:34:21,955] {scheduler_job.py:182} INFO - Started process (PID=10142) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:21,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:34:21,961] {logging_mixin.py:104} INFO - [2022-03-18 04:34:21,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:22,012] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:22,057] {logging_mixin.py:104} INFO - [2022-03-18 04:34:22,057] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:34:22,099] {logging_mixin.py:104} INFO - [2022-03-18 04:34:22,098] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:34:22,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 04:34:52,494] {scheduler_job.py:182} INFO - Started process (PID=10167) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:52,499] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:34:52,503] {logging_mixin.py:104} INFO - [2022-03-18 04:34:52,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:52,572] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:34:52,626] {logging_mixin.py:104} INFO - [2022-03-18 04:34:52,625] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:34:52,676] {logging_mixin.py:104} INFO - [2022-03-18 04:34:52,675] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:34:52,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.209 seconds
[2022-03-18 04:35:23,534] {scheduler_job.py:182} INFO - Started process (PID=10196) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:23,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:35:23,542] {logging_mixin.py:104} INFO - [2022-03-18 04:35:23,541] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:23,592] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:23,641] {logging_mixin.py:104} INFO - [2022-03-18 04:35:23,640] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:35:23,687] {logging_mixin.py:104} INFO - [2022-03-18 04:35:23,687] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:35:23,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 04:35:53,917] {scheduler_job.py:182} INFO - Started process (PID=10226) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:53,922] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:35:53,925] {logging_mixin.py:104} INFO - [2022-03-18 04:35:53,925] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:53,978] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:35:54,021] {logging_mixin.py:104} INFO - [2022-03-18 04:35:54,021] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:35:54,059] {logging_mixin.py:104} INFO - [2022-03-18 04:35:54,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:35:54,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 04:36:24,252] {scheduler_job.py:182} INFO - Started process (PID=10258) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:24,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:36:24,261] {logging_mixin.py:104} INFO - [2022-03-18 04:36:24,261] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:24,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:24,375] {logging_mixin.py:104} INFO - [2022-03-18 04:36:24,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:36:24,424] {logging_mixin.py:104} INFO - [2022-03-18 04:36:24,423] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:36:24,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.202 seconds
[2022-03-18 04:36:54,796] {scheduler_job.py:182} INFO - Started process (PID=10290) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:54,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:36:54,803] {logging_mixin.py:104} INFO - [2022-03-18 04:36:54,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:54,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:36:54,898] {logging_mixin.py:104} INFO - [2022-03-18 04:36:54,898] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:36:54,939] {logging_mixin.py:104} INFO - [2022-03-18 04:36:54,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:36:54,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 04:37:25,236] {scheduler_job.py:182} INFO - Started process (PID=10322) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:37:25,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:37:25,244] {logging_mixin.py:104} INFO - [2022-03-18 04:37:25,244] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:37:25,292] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:37:25,333] {logging_mixin.py:104} INFO - [2022-03-18 04:37:25,333] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:37:25,373] {logging_mixin.py:104} INFO - [2022-03-18 04:37:25,373] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:37:25,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 04:38:22,679] {scheduler_job.py:182} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:22,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:38:22,686] {logging_mixin.py:104} INFO - [2022-03-18 04:38:22,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:22,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:22,849] {logging_mixin.py:104} INFO - [2022-03-18 04:38:22,849] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:38:22,899] {logging_mixin.py:104} INFO - [2022-03-18 04:38:22,898] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:38:22,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.246 seconds
[2022-03-18 04:38:53,517] {scheduler_job.py:182} INFO - Started process (PID=246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:53,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:38:53,525] {logging_mixin.py:104} INFO - [2022-03-18 04:38:53,525] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:53,594] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:38:53,648] {logging_mixin.py:104} INFO - [2022-03-18 04:38:53,647] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:38:53,703] {logging_mixin.py:104} INFO - [2022-03-18 04:38:53,702] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:38:53,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.214 seconds
[2022-03-18 04:39:24,576] {scheduler_job.py:182} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:24,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:39:24,583] {logging_mixin.py:104} INFO - [2022-03-18 04:39:24,582] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:24,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:24,688] {logging_mixin.py:104} INFO - [2022-03-18 04:39:24,688] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:39:24,734] {logging_mixin.py:104} INFO - [2022-03-18 04:39:24,734] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:39:24,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-18 04:39:55,617] {scheduler_job.py:182} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:55,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:39:55,625] {logging_mixin.py:104} INFO - [2022-03-18 04:39:55,625] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:55,686] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:39:55,740] {logging_mixin.py:104} INFO - [2022-03-18 04:39:55,739] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:39:55,790] {logging_mixin.py:104} INFO - [2022-03-18 04:39:55,789] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:39:55,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.200 seconds
[2022-03-18 04:40:26,229] {scheduler_job.py:182} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:26,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:40:26,238] {logging_mixin.py:104} INFO - [2022-03-18 04:40:26,238] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:26,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:26,356] {logging_mixin.py:104} INFO - [2022-03-18 04:40:26,355] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:40:26,405] {logging_mixin.py:104} INFO - [2022-03-18 04:40:26,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to 2022-03-17 00:00:00+00:00
[2022-03-18 04:40:26,425] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.203 seconds
[2022-03-18 04:40:57,570] {scheduler_job.py:182} INFO - Started process (PID=532) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:57,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:40:57,586] {logging_mixin.py:104} INFO - [2022-03-18 04:40:57,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:57,686] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:40:57,781] {logging_mixin.py:104} INFO - [2022-03-18 04:40:57,781] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:40:57,894] {logging_mixin.py:104} INFO - [2022-03-18 04:40:57,893] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:40:57,941] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.380 seconds
[2022-03-18 04:41:38,202] {scheduler_job.py:182} INFO - Started process (PID=802) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:41:38,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:41:38,225] {logging_mixin.py:104} INFO - [2022-03-18 04:41:38,225] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:41:38,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:41:38,544] {logging_mixin.py:104} INFO - [2022-03-18 04:41:38,543] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:41:38,668] {logging_mixin.py:104} INFO - [2022-03-18 04:41:38,668] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:41:38,727] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.537 seconds
[2022-03-18 04:42:27,861] {scheduler_job.py:182} INFO - Started process (PID=1138) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:42:27,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:42:27,915] {logging_mixin.py:104} INFO - [2022-03-18 04:42:27,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:42:28,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:42:28,525] {logging_mixin.py:104} INFO - [2022-03-18 04:42:28,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:42:28,686] {logging_mixin.py:104} INFO - [2022-03-18 04:42:28,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:42:28,725] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.886 seconds
[2022-03-18 04:43:27,833] {scheduler_job.py:182} INFO - Started process (PID=1507) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:43:27,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:43:27,863] {logging_mixin.py:104} INFO - [2022-03-18 04:43:27,862] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:43:28,540] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:43:29,357] {logging_mixin.py:104} INFO - [2022-03-18 04:43:29,356] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:43:30,028] {logging_mixin.py:104} INFO - [2022-03-18 04:43:30,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:43:30,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 2.486 seconds
[2022-03-18 04:44:18,769] {scheduler_job.py:182} INFO - Started process (PID=1842) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:18,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:44:18,807] {logging_mixin.py:104} INFO - [2022-03-18 04:44:18,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:19,027] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:19,595] {logging_mixin.py:104} INFO - [2022-03-18 04:44:19,594] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:44:20,046] {logging_mixin.py:104} INFO - [2022-03-18 04:44:20,046] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:44:20,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 1.552 seconds
[2022-03-18 04:44:50,722] {scheduler_job.py:182} INFO - Started process (PID=2020) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:50,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:44:50,736] {logging_mixin.py:104} INFO - [2022-03-18 04:44:50,736] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:50,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:44:50,871] {logging_mixin.py:104} INFO - [2022-03-18 04:44:50,870] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:44:50,930] {logging_mixin.py:104} INFO - [2022-03-18 04:44:50,929] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:44:50,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.243 seconds
[2022-03-18 04:45:21,120] {scheduler_job.py:182} INFO - Started process (PID=2185) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:21,125] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:45:21,128] {logging_mixin.py:104} INFO - [2022-03-18 04:45:21,127] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:21,198] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:21,255] {logging_mixin.py:104} INFO - [2022-03-18 04:45:21,255] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:45:21,300] {logging_mixin.py:104} INFO - [2022-03-18 04:45:21,300] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:45:21,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.206 seconds
[2022-03-18 04:45:51,958] {scheduler_job.py:182} INFO - Started process (PID=2237) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:51,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:45:51,966] {logging_mixin.py:104} INFO - [2022-03-18 04:45:51,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:52,017] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:45:52,062] {logging_mixin.py:104} INFO - [2022-03-18 04:45:52,061] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:45:52,101] {logging_mixin.py:104} INFO - [2022-03-18 04:45:52,101] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:45:52,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 04:46:22,586] {scheduler_job.py:182} INFO - Started process (PID=2272) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:22,591] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:46:22,594] {logging_mixin.py:104} INFO - [2022-03-18 04:46:22,594] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:22,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:22,694] {logging_mixin.py:104} INFO - [2022-03-18 04:46:22,694] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:46:22,735] {logging_mixin.py:104} INFO - [2022-03-18 04:46:22,735] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:46:22,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 04:46:53,331] {scheduler_job.py:182} INFO - Started process (PID=2304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:53,335] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:46:53,338] {logging_mixin.py:104} INFO - [2022-03-18 04:46:53,338] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:53,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:46:53,429] {logging_mixin.py:104} INFO - [2022-03-18 04:46:53,429] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:46:53,468] {logging_mixin.py:104} INFO - [2022-03-18 04:46:53,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:46:53,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 04:47:23,973] {scheduler_job.py:182} INFO - Started process (PID=2336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:23,980] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:47:23,984] {logging_mixin.py:104} INFO - [2022-03-18 04:47:23,983] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:24,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:24,075] {logging_mixin.py:104} INFO - [2022-03-18 04:47:24,075] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:47:24,114] {logging_mixin.py:104} INFO - [2022-03-18 04:47:24,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:47:24,129] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 04:47:54,497] {scheduler_job.py:182} INFO - Started process (PID=2368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:54,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:47:54,503] {logging_mixin.py:104} INFO - [2022-03-18 04:47:54,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:54,549] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:47:54,592] {logging_mixin.py:104} INFO - [2022-03-18 04:47:54,592] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:47:54,631] {logging_mixin.py:104} INFO - [2022-03-18 04:47:54,631] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:47:54,647] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 04:48:25,081] {scheduler_job.py:182} INFO - Started process (PID=2396) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:25,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:48:25,092] {logging_mixin.py:104} INFO - [2022-03-18 04:48:25,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:25,149] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:25,198] {logging_mixin.py:104} INFO - [2022-03-18 04:48:25,197] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:48:25,241] {logging_mixin.py:104} INFO - [2022-03-18 04:48:25,240] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:48:25,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 04:48:55,494] {scheduler_job.py:182} INFO - Started process (PID=2422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:55,499] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:48:55,502] {logging_mixin.py:104} INFO - [2022-03-18 04:48:55,502] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:55,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:48:55,605] {logging_mixin.py:104} INFO - [2022-03-18 04:48:55,605] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:48:55,651] {logging_mixin.py:104} INFO - [2022-03-18 04:48:55,651] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:48:55,672] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 04:49:25,773] {scheduler_job.py:182} INFO - Started process (PID=2450) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:25,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:49:25,780] {logging_mixin.py:104} INFO - [2022-03-18 04:49:25,780] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:25,827] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:25,868] {logging_mixin.py:104} INFO - [2022-03-18 04:49:25,868] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:49:25,908] {logging_mixin.py:104} INFO - [2022-03-18 04:49:25,908] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:49:25,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 04:49:56,182] {scheduler_job.py:182} INFO - Started process (PID=2482) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:56,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:49:56,191] {logging_mixin.py:104} INFO - [2022-03-18 04:49:56,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:56,245] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:49:56,296] {logging_mixin.py:104} INFO - [2022-03-18 04:49:56,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:49:56,340] {logging_mixin.py:104} INFO - [2022-03-18 04:49:56,340] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:49:56,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 04:50:26,626] {scheduler_job.py:182} INFO - Started process (PID=2514) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:26,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:50:26,635] {logging_mixin.py:104} INFO - [2022-03-18 04:50:26,634] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:26,685] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:26,730] {logging_mixin.py:104} INFO - [2022-03-18 04:50:26,729] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:50:26,769] {logging_mixin.py:104} INFO - [2022-03-18 04:50:26,769] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:50:26,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 04:50:56,901] {scheduler_job.py:182} INFO - Started process (PID=2546) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:56,908] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:50:56,911] {logging_mixin.py:104} INFO - [2022-03-18 04:50:56,911] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:56,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:50:57,011] {logging_mixin.py:104} INFO - [2022-03-18 04:50:57,011] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:50:57,053] {logging_mixin.py:104} INFO - [2022-03-18 04:50:57,052] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:50:57,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 04:51:27,251] {scheduler_job.py:182} INFO - Started process (PID=2578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:27,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:51:27,258] {logging_mixin.py:104} INFO - [2022-03-18 04:51:27,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:27,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:27,348] {logging_mixin.py:104} INFO - [2022-03-18 04:51:27,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:51:27,386] {logging_mixin.py:104} INFO - [2022-03-18 04:51:27,386] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:51:27,401] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 04:51:57,562] {scheduler_job.py:182} INFO - Started process (PID=2610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:57,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:51:57,569] {logging_mixin.py:104} INFO - [2022-03-18 04:51:57,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:57,617] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:51:57,659] {logging_mixin.py:104} INFO - [2022-03-18 04:51:57,659] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:51:57,698] {logging_mixin.py:104} INFO - [2022-03-18 04:51:57,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:51:57,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 04:52:27,925] {scheduler_job.py:182} INFO - Started process (PID=2640) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:27,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:52:27,932] {logging_mixin.py:104} INFO - [2022-03-18 04:52:27,931] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:27,981] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:28,025] {logging_mixin.py:104} INFO - [2022-03-18 04:52:28,025] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:52:28,068] {logging_mixin.py:104} INFO - [2022-03-18 04:52:28,068] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:52:28,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 04:52:58,576] {scheduler_job.py:182} INFO - Started process (PID=2665) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:58,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:52:58,584] {logging_mixin.py:104} INFO - [2022-03-18 04:52:58,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:58,632] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:52:58,678] {logging_mixin.py:104} INFO - [2022-03-18 04:52:58,677] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:52:58,722] {logging_mixin.py:104} INFO - [2022-03-18 04:52:58,721] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:52:58,740] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 04:53:29,135] {scheduler_job.py:182} INFO - Started process (PID=2692) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:29,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:53:29,144] {logging_mixin.py:104} INFO - [2022-03-18 04:53:29,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:29,190] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:29,231] {logging_mixin.py:104} INFO - [2022-03-18 04:53:29,230] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:53:29,268] {logging_mixin.py:104} INFO - [2022-03-18 04:53:29,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:53:29,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 04:53:59,501] {scheduler_job.py:182} INFO - Started process (PID=2724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:59,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:53:59,510] {logging_mixin.py:104} INFO - [2022-03-18 04:53:59,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:59,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:53:59,601] {logging_mixin.py:104} INFO - [2022-03-18 04:53:59,600] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:53:59,640] {logging_mixin.py:104} INFO - [2022-03-18 04:53:59,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:53:59,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 04:54:30,286] {scheduler_job.py:182} INFO - Started process (PID=2756) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:54:30,292] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:54:30,295] {logging_mixin.py:104} INFO - [2022-03-18 04:54:30,295] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:54:30,343] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:54:30,385] {logging_mixin.py:104} INFO - [2022-03-18 04:54:30,384] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:54:30,423] {logging_mixin.py:104} INFO - [2022-03-18 04:54:30,422] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:54:30,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 04:55:00,687] {scheduler_job.py:182} INFO - Started process (PID=2788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:00,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:55:00,695] {logging_mixin.py:104} INFO - [2022-03-18 04:55:00,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:00,747] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:00,794] {logging_mixin.py:104} INFO - [2022-03-18 04:55:00,793] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:55:00,836] {logging_mixin.py:104} INFO - [2022-03-18 04:55:00,835] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:55:00,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 04:55:31,286] {scheduler_job.py:182} INFO - Started process (PID=2820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:31,292] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:55:31,295] {logging_mixin.py:104} INFO - [2022-03-18 04:55:31,294] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:31,343] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:55:31,384] {logging_mixin.py:104} INFO - [2022-03-18 04:55:31,384] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:55:31,423] {logging_mixin.py:104} INFO - [2022-03-18 04:55:31,422] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:55:31,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 04:56:01,718] {scheduler_job.py:182} INFO - Started process (PID=2852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:01,724] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:56:01,727] {logging_mixin.py:104} INFO - [2022-03-18 04:56:01,727] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:01,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:01,819] {logging_mixin.py:104} INFO - [2022-03-18 04:56:01,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:56:01,859] {logging_mixin.py:104} INFO - [2022-03-18 04:56:01,858] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:56:01,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 04:56:32,094] {scheduler_job.py:182} INFO - Started process (PID=2884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:32,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:56:32,103] {logging_mixin.py:104} INFO - [2022-03-18 04:56:32,103] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:32,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:56:32,204] {logging_mixin.py:104} INFO - [2022-03-18 04:56:32,204] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:56:32,246] {logging_mixin.py:104} INFO - [2022-03-18 04:56:32,246] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:56:32,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 04:57:02,644] {scheduler_job.py:182} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:02,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:57:02,650] {logging_mixin.py:104} INFO - [2022-03-18 04:57:02,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:02,699] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:02,744] {logging_mixin.py:104} INFO - [2022-03-18 04:57:02,744] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:57:02,788] {logging_mixin.py:104} INFO - [2022-03-18 04:57:02,787] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:57:02,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 04:57:32,924] {scheduler_job.py:182} INFO - Started process (PID=2939) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:32,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:57:32,933] {logging_mixin.py:104} INFO - [2022-03-18 04:57:32,932] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:32,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:57:33,053] {logging_mixin.py:104} INFO - [2022-03-18 04:57:33,053] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:57:33,099] {logging_mixin.py:104} INFO - [2022-03-18 04:57:33,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:57:33,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.201 seconds
[2022-03-18 04:58:03,479] {scheduler_job.py:182} INFO - Started process (PID=2966) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:03,484] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:58:03,487] {logging_mixin.py:104} INFO - [2022-03-18 04:58:03,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:03,541] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:03,589] {logging_mixin.py:104} INFO - [2022-03-18 04:58:03,588] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:58:03,634] {logging_mixin.py:104} INFO - [2022-03-18 04:58:03,633] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:58:03,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 04:58:33,934] {scheduler_job.py:182} INFO - Started process (PID=2998) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:33,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:58:33,942] {logging_mixin.py:104} INFO - [2022-03-18 04:58:33,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:33,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:58:34,045] {logging_mixin.py:104} INFO - [2022-03-18 04:58:34,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:58:34,086] {logging_mixin.py:104} INFO - [2022-03-18 04:58:34,086] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:58:34,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 04:59:04,434] {scheduler_job.py:182} INFO - Started process (PID=3030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:04,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:59:04,443] {logging_mixin.py:104} INFO - [2022-03-18 04:59:04,442] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:04,493] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:04,549] {logging_mixin.py:104} INFO - [2022-03-18 04:59:04,548] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:59:04,595] {logging_mixin.py:104} INFO - [2022-03-18 04:59:04,595] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:59:04,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-18 04:59:35,161] {scheduler_job.py:182} INFO - Started process (PID=3062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:35,165] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 04:59:35,168] {logging_mixin.py:104} INFO - [2022-03-18 04:59:35,167] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:35,215] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 04:59:35,262] {logging_mixin.py:104} INFO - [2022-03-18 04:59:35,261] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 04:59:35,304] {logging_mixin.py:104} INFO - [2022-03-18 04:59:35,304] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 04:59:35,320] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 05:00:05,643] {scheduler_job.py:182} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:05,646] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:00:05,649] {logging_mixin.py:104} INFO - [2022-03-18 05:00:05,649] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:05,694] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:05,736] {logging_mixin.py:104} INFO - [2022-03-18 05:00:05,736] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:00:05,778] {logging_mixin.py:104} INFO - [2022-03-18 05:00:05,777] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:00:05,797] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 05:00:36,180] {scheduler_job.py:182} INFO - Started process (PID=3126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:36,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:00:36,190] {logging_mixin.py:104} INFO - [2022-03-18 05:00:36,189] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:36,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:00:36,295] {logging_mixin.py:104} INFO - [2022-03-18 05:00:36,294] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:00:36,336] {logging_mixin.py:104} INFO - [2022-03-18 05:00:36,336] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:00:36,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 05:01:06,945] {scheduler_job.py:182} INFO - Started process (PID=3158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:06,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:01:06,951] {logging_mixin.py:104} INFO - [2022-03-18 05:01:06,951] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:06,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:07,039] {logging_mixin.py:104} INFO - [2022-03-18 05:01:07,038] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:01:07,078] {logging_mixin.py:104} INFO - [2022-03-18 05:01:07,077] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:01:07,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 05:01:37,827] {scheduler_job.py:182} INFO - Started process (PID=3185) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:37,831] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:01:37,834] {logging_mixin.py:104} INFO - [2022-03-18 05:01:37,833] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:37,885] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:01:37,933] {logging_mixin.py:104} INFO - [2022-03-18 05:01:37,933] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:01:37,983] {logging_mixin.py:104} INFO - [2022-03-18 05:01:37,982] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:01:38,004] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 05:02:08,607] {scheduler_job.py:182} INFO - Started process (PID=3208) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:08,615] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:02:08,618] {logging_mixin.py:104} INFO - [2022-03-18 05:02:08,618] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:08,672] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:08,722] {logging_mixin.py:104} INFO - [2022-03-18 05:02:08,722] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:02:08,767] {logging_mixin.py:104} INFO - [2022-03-18 05:02:08,767] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:02:08,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 05:02:38,963] {scheduler_job.py:182} INFO - Started process (PID=3240) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:38,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:02:38,970] {logging_mixin.py:104} INFO - [2022-03-18 05:02:38,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:39,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:02:39,057] {logging_mixin.py:104} INFO - [2022-03-18 05:02:39,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:02:39,096] {logging_mixin.py:104} INFO - [2022-03-18 05:02:39,095] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:02:39,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 05:03:09,179] {scheduler_job.py:182} INFO - Started process (PID=3272) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:09,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:03:09,186] {logging_mixin.py:104} INFO - [2022-03-18 05:03:09,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:09,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:09,274] {logging_mixin.py:104} INFO - [2022-03-18 05:03:09,274] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:03:09,312] {logging_mixin.py:104} INFO - [2022-03-18 05:03:09,312] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:03:09,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 05:03:39,566] {scheduler_job.py:182} INFO - Started process (PID=3304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:39,572] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:03:39,575] {logging_mixin.py:104} INFO - [2022-03-18 05:03:39,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:39,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:03:39,683] {logging_mixin.py:104} INFO - [2022-03-18 05:03:39,683] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:03:39,724] {logging_mixin.py:104} INFO - [2022-03-18 05:03:39,723] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:03:39,740] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 05:04:10,520] {scheduler_job.py:182} INFO - Started process (PID=3336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:10,525] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:04:10,528] {logging_mixin.py:104} INFO - [2022-03-18 05:04:10,528] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:10,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:10,613] {logging_mixin.py:104} INFO - [2022-03-18 05:04:10,613] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:04:10,652] {logging_mixin.py:104} INFO - [2022-03-18 05:04:10,651] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:04:10,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 05:04:41,289] {scheduler_job.py:182} INFO - Started process (PID=3368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:41,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:04:41,297] {logging_mixin.py:104} INFO - [2022-03-18 05:04:41,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:41,343] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:04:41,383] {logging_mixin.py:104} INFO - [2022-03-18 05:04:41,382] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:04:41,423] {logging_mixin.py:104} INFO - [2022-03-18 05:04:41,422] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:04:41,438] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 05:05:11,938] {scheduler_job.py:182} INFO - Started process (PID=3400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:11,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:05:11,947] {logging_mixin.py:104} INFO - [2022-03-18 05:05:11,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:11,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:12,038] {logging_mixin.py:104} INFO - [2022-03-18 05:05:12,038] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:05:12,080] {logging_mixin.py:104} INFO - [2022-03-18 05:05:12,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:05:12,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 05:05:42,458] {scheduler_job.py:182} INFO - Started process (PID=3430) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:42,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:05:42,464] {logging_mixin.py:104} INFO - [2022-03-18 05:05:42,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:42,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:05:42,572] {logging_mixin.py:104} INFO - [2022-03-18 05:05:42,572] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:05:42,616] {logging_mixin.py:104} INFO - [2022-03-18 05:05:42,616] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:05:42,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 05:06:13,277] {scheduler_job.py:182} INFO - Started process (PID=3455) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:13,281] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:06:13,283] {logging_mixin.py:104} INFO - [2022-03-18 05:06:13,283] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:13,331] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:13,376] {logging_mixin.py:104} INFO - [2022-03-18 05:06:13,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:06:13,419] {logging_mixin.py:104} INFO - [2022-03-18 05:06:13,418] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:06:13,436] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 05:06:44,038] {scheduler_job.py:182} INFO - Started process (PID=3482) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:44,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:06:44,046] {logging_mixin.py:104} INFO - [2022-03-18 05:06:44,045] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:44,095] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:06:44,141] {logging_mixin.py:104} INFO - [2022-03-18 05:06:44,140] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:06:44,181] {logging_mixin.py:104} INFO - [2022-03-18 05:06:44,181] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:06:44,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 05:07:14,411] {scheduler_job.py:182} INFO - Started process (PID=3514) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:14,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:07:14,420] {logging_mixin.py:104} INFO - [2022-03-18 05:07:14,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:14,471] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:14,514] {logging_mixin.py:104} INFO - [2022-03-18 05:07:14,514] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:07:14,553] {logging_mixin.py:104} INFO - [2022-03-18 05:07:14,553] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:07:14,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 05:07:44,707] {scheduler_job.py:182} INFO - Started process (PID=3546) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:44,712] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:07:44,717] {logging_mixin.py:104} INFO - [2022-03-18 05:07:44,717] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:44,762] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:07:44,805] {logging_mixin.py:104} INFO - [2022-03-18 05:07:44,805] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:07:44,846] {logging_mixin.py:104} INFO - [2022-03-18 05:07:44,846] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:07:44,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 05:08:15,078] {scheduler_job.py:182} INFO - Started process (PID=3578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:15,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:08:15,086] {logging_mixin.py:104} INFO - [2022-03-18 05:08:15,085] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:15,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:15,179] {logging_mixin.py:104} INFO - [2022-03-18 05:08:15,179] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:08:15,218] {logging_mixin.py:104} INFO - [2022-03-18 05:08:15,218] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:08:15,234] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 05:08:45,501] {scheduler_job.py:182} INFO - Started process (PID=3610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:45,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:08:45,507] {logging_mixin.py:104} INFO - [2022-03-18 05:08:45,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:45,555] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:08:45,598] {logging_mixin.py:104} INFO - [2022-03-18 05:08:45,598] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:08:45,637] {logging_mixin.py:104} INFO - [2022-03-18 05:08:45,637] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:08:45,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 05:09:15,817] {scheduler_job.py:182} INFO - Started process (PID=3642) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:15,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:09:15,825] {logging_mixin.py:104} INFO - [2022-03-18 05:09:15,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:15,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:15,912] {logging_mixin.py:104} INFO - [2022-03-18 05:09:15,911] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:09:15,951] {logging_mixin.py:104} INFO - [2022-03-18 05:09:15,951] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:09:15,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 05:09:46,067] {scheduler_job.py:182} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:46,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:09:46,075] {logging_mixin.py:104} INFO - [2022-03-18 05:09:46,074] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:46,121] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:09:46,163] {logging_mixin.py:104} INFO - [2022-03-18 05:09:46,163] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:09:46,203] {logging_mixin.py:104} INFO - [2022-03-18 05:09:46,203] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:09:46,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 05:10:16,360] {scheduler_job.py:182} INFO - Started process (PID=3704) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:16,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:10:16,367] {logging_mixin.py:104} INFO - [2022-03-18 05:10:16,366] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:16,418] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:16,464] {logging_mixin.py:104} INFO - [2022-03-18 05:10:16,463] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:10:16,507] {logging_mixin.py:104} INFO - [2022-03-18 05:10:16,507] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:10:16,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 05:10:47,313] {scheduler_job.py:182} INFO - Started process (PID=3729) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:47,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:10:47,321] {logging_mixin.py:104} INFO - [2022-03-18 05:10:47,320] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:47,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:10:47,418] {logging_mixin.py:104} INFO - [2022-03-18 05:10:47,417] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:10:47,463] {logging_mixin.py:104} INFO - [2022-03-18 05:10:47,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:10:47,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 05:11:17,955] {scheduler_job.py:182} INFO - Started process (PID=3756) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:17,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:11:17,962] {logging_mixin.py:104} INFO - [2022-03-18 05:11:17,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:18,012] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:18,058] {logging_mixin.py:104} INFO - [2022-03-18 05:11:18,057] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:11:18,100] {logging_mixin.py:104} INFO - [2022-03-18 05:11:18,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:11:18,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 05:11:48,551] {scheduler_job.py:182} INFO - Started process (PID=3788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:48,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:11:48,559] {logging_mixin.py:104} INFO - [2022-03-18 05:11:48,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:48,611] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:11:48,658] {logging_mixin.py:104} INFO - [2022-03-18 05:11:48,658] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:11:48,698] {logging_mixin.py:104} INFO - [2022-03-18 05:11:48,697] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:11:48,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 05:12:19,021] {scheduler_job.py:182} INFO - Started process (PID=3820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:19,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:12:19,028] {logging_mixin.py:104} INFO - [2022-03-18 05:12:19,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:19,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:19,119] {logging_mixin.py:104} INFO - [2022-03-18 05:12:19,119] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:12:19,157] {logging_mixin.py:104} INFO - [2022-03-18 05:12:19,156] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:12:19,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 05:12:49,261] {scheduler_job.py:182} INFO - Started process (PID=3852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:49,266] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:12:49,269] {logging_mixin.py:104} INFO - [2022-03-18 05:12:49,268] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:49,318] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:12:49,364] {logging_mixin.py:104} INFO - [2022-03-18 05:12:49,364] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:12:49,403] {logging_mixin.py:104} INFO - [2022-03-18 05:12:49,403] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:12:49,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 05:13:19,555] {scheduler_job.py:182} INFO - Started process (PID=3884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:19,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:13:19,562] {logging_mixin.py:104} INFO - [2022-03-18 05:13:19,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:19,613] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:19,663] {logging_mixin.py:104} INFO - [2022-03-18 05:13:19,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:13:19,703] {logging_mixin.py:104} INFO - [2022-03-18 05:13:19,702] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:13:19,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 05:13:50,071] {scheduler_job.py:182} INFO - Started process (PID=3916) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:50,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:13:50,079] {logging_mixin.py:104} INFO - [2022-03-18 05:13:50,079] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:50,127] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:13:50,173] {logging_mixin.py:104} INFO - [2022-03-18 05:13:50,173] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:13:50,215] {logging_mixin.py:104} INFO - [2022-03-18 05:13:50,215] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:13:50,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 05:14:20,422] {scheduler_job.py:182} INFO - Started process (PID=3948) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:20,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:14:20,429] {logging_mixin.py:104} INFO - [2022-03-18 05:14:20,429] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:20,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:20,520] {logging_mixin.py:104} INFO - [2022-03-18 05:14:20,520] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:14:20,560] {logging_mixin.py:104} INFO - [2022-03-18 05:14:20,560] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:14:20,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 05:14:50,994] {scheduler_job.py:182} INFO - Started process (PID=3978) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:50,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:14:51,001] {logging_mixin.py:104} INFO - [2022-03-18 05:14:51,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:51,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:14:51,098] {logging_mixin.py:104} INFO - [2022-03-18 05:14:51,097] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:14:51,147] {logging_mixin.py:104} INFO - [2022-03-18 05:14:51,146] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:14:51,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 05:15:21,734] {scheduler_job.py:182} INFO - Started process (PID=4002) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:21,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:15:21,740] {logging_mixin.py:104} INFO - [2022-03-18 05:15:21,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:21,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:21,834] {logging_mixin.py:104} INFO - [2022-03-18 05:15:21,834] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:15:21,876] {logging_mixin.py:104} INFO - [2022-03-18 05:15:21,876] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:15:21,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 05:15:52,244] {scheduler_job.py:182} INFO - Started process (PID=4030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:52,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:15:52,253] {logging_mixin.py:104} INFO - [2022-03-18 05:15:52,252] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:52,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:15:52,356] {logging_mixin.py:104} INFO - [2022-03-18 05:15:52,355] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:15:52,396] {logging_mixin.py:104} INFO - [2022-03-18 05:15:52,396] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:15:52,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 05:16:22,946] {scheduler_job.py:182} INFO - Started process (PID=4062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:22,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:16:22,956] {logging_mixin.py:104} INFO - [2022-03-18 05:16:22,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:23,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:23,046] {logging_mixin.py:104} INFO - [2022-03-18 05:16:23,046] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:16:23,085] {logging_mixin.py:104} INFO - [2022-03-18 05:16:23,084] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:16:23,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 05:16:53,519] {scheduler_job.py:182} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:53,524] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:16:53,528] {logging_mixin.py:104} INFO - [2022-03-18 05:16:53,528] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:53,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:16:53,619] {logging_mixin.py:104} INFO - [2022-03-18 05:16:53,619] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:16:53,661] {logging_mixin.py:104} INFO - [2022-03-18 05:16:53,661] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:16:53,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 05:17:24,060] {scheduler_job.py:182} INFO - Started process (PID=4126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:24,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:17:24,067] {logging_mixin.py:104} INFO - [2022-03-18 05:17:24,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:24,115] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:24,157] {logging_mixin.py:104} INFO - [2022-03-18 05:17:24,157] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:17:24,195] {logging_mixin.py:104} INFO - [2022-03-18 05:17:24,194] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:17:24,212] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 05:17:54,786] {scheduler_job.py:182} INFO - Started process (PID=4158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:54,791] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:17:54,794] {logging_mixin.py:104} INFO - [2022-03-18 05:17:54,794] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:54,847] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:17:54,893] {logging_mixin.py:104} INFO - [2022-03-18 05:17:54,893] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:17:54,933] {logging_mixin.py:104} INFO - [2022-03-18 05:17:54,933] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:17:54,949] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 05:18:25,486] {scheduler_job.py:182} INFO - Started process (PID=4190) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:25,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:18:25,494] {logging_mixin.py:104} INFO - [2022-03-18 05:18:25,494] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:25,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:25,585] {logging_mixin.py:104} INFO - [2022-03-18 05:18:25,584] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:18:25,624] {logging_mixin.py:104} INFO - [2022-03-18 05:18:25,623] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:18:25,639] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 05:18:56,153] {scheduler_job.py:182} INFO - Started process (PID=4220) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:56,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:18:56,159] {logging_mixin.py:104} INFO - [2022-03-18 05:18:56,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:56,211] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:18:56,261] {logging_mixin.py:104} INFO - [2022-03-18 05:18:56,261] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:18:56,302] {logging_mixin.py:104} INFO - [2022-03-18 05:18:56,301] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:18:56,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 05:19:27,986] {scheduler_job.py:182} INFO - Started process (PID=4252) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:27,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:19:27,994] {logging_mixin.py:104} INFO - [2022-03-18 05:19:27,993] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:28,045] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:28,091] {logging_mixin.py:104} INFO - [2022-03-18 05:19:28,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:19:28,136] {logging_mixin.py:104} INFO - [2022-03-18 05:19:28,136] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:19:28,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 05:19:58,379] {scheduler_job.py:182} INFO - Started process (PID=4272) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:58,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:19:58,385] {logging_mixin.py:104} INFO - [2022-03-18 05:19:58,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:58,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:19:58,484] {logging_mixin.py:104} INFO - [2022-03-18 05:19:58,483] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:19:58,526] {logging_mixin.py:104} INFO - [2022-03-18 05:19:58,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:19:58,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 05:20:28,679] {scheduler_job.py:182} INFO - Started process (PID=4304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:28,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:20:28,686] {logging_mixin.py:104} INFO - [2022-03-18 05:20:28,686] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:28,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:28,783] {logging_mixin.py:104} INFO - [2022-03-18 05:20:28,782] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:20:28,822] {logging_mixin.py:104} INFO - [2022-03-18 05:20:28,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:20:28,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 05:20:59,137] {scheduler_job.py:182} INFO - Started process (PID=4336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:59,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:20:59,144] {logging_mixin.py:104} INFO - [2022-03-18 05:20:59,144] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:59,209] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:20:59,254] {logging_mixin.py:104} INFO - [2022-03-18 05:20:59,253] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:20:59,292] {logging_mixin.py:104} INFO - [2022-03-18 05:20:59,291] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:20:59,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 05:21:29,747] {scheduler_job.py:182} INFO - Started process (PID=4368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:21:29,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:21:29,758] {logging_mixin.py:104} INFO - [2022-03-18 05:21:29,757] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:21:29,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:21:29,856] {logging_mixin.py:104} INFO - [2022-03-18 05:21:29,855] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:21:29,895] {logging_mixin.py:104} INFO - [2022-03-18 05:21:29,895] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:21:29,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 05:22:00,342] {scheduler_job.py:182} INFO - Started process (PID=4400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:00,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:22:00,349] {logging_mixin.py:104} INFO - [2022-03-18 05:22:00,348] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:00,396] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:00,438] {logging_mixin.py:104} INFO - [2022-03-18 05:22:00,438] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:22:00,476] {logging_mixin.py:104} INFO - [2022-03-18 05:22:00,476] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:22:00,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 05:22:31,110] {scheduler_job.py:182} INFO - Started process (PID=4432) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:31,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:22:31,119] {logging_mixin.py:104} INFO - [2022-03-18 05:22:31,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:31,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:22:31,211] {logging_mixin.py:104} INFO - [2022-03-18 05:22:31,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:22:31,249] {logging_mixin.py:104} INFO - [2022-03-18 05:22:31,248] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:22:31,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 05:23:01,755] {scheduler_job.py:182} INFO - Started process (PID=4464) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:01,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:23:01,763] {logging_mixin.py:104} INFO - [2022-03-18 05:23:01,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:01,811] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:01,853] {logging_mixin.py:104} INFO - [2022-03-18 05:23:01,852] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:23:01,891] {logging_mixin.py:104} INFO - [2022-03-18 05:23:01,891] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:23:01,908] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 05:23:32,455] {scheduler_job.py:182} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:32,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:23:32,463] {logging_mixin.py:104} INFO - [2022-03-18 05:23:32,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:32,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:23:32,559] {logging_mixin.py:104} INFO - [2022-03-18 05:23:32,559] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:23:32,601] {logging_mixin.py:104} INFO - [2022-03-18 05:23:32,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:23:32,629] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 05:24:03,353] {scheduler_job.py:182} INFO - Started process (PID=4519) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:03,358] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:24:03,361] {logging_mixin.py:104} INFO - [2022-03-18 05:24:03,361] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:03,411] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:03,460] {logging_mixin.py:104} INFO - [2022-03-18 05:24:03,460] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:24:03,505] {logging_mixin.py:104} INFO - [2022-03-18 05:24:03,504] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:24:03,523] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 05:24:33,881] {scheduler_job.py:182} INFO - Started process (PID=4546) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:33,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:24:33,890] {logging_mixin.py:104} INFO - [2022-03-18 05:24:33,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:33,939] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:24:33,981] {logging_mixin.py:104} INFO - [2022-03-18 05:24:33,981] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:24:34,021] {logging_mixin.py:104} INFO - [2022-03-18 05:24:34,020] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:24:34,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 05:25:04,253] {scheduler_job.py:182} INFO - Started process (PID=4578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:04,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:25:04,262] {logging_mixin.py:104} INFO - [2022-03-18 05:25:04,262] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:04,311] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:04,353] {logging_mixin.py:104} INFO - [2022-03-18 05:25:04,353] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:25:04,395] {logging_mixin.py:104} INFO - [2022-03-18 05:25:04,394] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:25:04,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 05:25:34,766] {scheduler_job.py:182} INFO - Started process (PID=4610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:34,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:25:34,772] {logging_mixin.py:104} INFO - [2022-03-18 05:25:34,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:34,820] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:25:34,864] {logging_mixin.py:104} INFO - [2022-03-18 05:25:34,864] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:25:34,904] {logging_mixin.py:104} INFO - [2022-03-18 05:25:34,903] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:25:34,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 05:26:05,475] {scheduler_job.py:182} INFO - Started process (PID=4642) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:05,481] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:26:05,484] {logging_mixin.py:104} INFO - [2022-03-18 05:26:05,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:05,530] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:05,572] {logging_mixin.py:104} INFO - [2022-03-18 05:26:05,571] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:26:05,610] {logging_mixin.py:104} INFO - [2022-03-18 05:26:05,609] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:26:05,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 05:26:35,959] {scheduler_job.py:182} INFO - Started process (PID=4674) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:35,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:26:35,966] {logging_mixin.py:104} INFO - [2022-03-18 05:26:35,965] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:36,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:26:36,054] {logging_mixin.py:104} INFO - [2022-03-18 05:26:36,054] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:26:36,093] {logging_mixin.py:104} INFO - [2022-03-18 05:26:36,093] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:26:36,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 05:27:06,504] {scheduler_job.py:182} INFO - Started process (PID=4706) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:06,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:27:06,510] {logging_mixin.py:104} INFO - [2022-03-18 05:27:06,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:06,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:06,598] {logging_mixin.py:104} INFO - [2022-03-18 05:27:06,597] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:27:06,636] {logging_mixin.py:104} INFO - [2022-03-18 05:27:06,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:27:06,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 05:27:37,163] {scheduler_job.py:182} INFO - Started process (PID=4738) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:37,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:27:37,170] {logging_mixin.py:104} INFO - [2022-03-18 05:27:37,169] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:37,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:27:37,260] {logging_mixin.py:104} INFO - [2022-03-18 05:27:37,260] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:27:37,300] {logging_mixin.py:104} INFO - [2022-03-18 05:27:37,300] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:27:37,319] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 05:28:07,660] {scheduler_job.py:182} INFO - Started process (PID=4768) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:07,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:28:07,667] {logging_mixin.py:104} INFO - [2022-03-18 05:28:07,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:07,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:07,760] {logging_mixin.py:104} INFO - [2022-03-18 05:28:07,760] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:28:07,803] {logging_mixin.py:104} INFO - [2022-03-18 05:28:07,802] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:28:07,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 05:28:38,502] {scheduler_job.py:182} INFO - Started process (PID=4788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:38,507] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:28:38,510] {logging_mixin.py:104} INFO - [2022-03-18 05:28:38,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:38,564] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:28:38,613] {logging_mixin.py:104} INFO - [2022-03-18 05:28:38,613] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:28:38,656] {logging_mixin.py:104} INFO - [2022-03-18 05:28:38,656] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:28:38,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 05:29:09,057] {scheduler_job.py:182} INFO - Started process (PID=4820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 05:29:09,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 05:29:09,066] {logging_mixin.py:104} INFO - [2022-03-18 05:29:09,065] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 05:29:09,112] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 05:29:09,155] {logging_mixin.py:104} INFO - [2022-03-18 05:29:09,154] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 05:29:09,193] {logging_mixin.py:104} INFO - [2022-03-18 05:29:09,193] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 05:29:09,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:15:35,604] {scheduler_job.py:182} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:15:35,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:15:35,613] {logging_mixin.py:104} INFO - [2022-03-18 13:15:35,612] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:15:35,689] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:15:35,746] {logging_mixin.py:104} INFO - [2022-03-18 13:15:35,746] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:15:35,799] {logging_mixin.py:104} INFO - [2022-03-18 13:15:35,799] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:15:35,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.220 seconds
[2022-03-18 13:16:05,962] {scheduler_job.py:182} INFO - Started process (PID=247) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:05,966] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:16:05,969] {logging_mixin.py:104} INFO - [2022-03-18 13:16:05,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:06,034] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:06,090] {logging_mixin.py:104} INFO - [2022-03-18 13:16:06,090] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:16:06,145] {logging_mixin.py:104} INFO - [2022-03-18 13:16:06,145] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:16:06,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.210 seconds
[2022-03-18 13:16:37,359] {scheduler_job.py:182} INFO - Started process (PID=286) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:37,363] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:16:37,365] {logging_mixin.py:104} INFO - [2022-03-18 13:16:37,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:37,425] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:16:37,473] {logging_mixin.py:104} INFO - [2022-03-18 13:16:37,473] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:16:37,519] {logging_mixin.py:104} INFO - [2022-03-18 13:16:37,518] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:16:37,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 13:17:07,646] {scheduler_job.py:182} INFO - Started process (PID=317) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:07,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:17:07,654] {logging_mixin.py:104} INFO - [2022-03-18 13:17:07,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:07,727] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:07,784] {logging_mixin.py:104} INFO - [2022-03-18 13:17:07,783] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:17:07,836] {logging_mixin.py:104} INFO - [2022-03-18 13:17:07,835] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:17:07,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.216 seconds
[2022-03-18 13:17:38,511] {scheduler_job.py:182} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:38,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:17:38,520] {logging_mixin.py:104} INFO - [2022-03-18 13:17:38,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:38,585] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:17:38,657] {logging_mixin.py:104} INFO - [2022-03-18 13:17:38,657] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:17:38,711] {logging_mixin.py:104} INFO - [2022-03-18 13:17:38,710] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:17:38,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.226 seconds
[2022-03-18 13:18:09,563] {scheduler_job.py:182} INFO - Started process (PID=382) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:09,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:18:09,570] {logging_mixin.py:104} INFO - [2022-03-18 13:18:09,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:09,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:09,668] {logging_mixin.py:104} INFO - [2022-03-18 13:18:09,667] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:18:09,706] {logging_mixin.py:104} INFO - [2022-03-18 13:18:09,706] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:18:09,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:18:42,552] {scheduler_job.py:182} INFO - Started process (PID=414) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:42,557] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:18:42,559] {logging_mixin.py:104} INFO - [2022-03-18 13:18:42,559] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:42,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:18:42,658] {logging_mixin.py:104} INFO - [2022-03-18 13:18:42,658] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:18:42,706] {logging_mixin.py:104} INFO - [2022-03-18 13:18:42,705] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:18:42,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 13:19:13,404] {scheduler_job.py:182} INFO - Started process (PID=432) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:13,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:19:13,411] {logging_mixin.py:104} INFO - [2022-03-18 13:19:13,410] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:13,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:13,507] {logging_mixin.py:104} INFO - [2022-03-18 13:19:13,507] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:19:13,552] {logging_mixin.py:104} INFO - [2022-03-18 13:19:13,551] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:19:13,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 13:19:44,644] {scheduler_job.py:182} INFO - Started process (PID=464) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:44,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:19:44,651] {logging_mixin.py:104} INFO - [2022-03-18 13:19:44,651] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:44,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:19:44,747] {logging_mixin.py:104} INFO - [2022-03-18 13:19:44,747] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:19:44,788] {logging_mixin.py:104} INFO - [2022-03-18 13:19:44,788] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:19:44,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 13:20:15,475] {scheduler_job.py:182} INFO - Started process (PID=496) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:15,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:20:15,481] {logging_mixin.py:104} INFO - [2022-03-18 13:20:15,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:15,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:15,575] {logging_mixin.py:104} INFO - [2022-03-18 13:20:15,575] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:20:15,614] {logging_mixin.py:104} INFO - [2022-03-18 13:20:15,614] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:20:15,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 13:20:46,418] {scheduler_job.py:182} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:46,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:20:46,424] {logging_mixin.py:104} INFO - [2022-03-18 13:20:46,424] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:46,479] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:20:46,523] {logging_mixin.py:104} INFO - [2022-03-18 13:20:46,523] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:20:46,565] {logging_mixin.py:104} INFO - [2022-03-18 13:20:46,564] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:20:46,580] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 13:21:17,155] {scheduler_job.py:182} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:17,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:21:17,162] {logging_mixin.py:104} INFO - [2022-03-18 13:21:17,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:17,214] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:17,256] {logging_mixin.py:104} INFO - [2022-03-18 13:21:17,256] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:21:17,295] {logging_mixin.py:104} INFO - [2022-03-18 13:21:17,294] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:21:17,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 13:21:47,831] {scheduler_job.py:182} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:47,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:21:47,838] {logging_mixin.py:104} INFO - [2022-03-18 13:21:47,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:47,893] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:21:47,937] {logging_mixin.py:104} INFO - [2022-03-18 13:21:47,937] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:21:47,981] {logging_mixin.py:104} INFO - [2022-03-18 13:21:47,980] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:21:48,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 13:22:18,410] {scheduler_job.py:182} INFO - Started process (PID=660) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:18,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:22:18,446] {logging_mixin.py:104} INFO - [2022-03-18 13:22:18,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:18,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:18,564] {logging_mixin.py:104} INFO - [2022-03-18 13:22:18,564] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:22:18,611] {logging_mixin.py:104} INFO - [2022-03-18 13:22:18,611] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:22:18,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.226 seconds
[2022-03-18 13:22:49,310] {scheduler_job.py:182} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:49,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:22:49,317] {logging_mixin.py:104} INFO - [2022-03-18 13:22:49,317] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:49,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:22:49,419] {logging_mixin.py:104} INFO - [2022-03-18 13:22:49,419] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:22:49,459] {logging_mixin.py:104} INFO - [2022-03-18 13:22:49,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:22:49,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 13:23:20,340] {scheduler_job.py:182} INFO - Started process (PID=724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:20,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:23:20,347] {logging_mixin.py:104} INFO - [2022-03-18 13:23:20,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:20,395] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:20,440] {logging_mixin.py:104} INFO - [2022-03-18 13:23:20,439] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:23:20,484] {logging_mixin.py:104} INFO - [2022-03-18 13:23:20,483] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:23:20,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 13:23:50,852] {scheduler_job.py:182} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:50,856] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:23:50,862] {logging_mixin.py:104} INFO - [2022-03-18 13:23:50,861] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:50,913] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:23:50,960] {logging_mixin.py:104} INFO - [2022-03-18 13:23:50,959] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:23:51,003] {logging_mixin.py:104} INFO - [2022-03-18 13:23:51,003] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:23:51,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 13:24:21,449] {scheduler_job.py:182} INFO - Started process (PID=774) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:21,454] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:24:21,457] {logging_mixin.py:104} INFO - [2022-03-18 13:24:21,456] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:21,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:21,552] {logging_mixin.py:104} INFO - [2022-03-18 13:24:21,552] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:24:21,595] {logging_mixin.py:104} INFO - [2022-03-18 13:24:21,595] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:24:21,612] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 13:24:52,082] {scheduler_job.py:182} INFO - Started process (PID=806) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:52,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:24:52,091] {logging_mixin.py:104} INFO - [2022-03-18 13:24:52,091] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:52,141] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:24:52,184] {logging_mixin.py:104} INFO - [2022-03-18 13:24:52,183] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:24:52,222] {logging_mixin.py:104} INFO - [2022-03-18 13:24:52,222] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:24:52,237] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 13:25:22,756] {scheduler_job.py:182} INFO - Started process (PID=838) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:22,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:25:22,764] {logging_mixin.py:104} INFO - [2022-03-18 13:25:22,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:22,815] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:22,858] {logging_mixin.py:104} INFO - [2022-03-18 13:25:22,858] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:25:22,897] {logging_mixin.py:104} INFO - [2022-03-18 13:25:22,897] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:25:22,913] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 13:25:53,499] {scheduler_job.py:182} INFO - Started process (PID=870) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:53,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:25:53,505] {logging_mixin.py:104} INFO - [2022-03-18 13:25:53,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:53,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:25:53,600] {logging_mixin.py:104} INFO - [2022-03-18 13:25:53,599] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:25:53,638] {logging_mixin.py:104} INFO - [2022-03-18 13:25:53,638] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:25:53,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:26:24,321] {scheduler_job.py:182} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:24,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:26:24,327] {logging_mixin.py:104} INFO - [2022-03-18 13:26:24,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:24,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:24,420] {logging_mixin.py:104} INFO - [2022-03-18 13:26:24,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:26:24,459] {logging_mixin.py:104} INFO - [2022-03-18 13:26:24,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:26:24,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:26:55,251] {scheduler_job.py:182} INFO - Started process (PID=934) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:55,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:26:55,260] {logging_mixin.py:104} INFO - [2022-03-18 13:26:55,259] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:55,308] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:26:55,351] {logging_mixin.py:104} INFO - [2022-03-18 13:26:55,350] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:26:55,391] {logging_mixin.py:104} INFO - [2022-03-18 13:26:55,391] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:26:55,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 13:27:25,909] {scheduler_job.py:182} INFO - Started process (PID=966) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:25,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:27:25,915] {logging_mixin.py:104} INFO - [2022-03-18 13:27:25,915] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:25,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:26,018] {logging_mixin.py:104} INFO - [2022-03-18 13:27:26,017] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:27:26,059] {logging_mixin.py:104} INFO - [2022-03-18 13:27:26,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:27:26,073] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 13:27:56,958] {scheduler_job.py:182} INFO - Started process (PID=985) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:56,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:27:56,964] {logging_mixin.py:104} INFO - [2022-03-18 13:27:56,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:57,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:27:57,057] {logging_mixin.py:104} INFO - [2022-03-18 13:27:57,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:27:57,100] {logging_mixin.py:104} INFO - [2022-03-18 13:27:57,099] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:27:57,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:28:28,105] {scheduler_job.py:182} INFO - Started process (PID=1016) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:28,109] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:28:28,112] {logging_mixin.py:104} INFO - [2022-03-18 13:28:28,111] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:28,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:28,205] {logging_mixin.py:104} INFO - [2022-03-18 13:28:28,204] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:28:28,243] {logging_mixin.py:104} INFO - [2022-03-18 13:28:28,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:28:28,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:28:58,775] {scheduler_job.py:182} INFO - Started process (PID=1048) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:58,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:28:58,781] {logging_mixin.py:104} INFO - [2022-03-18 13:28:58,781] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:58,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:28:58,879] {logging_mixin.py:104} INFO - [2022-03-18 13:28:58,879] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:28:58,918] {logging_mixin.py:104} INFO - [2022-03-18 13:28:58,918] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:28:58,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 13:29:29,505] {scheduler_job.py:182} INFO - Started process (PID=1080) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:29:29,523] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:29:29,558] {logging_mixin.py:104} INFO - [2022-03-18 13:29:29,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:29:29,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:29:29,662] {logging_mixin.py:104} INFO - [2022-03-18 13:29:29,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:29:29,706] {logging_mixin.py:104} INFO - [2022-03-18 13:29:29,706] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:29:29,723] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.226 seconds
[2022-03-18 13:29:59,927] {scheduler_job.py:182} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:29:59,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:29:59,934] {logging_mixin.py:104} INFO - [2022-03-18 13:29:59,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:29:59,986] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:30:00,031] {logging_mixin.py:104} INFO - [2022-03-18 13:30:00,031] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:30:00,072] {logging_mixin.py:104} INFO - [2022-03-18 13:30:00,072] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:30:00,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 13:30:30,280] {scheduler_job.py:182} INFO - Started process (PID=1144) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:30:30,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:30:30,286] {logging_mixin.py:104} INFO - [2022-03-18 13:30:30,286] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:30:30,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:30:30,383] {logging_mixin.py:104} INFO - [2022-03-18 13:30:30,383] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:30:30,422] {logging_mixin.py:104} INFO - [2022-03-18 13:30:30,421] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:30:30,438] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 13:31:00,707] {scheduler_job.py:182} INFO - Started process (PID=1176) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:00,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:31:00,713] {logging_mixin.py:104} INFO - [2022-03-18 13:31:00,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:00,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:00,808] {logging_mixin.py:104} INFO - [2022-03-18 13:31:00,807] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:31:00,847] {logging_mixin.py:104} INFO - [2022-03-18 13:31:00,847] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:31:00,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:31:31,089] {scheduler_job.py:182} INFO - Started process (PID=1208) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:31,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:31:31,096] {logging_mixin.py:104} INFO - [2022-03-18 13:31:31,095] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:31,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:31:31,191] {logging_mixin.py:104} INFO - [2022-03-18 13:31:31,190] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:31:31,229] {logging_mixin.py:104} INFO - [2022-03-18 13:31:31,228] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:31:31,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:32:01,959] {scheduler_job.py:182} INFO - Started process (PID=1240) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:01,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:32:01,966] {logging_mixin.py:104} INFO - [2022-03-18 13:32:01,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:02,017] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:02,066] {logging_mixin.py:104} INFO - [2022-03-18 13:32:02,065] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:32:02,110] {logging_mixin.py:104} INFO - [2022-03-18 13:32:02,109] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:32:02,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 13:32:33,168] {scheduler_job.py:182} INFO - Started process (PID=1265) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:33,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:32:33,174] {logging_mixin.py:104} INFO - [2022-03-18 13:32:33,174] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:33,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:32:33,271] {logging_mixin.py:104} INFO - [2022-03-18 13:32:33,270] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:32:33,316] {logging_mixin.py:104} INFO - [2022-03-18 13:32:33,315] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:32:33,333] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 13:33:04,173] {scheduler_job.py:182} INFO - Started process (PID=1296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:04,178] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:33:04,180] {logging_mixin.py:104} INFO - [2022-03-18 13:33:04,180] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:04,230] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:04,275] {logging_mixin.py:104} INFO - [2022-03-18 13:33:04,274] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:33:04,316] {logging_mixin.py:104} INFO - [2022-03-18 13:33:04,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:33:04,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:33:34,391] {scheduler_job.py:182} INFO - Started process (PID=1321) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:34,396] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:33:34,398] {logging_mixin.py:104} INFO - [2022-03-18 13:33:34,398] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:34,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:33:34,496] {logging_mixin.py:104} INFO - [2022-03-18 13:33:34,496] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:33:34,544] {logging_mixin.py:104} INFO - [2022-03-18 13:33:34,544] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:33:34,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 13:34:04,780] {scheduler_job.py:182} INFO - Started process (PID=1353) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:04,784] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:34:04,788] {logging_mixin.py:104} INFO - [2022-03-18 13:34:04,787] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:04,837] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:04,884] {logging_mixin.py:104} INFO - [2022-03-18 13:34:04,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:34:04,927] {logging_mixin.py:104} INFO - [2022-03-18 13:34:04,927] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:34:04,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 13:34:35,217] {scheduler_job.py:182} INFO - Started process (PID=1385) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:35,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:34:35,223] {logging_mixin.py:104} INFO - [2022-03-18 13:34:35,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:35,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:34:35,326] {logging_mixin.py:104} INFO - [2022-03-18 13:34:35,326] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:34:35,369] {logging_mixin.py:104} INFO - [2022-03-18 13:34:35,369] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:34:35,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 13:35:05,511] {scheduler_job.py:182} INFO - Started process (PID=1408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:05,517] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:35:05,520] {logging_mixin.py:104} INFO - [2022-03-18 13:35:05,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:05,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:05,617] {logging_mixin.py:104} INFO - [2022-03-18 13:35:05,616] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:35:05,658] {logging_mixin.py:104} INFO - [2022-03-18 13:35:05,657] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:35:05,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 13:35:35,837] {scheduler_job.py:182} INFO - Started process (PID=1440) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:35,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:35:35,845] {logging_mixin.py:104} INFO - [2022-03-18 13:35:35,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:35,900] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:35:35,947] {logging_mixin.py:104} INFO - [2022-03-18 13:35:35,947] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:35:35,990] {logging_mixin.py:104} INFO - [2022-03-18 13:35:35,990] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:35:36,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 13:36:06,503] {scheduler_job.py:182} INFO - Started process (PID=1482) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:06,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:36:06,511] {logging_mixin.py:104} INFO - [2022-03-18 13:36:06,511] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:06,561] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:06,602] {logging_mixin.py:104} INFO - [2022-03-18 13:36:06,602] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:36:06,640] {logging_mixin.py:104} INFO - [2022-03-18 13:36:06,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:36:06,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:36:37,192] {scheduler_job.py:182} INFO - Started process (PID=1514) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:37,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:36:37,199] {logging_mixin.py:104} INFO - [2022-03-18 13:36:37,199] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:37,251] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:36:37,299] {logging_mixin.py:104} INFO - [2022-03-18 13:36:37,298] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:36:37,342] {logging_mixin.py:104} INFO - [2022-03-18 13:36:37,342] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:36:37,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 13:37:07,497] {scheduler_job.py:182} INFO - Started process (PID=1539) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:07,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:37:07,503] {logging_mixin.py:104} INFO - [2022-03-18 13:37:07,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:07,554] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:07,601] {logging_mixin.py:104} INFO - [2022-03-18 13:37:07,600] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:37:07,643] {logging_mixin.py:104} INFO - [2022-03-18 13:37:07,642] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:37:07,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 13:37:38,095] {scheduler_job.py:182} INFO - Started process (PID=1564) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:38,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:37:38,102] {logging_mixin.py:104} INFO - [2022-03-18 13:37:38,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:38,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:37:38,196] {logging_mixin.py:104} INFO - [2022-03-18 13:37:38,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:37:38,238] {logging_mixin.py:104} INFO - [2022-03-18 13:37:38,238] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:37:38,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 13:38:08,502] {scheduler_job.py:182} INFO - Started process (PID=1596) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:08,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:38:08,509] {logging_mixin.py:104} INFO - [2022-03-18 13:38:08,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:08,595] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:08,638] {logging_mixin.py:104} INFO - [2022-03-18 13:38:08,638] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:38:08,676] {logging_mixin.py:104} INFO - [2022-03-18 13:38:08,676] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:38:08,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-18 13:38:38,874] {scheduler_job.py:182} INFO - Started process (PID=1628) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:38,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:38:38,880] {logging_mixin.py:104} INFO - [2022-03-18 13:38:38,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:38,932] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:38:38,974] {logging_mixin.py:104} INFO - [2022-03-18 13:38:38,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:38:39,012] {logging_mixin.py:104} INFO - [2022-03-18 13:38:39,012] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:38:39,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:39:09,135] {scheduler_job.py:182} INFO - Started process (PID=1659) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:09,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:39:09,142] {logging_mixin.py:104} INFO - [2022-03-18 13:39:09,141] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:09,193] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:09,243] {logging_mixin.py:104} INFO - [2022-03-18 13:39:09,243] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:39:09,289] {logging_mixin.py:104} INFO - [2022-03-18 13:39:09,288] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:39:09,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 13:39:39,889] {scheduler_job.py:182} INFO - Started process (PID=1692) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:39,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:39:39,896] {logging_mixin.py:104} INFO - [2022-03-18 13:39:39,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:39,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:39:39,990] {logging_mixin.py:104} INFO - [2022-03-18 13:39:39,990] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:39:40,029] {logging_mixin.py:104} INFO - [2022-03-18 13:39:40,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:39:40,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:40:10,309] {scheduler_job.py:182} INFO - Started process (PID=1724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:10,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:40:10,316] {logging_mixin.py:104} INFO - [2022-03-18 13:40:10,316] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:10,370] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:10,415] {logging_mixin.py:104} INFO - [2022-03-18 13:40:10,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:40:10,453] {logging_mixin.py:104} INFO - [2022-03-18 13:40:10,453] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:40:10,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 13:40:40,981] {scheduler_job.py:182} INFO - Started process (PID=1756) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:40,985] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:40:40,988] {logging_mixin.py:104} INFO - [2022-03-18 13:40:40,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:41,040] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:40:41,084] {logging_mixin.py:104} INFO - [2022-03-18 13:40:41,084] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:40:41,123] {logging_mixin.py:104} INFO - [2022-03-18 13:40:41,122] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:40:41,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 13:41:11,684] {scheduler_job.py:182} INFO - Started process (PID=1788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:11,688] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:41:11,691] {logging_mixin.py:104} INFO - [2022-03-18 13:41:11,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:11,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:11,786] {logging_mixin.py:104} INFO - [2022-03-18 13:41:11,786] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:41:11,828] {logging_mixin.py:104} INFO - [2022-03-18 13:41:11,827] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:41:11,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 13:41:42,497] {scheduler_job.py:182} INFO - Started process (PID=1813) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:42,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:41:42,504] {logging_mixin.py:104} INFO - [2022-03-18 13:41:42,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:42,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:41:42,599] {logging_mixin.py:104} INFO - [2022-03-18 13:41:42,599] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:41:42,641] {logging_mixin.py:104} INFO - [2022-03-18 13:41:42,640] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:41:42,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:42:12,870] {scheduler_job.py:182} INFO - Started process (PID=1840) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:12,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:42:12,878] {logging_mixin.py:104} INFO - [2022-03-18 13:42:12,878] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:12,929] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:12,974] {logging_mixin.py:104} INFO - [2022-03-18 13:42:12,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:42:13,014] {logging_mixin.py:104} INFO - [2022-03-18 13:42:13,014] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:42:13,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 13:42:43,238] {scheduler_job.py:182} INFO - Started process (PID=1870) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:43,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:42:43,244] {logging_mixin.py:104} INFO - [2022-03-18 13:42:43,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:43,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:42:43,337] {logging_mixin.py:104} INFO - [2022-03-18 13:42:43,337] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:42:43,375] {logging_mixin.py:104} INFO - [2022-03-18 13:42:43,375] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:42:43,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 13:43:14,079] {scheduler_job.py:182} INFO - Started process (PID=1902) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:14,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:43:14,086] {logging_mixin.py:104} INFO - [2022-03-18 13:43:14,085] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:14,137] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:14,178] {logging_mixin.py:104} INFO - [2022-03-18 13:43:14,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:43:14,216] {logging_mixin.py:104} INFO - [2022-03-18 13:43:14,216] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:43:14,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 13:43:44,370] {scheduler_job.py:182} INFO - Started process (PID=1933) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:44,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:43:44,377] {logging_mixin.py:104} INFO - [2022-03-18 13:43:44,376] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:44,425] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:43:44,475] {logging_mixin.py:104} INFO - [2022-03-18 13:43:44,475] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:43:44,521] {logging_mixin.py:104} INFO - [2022-03-18 13:43:44,520] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:43:44,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 13:44:14,662] {scheduler_job.py:182} INFO - Started process (PID=1956) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:14,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:44:14,669] {logging_mixin.py:104} INFO - [2022-03-18 13:44:14,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:14,722] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:14,768] {logging_mixin.py:104} INFO - [2022-03-18 13:44:14,767] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:44:14,808] {logging_mixin.py:104} INFO - [2022-03-18 13:44:14,808] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:44:14,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 13:44:45,810] {scheduler_job.py:182} INFO - Started process (PID=1998) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:45,814] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:44:45,817] {logging_mixin.py:104} INFO - [2022-03-18 13:44:45,817] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:45,868] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:44:45,911] {logging_mixin.py:104} INFO - [2022-03-18 13:44:45,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:44:45,952] {logging_mixin.py:104} INFO - [2022-03-18 13:44:45,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:44:45,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 13:45:16,034] {scheduler_job.py:182} INFO - Started process (PID=2029) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:16,039] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:45:16,043] {logging_mixin.py:104} INFO - [2022-03-18 13:45:16,042] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:16,091] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:16,138] {logging_mixin.py:104} INFO - [2022-03-18 13:45:16,138] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:45:16,183] {logging_mixin.py:104} INFO - [2022-03-18 13:45:16,182] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:45:16,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 13:45:46,948] {scheduler_job.py:182} INFO - Started process (PID=2062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:46,952] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:45:46,955] {logging_mixin.py:104} INFO - [2022-03-18 13:45:46,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:47,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:45:47,051] {logging_mixin.py:104} INFO - [2022-03-18 13:45:47,050] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:45:47,094] {logging_mixin.py:104} INFO - [2022-03-18 13:45:47,094] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:45:47,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 13:46:17,259] {scheduler_job.py:182} INFO - Started process (PID=2087) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:17,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:46:17,265] {logging_mixin.py:104} INFO - [2022-03-18 13:46:17,265] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:17,315] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:17,360] {logging_mixin.py:104} INFO - [2022-03-18 13:46:17,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:46:17,402] {logging_mixin.py:104} INFO - [2022-03-18 13:46:17,401] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:46:17,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:46:48,187] {scheduler_job.py:182} INFO - Started process (PID=2118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:48,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:46:48,195] {logging_mixin.py:104} INFO - [2022-03-18 13:46:48,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:48,243] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:46:48,289] {logging_mixin.py:104} INFO - [2022-03-18 13:46:48,289] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:46:48,333] {logging_mixin.py:104} INFO - [2022-03-18 13:46:48,332] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:46:48,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 13:47:18,784] {scheduler_job.py:182} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:18,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:47:18,791] {logging_mixin.py:104} INFO - [2022-03-18 13:47:18,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:18,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:18,885] {logging_mixin.py:104} INFO - [2022-03-18 13:47:18,884] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:47:18,926] {logging_mixin.py:104} INFO - [2022-03-18 13:47:18,926] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:47:18,942] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:47:49,563] {scheduler_job.py:182} INFO - Started process (PID=2176) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:49,569] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:47:49,572] {logging_mixin.py:104} INFO - [2022-03-18 13:47:49,572] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:49,632] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:47:49,682] {logging_mixin.py:104} INFO - [2022-03-18 13:47:49,681] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:47:49,728] {logging_mixin.py:104} INFO - [2022-03-18 13:47:49,728] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:47:49,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-18 13:48:20,155] {scheduler_job.py:182} INFO - Started process (PID=2208) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:20,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:48:20,162] {logging_mixin.py:104} INFO - [2022-03-18 13:48:20,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:20,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:20,266] {logging_mixin.py:104} INFO - [2022-03-18 13:48:20,266] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:48:20,311] {logging_mixin.py:104} INFO - [2022-03-18 13:48:20,311] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:48:20,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 13:48:50,648] {scheduler_job.py:182} INFO - Started process (PID=2240) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:50,652] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:48:50,655] {logging_mixin.py:104} INFO - [2022-03-18 13:48:50,654] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:50,711] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:48:50,758] {logging_mixin.py:104} INFO - [2022-03-18 13:48:50,757] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:48:50,804] {logging_mixin.py:104} INFO - [2022-03-18 13:48:50,804] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:48:50,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 13:49:21,344] {scheduler_job.py:182} INFO - Started process (PID=2272) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:21,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:49:21,352] {logging_mixin.py:104} INFO - [2022-03-18 13:49:21,352] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:21,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:21,446] {logging_mixin.py:104} INFO - [2022-03-18 13:49:21,445] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:49:21,485] {logging_mixin.py:104} INFO - [2022-03-18 13:49:21,484] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:49:21,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:49:51,759] {scheduler_job.py:182} INFO - Started process (PID=2304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:51,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:49:51,766] {logging_mixin.py:104} INFO - [2022-03-18 13:49:51,766] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:51,816] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:49:51,862] {logging_mixin.py:104} INFO - [2022-03-18 13:49:51,861] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:49:51,901] {logging_mixin.py:104} INFO - [2022-03-18 13:49:51,901] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:49:51,916] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 13:50:22,669] {scheduler_job.py:182} INFO - Started process (PID=2336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:22,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:50:22,678] {logging_mixin.py:104} INFO - [2022-03-18 13:50:22,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:22,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:22,792] {logging_mixin.py:104} INFO - [2022-03-18 13:50:22,792] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:50:22,840] {logging_mixin.py:104} INFO - [2022-03-18 13:50:22,840] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:50:22,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.198 seconds
[2022-03-18 13:50:53,224] {scheduler_job.py:182} INFO - Started process (PID=2361) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:53,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:50:53,231] {logging_mixin.py:104} INFO - [2022-03-18 13:50:53,231] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:53,287] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:50:53,333] {logging_mixin.py:104} INFO - [2022-03-18 13:50:53,333] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:50:53,373] {logging_mixin.py:104} INFO - [2022-03-18 13:50:53,372] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:50:53,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 13:51:24,291] {scheduler_job.py:182} INFO - Started process (PID=2392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:24,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:51:24,299] {logging_mixin.py:104} INFO - [2022-03-18 13:51:24,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:24,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:24,399] {logging_mixin.py:104} INFO - [2022-03-18 13:51:24,399] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:51:24,447] {logging_mixin.py:104} INFO - [2022-03-18 13:51:24,446] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:51:24,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 13:51:55,013] {scheduler_job.py:182} INFO - Started process (PID=2418) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:55,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:51:55,020] {logging_mixin.py:104} INFO - [2022-03-18 13:51:55,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:55,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:51:55,112] {logging_mixin.py:104} INFO - [2022-03-18 13:51:55,111] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:51:55,149] {logging_mixin.py:104} INFO - [2022-03-18 13:51:55,149] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:51:55,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 13:52:25,777] {scheduler_job.py:182} INFO - Started process (PID=2450) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:25,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:52:25,785] {logging_mixin.py:104} INFO - [2022-03-18 13:52:25,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:25,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:25,882] {logging_mixin.py:104} INFO - [2022-03-18 13:52:25,882] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:52:25,922] {logging_mixin.py:104} INFO - [2022-03-18 13:52:25,922] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:52:25,938] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 13:52:56,178] {scheduler_job.py:182} INFO - Started process (PID=2482) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:56,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:52:56,185] {logging_mixin.py:104} INFO - [2022-03-18 13:52:56,185] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:56,237] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:52:56,279] {logging_mixin.py:104} INFO - [2022-03-18 13:52:56,279] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:52:56,318] {logging_mixin.py:104} INFO - [2022-03-18 13:52:56,317] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:52:56,334] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 13:53:26,447] {scheduler_job.py:182} INFO - Started process (PID=2513) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:26,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:53:26,455] {logging_mixin.py:104} INFO - [2022-03-18 13:53:26,455] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:26,506] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:26,555] {logging_mixin.py:104} INFO - [2022-03-18 13:53:26,555] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:53:26,599] {logging_mixin.py:104} INFO - [2022-03-18 13:53:26,598] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:53:26,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 13:53:57,053] {scheduler_job.py:182} INFO - Started process (PID=2546) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:57,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:53:57,060] {logging_mixin.py:104} INFO - [2022-03-18 13:53:57,060] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:57,114] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:53:57,156] {logging_mixin.py:104} INFO - [2022-03-18 13:53:57,156] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:53:57,196] {logging_mixin.py:104} INFO - [2022-03-18 13:53:57,196] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:53:57,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 13:54:27,515] {scheduler_job.py:182} INFO - Started process (PID=2578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:27,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:54:27,522] {logging_mixin.py:104} INFO - [2022-03-18 13:54:27,521] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:27,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:27,617] {logging_mixin.py:104} INFO - [2022-03-18 13:54:27,617] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:54:27,656] {logging_mixin.py:104} INFO - [2022-03-18 13:54:27,655] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:54:27,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 13:54:58,335] {scheduler_job.py:182} INFO - Started process (PID=2610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:58,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:54:58,343] {logging_mixin.py:104} INFO - [2022-03-18 13:54:58,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:58,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:54:58,440] {logging_mixin.py:104} INFO - [2022-03-18 13:54:58,440] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:54:58,484] {logging_mixin.py:104} INFO - [2022-03-18 13:54:58,484] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:54:58,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 13:55:28,685] {scheduler_job.py:182} INFO - Started process (PID=2635) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:28,689] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:55:28,691] {logging_mixin.py:104} INFO - [2022-03-18 13:55:28,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:28,741] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:28,786] {logging_mixin.py:104} INFO - [2022-03-18 13:55:28,785] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:55:28,830] {logging_mixin.py:104} INFO - [2022-03-18 13:55:28,830] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:55:28,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 13:55:59,666] {scheduler_job.py:182} INFO - Started process (PID=2660) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:59,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:55:59,672] {logging_mixin.py:104} INFO - [2022-03-18 13:55:59,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:59,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:55:59,765] {logging_mixin.py:104} INFO - [2022-03-18 13:55:59,764] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:55:59,803] {logging_mixin.py:104} INFO - [2022-03-18 13:55:59,803] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:55:59,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 13:56:30,266] {scheduler_job.py:182} INFO - Started process (PID=2692) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:56:30,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:56:30,274] {logging_mixin.py:104} INFO - [2022-03-18 13:56:30,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:56:30,327] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:56:30,373] {logging_mixin.py:104} INFO - [2022-03-18 13:56:30,373] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:56:30,415] {logging_mixin.py:104} INFO - [2022-03-18 13:56:30,414] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:56:30,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 13:57:00,675] {scheduler_job.py:182} INFO - Started process (PID=2724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:00,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:57:00,681] {logging_mixin.py:104} INFO - [2022-03-18 13:57:00,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:00,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:00,776] {logging_mixin.py:104} INFO - [2022-03-18 13:57:00,775] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:57:00,828] {logging_mixin.py:104} INFO - [2022-03-18 13:57:00,827] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:57:00,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 13:57:31,097] {scheduler_job.py:182} INFO - Started process (PID=2756) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:31,101] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:57:31,103] {logging_mixin.py:104} INFO - [2022-03-18 13:57:31,103] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:31,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:57:31,200] {logging_mixin.py:104} INFO - [2022-03-18 13:57:31,200] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:57:31,240] {logging_mixin.py:104} INFO - [2022-03-18 13:57:31,239] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:57:31,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 13:58:01,736] {scheduler_job.py:182} INFO - Started process (PID=2788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:01,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:58:01,745] {logging_mixin.py:104} INFO - [2022-03-18 13:58:01,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:01,803] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:01,848] {logging_mixin.py:104} INFO - [2022-03-18 13:58:01,847] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:58:01,887] {logging_mixin.py:104} INFO - [2022-03-18 13:58:01,887] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:58:01,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 13:58:32,482] {scheduler_job.py:182} INFO - Started process (PID=2820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:32,487] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:58:32,490] {logging_mixin.py:104} INFO - [2022-03-18 13:58:32,489] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:32,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:58:32,581] {logging_mixin.py:104} INFO - [2022-03-18 13:58:32,581] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:58:32,621] {logging_mixin.py:104} INFO - [2022-03-18 13:58:32,621] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:58:32,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 13:59:03,395] {scheduler_job.py:182} INFO - Started process (PID=2852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:03,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:59:03,404] {logging_mixin.py:104} INFO - [2022-03-18 13:59:03,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:03,466] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:03,514] {logging_mixin.py:104} INFO - [2022-03-18 13:59:03,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:59:03,557] {logging_mixin.py:104} INFO - [2022-03-18 13:59:03,557] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:59:03,574] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 13:59:34,338] {scheduler_job.py:182} INFO - Started process (PID=2884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:34,343] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 13:59:34,346] {logging_mixin.py:104} INFO - [2022-03-18 13:59:34,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:34,395] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 13:59:34,441] {logging_mixin.py:104} INFO - [2022-03-18 13:59:34,441] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 13:59:34,482] {logging_mixin.py:104} INFO - [2022-03-18 13:59:34,482] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 13:59:34,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 14:00:04,919] {scheduler_job.py:182} INFO - Started process (PID=2908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:04,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:00:04,927] {logging_mixin.py:104} INFO - [2022-03-18 14:00:04,927] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:04,987] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:05,037] {logging_mixin.py:104} INFO - [2022-03-18 14:00:05,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:00:05,087] {logging_mixin.py:104} INFO - [2022-03-18 14:00:05,087] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:00:05,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.195 seconds
[2022-03-18 14:00:35,903] {scheduler_job.py:182} INFO - Started process (PID=2934) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:35,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:00:35,910] {logging_mixin.py:104} INFO - [2022-03-18 14:00:35,910] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:35,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:00:36,023] {logging_mixin.py:104} INFO - [2022-03-18 14:00:36,023] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:00:36,062] {logging_mixin.py:104} INFO - [2022-03-18 14:00:36,062] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:00:36,078] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 14:01:06,431] {scheduler_job.py:182} INFO - Started process (PID=2966) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:06,435] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:01:06,438] {logging_mixin.py:104} INFO - [2022-03-18 14:01:06,437] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:06,494] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:06,546] {logging_mixin.py:104} INFO - [2022-03-18 14:01:06,545] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:01:06,592] {logging_mixin.py:104} INFO - [2022-03-18 14:01:06,591] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:01:06,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-18 14:01:36,796] {scheduler_job.py:182} INFO - Started process (PID=2998) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:36,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:01:36,803] {logging_mixin.py:104} INFO - [2022-03-18 14:01:36,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:36,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:01:36,903] {logging_mixin.py:104} INFO - [2022-03-18 14:01:36,903] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:01:36,944] {logging_mixin.py:104} INFO - [2022-03-18 14:01:36,943] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:01:36,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 14:02:07,679] {scheduler_job.py:182} INFO - Started process (PID=3030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:07,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:02:07,685] {logging_mixin.py:104} INFO - [2022-03-18 14:02:07,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:07,743] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:07,791] {logging_mixin.py:104} INFO - [2022-03-18 14:02:07,791] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:02:07,831] {logging_mixin.py:104} INFO - [2022-03-18 14:02:07,830] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:02:07,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 14:02:38,017] {scheduler_job.py:182} INFO - Started process (PID=3062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:38,022] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:02:38,024] {logging_mixin.py:104} INFO - [2022-03-18 14:02:38,024] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:38,077] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:02:38,120] {logging_mixin.py:104} INFO - [2022-03-18 14:02:38,120] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:02:38,160] {logging_mixin.py:104} INFO - [2022-03-18 14:02:38,160] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:02:38,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 14:03:08,488] {scheduler_job.py:182} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:08,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:03:08,495] {logging_mixin.py:104} INFO - [2022-03-18 14:03:08,494] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:08,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:08,585] {logging_mixin.py:104} INFO - [2022-03-18 14:03:08,585] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:03:08,626] {logging_mixin.py:104} INFO - [2022-03-18 14:03:08,625] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:03:08,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 14:03:38,744] {scheduler_job.py:182} INFO - Started process (PID=3126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:38,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:03:38,751] {logging_mixin.py:104} INFO - [2022-03-18 14:03:38,750] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:38,805] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:03:38,850] {logging_mixin.py:104} INFO - [2022-03-18 14:03:38,850] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:03:38,888] {logging_mixin.py:104} INFO - [2022-03-18 14:03:38,888] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:03:38,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 14:04:09,284] {scheduler_job.py:182} INFO - Started process (PID=3157) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:09,288] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:04:09,291] {logging_mixin.py:104} INFO - [2022-03-18 14:04:09,290] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:09,343] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:09,389] {logging_mixin.py:104} INFO - [2022-03-18 14:04:09,389] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:04:09,436] {logging_mixin.py:104} INFO - [2022-03-18 14:04:09,436] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:04:09,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 14:04:39,982] {scheduler_job.py:182} INFO - Started process (PID=3182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:39,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:04:39,990] {logging_mixin.py:104} INFO - [2022-03-18 14:04:39,989] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:40,041] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:04:40,089] {logging_mixin.py:104} INFO - [2022-03-18 14:04:40,088] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:04:40,131] {logging_mixin.py:104} INFO - [2022-03-18 14:04:40,131] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:04:40,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 14:05:10,373] {scheduler_job.py:182} INFO - Started process (PID=3208) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:10,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:05:10,379] {logging_mixin.py:104} INFO - [2022-03-18 14:05:10,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:10,434] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:10,477] {logging_mixin.py:104} INFO - [2022-03-18 14:05:10,477] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:05:10,516] {logging_mixin.py:104} INFO - [2022-03-18 14:05:10,516] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:05:10,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 14:05:40,886] {scheduler_job.py:182} INFO - Started process (PID=3240) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:40,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:05:40,893] {logging_mixin.py:104} INFO - [2022-03-18 14:05:40,893] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:40,941] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:05:40,985] {logging_mixin.py:104} INFO - [2022-03-18 14:05:40,984] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:05:41,023] {logging_mixin.py:104} INFO - [2022-03-18 14:05:41,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:05:41,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 14:06:11,151] {scheduler_job.py:182} INFO - Started process (PID=3272) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:11,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:06:11,157] {logging_mixin.py:104} INFO - [2022-03-18 14:06:11,157] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:11,210] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:11,253] {logging_mixin.py:104} INFO - [2022-03-18 14:06:11,252] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:06:11,291] {logging_mixin.py:104} INFO - [2022-03-18 14:06:11,291] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:06:11,306] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:06:41,601] {scheduler_job.py:182} INFO - Started process (PID=3304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:41,606] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:06:41,608] {logging_mixin.py:104} INFO - [2022-03-18 14:06:41,608] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:41,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:06:41,707] {logging_mixin.py:104} INFO - [2022-03-18 14:06:41,706] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:06:41,746] {logging_mixin.py:104} INFO - [2022-03-18 14:06:41,745] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:06:41,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 14:07:12,027] {scheduler_job.py:182} INFO - Started process (PID=3336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:12,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:07:12,035] {logging_mixin.py:104} INFO - [2022-03-18 14:07:12,034] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:12,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:12,150] {logging_mixin.py:104} INFO - [2022-03-18 14:07:12,149] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:07:12,202] {logging_mixin.py:104} INFO - [2022-03-18 14:07:12,202] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:07:12,224] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.205 seconds
[2022-03-18 14:07:42,453] {scheduler_job.py:182} INFO - Started process (PID=3368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:42,457] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:07:42,460] {logging_mixin.py:104} INFO - [2022-03-18 14:07:42,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:42,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:07:42,558] {logging_mixin.py:104} INFO - [2022-03-18 14:07:42,558] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:07:42,601] {logging_mixin.py:104} INFO - [2022-03-18 14:07:42,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:07:42,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 14:08:13,296] {scheduler_job.py:182} INFO - Started process (PID=3400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:13,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:08:13,304] {logging_mixin.py:104} INFO - [2022-03-18 14:08:13,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:13,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:13,402] {logging_mixin.py:104} INFO - [2022-03-18 14:08:13,401] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:08:13,445] {logging_mixin.py:104} INFO - [2022-03-18 14:08:13,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:08:13,462] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 14:08:43,907] {scheduler_job.py:182} INFO - Started process (PID=3425) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:43,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:08:43,914] {logging_mixin.py:104} INFO - [2022-03-18 14:08:43,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:43,972] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:08:44,026] {logging_mixin.py:104} INFO - [2022-03-18 14:08:44,025] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:08:44,073] {logging_mixin.py:104} INFO - [2022-03-18 14:08:44,072] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:08:44,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.190 seconds
[2022-03-18 14:09:14,498] {scheduler_job.py:182} INFO - Started process (PID=3450) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:14,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:09:14,504] {logging_mixin.py:104} INFO - [2022-03-18 14:09:14,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:14,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:14,600] {logging_mixin.py:104} INFO - [2022-03-18 14:09:14,600] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:09:14,639] {logging_mixin.py:104} INFO - [2022-03-18 14:09:14,638] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:09:14,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:09:44,912] {scheduler_job.py:182} INFO - Started process (PID=3482) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:44,916] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:09:44,918] {logging_mixin.py:104} INFO - [2022-03-18 14:09:44,918] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:44,972] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:09:45,016] {logging_mixin.py:104} INFO - [2022-03-18 14:09:45,016] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:09:45,055] {logging_mixin.py:104} INFO - [2022-03-18 14:09:45,054] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:09:45,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 14:10:15,189] {scheduler_job.py:182} INFO - Started process (PID=3512) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:15,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:10:15,197] {logging_mixin.py:104} INFO - [2022-03-18 14:10:15,196] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:15,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:15,301] {logging_mixin.py:104} INFO - [2022-03-18 14:10:15,301] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:10:15,345] {logging_mixin.py:104} INFO - [2022-03-18 14:10:15,344] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:10:15,361] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 14:10:45,596] {scheduler_job.py:182} INFO - Started process (PID=3545) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:45,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:10:45,603] {logging_mixin.py:104} INFO - [2022-03-18 14:10:45,602] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:45,652] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:10:45,699] {logging_mixin.py:104} INFO - [2022-03-18 14:10:45,699] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:10:45,744] {logging_mixin.py:104} INFO - [2022-03-18 14:10:45,744] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:10:45,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 14:11:16,293] {scheduler_job.py:182} INFO - Started process (PID=3578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:16,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:11:16,303] {logging_mixin.py:104} INFO - [2022-03-18 14:11:16,303] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:16,350] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:16,395] {logging_mixin.py:104} INFO - [2022-03-18 14:11:16,394] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:11:16,439] {logging_mixin.py:104} INFO - [2022-03-18 14:11:16,439] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:11:16,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 14:11:46,876] {scheduler_job.py:182} INFO - Started process (PID=3610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:46,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:11:46,883] {logging_mixin.py:104} INFO - [2022-03-18 14:11:46,882] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:46,936] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:11:46,983] {logging_mixin.py:104} INFO - [2022-03-18 14:11:46,983] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:11:47,022] {logging_mixin.py:104} INFO - [2022-03-18 14:11:47,022] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:11:47,037] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 14:12:17,460] {scheduler_job.py:182} INFO - Started process (PID=3642) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:17,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:12:17,466] {logging_mixin.py:104} INFO - [2022-03-18 14:12:17,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:17,514] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:17,556] {logging_mixin.py:104} INFO - [2022-03-18 14:12:17,556] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:12:17,595] {logging_mixin.py:104} INFO - [2022-03-18 14:12:17,595] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:12:17,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 14:12:48,309] {scheduler_job.py:182} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:48,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:12:48,315] {logging_mixin.py:104} INFO - [2022-03-18 14:12:48,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:48,361] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:12:48,410] {logging_mixin.py:104} INFO - [2022-03-18 14:12:48,409] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:12:48,454] {logging_mixin.py:104} INFO - [2022-03-18 14:12:48,454] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:12:48,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 14:13:18,654] {scheduler_job.py:182} INFO - Started process (PID=3698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:18,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:13:18,661] {logging_mixin.py:104} INFO - [2022-03-18 14:13:18,660] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:18,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:18,756] {logging_mixin.py:104} INFO - [2022-03-18 14:13:18,755] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:13:18,797] {logging_mixin.py:104} INFO - [2022-03-18 14:13:18,797] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:13:18,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 14:13:49,582] {scheduler_job.py:182} INFO - Started process (PID=3724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:49,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:13:49,588] {logging_mixin.py:104} INFO - [2022-03-18 14:13:49,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:49,646] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:13:49,692] {logging_mixin.py:104} INFO - [2022-03-18 14:13:49,691] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:13:49,731] {logging_mixin.py:104} INFO - [2022-03-18 14:13:49,731] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:13:49,746] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 14:14:20,395] {scheduler_job.py:182} INFO - Started process (PID=3756) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:20,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:14:20,403] {logging_mixin.py:104} INFO - [2022-03-18 14:14:20,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:20,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:20,495] {logging_mixin.py:104} INFO - [2022-03-18 14:14:20,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:14:20,534] {logging_mixin.py:104} INFO - [2022-03-18 14:14:20,534] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:14:20,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 14:14:50,957] {scheduler_job.py:182} INFO - Started process (PID=3788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:50,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:14:50,964] {logging_mixin.py:104} INFO - [2022-03-18 14:14:50,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:51,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:14:51,060] {logging_mixin.py:104} INFO - [2022-03-18 14:14:51,059] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:14:51,098] {logging_mixin.py:104} INFO - [2022-03-18 14:14:51,098] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:14:51,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:15:21,502] {scheduler_job.py:182} INFO - Started process (PID=3820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:21,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:15:21,509] {logging_mixin.py:104} INFO - [2022-03-18 14:15:21,508] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:21,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:21,605] {logging_mixin.py:104} INFO - [2022-03-18 14:15:21,604] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:15:21,647] {logging_mixin.py:104} INFO - [2022-03-18 14:15:21,647] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:15:21,663] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 14:15:52,014] {scheduler_job.py:182} INFO - Started process (PID=3852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:52,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:15:52,020] {logging_mixin.py:104} INFO - [2022-03-18 14:15:52,020] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:52,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:15:52,114] {logging_mixin.py:104} INFO - [2022-03-18 14:15:52,114] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:15:52,153] {logging_mixin.py:104} INFO - [2022-03-18 14:15:52,153] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:15:52,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:16:22,688] {scheduler_job.py:182} INFO - Started process (PID=3884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:22,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:16:22,695] {logging_mixin.py:104} INFO - [2022-03-18 14:16:22,695] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:22,746] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:22,789] {logging_mixin.py:104} INFO - [2022-03-18 14:16:22,789] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:16:22,828] {logging_mixin.py:104} INFO - [2022-03-18 14:16:22,827] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:16:22,843] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:16:53,245] {scheduler_job.py:182} INFO - Started process (PID=3916) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:53,249] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:16:53,252] {logging_mixin.py:104} INFO - [2022-03-18 14:16:53,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:53,305] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:16:53,348] {logging_mixin.py:104} INFO - [2022-03-18 14:16:53,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:16:53,388] {logging_mixin.py:104} INFO - [2022-03-18 14:16:53,388] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:16:53,403] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 14:17:24,134] {scheduler_job.py:182} INFO - Started process (PID=3948) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:24,139] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:17:24,141] {logging_mixin.py:104} INFO - [2022-03-18 14:17:24,141] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:24,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:24,245] {logging_mixin.py:104} INFO - [2022-03-18 14:17:24,244] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:17:24,288] {logging_mixin.py:104} INFO - [2022-03-18 14:17:24,287] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:17:24,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 14:17:54,913] {scheduler_job.py:182} INFO - Started process (PID=3972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:54,917] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:17:54,919] {logging_mixin.py:104} INFO - [2022-03-18 14:17:54,919] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:54,972] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:17:55,019] {logging_mixin.py:104} INFO - [2022-03-18 14:17:55,019] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:17:55,060] {logging_mixin.py:104} INFO - [2022-03-18 14:17:55,060] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:17:55,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 14:18:25,559] {scheduler_job.py:182} INFO - Started process (PID=3998) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:25,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:18:25,565] {logging_mixin.py:104} INFO - [2022-03-18 14:18:25,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:25,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:25,660] {logging_mixin.py:104} INFO - [2022-03-18 14:18:25,659] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:18:25,700] {logging_mixin.py:104} INFO - [2022-03-18 14:18:25,700] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:18:25,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 14:18:56,202] {scheduler_job.py:182} INFO - Started process (PID=4030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:56,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:18:56,210] {logging_mixin.py:104} INFO - [2022-03-18 14:18:56,209] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:56,260] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:18:56,303] {logging_mixin.py:104} INFO - [2022-03-18 14:18:56,302] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:18:56,341] {logging_mixin.py:104} INFO - [2022-03-18 14:18:56,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:18:56,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:19:26,736] {scheduler_job.py:182} INFO - Started process (PID=4062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:26,741] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:19:26,744] {logging_mixin.py:104} INFO - [2022-03-18 14:19:26,743] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:26,797] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:26,840] {logging_mixin.py:104} INFO - [2022-03-18 14:19:26,840] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:19:26,879] {logging_mixin.py:104} INFO - [2022-03-18 14:19:26,879] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:19:26,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 14:19:57,300] {scheduler_job.py:182} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:57,303] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:19:57,306] {logging_mixin.py:104} INFO - [2022-03-18 14:19:57,306] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:57,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:19:57,398] {logging_mixin.py:104} INFO - [2022-03-18 14:19:57,397] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:19:57,438] {logging_mixin.py:104} INFO - [2022-03-18 14:19:57,438] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:19:57,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 14:20:27,942] {scheduler_job.py:182} INFO - Started process (PID=4126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:27,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:20:27,949] {logging_mixin.py:104} INFO - [2022-03-18 14:20:27,948] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:28,000] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:28,044] {logging_mixin.py:104} INFO - [2022-03-18 14:20:28,044] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:20:28,084] {logging_mixin.py:104} INFO - [2022-03-18 14:20:28,083] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:20:28,099] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 14:20:58,863] {scheduler_job.py:182} INFO - Started process (PID=4158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:58,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:20:58,870] {logging_mixin.py:104} INFO - [2022-03-18 14:20:58,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:58,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:20:58,966] {logging_mixin.py:104} INFO - [2022-03-18 14:20:58,965] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:20:59,005] {logging_mixin.py:104} INFO - [2022-03-18 14:20:59,005] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:20:59,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 14:21:29,518] {scheduler_job.py:182} INFO - Started process (PID=4190) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:21:29,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:21:29,524] {logging_mixin.py:104} INFO - [2022-03-18 14:21:29,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:21:29,576] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:21:29,620] {logging_mixin.py:104} INFO - [2022-03-18 14:21:29,619] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:21:29,659] {logging_mixin.py:104} INFO - [2022-03-18 14:21:29,659] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:21:29,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:22:00,380] {scheduler_job.py:182} INFO - Started process (PID=4209) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:00,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:22:00,387] {logging_mixin.py:104} INFO - [2022-03-18 14:22:00,387] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:00,436] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:00,482] {logging_mixin.py:104} INFO - [2022-03-18 14:22:00,482] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:22:00,527] {logging_mixin.py:104} INFO - [2022-03-18 14:22:00,526] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:22:00,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 14:22:30,771] {scheduler_job.py:182} INFO - Started process (PID=4236) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:30,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:22:30,778] {logging_mixin.py:104} INFO - [2022-03-18 14:22:30,778] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:30,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:22:30,866] {logging_mixin.py:104} INFO - [2022-03-18 14:22:30,866] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:22:30,904] {logging_mixin.py:104} INFO - [2022-03-18 14:22:30,904] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:22:30,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 14:23:01,031] {scheduler_job.py:182} INFO - Started process (PID=4265) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:01,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:23:01,042] {logging_mixin.py:104} INFO - [2022-03-18 14:23:01,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:01,091] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:01,138] {logging_mixin.py:104} INFO - [2022-03-18 14:23:01,138] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:23:01,184] {logging_mixin.py:104} INFO - [2022-03-18 14:23:01,184] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:23:01,201] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 14:23:32,189] {scheduler_job.py:182} INFO - Started process (PID=4304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:32,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:23:32,196] {logging_mixin.py:104} INFO - [2022-03-18 14:23:32,195] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:32,250] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:23:32,296] {logging_mixin.py:104} INFO - [2022-03-18 14:23:32,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:23:32,336] {logging_mixin.py:104} INFO - [2022-03-18 14:23:32,335] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:23:32,352] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 14:24:02,508] {scheduler_job.py:182} INFO - Started process (PID=4336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:02,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:24:02,514] {logging_mixin.py:104} INFO - [2022-03-18 14:24:02,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:02,567] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:02,609] {logging_mixin.py:104} INFO - [2022-03-18 14:24:02,609] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:24:02,648] {logging_mixin.py:104} INFO - [2022-03-18 14:24:02,648] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:24:02,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:24:32,850] {scheduler_job.py:182} INFO - Started process (PID=4368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:32,854] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:24:32,856] {logging_mixin.py:104} INFO - [2022-03-18 14:24:32,856] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:32,907] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:24:32,949] {logging_mixin.py:104} INFO - [2022-03-18 14:24:32,949] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:24:32,987] {logging_mixin.py:104} INFO - [2022-03-18 14:24:32,987] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:24:33,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 14:25:03,184] {scheduler_job.py:182} INFO - Started process (PID=4400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:03,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:25:03,190] {logging_mixin.py:104} INFO - [2022-03-18 14:25:03,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:03,240] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:03,283] {logging_mixin.py:104} INFO - [2022-03-18 14:25:03,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:25:03,321] {logging_mixin.py:104} INFO - [2022-03-18 14:25:03,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:25:03,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 14:25:34,109] {scheduler_job.py:182} INFO - Started process (PID=4432) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:34,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:25:34,114] {logging_mixin.py:104} INFO - [2022-03-18 14:25:34,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:34,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:25:34,206] {logging_mixin.py:104} INFO - [2022-03-18 14:25:34,206] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:25:34,246] {logging_mixin.py:104} INFO - [2022-03-18 14:25:34,246] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:25:34,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:26:04,631] {scheduler_job.py:182} INFO - Started process (PID=4464) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:04,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:26:04,644] {logging_mixin.py:104} INFO - [2022-03-18 14:26:04,643] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:04,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:04,734] {logging_mixin.py:104} INFO - [2022-03-18 14:26:04,733] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:26:04,772] {logging_mixin.py:104} INFO - [2022-03-18 14:26:04,772] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:26:04,786] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:26:35,197] {scheduler_job.py:182} INFO - Started process (PID=4495) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:35,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:26:35,204] {logging_mixin.py:104} INFO - [2022-03-18 14:26:35,203] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:35,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:26:35,300] {logging_mixin.py:104} INFO - [2022-03-18 14:26:35,299] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:26:35,342] {logging_mixin.py:104} INFO - [2022-03-18 14:26:35,342] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:26:35,360] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 14:27:05,887] {scheduler_job.py:182} INFO - Started process (PID=4520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:05,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:27:05,894] {logging_mixin.py:104} INFO - [2022-03-18 14:27:05,893] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:05,942] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:05,988] {logging_mixin.py:104} INFO - [2022-03-18 14:27:05,987] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:27:06,028] {logging_mixin.py:104} INFO - [2022-03-18 14:27:06,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:27:06,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 14:27:36,549] {scheduler_job.py:182} INFO - Started process (PID=4546) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:36,552] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:27:36,555] {logging_mixin.py:104} INFO - [2022-03-18 14:27:36,554] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:36,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:27:36,650] {logging_mixin.py:104} INFO - [2022-03-18 14:27:36,650] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:27:36,690] {logging_mixin.py:104} INFO - [2022-03-18 14:27:36,690] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:27:36,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 14:28:06,800] {scheduler_job.py:182} INFO - Started process (PID=4577) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:06,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:28:06,806] {logging_mixin.py:104} INFO - [2022-03-18 14:28:06,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:06,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:06,905] {logging_mixin.py:104} INFO - [2022-03-18 14:28:06,905] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:28:06,949] {logging_mixin.py:104} INFO - [2022-03-18 14:28:06,949] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:28:06,965] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 14:28:37,068] {scheduler_job.py:182} INFO - Started process (PID=4600) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:37,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:28:37,078] {logging_mixin.py:104} INFO - [2022-03-18 14:28:37,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:37,127] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:28:37,172] {logging_mixin.py:104} INFO - [2022-03-18 14:28:37,172] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:28:37,215] {logging_mixin.py:104} INFO - [2022-03-18 14:28:37,215] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:28:37,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 14:29:07,352] {scheduler_job.py:182} INFO - Started process (PID=4632) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:07,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:29:07,362] {logging_mixin.py:104} INFO - [2022-03-18 14:29:07,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:07,411] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:07,453] {logging_mixin.py:104} INFO - [2022-03-18 14:29:07,452] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:29:07,495] {logging_mixin.py:104} INFO - [2022-03-18 14:29:07,494] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:29:07,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 14:29:37,702] {scheduler_job.py:182} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:37,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:29:37,710] {logging_mixin.py:104} INFO - [2022-03-18 14:29:37,710] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:37,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:29:37,803] {logging_mixin.py:104} INFO - [2022-03-18 14:29:37,802] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:29:37,843] {logging_mixin.py:104} INFO - [2022-03-18 14:29:37,843] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:29:37,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 14:30:08,990] {scheduler_job.py:182} INFO - Started process (PID=4708) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:30:08,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:30:09,001] {logging_mixin.py:104} INFO - [2022-03-18 14:30:09,000] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:30:09,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:30:09,114] {logging_mixin.py:104} INFO - [2022-03-18 14:30:09,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:30:09,170] {logging_mixin.py:104} INFO - [2022-03-18 14:30:09,170] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:30:09,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.230 seconds
[2022-03-18 14:49:13,337] {scheduler_job.py:182} INFO - Started process (PID=4724) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:13,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:49:13,346] {logging_mixin.py:104} INFO - [2022-03-18 14:49:13,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:13,452] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:13,528] {logging_mixin.py:104} INFO - [2022-03-18 14:49:13,527] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:49:13,600] {logging_mixin.py:104} INFO - [2022-03-18 14:49:13,599] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:49:13,620] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.303 seconds
[2022-03-18 14:49:43,913] {scheduler_job.py:182} INFO - Started process (PID=4749) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:43,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:49:43,923] {logging_mixin.py:104} INFO - [2022-03-18 14:49:43,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:44,023] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:49:44,080] {logging_mixin.py:104} INFO - [2022-03-18 14:49:44,080] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:49:44,132] {logging_mixin.py:104} INFO - [2022-03-18 14:49:44,132] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:49:44,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.246 seconds
[2022-03-18 14:50:14,907] {scheduler_job.py:182} INFO - Started process (PID=4788) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:14,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:50:14,914] {logging_mixin.py:104} INFO - [2022-03-18 14:50:14,914] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:14,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:15,009] {logging_mixin.py:104} INFO - [2022-03-18 14:50:15,009] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:50:15,047] {logging_mixin.py:104} INFO - [2022-03-18 14:50:15,047] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:50:15,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 14:50:45,762] {scheduler_job.py:182} INFO - Started process (PID=4820) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:45,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:50:45,775] {logging_mixin.py:104} INFO - [2022-03-18 14:50:45,774] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:45,849] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:50:45,900] {logging_mixin.py:104} INFO - [2022-03-18 14:50:45,899] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:50:45,941] {logging_mixin.py:104} INFO - [2022-03-18 14:50:45,941] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:50:45,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.208 seconds
[2022-03-18 14:51:16,944] {scheduler_job.py:182} INFO - Started process (PID=4852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:16,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:51:16,950] {logging_mixin.py:104} INFO - [2022-03-18 14:51:16,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:17,001] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:17,044] {logging_mixin.py:104} INFO - [2022-03-18 14:51:17,044] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:51:17,082] {logging_mixin.py:104} INFO - [2022-03-18 14:51:17,082] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:51:17,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 14:51:47,567] {scheduler_job.py:182} INFO - Started process (PID=4884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:47,572] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:51:47,576] {logging_mixin.py:104} INFO - [2022-03-18 14:51:47,575] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:47,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:51:47,672] {logging_mixin.py:104} INFO - [2022-03-18 14:51:47,672] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:51:47,710] {logging_mixin.py:104} INFO - [2022-03-18 14:51:47,710] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:51:47,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 14:52:18,529] {scheduler_job.py:182} INFO - Started process (PID=4916) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:18,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:52:18,536] {logging_mixin.py:104} INFO - [2022-03-18 14:52:18,536] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:18,586] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:18,635] {logging_mixin.py:104} INFO - [2022-03-18 14:52:18,634] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:52:18,674] {logging_mixin.py:104} INFO - [2022-03-18 14:52:18,674] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:52:18,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 14:52:49,201] {scheduler_job.py:182} INFO - Started process (PID=4948) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:49,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:52:49,208] {logging_mixin.py:104} INFO - [2022-03-18 14:52:49,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:49,257] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:52:49,299] {logging_mixin.py:104} INFO - [2022-03-18 14:52:49,298] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:52:49,337] {logging_mixin.py:104} INFO - [2022-03-18 14:52:49,336] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:52:49,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:53:22,189] {scheduler_job.py:182} INFO - Started process (PID=4980) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:22,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:53:22,196] {logging_mixin.py:104} INFO - [2022-03-18 14:53:22,195] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:22,245] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:22,292] {logging_mixin.py:104} INFO - [2022-03-18 14:53:22,292] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:53:22,336] {logging_mixin.py:104} INFO - [2022-03-18 14:53:22,335] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:53:22,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 14:53:52,888] {scheduler_job.py:182} INFO - Started process (PID=5004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:52,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:53:52,895] {logging_mixin.py:104} INFO - [2022-03-18 14:53:52,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:52,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:53:52,989] {logging_mixin.py:104} INFO - [2022-03-18 14:53:52,989] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:53:53,031] {logging_mixin.py:104} INFO - [2022-03-18 14:53:53,031] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:53:53,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 14:54:23,871] {scheduler_job.py:182} INFO - Started process (PID=5030) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:23,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:54:23,878] {logging_mixin.py:104} INFO - [2022-03-18 14:54:23,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:23,928] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:23,972] {logging_mixin.py:104} INFO - [2022-03-18 14:54:23,972] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:54:24,011] {logging_mixin.py:104} INFO - [2022-03-18 14:54:24,010] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:54:24,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:54:54,513] {scheduler_job.py:182} INFO - Started process (PID=5062) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:54,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:54:54,519] {logging_mixin.py:104} INFO - [2022-03-18 14:54:54,519] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:54,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:54:54,611] {logging_mixin.py:104} INFO - [2022-03-18 14:54:54,611] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:54:54,649] {logging_mixin.py:104} INFO - [2022-03-18 14:54:54,649] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:54:54,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 14:55:25,126] {scheduler_job.py:182} INFO - Started process (PID=5094) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:25,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:55:25,132] {logging_mixin.py:104} INFO - [2022-03-18 14:55:25,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:25,183] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:25,226] {logging_mixin.py:104} INFO - [2022-03-18 14:55:25,226] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:55:25,266] {logging_mixin.py:104} INFO - [2022-03-18 14:55:25,266] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:55:25,282] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:55:55,746] {scheduler_job.py:182} INFO - Started process (PID=5126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:55,750] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:55:55,752] {logging_mixin.py:104} INFO - [2022-03-18 14:55:55,752] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:55,804] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:55:55,847] {logging_mixin.py:104} INFO - [2022-03-18 14:55:55,846] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:55:55,885] {logging_mixin.py:104} INFO - [2022-03-18 14:55:55,885] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:55:55,900] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:56:26,383] {scheduler_job.py:182} INFO - Started process (PID=5158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:26,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:56:26,389] {logging_mixin.py:104} INFO - [2022-03-18 14:56:26,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:26,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:26,484] {logging_mixin.py:104} INFO - [2022-03-18 14:56:26,483] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:56:26,523] {logging_mixin.py:104} INFO - [2022-03-18 14:56:26,523] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:56:26,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 14:56:56,966] {scheduler_job.py:182} INFO - Started process (PID=5190) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:56,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:56:56,973] {logging_mixin.py:104} INFO - [2022-03-18 14:56:56,973] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:57,028] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:56:57,070] {logging_mixin.py:104} INFO - [2022-03-18 14:56:57,070] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:56:57,108] {logging_mixin.py:104} INFO - [2022-03-18 14:56:57,108] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:56:57,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 14:57:27,566] {scheduler_job.py:182} INFO - Started process (PID=5222) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:27,569] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:57:27,572] {logging_mixin.py:104} INFO - [2022-03-18 14:57:27,571] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:27,624] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:27,667] {logging_mixin.py:104} INFO - [2022-03-18 14:57:27,667] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:57:27,707] {logging_mixin.py:104} INFO - [2022-03-18 14:57:27,707] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:57:27,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:57:58,381] {scheduler_job.py:182} INFO - Started process (PID=5254) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:58,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:57:58,389] {logging_mixin.py:104} INFO - [2022-03-18 14:57:58,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:58,442] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:57:58,489] {logging_mixin.py:104} INFO - [2022-03-18 14:57:58,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:57:58,531] {logging_mixin.py:104} INFO - [2022-03-18 14:57:58,531] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:57:58,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 14:58:29,051] {scheduler_job.py:182} INFO - Started process (PID=5278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:58:29,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:58:29,057] {logging_mixin.py:104} INFO - [2022-03-18 14:58:29,057] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:58:29,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:58:29,150] {logging_mixin.py:104} INFO - [2022-03-18 14:58:29,149] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:58:29,190] {logging_mixin.py:104} INFO - [2022-03-18 14:58:29,190] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:58:29,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 14:58:59,955] {scheduler_job.py:182} INFO - Started process (PID=5304) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:58:59,958] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:58:59,961] {logging_mixin.py:104} INFO - [2022-03-18 14:58:59,961] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:59:00,014] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:59:00,058] {logging_mixin.py:104} INFO - [2022-03-18 14:59:00,057] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:59:00,098] {logging_mixin.py:104} INFO - [2022-03-18 14:59:00,097] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:59:00,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 14:59:30,699] {scheduler_job.py:182} INFO - Started process (PID=5336) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 14:59:30,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 14:59:30,706] {logging_mixin.py:104} INFO - [2022-03-18 14:59:30,706] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 14:59:30,758] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 14:59:30,801] {logging_mixin.py:104} INFO - [2022-03-18 14:59:30,801] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 14:59:30,839] {logging_mixin.py:104} INFO - [2022-03-18 14:59:30,839] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 14:59:30,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:00:01,399] {scheduler_job.py:182} INFO - Started process (PID=5368) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:01,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:00:01,407] {logging_mixin.py:104} INFO - [2022-03-18 15:00:01,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:01,457] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:01,500] {logging_mixin.py:104} INFO - [2022-03-18 15:00:01,499] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:00:01,538] {logging_mixin.py:104} INFO - [2022-03-18 15:00:01,538] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:00:01,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:00:32,092] {scheduler_job.py:182} INFO - Started process (PID=5400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:32,096] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:00:32,099] {logging_mixin.py:104} INFO - [2022-03-18 15:00:32,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:32,151] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:00:32,192] {logging_mixin.py:104} INFO - [2022-03-18 15:00:32,192] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:00:32,230] {logging_mixin.py:104} INFO - [2022-03-18 15:00:32,230] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:00:32,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:01:02,617] {scheduler_job.py:182} INFO - Started process (PID=5432) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:02,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:01:02,624] {logging_mixin.py:104} INFO - [2022-03-18 15:01:02,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:02,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:02,717] {logging_mixin.py:104} INFO - [2022-03-18 15:01:02,716] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:01:02,754] {logging_mixin.py:104} INFO - [2022-03-18 15:01:02,754] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:01:02,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 15:01:33,104] {scheduler_job.py:182} INFO - Started process (PID=5464) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:33,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:01:33,110] {logging_mixin.py:104} INFO - [2022-03-18 15:01:33,110] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:33,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:01:33,203] {logging_mixin.py:104} INFO - [2022-03-18 15:01:33,202] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:01:33,243] {logging_mixin.py:104} INFO - [2022-03-18 15:01:33,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:01:33,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:02:03,635] {scheduler_job.py:182} INFO - Started process (PID=5496) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:03,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:02:03,641] {logging_mixin.py:104} INFO - [2022-03-18 15:02:03,641] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:03,694] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:03,739] {logging_mixin.py:104} INFO - [2022-03-18 15:02:03,738] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:02:03,779] {logging_mixin.py:104} INFO - [2022-03-18 15:02:03,778] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:02:03,794] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:02:34,513] {scheduler_job.py:182} INFO - Started process (PID=5528) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:34,518] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:02:34,520] {logging_mixin.py:104} INFO - [2022-03-18 15:02:34,520] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:34,572] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:02:34,619] {logging_mixin.py:104} INFO - [2022-03-18 15:02:34,618] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:02:34,661] {logging_mixin.py:104} INFO - [2022-03-18 15:02:34,660] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:02:34,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 15:03:05,239] {scheduler_job.py:182} INFO - Started process (PID=5552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:05,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:03:05,246] {logging_mixin.py:104} INFO - [2022-03-18 15:03:05,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:05,294] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:05,337] {logging_mixin.py:104} INFO - [2022-03-18 15:03:05,337] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:03:05,379] {logging_mixin.py:104} INFO - [2022-03-18 15:03:05,379] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:03:05,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:03:35,785] {scheduler_job.py:182} INFO - Started process (PID=5578) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:35,789] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:03:35,791] {logging_mixin.py:104} INFO - [2022-03-18 15:03:35,791] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:35,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:03:35,886] {logging_mixin.py:104} INFO - [2022-03-18 15:03:35,886] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:03:35,924] {logging_mixin.py:104} INFO - [2022-03-18 15:03:35,924] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:03:35,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:04:06,434] {scheduler_job.py:182} INFO - Started process (PID=5610) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:06,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:04:06,441] {logging_mixin.py:104} INFO - [2022-03-18 15:04:06,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:06,494] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:06,534] {logging_mixin.py:104} INFO - [2022-03-18 15:04:06,534] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:04:06,574] {logging_mixin.py:104} INFO - [2022-03-18 15:04:06,573] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:04:06,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:04:36,931] {scheduler_job.py:182} INFO - Started process (PID=5642) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:36,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:04:36,938] {logging_mixin.py:104} INFO - [2022-03-18 15:04:36,937] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:36,990] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:04:37,033] {logging_mixin.py:104} INFO - [2022-03-18 15:04:37,033] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:04:37,074] {logging_mixin.py:104} INFO - [2022-03-18 15:04:37,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:04:37,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:05:07,568] {scheduler_job.py:182} INFO - Started process (PID=5674) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:07,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:05:07,574] {logging_mixin.py:104} INFO - [2022-03-18 15:05:07,573] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:07,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:07,668] {logging_mixin.py:104} INFO - [2022-03-18 15:05:07,668] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:05:07,709] {logging_mixin.py:104} INFO - [2022-03-18 15:05:07,709] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:05:07,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:05:38,125] {scheduler_job.py:182} INFO - Started process (PID=5706) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:38,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:05:38,133] {logging_mixin.py:104} INFO - [2022-03-18 15:05:38,132] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:38,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:05:38,225] {logging_mixin.py:104} INFO - [2022-03-18 15:05:38,225] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:05:38,268] {logging_mixin.py:104} INFO - [2022-03-18 15:05:38,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:05:38,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:06:08,755] {scheduler_job.py:182} INFO - Started process (PID=5738) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:08,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:06:08,763] {logging_mixin.py:104} INFO - [2022-03-18 15:06:08,763] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:08,817] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:08,863] {logging_mixin.py:104} INFO - [2022-03-18 15:06:08,863] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:06:08,909] {logging_mixin.py:104} INFO - [2022-03-18 15:06:08,908] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:06:08,924] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 15:06:39,361] {scheduler_job.py:182} INFO - Started process (PID=5770) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:39,366] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:06:39,368] {logging_mixin.py:104} INFO - [2022-03-18 15:06:39,368] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:39,420] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:06:39,463] {logging_mixin.py:104} INFO - [2022-03-18 15:06:39,463] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:06:39,501] {logging_mixin.py:104} INFO - [2022-03-18 15:06:39,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:06:39,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:07:11,165] {scheduler_job.py:182} INFO - Started process (PID=5802) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:11,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:07:11,172] {logging_mixin.py:104} INFO - [2022-03-18 15:07:11,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:11,226] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:11,276] {logging_mixin.py:104} INFO - [2022-03-18 15:07:11,275] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:07:11,317] {logging_mixin.py:104} INFO - [2022-03-18 15:07:11,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:07:11,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 15:07:41,839] {scheduler_job.py:182} INFO - Started process (PID=5826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:41,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:07:41,845] {logging_mixin.py:104} INFO - [2022-03-18 15:07:41,845] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:41,897] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:07:41,945] {logging_mixin.py:104} INFO - [2022-03-18 15:07:41,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:07:41,987] {logging_mixin.py:104} INFO - [2022-03-18 15:07:41,987] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:07:42,004] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 15:08:12,544] {scheduler_job.py:182} INFO - Started process (PID=5852) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:12,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:08:12,552] {logging_mixin.py:104} INFO - [2022-03-18 15:08:12,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:12,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:12,645] {logging_mixin.py:104} INFO - [2022-03-18 15:08:12,645] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:08:12,684] {logging_mixin.py:104} INFO - [2022-03-18 15:08:12,683] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:08:12,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:08:43,094] {scheduler_job.py:182} INFO - Started process (PID=5884) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:43,102] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:08:43,105] {logging_mixin.py:104} INFO - [2022-03-18 15:08:43,104] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:43,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:08:43,198] {logging_mixin.py:104} INFO - [2022-03-18 15:08:43,198] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:08:43,238] {logging_mixin.py:104} INFO - [2022-03-18 15:08:43,237] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:08:43,252] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:09:13,649] {scheduler_job.py:182} INFO - Started process (PID=5916) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:13,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:09:13,656] {logging_mixin.py:104} INFO - [2022-03-18 15:09:13,655] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:13,708] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:13,751] {logging_mixin.py:104} INFO - [2022-03-18 15:09:13,750] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:09:13,789] {logging_mixin.py:104} INFO - [2022-03-18 15:09:13,789] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:09:13,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:09:44,405] {scheduler_job.py:182} INFO - Started process (PID=5948) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:44,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:09:44,412] {logging_mixin.py:104} INFO - [2022-03-18 15:09:44,411] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:44,462] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:09:44,503] {logging_mixin.py:104} INFO - [2022-03-18 15:09:44,503] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:09:44,542] {logging_mixin.py:104} INFO - [2022-03-18 15:09:44,541] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:09:44,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 15:10:15,226] {scheduler_job.py:182} INFO - Started process (PID=5980) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:15,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:10:15,233] {logging_mixin.py:104} INFO - [2022-03-18 15:10:15,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:15,290] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:15,335] {logging_mixin.py:104} INFO - [2022-03-18 15:10:15,335] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:10:15,376] {logging_mixin.py:104} INFO - [2022-03-18 15:10:15,376] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:10:15,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 15:10:45,930] {scheduler_job.py:182} INFO - Started process (PID=6012) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:45,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:10:45,937] {logging_mixin.py:104} INFO - [2022-03-18 15:10:45,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:45,992] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:10:46,037] {logging_mixin.py:104} INFO - [2022-03-18 15:10:46,036] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:10:46,079] {logging_mixin.py:104} INFO - [2022-03-18 15:10:46,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:10:46,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 15:11:16,477] {scheduler_job.py:182} INFO - Started process (PID=6044) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:16,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:11:16,485] {logging_mixin.py:104} INFO - [2022-03-18 15:11:16,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:16,537] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:16,581] {logging_mixin.py:104} INFO - [2022-03-18 15:11:16,580] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:11:16,622] {logging_mixin.py:104} INFO - [2022-03-18 15:11:16,622] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:11:16,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:11:47,315] {scheduler_job.py:182} INFO - Started process (PID=6076) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:47,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:11:47,321] {logging_mixin.py:104} INFO - [2022-03-18 15:11:47,320] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:47,368] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:11:47,412] {logging_mixin.py:104} INFO - [2022-03-18 15:11:47,411] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:11:47,452] {logging_mixin.py:104} INFO - [2022-03-18 15:11:47,452] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:11:47,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:12:18,172] {scheduler_job.py:182} INFO - Started process (PID=6100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:18,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:12:18,191] {logging_mixin.py:104} INFO - [2022-03-18 15:12:18,190] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:18,238] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:18,283] {logging_mixin.py:104} INFO - [2022-03-18 15:12:18,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:12:18,325] {logging_mixin.py:104} INFO - [2022-03-18 15:12:18,324] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:12:18,341] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 15:12:48,557] {scheduler_job.py:182} INFO - Started process (PID=6126) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:48,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:12:48,563] {logging_mixin.py:104} INFO - [2022-03-18 15:12:48,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:48,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:12:48,657] {logging_mixin.py:104} INFO - [2022-03-18 15:12:48,657] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:12:48,697] {logging_mixin.py:104} INFO - [2022-03-18 15:12:48,696] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:12:48,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:13:19,145] {scheduler_job.py:182} INFO - Started process (PID=6158) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:19,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:13:19,151] {logging_mixin.py:104} INFO - [2022-03-18 15:13:19,151] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:19,201] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:19,245] {logging_mixin.py:104} INFO - [2022-03-18 15:13:19,245] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:13:19,285] {logging_mixin.py:104} INFO - [2022-03-18 15:13:19,285] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:13:19,301] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 15:13:49,699] {scheduler_job.py:182} INFO - Started process (PID=6190) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:49,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:13:49,705] {logging_mixin.py:104} INFO - [2022-03-18 15:13:49,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:49,756] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:13:49,800] {logging_mixin.py:104} INFO - [2022-03-18 15:13:49,799] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:13:49,839] {logging_mixin.py:104} INFO - [2022-03-18 15:13:49,839] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:13:49,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:14:20,297] {scheduler_job.py:182} INFO - Started process (PID=6222) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:20,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:14:20,305] {logging_mixin.py:104} INFO - [2022-03-18 15:14:20,305] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:20,357] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:20,402] {logging_mixin.py:104} INFO - [2022-03-18 15:14:20,402] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:14:20,444] {logging_mixin.py:104} INFO - [2022-03-18 15:14:20,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:14:20,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 15:14:50,754] {scheduler_job.py:182} INFO - Started process (PID=6254) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:50,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:14:50,760] {logging_mixin.py:104} INFO - [2022-03-18 15:14:50,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:50,813] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:14:50,855] {logging_mixin.py:104} INFO - [2022-03-18 15:14:50,854] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:14:50,894] {logging_mixin.py:104} INFO - [2022-03-18 15:14:50,893] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:14:50,909] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:15:21,111] {scheduler_job.py:182} INFO - Started process (PID=6286) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:21,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:15:21,119] {logging_mixin.py:104} INFO - [2022-03-18 15:15:21,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:21,175] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:21,218] {logging_mixin.py:104} INFO - [2022-03-18 15:15:21,218] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:15:21,258] {logging_mixin.py:104} INFO - [2022-03-18 15:15:21,258] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:15:21,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 15:15:52,011] {scheduler_job.py:182} INFO - Started process (PID=6318) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:52,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:15:52,017] {logging_mixin.py:104} INFO - [2022-03-18 15:15:52,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:52,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:15:52,113] {logging_mixin.py:104} INFO - [2022-03-18 15:15:52,112] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:15:52,151] {logging_mixin.py:104} INFO - [2022-03-18 15:15:52,151] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:15:52,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:16:22,679] {scheduler_job.py:182} INFO - Started process (PID=6350) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:22,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:16:22,685] {logging_mixin.py:104} INFO - [2022-03-18 15:16:22,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:22,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:22,779] {logging_mixin.py:104} INFO - [2022-03-18 15:16:22,779] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:16:22,822] {logging_mixin.py:104} INFO - [2022-03-18 15:16:22,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:16:22,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 15:16:52,935] {scheduler_job.py:182} INFO - Started process (PID=6374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:52,939] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:16:52,941] {logging_mixin.py:104} INFO - [2022-03-18 15:16:52,941] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:52,991] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:16:53,037] {logging_mixin.py:104} INFO - [2022-03-18 15:16:53,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:16:53,080] {logging_mixin.py:104} INFO - [2022-03-18 15:16:53,080] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:16:53,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 15:17:23,858] {scheduler_job.py:182} INFO - Started process (PID=6400) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:23,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:17:23,866] {logging_mixin.py:104} INFO - [2022-03-18 15:17:23,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:23,916] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:23,958] {logging_mixin.py:104} INFO - [2022-03-18 15:17:23,958] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:17:23,997] {logging_mixin.py:104} INFO - [2022-03-18 15:17:23,996] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:17:24,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:17:54,797] {scheduler_job.py:182} INFO - Started process (PID=6432) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:54,801] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:17:54,804] {logging_mixin.py:104} INFO - [2022-03-18 15:17:54,804] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:54,857] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:17:54,902] {logging_mixin.py:104} INFO - [2022-03-18 15:17:54,902] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:17:54,940] {logging_mixin.py:104} INFO - [2022-03-18 15:17:54,940] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:17:54,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:18:25,660] {scheduler_job.py:182} INFO - Started process (PID=6464) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:25,664] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:18:25,667] {logging_mixin.py:104} INFO - [2022-03-18 15:18:25,666] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:25,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:25,758] {logging_mixin.py:104} INFO - [2022-03-18 15:18:25,758] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:18:25,796] {logging_mixin.py:104} INFO - [2022-03-18 15:18:25,795] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:18:25,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 15:18:56,471] {scheduler_job.py:182} INFO - Started process (PID=6496) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:56,475] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:18:56,479] {logging_mixin.py:104} INFO - [2022-03-18 15:18:56,479] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:56,530] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:18:56,574] {logging_mixin.py:104} INFO - [2022-03-18 15:18:56,573] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:18:56,612] {logging_mixin.py:104} INFO - [2022-03-18 15:18:56,612] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:18:56,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 15:19:26,823] {scheduler_job.py:182} INFO - Started process (PID=6528) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:26,828] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:19:26,830] {logging_mixin.py:104} INFO - [2022-03-18 15:19:26,829] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:26,881] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:26,924] {logging_mixin.py:104} INFO - [2022-03-18 15:19:26,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:19:26,963] {logging_mixin.py:104} INFO - [2022-03-18 15:19:26,963] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:19:26,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:19:57,627] {scheduler_job.py:182} INFO - Started process (PID=6560) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:57,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:19:57,634] {logging_mixin.py:104} INFO - [2022-03-18 15:19:57,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:57,686] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:19:57,729] {logging_mixin.py:104} INFO - [2022-03-18 15:19:57,729] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:19:57,769] {logging_mixin.py:104} INFO - [2022-03-18 15:19:57,769] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:19:57,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:20:28,001] {scheduler_job.py:182} INFO - Started process (PID=6592) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:28,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:20:28,008] {logging_mixin.py:104} INFO - [2022-03-18 15:20:28,008] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:28,057] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:28,098] {logging_mixin.py:104} INFO - [2022-03-18 15:20:28,098] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:20:28,137] {logging_mixin.py:104} INFO - [2022-03-18 15:20:28,136] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:20:28,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 15:20:58,865] {scheduler_job.py:182} INFO - Started process (PID=6624) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:58,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:20:58,871] {logging_mixin.py:104} INFO - [2022-03-18 15:20:58,871] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:58,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:20:58,964] {logging_mixin.py:104} INFO - [2022-03-18 15:20:58,964] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:20:59,002] {logging_mixin.py:104} INFO - [2022-03-18 15:20:59,001] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:20:59,018] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:21:30,478] {scheduler_job.py:182} INFO - Started process (PID=6656) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:21:30,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:21:30,484] {logging_mixin.py:104} INFO - [2022-03-18 15:21:30,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:21:30,534] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:21:30,578] {logging_mixin.py:104} INFO - [2022-03-18 15:21:30,578] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:21:30,621] {logging_mixin.py:104} INFO - [2022-03-18 15:21:30,620] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:21:30,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:22:00,868] {scheduler_job.py:182} INFO - Started process (PID=6681) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:00,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:22:00,875] {logging_mixin.py:104} INFO - [2022-03-18 15:22:00,875] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:00,925] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:00,971] {logging_mixin.py:104} INFO - [2022-03-18 15:22:00,970] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:22:01,015] {logging_mixin.py:104} INFO - [2022-03-18 15:22:01,014] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:22:01,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 15:22:31,727] {scheduler_job.py:182} INFO - Started process (PID=6702) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:31,732] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:22:31,734] {logging_mixin.py:104} INFO - [2022-03-18 15:22:31,734] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:31,785] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:22:31,827] {logging_mixin.py:104} INFO - [2022-03-18 15:22:31,827] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:22:31,868] {logging_mixin.py:104} INFO - [2022-03-18 15:22:31,868] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:22:31,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:23:02,419] {scheduler_job.py:182} INFO - Started process (PID=6734) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:02,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:23:02,427] {logging_mixin.py:104} INFO - [2022-03-18 15:23:02,426] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:02,478] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:02,524] {logging_mixin.py:104} INFO - [2022-03-18 15:23:02,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:23:02,567] {logging_mixin.py:104} INFO - [2022-03-18 15:23:02,567] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:23:02,583] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 15:23:32,820] {scheduler_job.py:182} INFO - Started process (PID=6766) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:32,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:23:32,832] {logging_mixin.py:104} INFO - [2022-03-18 15:23:32,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:32,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:23:32,926] {logging_mixin.py:104} INFO - [2022-03-18 15:23:32,926] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:23:32,968] {logging_mixin.py:104} INFO - [2022-03-18 15:23:32,967] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:23:32,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 15:24:03,272] {scheduler_job.py:182} INFO - Started process (PID=6798) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:03,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:24:03,279] {logging_mixin.py:104} INFO - [2022-03-18 15:24:03,279] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:03,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:03,378] {logging_mixin.py:104} INFO - [2022-03-18 15:24:03,378] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:24:03,420] {logging_mixin.py:104} INFO - [2022-03-18 15:24:03,420] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:24:03,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 15:24:33,949] {scheduler_job.py:182} INFO - Started process (PID=6830) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:33,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:24:33,956] {logging_mixin.py:104} INFO - [2022-03-18 15:24:33,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:34,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:24:34,050] {logging_mixin.py:104} INFO - [2022-03-18 15:24:34,049] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:24:34,091] {logging_mixin.py:104} INFO - [2022-03-18 15:24:34,091] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:24:34,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:25:04,338] {scheduler_job.py:182} INFO - Started process (PID=6862) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:04,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:25:04,347] {logging_mixin.py:104} INFO - [2022-03-18 15:25:04,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:04,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:04,443] {logging_mixin.py:104} INFO - [2022-03-18 15:25:04,442] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:25:04,487] {logging_mixin.py:104} INFO - [2022-03-18 15:25:04,486] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:25:04,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 15:25:35,054] {scheduler_job.py:182} INFO - Started process (PID=6894) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:35,059] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:25:35,062] {logging_mixin.py:104} INFO - [2022-03-18 15:25:35,062] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:35,116] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:25:35,163] {logging_mixin.py:104} INFO - [2022-03-18 15:25:35,162] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:25:35,205] {logging_mixin.py:104} INFO - [2022-03-18 15:25:35,204] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:25:35,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 15:26:05,410] {scheduler_job.py:182} INFO - Started process (PID=6926) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:05,414] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:26:05,417] {logging_mixin.py:104} INFO - [2022-03-18 15:26:05,416] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:05,468] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:05,513] {logging_mixin.py:104} INFO - [2022-03-18 15:26:05,512] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:26:05,556] {logging_mixin.py:104} INFO - [2022-03-18 15:26:05,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:26:05,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 15:26:35,759] {scheduler_job.py:182} INFO - Started process (PID=6951) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:35,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:26:35,767] {logging_mixin.py:104} INFO - [2022-03-18 15:26:35,766] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:35,815] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:26:35,860] {logging_mixin.py:104} INFO - [2022-03-18 15:26:35,859] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:26:35,899] {logging_mixin.py:104} INFO - [2022-03-18 15:26:35,899] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:26:35,915] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:27:06,508] {scheduler_job.py:182} INFO - Started process (PID=6986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:06,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:27:06,514] {logging_mixin.py:104} INFO - [2022-03-18 15:27:06,514] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:06,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:06,607] {logging_mixin.py:104} INFO - [2022-03-18 15:27:06,607] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:27:06,650] {logging_mixin.py:104} INFO - [2022-03-18 15:27:06,650] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:27:06,667] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:27:37,468] {scheduler_job.py:182} INFO - Started process (PID=7012) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:37,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:27:37,475] {logging_mixin.py:104} INFO - [2022-03-18 15:27:37,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:37,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:27:37,570] {logging_mixin.py:104} INFO - [2022-03-18 15:27:37,569] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:27:37,614] {logging_mixin.py:104} INFO - [2022-03-18 15:27:37,613] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:27:37,629] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 15:28:08,338] {scheduler_job.py:182} INFO - Started process (PID=7044) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:08,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:28:08,345] {logging_mixin.py:104} INFO - [2022-03-18 15:28:08,344] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:08,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:08,438] {logging_mixin.py:104} INFO - [2022-03-18 15:28:08,437] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:28:08,478] {logging_mixin.py:104} INFO - [2022-03-18 15:28:08,478] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:28:08,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 15:28:39,093] {scheduler_job.py:182} INFO - Started process (PID=7076) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:39,097] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:28:39,100] {logging_mixin.py:104} INFO - [2022-03-18 15:28:39,099] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:39,151] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:28:39,192] {logging_mixin.py:104} INFO - [2022-03-18 15:28:39,192] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:28:39,232] {logging_mixin.py:104} INFO - [2022-03-18 15:28:39,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:28:39,248] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:29:09,341] {scheduler_job.py:182} INFO - Started process (PID=7107) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:09,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:29:09,347] {logging_mixin.py:104} INFO - [2022-03-18 15:29:09,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:09,399] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:09,446] {logging_mixin.py:104} INFO - [2022-03-18 15:29:09,446] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:29:09,492] {logging_mixin.py:104} INFO - [2022-03-18 15:29:09,492] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:29:09,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 15:29:39,929] {scheduler_job.py:182} INFO - Started process (PID=7140) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:39,933] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:29:39,936] {logging_mixin.py:104} INFO - [2022-03-18 15:29:39,935] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:39,987] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:29:40,029] {logging_mixin.py:104} INFO - [2022-03-18 15:29:40,029] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:29:40,067] {logging_mixin.py:104} INFO - [2022-03-18 15:29:40,067] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:29:40,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:30:10,265] {scheduler_job.py:182} INFO - Started process (PID=7172) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:10,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:30:10,272] {logging_mixin.py:104} INFO - [2022-03-18 15:30:10,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:10,323] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:10,365] {logging_mixin.py:104} INFO - [2022-03-18 15:30:10,365] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:30:10,404] {logging_mixin.py:104} INFO - [2022-03-18 15:30:10,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:30:10,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:30:40,735] {scheduler_job.py:182} INFO - Started process (PID=7204) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:40,739] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:30:40,742] {logging_mixin.py:104} INFO - [2022-03-18 15:30:40,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:40,791] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:30:40,833] {logging_mixin.py:104} INFO - [2022-03-18 15:30:40,833] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:30:40,871] {logging_mixin.py:104} INFO - [2022-03-18 15:30:40,871] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:30:40,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 15:31:11,560] {scheduler_job.py:182} INFO - Started process (PID=7236) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:11,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:31:11,566] {logging_mixin.py:104} INFO - [2022-03-18 15:31:11,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:11,612] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:11,658] {logging_mixin.py:104} INFO - [2022-03-18 15:31:11,658] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:31:11,699] {logging_mixin.py:104} INFO - [2022-03-18 15:31:11,699] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:31:11,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:31:41,882] {scheduler_job.py:182} INFO - Started process (PID=7260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:41,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:31:41,889] {logging_mixin.py:104} INFO - [2022-03-18 15:31:41,888] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:41,937] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:31:41,981] {logging_mixin.py:104} INFO - [2022-03-18 15:31:41,980] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:31:42,023] {logging_mixin.py:104} INFO - [2022-03-18 15:31:42,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:31:42,040] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:32:12,653] {scheduler_job.py:182} INFO - Started process (PID=7286) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:12,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:32:12,661] {logging_mixin.py:104} INFO - [2022-03-18 15:32:12,661] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:12,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:12,754] {logging_mixin.py:104} INFO - [2022-03-18 15:32:12,754] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:32:12,794] {logging_mixin.py:104} INFO - [2022-03-18 15:32:12,794] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:32:12,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 15:32:42,942] {scheduler_job.py:182} INFO - Started process (PID=7318) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:42,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:32:42,948] {logging_mixin.py:104} INFO - [2022-03-18 15:32:42,948] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:43,000] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:32:43,042] {logging_mixin.py:104} INFO - [2022-03-18 15:32:43,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:32:43,079] {logging_mixin.py:104} INFO - [2022-03-18 15:32:43,079] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:32:43,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 15:33:13,208] {scheduler_job.py:182} INFO - Started process (PID=7348) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:13,212] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:33:13,214] {logging_mixin.py:104} INFO - [2022-03-18 15:33:13,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:13,264] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:13,312] {logging_mixin.py:104} INFO - [2022-03-18 15:33:13,311] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:33:13,356] {logging_mixin.py:104} INFO - [2022-03-18 15:33:13,356] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:33:13,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 15:33:43,456] {scheduler_job.py:182} INFO - Started process (PID=7372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:43,461] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:33:43,465] {logging_mixin.py:104} INFO - [2022-03-18 15:33:43,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:43,522] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:33:43,570] {logging_mixin.py:104} INFO - [2022-03-18 15:33:43,569] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:33:43,610] {logging_mixin.py:104} INFO - [2022-03-18 15:33:43,609] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:33:43,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 15:34:14,559] {scheduler_job.py:182} INFO - Started process (PID=7414) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:14,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:34:14,566] {logging_mixin.py:104} INFO - [2022-03-18 15:34:14,565] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:14,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:14,662] {logging_mixin.py:104} INFO - [2022-03-18 15:34:14,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:34:14,702] {logging_mixin.py:104} INFO - [2022-03-18 15:34:14,701] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:34:14,718] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:34:44,899] {scheduler_job.py:182} INFO - Started process (PID=7446) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:44,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:34:44,906] {logging_mixin.py:104} INFO - [2022-03-18 15:34:44,905] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:44,963] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:34:45,006] {logging_mixin.py:104} INFO - [2022-03-18 15:34:45,005] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:34:45,046] {logging_mixin.py:104} INFO - [2022-03-18 15:34:45,046] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:34:45,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 15:35:15,783] {scheduler_job.py:182} INFO - Started process (PID=7478) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:15,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:35:15,789] {logging_mixin.py:104} INFO - [2022-03-18 15:35:15,789] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:15,840] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:15,883] {logging_mixin.py:104} INFO - [2022-03-18 15:35:15,883] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:35:15,921] {logging_mixin.py:104} INFO - [2022-03-18 15:35:15,921] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:35:15,937] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:35:46,537] {scheduler_job.py:182} INFO - Started process (PID=7510) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:46,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:35:46,544] {logging_mixin.py:104} INFO - [2022-03-18 15:35:46,544] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:46,593] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:35:46,636] {logging_mixin.py:104} INFO - [2022-03-18 15:35:46,635] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:35:46,678] {logging_mixin.py:104} INFO - [2022-03-18 15:35:46,677] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:35:46,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:36:16,840] {scheduler_job.py:182} INFO - Started process (PID=7535) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:16,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:36:16,846] {logging_mixin.py:104} INFO - [2022-03-18 15:36:16,846] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:16,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:16,941] {logging_mixin.py:104} INFO - [2022-03-18 15:36:16,940] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:36:16,984] {logging_mixin.py:104} INFO - [2022-03-18 15:36:16,983] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:36:17,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 15:36:47,613] {scheduler_job.py:182} INFO - Started process (PID=7560) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:47,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:36:47,621] {logging_mixin.py:104} INFO - [2022-03-18 15:36:47,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:47,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:36:47,718] {logging_mixin.py:104} INFO - [2022-03-18 15:36:47,717] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:36:47,776] {logging_mixin.py:104} INFO - [2022-03-18 15:36:47,775] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:36:47,792] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 15:37:18,061] {scheduler_job.py:182} INFO - Started process (PID=7592) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:18,066] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:37:18,068] {logging_mixin.py:104} INFO - [2022-03-18 15:37:18,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:18,121] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:18,162] {logging_mixin.py:104} INFO - [2022-03-18 15:37:18,162] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:37:18,200] {logging_mixin.py:104} INFO - [2022-03-18 15:37:18,200] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:37:18,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 15:37:48,845] {scheduler_job.py:182} INFO - Started process (PID=7624) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:48,849] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:37:48,852] {logging_mixin.py:104} INFO - [2022-03-18 15:37:48,852] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:48,902] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:37:48,944] {logging_mixin.py:104} INFO - [2022-03-18 15:37:48,943] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:37:48,982] {logging_mixin.py:104} INFO - [2022-03-18 15:37:48,982] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:37:48,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 15:38:19,196] {scheduler_job.py:182} INFO - Started process (PID=7656) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:19,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:38:19,205] {logging_mixin.py:104} INFO - [2022-03-18 15:38:19,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:19,255] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:19,297] {logging_mixin.py:104} INFO - [2022-03-18 15:38:19,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:38:19,335] {logging_mixin.py:104} INFO - [2022-03-18 15:38:19,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:38:19,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:38:49,470] {scheduler_job.py:182} INFO - Started process (PID=7686) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:49,474] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:38:49,477] {logging_mixin.py:104} INFO - [2022-03-18 15:38:49,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:49,527] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:38:49,576] {logging_mixin.py:104} INFO - [2022-03-18 15:38:49,575] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:38:49,619] {logging_mixin.py:104} INFO - [2022-03-18 15:38:49,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:38:49,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 15:39:19,990] {scheduler_job.py:182} INFO - Started process (PID=7720) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:19,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:39:19,997] {logging_mixin.py:104} INFO - [2022-03-18 15:39:19,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:20,047] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:20,089] {logging_mixin.py:104} INFO - [2022-03-18 15:39:20,088] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:39:20,128] {logging_mixin.py:104} INFO - [2022-03-18 15:39:20,128] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:39:20,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 15:39:50,402] {scheduler_job.py:182} INFO - Started process (PID=7752) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:50,406] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:39:50,409] {logging_mixin.py:104} INFO - [2022-03-18 15:39:50,409] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:50,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:39:50,502] {logging_mixin.py:104} INFO - [2022-03-18 15:39:50,502] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:39:50,543] {logging_mixin.py:104} INFO - [2022-03-18 15:39:50,542] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:39:50,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:40:21,189] {scheduler_job.py:182} INFO - Started process (PID=7784) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:21,192] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:40:21,194] {logging_mixin.py:104} INFO - [2022-03-18 15:40:21,194] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:21,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:21,285] {logging_mixin.py:104} INFO - [2022-03-18 15:40:21,285] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:40:21,327] {logging_mixin.py:104} INFO - [2022-03-18 15:40:21,326] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:40:21,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:40:51,459] {scheduler_job.py:182} INFO - Started process (PID=7809) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:51,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:40:51,467] {logging_mixin.py:104} INFO - [2022-03-18 15:40:51,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:51,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:40:51,559] {logging_mixin.py:104} INFO - [2022-03-18 15:40:51,559] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:40:51,603] {logging_mixin.py:104} INFO - [2022-03-18 15:40:51,602] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:40:51,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 15:41:22,468] {scheduler_job.py:182} INFO - Started process (PID=7834) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:22,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:41:22,474] {logging_mixin.py:104} INFO - [2022-03-18 15:41:22,474] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:22,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:22,570] {logging_mixin.py:104} INFO - [2022-03-18 15:41:22,570] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:41:22,610] {logging_mixin.py:104} INFO - [2022-03-18 15:41:22,609] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:41:22,625] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 15:41:52,927] {scheduler_job.py:182} INFO - Started process (PID=7866) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:52,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:41:52,934] {logging_mixin.py:104} INFO - [2022-03-18 15:41:52,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:52,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:41:53,025] {logging_mixin.py:104} INFO - [2022-03-18 15:41:53,025] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:41:53,064] {logging_mixin.py:104} INFO - [2022-03-18 15:41:53,064] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:41:53,080] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 15:42:23,838] {scheduler_job.py:182} INFO - Started process (PID=7898) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:23,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:42:23,844] {logging_mixin.py:104} INFO - [2022-03-18 15:42:23,844] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:23,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:23,942] {logging_mixin.py:104} INFO - [2022-03-18 15:42:23,942] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:42:23,982] {logging_mixin.py:104} INFO - [2022-03-18 15:42:23,981] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:42:23,997] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:42:54,171] {scheduler_job.py:182} INFO - Started process (PID=7930) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:54,174] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:42:54,177] {logging_mixin.py:104} INFO - [2022-03-18 15:42:54,177] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:54,227] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:42:54,270] {logging_mixin.py:104} INFO - [2022-03-18 15:42:54,269] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:42:54,310] {logging_mixin.py:104} INFO - [2022-03-18 15:42:54,310] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:42:54,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:43:24,536] {scheduler_job.py:182} INFO - Started process (PID=7962) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:24,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:43:24,543] {logging_mixin.py:104} INFO - [2022-03-18 15:43:24,543] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:24,595] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:24,635] {logging_mixin.py:104} INFO - [2022-03-18 15:43:24,635] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:43:24,674] {logging_mixin.py:104} INFO - [2022-03-18 15:43:24,673] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:43:24,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:43:54,843] {scheduler_job.py:182} INFO - Started process (PID=7994) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:54,849] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:43:54,852] {logging_mixin.py:104} INFO - [2022-03-18 15:43:54,851] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:54,900] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:43:54,943] {logging_mixin.py:104} INFO - [2022-03-18 15:43:54,943] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:43:54,983] {logging_mixin.py:104} INFO - [2022-03-18 15:43:54,982] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:43:54,999] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 15:44:25,602] {scheduler_job.py:182} INFO - Started process (PID=8026) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:25,606] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:44:25,609] {logging_mixin.py:104} INFO - [2022-03-18 15:44:25,609] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:25,662] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:25,705] {logging_mixin.py:104} INFO - [2022-03-18 15:44:25,705] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:44:25,745] {logging_mixin.py:104} INFO - [2022-03-18 15:44:25,745] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:44:25,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 15:44:56,387] {scheduler_job.py:182} INFO - Started process (PID=8058) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:56,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:44:56,393] {logging_mixin.py:104} INFO - [2022-03-18 15:44:56,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:56,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:44:56,490] {logging_mixin.py:104} INFO - [2022-03-18 15:44:56,489] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:44:56,532] {logging_mixin.py:104} INFO - [2022-03-18 15:44:56,532] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:44:56,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 15:45:26,611] {scheduler_job.py:182} INFO - Started process (PID=8077) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:26,615] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:45:26,618] {logging_mixin.py:104} INFO - [2022-03-18 15:45:26,617] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:26,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:26,711] {logging_mixin.py:104} INFO - [2022-03-18 15:45:26,711] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:45:26,754] {logging_mixin.py:104} INFO - [2022-03-18 15:45:26,753] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:45:26,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 15:45:57,666] {scheduler_job.py:182} INFO - Started process (PID=8114) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:57,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:45:57,673] {logging_mixin.py:104} INFO - [2022-03-18 15:45:57,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:57,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:45:57,768] {logging_mixin.py:104} INFO - [2022-03-18 15:45:57,768] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:45:57,811] {logging_mixin.py:104} INFO - [2022-03-18 15:45:57,810] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:45:57,828] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 15:46:28,691] {scheduler_job.py:182} INFO - Started process (PID=8140) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:28,695] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:46:28,698] {logging_mixin.py:104} INFO - [2022-03-18 15:46:28,697] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:28,751] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:28,792] {logging_mixin.py:104} INFO - [2022-03-18 15:46:28,791] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:46:28,831] {logging_mixin.py:104} INFO - [2022-03-18 15:46:28,831] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:46:28,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:46:59,036] {scheduler_job.py:182} INFO - Started process (PID=8172) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:59,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:46:59,044] {logging_mixin.py:104} INFO - [2022-03-18 15:46:59,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:59,098] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:46:59,139] {logging_mixin.py:104} INFO - [2022-03-18 15:46:59,139] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:46:59,177] {logging_mixin.py:104} INFO - [2022-03-18 15:46:59,176] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:46:59,191] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:47:29,395] {scheduler_job.py:182} INFO - Started process (PID=8204) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:29,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:47:29,404] {logging_mixin.py:104} INFO - [2022-03-18 15:47:29,403] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:29,451] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:29,495] {logging_mixin.py:104} INFO - [2022-03-18 15:47:29,494] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:47:29,535] {logging_mixin.py:104} INFO - [2022-03-18 15:47:29,534] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:47:29,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 15:47:59,823] {scheduler_job.py:182} INFO - Started process (PID=8238) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:59,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:47:59,829] {logging_mixin.py:104} INFO - [2022-03-18 15:47:59,829] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:59,874] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:47:59,915] {logging_mixin.py:104} INFO - [2022-03-18 15:47:59,915] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:47:59,953] {logging_mixin.py:104} INFO - [2022-03-18 15:47:59,953] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:47:59,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-18 15:48:30,142] {scheduler_job.py:182} INFO - Started process (PID=8268) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:48:30,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:48:30,148] {logging_mixin.py:104} INFO - [2022-03-18 15:48:30,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:48:30,200] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:48:30,246] {logging_mixin.py:104} INFO - [2022-03-18 15:48:30,245] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:48:30,284] {logging_mixin.py:104} INFO - [2022-03-18 15:48:30,284] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:48:30,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 15:49:00,379] {scheduler_job.py:182} INFO - Started process (PID=8299) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:00,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:49:00,386] {logging_mixin.py:104} INFO - [2022-03-18 15:49:00,385] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:00,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:00,488] {logging_mixin.py:104} INFO - [2022-03-18 15:49:00,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:49:00,532] {logging_mixin.py:104} INFO - [2022-03-18 15:49:00,531] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:49:00,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 15:49:31,328] {scheduler_job.py:182} INFO - Started process (PID=8332) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:31,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:49:31,336] {logging_mixin.py:104} INFO - [2022-03-18 15:49:31,334] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:31,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:49:31,433] {logging_mixin.py:104} INFO - [2022-03-18 15:49:31,432] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:49:31,478] {logging_mixin.py:104} INFO - [2022-03-18 15:49:31,477] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:49:31,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 15:50:02,391] {scheduler_job.py:182} INFO - Started process (PID=8351) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 15:50:02,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 15:50:02,414] {logging_mixin.py:104} INFO - [2022-03-18 15:50:02,414] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 15:50:02,465] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 15:50:02,529] {logging_mixin.py:104} INFO - [2022-03-18 15:50:02,529] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 15:50:02,582] {logging_mixin.py:104} INFO - [2022-03-18 15:50:02,582] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 15:50:02,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.220 seconds
[2022-03-18 16:05:21,198] {scheduler_job.py:182} INFO - Started process (PID=8382) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:21,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:05:21,213] {logging_mixin.py:104} INFO - [2022-03-18 16:05:21,212] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:21,284] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:21,358] {logging_mixin.py:104} INFO - [2022-03-18 16:05:21,357] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:05:21,433] {logging_mixin.py:104} INFO - [2022-03-18 16:05:21,433] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:05:21,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.273 seconds
[2022-03-18 16:05:51,605] {scheduler_job.py:182} INFO - Started process (PID=8408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:51,611] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:05:51,615] {logging_mixin.py:104} INFO - [2022-03-18 16:05:51,614] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:51,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:05:51,733] {logging_mixin.py:104} INFO - [2022-03-18 16:05:51,732] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:05:51,786] {logging_mixin.py:104} INFO - [2022-03-18 16:05:51,785] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:05:51,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.209 seconds
[2022-03-18 16:06:22,351] {scheduler_job.py:182} INFO - Started process (PID=8438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:22,356] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:06:22,359] {logging_mixin.py:104} INFO - [2022-03-18 16:06:22,358] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:22,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:22,458] {logging_mixin.py:104} INFO - [2022-03-18 16:06:22,457] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:06:22,501] {logging_mixin.py:104} INFO - [2022-03-18 16:06:22,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:06:22,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:06:53,324] {scheduler_job.py:182} INFO - Started process (PID=8470) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:53,329] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:06:53,333] {logging_mixin.py:104} INFO - [2022-03-18 16:06:53,333] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:53,390] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:06:53,442] {logging_mixin.py:104} INFO - [2022-03-18 16:06:53,442] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:06:53,490] {logging_mixin.py:104} INFO - [2022-03-18 16:06:53,490] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:06:53,507] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-18 16:07:23,943] {scheduler_job.py:182} INFO - Started process (PID=8502) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:23,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:07:23,951] {logging_mixin.py:104} INFO - [2022-03-18 16:07:23,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:24,006] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:24,055] {logging_mixin.py:104} INFO - [2022-03-18 16:07:24,054] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:07:24,100] {logging_mixin.py:104} INFO - [2022-03-18 16:07:24,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:07:24,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 16:07:54,702] {scheduler_job.py:182} INFO - Started process (PID=8535) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:54,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:07:54,709] {logging_mixin.py:104} INFO - [2022-03-18 16:07:54,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:54,759] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:07:54,808] {logging_mixin.py:104} INFO - [2022-03-18 16:07:54,808] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:07:54,852] {logging_mixin.py:104} INFO - [2022-03-18 16:07:54,852] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:07:54,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:08:25,315] {scheduler_job.py:182} INFO - Started process (PID=8567) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:25,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:08:25,324] {logging_mixin.py:104} INFO - [2022-03-18 16:08:25,324] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:25,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:25,425] {logging_mixin.py:104} INFO - [2022-03-18 16:08:25,424] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:08:25,469] {logging_mixin.py:104} INFO - [2022-03-18 16:08:25,469] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:08:25,486] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 16:08:56,069] {scheduler_job.py:182} INFO - Started process (PID=8600) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:56,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:08:56,075] {logging_mixin.py:104} INFO - [2022-03-18 16:08:56,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:56,128] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:08:56,174] {logging_mixin.py:104} INFO - [2022-03-18 16:08:56,174] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:08:56,218] {logging_mixin.py:104} INFO - [2022-03-18 16:08:56,218] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:08:56,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 16:09:28,645] {scheduler_job.py:182} INFO - Started process (PID=8632) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:28,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:09:28,653] {logging_mixin.py:104} INFO - [2022-03-18 16:09:28,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:28,704] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:28,753] {logging_mixin.py:104} INFO - [2022-03-18 16:09:28,753] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:09:28,795] {logging_mixin.py:104} INFO - [2022-03-18 16:09:28,794] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:09:28,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 16:09:59,429] {scheduler_job.py:182} INFO - Started process (PID=8652) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:59,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:09:59,437] {logging_mixin.py:104} INFO - [2022-03-18 16:09:59,437] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:59,491] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:09:59,534] {logging_mixin.py:104} INFO - [2022-03-18 16:09:59,533] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:09:59,576] {logging_mixin.py:104} INFO - [2022-03-18 16:09:59,575] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:09:59,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:10:30,147] {scheduler_job.py:182} INFO - Started process (PID=8684) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:10:30,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:10:30,155] {logging_mixin.py:104} INFO - [2022-03-18 16:10:30,155] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:10:30,206] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:10:30,251] {logging_mixin.py:104} INFO - [2022-03-18 16:10:30,250] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:10:30,292] {logging_mixin.py:104} INFO - [2022-03-18 16:10:30,292] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:10:30,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 16:11:00,816] {scheduler_job.py:182} INFO - Started process (PID=8716) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:00,821] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:11:00,824] {logging_mixin.py:104} INFO - [2022-03-18 16:11:00,824] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:00,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:00,925] {logging_mixin.py:104} INFO - [2022-03-18 16:11:00,925] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:11:00,967] {logging_mixin.py:104} INFO - [2022-03-18 16:11:00,967] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:11:00,981] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 16:11:31,514] {scheduler_job.py:182} INFO - Started process (PID=8748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:31,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:11:31,522] {logging_mixin.py:104} INFO - [2022-03-18 16:11:31,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:31,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:11:31,624] {logging_mixin.py:104} INFO - [2022-03-18 16:11:31,624] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:11:31,666] {logging_mixin.py:104} INFO - [2022-03-18 16:11:31,665] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:11:31,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 16:12:02,309] {scheduler_job.py:182} INFO - Started process (PID=8780) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:02,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:12:02,318] {logging_mixin.py:104} INFO - [2022-03-18 16:12:02,317] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:02,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:02,410] {logging_mixin.py:104} INFO - [2022-03-18 16:12:02,410] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:12:02,450] {logging_mixin.py:104} INFO - [2022-03-18 16:12:02,450] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:12:02,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 16:12:33,183] {scheduler_job.py:182} INFO - Started process (PID=8812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:33,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:12:33,192] {logging_mixin.py:104} INFO - [2022-03-18 16:12:33,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:33,242] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:12:33,287] {logging_mixin.py:104} INFO - [2022-03-18 16:12:33,286] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:12:33,328] {logging_mixin.py:104} INFO - [2022-03-18 16:12:33,327] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:12:33,344] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:13:03,954] {scheduler_job.py:182} INFO - Started process (PID=8844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:03,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:13:03,963] {logging_mixin.py:104} INFO - [2022-03-18 16:13:03,963] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:04,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:04,059] {logging_mixin.py:104} INFO - [2022-03-18 16:13:04,058] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:13:04,098] {logging_mixin.py:104} INFO - [2022-03-18 16:13:04,098] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:13:04,114] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 16:13:34,667] {scheduler_job.py:182} INFO - Started process (PID=8874) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:34,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:13:34,673] {logging_mixin.py:104} INFO - [2022-03-18 16:13:34,673] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:34,727] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:13:34,776] {logging_mixin.py:104} INFO - [2022-03-18 16:13:34,775] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:13:34,821] {logging_mixin.py:104} INFO - [2022-03-18 16:13:34,820] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:13:34,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 16:14:05,335] {scheduler_job.py:182} INFO - Started process (PID=8899) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:05,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:14:05,342] {logging_mixin.py:104} INFO - [2022-03-18 16:14:05,342] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:05,392] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:05,437] {logging_mixin.py:104} INFO - [2022-03-18 16:14:05,436] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:14:05,479] {logging_mixin.py:104} INFO - [2022-03-18 16:14:05,479] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:14:05,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 16:14:36,368] {scheduler_job.py:182} INFO - Started process (PID=8926) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:36,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:14:36,375] {logging_mixin.py:104} INFO - [2022-03-18 16:14:36,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:36,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:14:36,468] {logging_mixin.py:104} INFO - [2022-03-18 16:14:36,468] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:14:36,508] {logging_mixin.py:104} INFO - [2022-03-18 16:14:36,507] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:14:36,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 16:15:07,093] {scheduler_job.py:182} INFO - Started process (PID=8958) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:07,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:15:07,100] {logging_mixin.py:104} INFO - [2022-03-18 16:15:07,100] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:07,150] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:07,193] {logging_mixin.py:104} INFO - [2022-03-18 16:15:07,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:15:07,233] {logging_mixin.py:104} INFO - [2022-03-18 16:15:07,233] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:15:07,250] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 16:15:37,802] {scheduler_job.py:182} INFO - Started process (PID=8990) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:37,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:15:37,809] {logging_mixin.py:104} INFO - [2022-03-18 16:15:37,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:37,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:15:37,910] {logging_mixin.py:104} INFO - [2022-03-18 16:15:37,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:15:37,951] {logging_mixin.py:104} INFO - [2022-03-18 16:15:37,951] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:15:37,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 16:16:08,488] {scheduler_job.py:182} INFO - Started process (PID=9022) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:08,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:16:08,498] {logging_mixin.py:104} INFO - [2022-03-18 16:16:08,497] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:08,548] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:08,594] {logging_mixin.py:104} INFO - [2022-03-18 16:16:08,594] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:16:08,635] {logging_mixin.py:104} INFO - [2022-03-18 16:16:08,634] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:16:08,651] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 16:16:39,020] {scheduler_job.py:182} INFO - Started process (PID=9054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:39,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:16:39,027] {logging_mixin.py:104} INFO - [2022-03-18 16:16:39,027] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:39,078] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:16:39,122] {logging_mixin.py:104} INFO - [2022-03-18 16:16:39,122] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:16:39,163] {logging_mixin.py:104} INFO - [2022-03-18 16:16:39,163] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:16:39,179] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:17:09,609] {scheduler_job.py:182} INFO - Started process (PID=9086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:09,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:17:09,617] {logging_mixin.py:104} INFO - [2022-03-18 16:17:09,616] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:09,667] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:09,711] {logging_mixin.py:104} INFO - [2022-03-18 16:17:09,711] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:17:09,752] {logging_mixin.py:104} INFO - [2022-03-18 16:17:09,752] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:17:09,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:17:40,046] {scheduler_job.py:182} INFO - Started process (PID=9118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:40,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:17:40,054] {logging_mixin.py:104} INFO - [2022-03-18 16:17:40,054] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:40,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:17:40,149] {logging_mixin.py:104} INFO - [2022-03-18 16:17:40,148] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:17:40,190] {logging_mixin.py:104} INFO - [2022-03-18 16:17:40,190] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:17:40,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:18:10,485] {scheduler_job.py:182} INFO - Started process (PID=9148) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:10,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:18:10,491] {logging_mixin.py:104} INFO - [2022-03-18 16:18:10,491] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:10,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:10,586] {logging_mixin.py:104} INFO - [2022-03-18 16:18:10,586] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:18:10,627] {logging_mixin.py:104} INFO - [2022-03-18 16:18:10,626] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:18:10,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 16:18:41,291] {scheduler_job.py:182} INFO - Started process (PID=9172) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:41,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:18:41,298] {logging_mixin.py:104} INFO - [2022-03-18 16:18:41,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:41,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:18:41,395] {logging_mixin.py:104} INFO - [2022-03-18 16:18:41,394] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:18:41,445] {logging_mixin.py:104} INFO - [2022-03-18 16:18:41,444] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:18:41,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 16:19:12,074] {scheduler_job.py:182} INFO - Started process (PID=9200) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:12,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:19:12,083] {logging_mixin.py:104} INFO - [2022-03-18 16:19:12,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:12,132] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:12,178] {logging_mixin.py:104} INFO - [2022-03-18 16:19:12,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:19:12,219] {logging_mixin.py:104} INFO - [2022-03-18 16:19:12,218] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:19:12,239] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 16:19:42,596] {scheduler_job.py:182} INFO - Started process (PID=9232) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:42,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:19:42,603] {logging_mixin.py:104} INFO - [2022-03-18 16:19:42,603] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:42,654] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:19:42,699] {logging_mixin.py:104} INFO - [2022-03-18 16:19:42,699] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:19:42,740] {logging_mixin.py:104} INFO - [2022-03-18 16:19:42,740] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:19:42,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 16:20:12,980] {scheduler_job.py:182} INFO - Started process (PID=9264) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:12,984] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:20:12,986] {logging_mixin.py:104} INFO - [2022-03-18 16:20:12,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:13,040] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:13,087] {logging_mixin.py:104} INFO - [2022-03-18 16:20:13,086] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:20:13,129] {logging_mixin.py:104} INFO - [2022-03-18 16:20:13,129] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:20:13,149] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 16:20:43,494] {scheduler_job.py:182} INFO - Started process (PID=9296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:43,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:20:43,501] {logging_mixin.py:104} INFO - [2022-03-18 16:20:43,501] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:43,550] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:20:43,592] {logging_mixin.py:104} INFO - [2022-03-18 16:20:43,592] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:20:43,636] {logging_mixin.py:104} INFO - [2022-03-18 16:20:43,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:20:43,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 16:21:14,316] {scheduler_job.py:182} INFO - Started process (PID=9328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:14,320] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:21:14,323] {logging_mixin.py:104} INFO - [2022-03-18 16:21:14,322] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:14,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:14,426] {logging_mixin.py:104} INFO - [2022-03-18 16:21:14,425] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:21:14,469] {logging_mixin.py:104} INFO - [2022-03-18 16:21:14,469] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:21:14,485] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 16:21:44,986] {scheduler_job.py:182} INFO - Started process (PID=9360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:44,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:21:44,993] {logging_mixin.py:104} INFO - [2022-03-18 16:21:44,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:45,042] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:21:45,084] {logging_mixin.py:104} INFO - [2022-03-18 16:21:45,084] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:21:45,127] {logging_mixin.py:104} INFO - [2022-03-18 16:21:45,126] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:21:45,144] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:22:15,554] {scheduler_job.py:182} INFO - Started process (PID=9392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:15,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:22:15,562] {logging_mixin.py:104} INFO - [2022-03-18 16:22:15,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:15,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:15,658] {logging_mixin.py:104} INFO - [2022-03-18 16:22:15,657] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:22:15,698] {logging_mixin.py:104} INFO - [2022-03-18 16:22:15,698] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:22:15,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:22:46,306] {scheduler_job.py:182} INFO - Started process (PID=9422) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:46,310] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:22:46,313] {logging_mixin.py:104} INFO - [2022-03-18 16:22:46,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:46,364] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:22:46,410] {logging_mixin.py:104} INFO - [2022-03-18 16:22:46,409] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:22:46,452] {logging_mixin.py:104} INFO - [2022-03-18 16:22:46,452] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:22:46,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:23:17,164] {scheduler_job.py:182} INFO - Started process (PID=9446) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:17,168] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:23:17,171] {logging_mixin.py:104} INFO - [2022-03-18 16:23:17,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:17,222] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:17,268] {logging_mixin.py:104} INFO - [2022-03-18 16:23:17,268] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:23:17,313] {logging_mixin.py:104} INFO - [2022-03-18 16:23:17,312] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:23:17,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:23:47,626] {scheduler_job.py:182} INFO - Started process (PID=9474) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:47,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:23:47,634] {logging_mixin.py:104} INFO - [2022-03-18 16:23:47,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:47,682] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:23:47,726] {logging_mixin.py:104} INFO - [2022-03-18 16:23:47,726] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:23:47,768] {logging_mixin.py:104} INFO - [2022-03-18 16:23:47,767] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:23:47,784] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 16:24:17,997] {scheduler_job.py:182} INFO - Started process (PID=9506) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:18,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:24:18,003] {logging_mixin.py:104} INFO - [2022-03-18 16:24:18,002] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:18,049] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:18,091] {logging_mixin.py:104} INFO - [2022-03-18 16:24:18,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:24:18,130] {logging_mixin.py:104} INFO - [2022-03-18 16:24:18,130] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:24:18,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 16:24:48,302] {scheduler_job.py:182} INFO - Started process (PID=9538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:48,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:24:48,308] {logging_mixin.py:104} INFO - [2022-03-18 16:24:48,307] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:48,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:24:48,397] {logging_mixin.py:104} INFO - [2022-03-18 16:24:48,397] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:24:48,435] {logging_mixin.py:104} INFO - [2022-03-18 16:24:48,435] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:24:48,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 16:25:18,725] {scheduler_job.py:182} INFO - Started process (PID=9570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:18,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:25:18,755] {logging_mixin.py:104} INFO - [2022-03-18 16:25:18,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:18,824] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:18,880] {logging_mixin.py:104} INFO - [2022-03-18 16:25:18,880] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:25:18,925] {logging_mixin.py:104} INFO - [2022-03-18 16:25:18,925] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:25:18,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.262 seconds
[2022-03-18 16:25:49,303] {scheduler_job.py:182} INFO - Started process (PID=9602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:49,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:25:49,311] {logging_mixin.py:104} INFO - [2022-03-18 16:25:49,311] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:49,360] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:25:49,403] {logging_mixin.py:104} INFO - [2022-03-18 16:25:49,403] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:25:49,443] {logging_mixin.py:104} INFO - [2022-03-18 16:25:49,443] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:25:49,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 16:26:19,640] {scheduler_job.py:182} INFO - Started process (PID=9634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:19,645] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:26:19,648] {logging_mixin.py:104} INFO - [2022-03-18 16:26:19,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:19,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:19,745] {logging_mixin.py:104} INFO - [2022-03-18 16:26:19,745] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:26:19,783] {logging_mixin.py:104} INFO - [2022-03-18 16:26:19,783] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:26:19,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 16:26:50,211] {scheduler_job.py:182} INFO - Started process (PID=9666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:50,214] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:26:50,216] {logging_mixin.py:104} INFO - [2022-03-18 16:26:50,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:50,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:26:50,305] {logging_mixin.py:104} INFO - [2022-03-18 16:26:50,304] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:26:50,347] {logging_mixin.py:104} INFO - [2022-03-18 16:26:50,347] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:26:50,363] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 16:27:20,438] {scheduler_job.py:182} INFO - Started process (PID=9691) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:20,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:27:20,445] {logging_mixin.py:104} INFO - [2022-03-18 16:27:20,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:20,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:20,547] {logging_mixin.py:104} INFO - [2022-03-18 16:27:20,546] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:27:20,590] {logging_mixin.py:104} INFO - [2022-03-18 16:27:20,589] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:27:20,607] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 16:27:51,071] {scheduler_job.py:182} INFO - Started process (PID=9716) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:51,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:27:51,079] {logging_mixin.py:104} INFO - [2022-03-18 16:27:51,079] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:51,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:27:51,174] {logging_mixin.py:104} INFO - [2022-03-18 16:27:51,174] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:27:51,217] {logging_mixin.py:104} INFO - [2022-03-18 16:27:51,217] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:27:51,234] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 16:28:21,356] {scheduler_job.py:182} INFO - Started process (PID=9748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:21,362] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:28:21,365] {logging_mixin.py:104} INFO - [2022-03-18 16:28:21,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:21,408] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:21,449] {logging_mixin.py:104} INFO - [2022-03-18 16:28:21,448] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:28:21,487] {logging_mixin.py:104} INFO - [2022-03-18 16:28:21,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:28:21,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-18 16:28:52,008] {scheduler_job.py:182} INFO - Started process (PID=9780) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:52,014] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:28:52,017] {logging_mixin.py:104} INFO - [2022-03-18 16:28:52,016] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:52,067] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:28:52,110] {logging_mixin.py:104} INFO - [2022-03-18 16:28:52,110] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:28:52,148] {logging_mixin.py:104} INFO - [2022-03-18 16:28:52,148] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:28:52,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 16:29:22,639] {scheduler_job.py:182} INFO - Started process (PID=9812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:22,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:29:22,649] {logging_mixin.py:104} INFO - [2022-03-18 16:29:22,648] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:22,700] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:22,744] {logging_mixin.py:104} INFO - [2022-03-18 16:29:22,743] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:29:22,783] {logging_mixin.py:104} INFO - [2022-03-18 16:29:22,783] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:29:22,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:29:53,277] {scheduler_job.py:182} INFO - Started process (PID=9844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:53,281] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:29:53,284] {logging_mixin.py:104} INFO - [2022-03-18 16:29:53,283] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:53,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:29:53,375] {logging_mixin.py:104} INFO - [2022-03-18 16:29:53,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:29:53,415] {logging_mixin.py:104} INFO - [2022-03-18 16:29:53,414] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:29:53,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 16:30:23,944] {scheduler_job.py:182} INFO - Started process (PID=9876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:23,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:30:23,950] {logging_mixin.py:104} INFO - [2022-03-18 16:30:23,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:23,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:24,040] {logging_mixin.py:104} INFO - [2022-03-18 16:30:24,040] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:30:24,078] {logging_mixin.py:104} INFO - [2022-03-18 16:30:24,077] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:30:24,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 16:30:54,576] {scheduler_job.py:182} INFO - Started process (PID=9908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:54,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:30:54,584] {logging_mixin.py:104} INFO - [2022-03-18 16:30:54,583] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:54,633] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:30:54,675] {logging_mixin.py:104} INFO - [2022-03-18 16:30:54,675] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:30:54,716] {logging_mixin.py:104} INFO - [2022-03-18 16:30:54,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:30:54,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 16:31:25,326] {scheduler_job.py:182} INFO - Started process (PID=9938) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:25,332] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:31:25,335] {logging_mixin.py:104} INFO - [2022-03-18 16:31:25,334] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:25,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:25,431] {logging_mixin.py:104} INFO - [2022-03-18 16:31:25,430] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:31:25,473] {logging_mixin.py:104} INFO - [2022-03-18 16:31:25,473] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:31:25,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 16:31:56,011] {scheduler_job.py:182} INFO - Started process (PID=9963) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:56,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:31:56,019] {logging_mixin.py:104} INFO - [2022-03-18 16:31:56,018] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:56,068] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:31:56,114] {logging_mixin.py:104} INFO - [2022-03-18 16:31:56,114] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:31:56,186] {logging_mixin.py:104} INFO - [2022-03-18 16:31:56,185] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:31:56,204] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.199 seconds
[2022-03-18 16:32:26,705] {scheduler_job.py:182} INFO - Started process (PID=9990) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:26,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:32:26,714] {logging_mixin.py:104} INFO - [2022-03-18 16:32:26,714] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:26,763] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:26,805] {logging_mixin.py:104} INFO - [2022-03-18 16:32:26,804] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:32:26,843] {logging_mixin.py:104} INFO - [2022-03-18 16:32:26,843] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:32:26,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 16:32:57,145] {scheduler_job.py:182} INFO - Started process (PID=10022) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:57,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:32:57,151] {logging_mixin.py:104} INFO - [2022-03-18 16:32:57,151] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:57,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:32:57,237] {logging_mixin.py:104} INFO - [2022-03-18 16:32:57,237] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:32:57,276] {logging_mixin.py:104} INFO - [2022-03-18 16:32:57,275] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:32:57,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-18 16:33:27,729] {scheduler_job.py:182} INFO - Started process (PID=10054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:27,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:33:27,736] {logging_mixin.py:104} INFO - [2022-03-18 16:33:27,736] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:27,784] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:27,824] {logging_mixin.py:104} INFO - [2022-03-18 16:33:27,824] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:33:27,862] {logging_mixin.py:104} INFO - [2022-03-18 16:33:27,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:33:27,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 16:33:58,108] {scheduler_job.py:182} INFO - Started process (PID=10086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:58,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:33:58,115] {logging_mixin.py:104} INFO - [2022-03-18 16:33:58,115] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:58,164] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:33:58,205] {logging_mixin.py:104} INFO - [2022-03-18 16:33:58,204] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:33:58,244] {logging_mixin.py:104} INFO - [2022-03-18 16:33:58,243] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:33:58,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 16:34:28,607] {scheduler_job.py:182} INFO - Started process (PID=10118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:28,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:34:28,617] {logging_mixin.py:104} INFO - [2022-03-18 16:34:28,616] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:28,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:28,710] {logging_mixin.py:104} INFO - [2022-03-18 16:34:28,710] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:34:28,748] {logging_mixin.py:104} INFO - [2022-03-18 16:34:28,748] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:34:28,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 16:34:59,130] {scheduler_job.py:182} INFO - Started process (PID=10150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:59,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:34:59,138] {logging_mixin.py:104} INFO - [2022-03-18 16:34:59,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:59,186] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:34:59,228] {logging_mixin.py:104} INFO - [2022-03-18 16:34:59,228] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:34:59,266] {logging_mixin.py:104} INFO - [2022-03-18 16:34:59,266] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:34:59,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 16:35:29,442] {scheduler_job.py:182} INFO - Started process (PID=10182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:35:29,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:35:29,451] {logging_mixin.py:104} INFO - [2022-03-18 16:35:29,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:35:29,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:35:29,540] {logging_mixin.py:104} INFO - [2022-03-18 16:35:29,540] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:35:29,580] {logging_mixin.py:104} INFO - [2022-03-18 16:35:29,579] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:35:29,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 16:36:00,095] {scheduler_job.py:182} INFO - Started process (PID=10212) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:00,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:36:00,102] {logging_mixin.py:104} INFO - [2022-03-18 16:36:00,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:00,150] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:00,197] {logging_mixin.py:104} INFO - [2022-03-18 16:36:00,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:36:00,239] {logging_mixin.py:104} INFO - [2022-03-18 16:36:00,238] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:36:00,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 16:36:30,902] {scheduler_job.py:182} INFO - Started process (PID=10236) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:30,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:36:30,909] {logging_mixin.py:104} INFO - [2022-03-18 16:36:30,908] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:30,958] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:36:31,005] {logging_mixin.py:104} INFO - [2022-03-18 16:36:31,005] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:36:31,050] {logging_mixin.py:104} INFO - [2022-03-18 16:36:31,049] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:36:31,069] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 16:37:01,379] {scheduler_job.py:182} INFO - Started process (PID=10264) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:01,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:37:01,387] {logging_mixin.py:104} INFO - [2022-03-18 16:37:01,386] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:01,433] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:01,476] {logging_mixin.py:104} INFO - [2022-03-18 16:37:01,476] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:37:01,515] {logging_mixin.py:104} INFO - [2022-03-18 16:37:01,514] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:37:01,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 16:37:31,737] {scheduler_job.py:182} INFO - Started process (PID=10296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:31,743] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:37:31,745] {logging_mixin.py:104} INFO - [2022-03-18 16:37:31,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:31,792] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:37:31,835] {logging_mixin.py:104} INFO - [2022-03-18 16:37:31,835] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:37:31,873] {logging_mixin.py:104} INFO - [2022-03-18 16:37:31,873] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:37:31,888] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 16:38:02,417] {scheduler_job.py:182} INFO - Started process (PID=10328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:02,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:38:02,426] {logging_mixin.py:104} INFO - [2022-03-18 16:38:02,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:02,474] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:02,516] {logging_mixin.py:104} INFO - [2022-03-18 16:38:02,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:38:02,555] {logging_mixin.py:104} INFO - [2022-03-18 16:38:02,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:38:02,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 16:38:33,063] {scheduler_job.py:182} INFO - Started process (PID=10360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:33,068] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:38:33,071] {logging_mixin.py:104} INFO - [2022-03-18 16:38:33,071] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:33,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:38:33,163] {logging_mixin.py:104} INFO - [2022-03-18 16:38:33,163] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:38:33,202] {logging_mixin.py:104} INFO - [2022-03-18 16:38:33,201] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:38:33,217] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 16:39:03,737] {scheduler_job.py:182} INFO - Started process (PID=10392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:03,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:39:03,745] {logging_mixin.py:104} INFO - [2022-03-18 16:39:03,745] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:03,792] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:03,833] {logging_mixin.py:104} INFO - [2022-03-18 16:39:03,832] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:39:03,870] {logging_mixin.py:104} INFO - [2022-03-18 16:39:03,870] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:39:03,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 16:39:34,441] {scheduler_job.py:182} INFO - Started process (PID=10424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:34,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:39:34,449] {logging_mixin.py:104} INFO - [2022-03-18 16:39:34,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:34,497] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:39:34,539] {logging_mixin.py:104} INFO - [2022-03-18 16:39:34,538] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:39:34,578] {logging_mixin.py:104} INFO - [2022-03-18 16:39:34,578] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:39:34,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 16:40:05,266] {scheduler_job.py:182} INFO - Started process (PID=10456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:05,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:40:05,275] {logging_mixin.py:104} INFO - [2022-03-18 16:40:05,275] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:05,321] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:05,365] {logging_mixin.py:104} INFO - [2022-03-18 16:40:05,364] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:40:05,404] {logging_mixin.py:104} INFO - [2022-03-18 16:40:05,404] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:40:05,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:40:36,143] {scheduler_job.py:182} INFO - Started process (PID=10486) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:36,149] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:40:36,151] {logging_mixin.py:104} INFO - [2022-03-18 16:40:36,151] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:36,200] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:40:36,246] {logging_mixin.py:104} INFO - [2022-03-18 16:40:36,245] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:40:36,288] {logging_mixin.py:104} INFO - [2022-03-18 16:40:36,288] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:40:36,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:41:06,502] {scheduler_job.py:182} INFO - Started process (PID=10511) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:06,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:41:06,508] {logging_mixin.py:104} INFO - [2022-03-18 16:41:06,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:06,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:06,604] {logging_mixin.py:104} INFO - [2022-03-18 16:41:06,603] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:41:06,648] {logging_mixin.py:104} INFO - [2022-03-18 16:41:06,648] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:41:06,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:41:37,227] {scheduler_job.py:182} INFO - Started process (PID=10538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:37,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:41:37,235] {logging_mixin.py:104} INFO - [2022-03-18 16:41:37,235] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:37,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:41:37,324] {logging_mixin.py:104} INFO - [2022-03-18 16:41:37,324] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:41:37,362] {logging_mixin.py:104} INFO - [2022-03-18 16:41:37,362] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:41:37,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 16:42:07,700] {scheduler_job.py:182} INFO - Started process (PID=10570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:07,705] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:42:07,708] {logging_mixin.py:104} INFO - [2022-03-18 16:42:07,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:07,758] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:07,801] {logging_mixin.py:104} INFO - [2022-03-18 16:42:07,801] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:42:07,841] {logging_mixin.py:104} INFO - [2022-03-18 16:42:07,841] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:42:07,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 16:42:38,164] {scheduler_job.py:182} INFO - Started process (PID=10602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:38,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:42:38,173] {logging_mixin.py:104} INFO - [2022-03-18 16:42:38,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:38,222] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:42:38,264] {logging_mixin.py:104} INFO - [2022-03-18 16:42:38,264] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:42:38,304] {logging_mixin.py:104} INFO - [2022-03-18 16:42:38,304] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:42:38,319] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 16:43:08,580] {scheduler_job.py:182} INFO - Started process (PID=10634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:08,584] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:43:08,588] {logging_mixin.py:104} INFO - [2022-03-18 16:43:08,587] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:08,634] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:08,675] {logging_mixin.py:104} INFO - [2022-03-18 16:43:08,674] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:43:08,713] {logging_mixin.py:104} INFO - [2022-03-18 16:43:08,713] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:43:08,728] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 16:43:38,950] {scheduler_job.py:182} INFO - Started process (PID=10666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:38,955] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:43:38,957] {logging_mixin.py:104} INFO - [2022-03-18 16:43:38,957] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:39,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:43:39,046] {logging_mixin.py:104} INFO - [2022-03-18 16:43:39,046] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:43:39,084] {logging_mixin.py:104} INFO - [2022-03-18 16:43:39,084] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:43:39,098] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 16:44:09,318] {scheduler_job.py:182} INFO - Started process (PID=10698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:09,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:44:09,326] {logging_mixin.py:104} INFO - [2022-03-18 16:44:09,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:09,373] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:09,415] {logging_mixin.py:104} INFO - [2022-03-18 16:44:09,414] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:44:09,452] {logging_mixin.py:104} INFO - [2022-03-18 16:44:09,452] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:44:09,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 16:44:39,794] {scheduler_job.py:182} INFO - Started process (PID=10730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:39,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:44:39,803] {logging_mixin.py:104} INFO - [2022-03-18 16:44:39,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:39,851] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:44:39,893] {logging_mixin.py:104} INFO - [2022-03-18 16:44:39,893] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:44:39,932] {logging_mixin.py:104} INFO - [2022-03-18 16:44:39,931] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:44:39,946] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:45:10,297] {scheduler_job.py:182} INFO - Started process (PID=10760) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:10,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:45:10,304] {logging_mixin.py:104} INFO - [2022-03-18 16:45:10,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:10,351] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:10,397] {logging_mixin.py:104} INFO - [2022-03-18 16:45:10,397] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:45:10,438] {logging_mixin.py:104} INFO - [2022-03-18 16:45:10,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:45:10,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:45:40,948] {scheduler_job.py:182} INFO - Started process (PID=10784) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:40,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:45:40,956] {logging_mixin.py:104} INFO - [2022-03-18 16:45:40,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:41,009] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:45:41,054] {logging_mixin.py:104} INFO - [2022-03-18 16:45:41,054] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:45:41,097] {logging_mixin.py:104} INFO - [2022-03-18 16:45:41,097] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:45:41,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:46:11,515] {scheduler_job.py:182} INFO - Started process (PID=10812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:11,529] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:46:11,532] {logging_mixin.py:104} INFO - [2022-03-18 16:46:11,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:11,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:11,657] {logging_mixin.py:104} INFO - [2022-03-18 16:46:11,656] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:46:11,716] {logging_mixin.py:104} INFO - [2022-03-18 16:46:11,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:46:11,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.255 seconds
[2022-03-18 16:46:42,407] {scheduler_job.py:182} INFO - Started process (PID=10844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:42,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:46:42,416] {logging_mixin.py:104} INFO - [2022-03-18 16:46:42,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:42,465] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:46:42,508] {logging_mixin.py:104} INFO - [2022-03-18 16:46:42,507] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:46:42,545] {logging_mixin.py:104} INFO - [2022-03-18 16:46:42,545] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:46:42,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 16:47:12,977] {scheduler_job.py:182} INFO - Started process (PID=10876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:12,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:47:12,986] {logging_mixin.py:104} INFO - [2022-03-18 16:47:12,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:13,036] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:13,078] {logging_mixin.py:104} INFO - [2022-03-18 16:47:13,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:47:13,115] {logging_mixin.py:104} INFO - [2022-03-18 16:47:13,115] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:47:13,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:47:43,571] {scheduler_job.py:182} INFO - Started process (PID=10908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:43,575] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:47:43,577] {logging_mixin.py:104} INFO - [2022-03-18 16:47:43,577] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:43,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:47:43,674] {logging_mixin.py:104} INFO - [2022-03-18 16:47:43,673] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:47:43,711] {logging_mixin.py:104} INFO - [2022-03-18 16:47:43,711] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:47:43,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:48:14,166] {scheduler_job.py:182} INFO - Started process (PID=10940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:14,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:48:14,173] {logging_mixin.py:104} INFO - [2022-03-18 16:48:14,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:14,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:14,263] {logging_mixin.py:104} INFO - [2022-03-18 16:48:14,262] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:48:14,300] {logging_mixin.py:104} INFO - [2022-03-18 16:48:14,300] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:48:14,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 16:48:44,820] {scheduler_job.py:182} INFO - Started process (PID=10972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:44,825] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:48:44,827] {logging_mixin.py:104} INFO - [2022-03-18 16:48:44,827] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:44,876] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:48:44,918] {logging_mixin.py:104} INFO - [2022-03-18 16:48:44,918] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:48:44,975] {logging_mixin.py:104} INFO - [2022-03-18 16:48:44,974] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:48:45,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.229 seconds
[2022-03-18 16:49:15,594] {scheduler_job.py:182} INFO - Started process (PID=11002) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:15,599] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:49:15,602] {logging_mixin.py:104} INFO - [2022-03-18 16:49:15,601] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:15,654] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:15,697] {logging_mixin.py:104} INFO - [2022-03-18 16:49:15,697] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:49:15,736] {logging_mixin.py:104} INFO - [2022-03-18 16:49:15,736] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:49:15,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 16:49:46,294] {scheduler_job.py:182} INFO - Started process (PID=11027) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:46,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:49:46,302] {logging_mixin.py:104} INFO - [2022-03-18 16:49:46,301] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:46,352] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:49:46,400] {logging_mixin.py:104} INFO - [2022-03-18 16:49:46,399] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:49:46,443] {logging_mixin.py:104} INFO - [2022-03-18 16:49:46,442] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:49:46,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 16:50:17,170] {scheduler_job.py:182} INFO - Started process (PID=11054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:17,176] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:50:17,179] {logging_mixin.py:104} INFO - [2022-03-18 16:50:17,179] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:17,230] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:17,272] {logging_mixin.py:104} INFO - [2022-03-18 16:50:17,271] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:50:17,309] {logging_mixin.py:104} INFO - [2022-03-18 16:50:17,309] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:50:17,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 16:50:47,855] {scheduler_job.py:182} INFO - Started process (PID=11086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:47,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:50:47,863] {logging_mixin.py:104} INFO - [2022-03-18 16:50:47,863] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:47,911] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:50:47,953] {logging_mixin.py:104} INFO - [2022-03-18 16:50:47,953] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:50:47,992] {logging_mixin.py:104} INFO - [2022-03-18 16:50:47,992] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:50:48,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 16:51:18,429] {scheduler_job.py:182} INFO - Started process (PID=11118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:18,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:51:18,437] {logging_mixin.py:104} INFO - [2022-03-18 16:51:18,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:18,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:18,530] {logging_mixin.py:104} INFO - [2022-03-18 16:51:18,530] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:51:18,570] {logging_mixin.py:104} INFO - [2022-03-18 16:51:18,570] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:51:18,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 16:51:49,060] {scheduler_job.py:182} INFO - Started process (PID=11150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:49,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:51:49,068] {logging_mixin.py:104} INFO - [2022-03-18 16:51:49,067] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:49,114] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:51:49,156] {logging_mixin.py:104} INFO - [2022-03-18 16:51:49,156] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:51:49,195] {logging_mixin.py:104} INFO - [2022-03-18 16:51:49,195] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:51:49,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 16:52:19,815] {scheduler_job.py:182} INFO - Started process (PID=11182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:19,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:52:19,823] {logging_mixin.py:104} INFO - [2022-03-18 16:52:19,823] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:19,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:19,913] {logging_mixin.py:104} INFO - [2022-03-18 16:52:19,913] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:52:19,951] {logging_mixin.py:104} INFO - [2022-03-18 16:52:19,950] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:52:19,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 16:52:50,462] {scheduler_job.py:182} INFO - Started process (PID=11214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:50,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:52:50,469] {logging_mixin.py:104} INFO - [2022-03-18 16:52:50,469] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:50,516] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:52:50,557] {logging_mixin.py:104} INFO - [2022-03-18 16:52:50,557] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:52:50,595] {logging_mixin.py:104} INFO - [2022-03-18 16:52:50,595] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:52:50,610] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 16:53:21,129] {scheduler_job.py:182} INFO - Started process (PID=11246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:21,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:53:21,137] {logging_mixin.py:104} INFO - [2022-03-18 16:53:21,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:21,184] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:21,225] {logging_mixin.py:104} INFO - [2022-03-18 16:53:21,225] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:53:21,264] {logging_mixin.py:104} INFO - [2022-03-18 16:53:21,264] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:53:21,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 16:53:51,818] {scheduler_job.py:182} INFO - Started process (PID=11276) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:51,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:53:51,827] {logging_mixin.py:104} INFO - [2022-03-18 16:53:51,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:51,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:53:51,927] {logging_mixin.py:104} INFO - [2022-03-18 16:53:51,926] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:53:51,969] {logging_mixin.py:104} INFO - [2022-03-18 16:53:51,969] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:53:51,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 16:54:22,500] {scheduler_job.py:182} INFO - Started process (PID=11301) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:22,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:54:22,507] {logging_mixin.py:104} INFO - [2022-03-18 16:54:22,506] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:22,558] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:22,603] {logging_mixin.py:104} INFO - [2022-03-18 16:54:22,602] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:54:22,645] {logging_mixin.py:104} INFO - [2022-03-18 16:54:22,645] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:54:22,663] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 16:54:53,058] {scheduler_job.py:182} INFO - Started process (PID=11328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:53,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:54:53,067] {logging_mixin.py:104} INFO - [2022-03-18 16:54:53,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:53,115] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:54:53,159] {logging_mixin.py:104} INFO - [2022-03-18 16:54:53,159] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:54:53,198] {logging_mixin.py:104} INFO - [2022-03-18 16:54:53,198] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:54:53,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 16:55:23,651] {scheduler_job.py:182} INFO - Started process (PID=11360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:23,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:55:23,659] {logging_mixin.py:104} INFO - [2022-03-18 16:55:23,658] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:23,710] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:23,753] {logging_mixin.py:104} INFO - [2022-03-18 16:55:23,752] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:55:23,792] {logging_mixin.py:104} INFO - [2022-03-18 16:55:23,791] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:55:23,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 16:55:54,341] {scheduler_job.py:182} INFO - Started process (PID=11392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:54,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:55:54,350] {logging_mixin.py:104} INFO - [2022-03-18 16:55:54,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:54,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:55:54,447] {logging_mixin.py:104} INFO - [2022-03-18 16:55:54,447] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:55:54,489] {logging_mixin.py:104} INFO - [2022-03-18 16:55:54,489] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:55:54,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:56:24,881] {scheduler_job.py:182} INFO - Started process (PID=11424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:24,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:56:24,888] {logging_mixin.py:104} INFO - [2022-03-18 16:56:24,888] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:24,936] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:24,979] {logging_mixin.py:104} INFO - [2022-03-18 16:56:24,979] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:56:25,019] {logging_mixin.py:104} INFO - [2022-03-18 16:56:25,018] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:56:25,035] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:56:55,478] {scheduler_job.py:182} INFO - Started process (PID=11456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:55,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:56:55,485] {logging_mixin.py:104} INFO - [2022-03-18 16:56:55,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:55,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:56:55,579] {logging_mixin.py:104} INFO - [2022-03-18 16:56:55,579] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:56:55,619] {logging_mixin.py:104} INFO - [2022-03-18 16:56:55,618] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:56:55,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 16:57:26,231] {scheduler_job.py:182} INFO - Started process (PID=11488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:26,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:57:26,239] {logging_mixin.py:104} INFO - [2022-03-18 16:57:26,239] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:26,289] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:26,330] {logging_mixin.py:104} INFO - [2022-03-18 16:57:26,330] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:57:26,370] {logging_mixin.py:104} INFO - [2022-03-18 16:57:26,370] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:57:26,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 16:57:56,848] {scheduler_job.py:182} INFO - Started process (PID=11520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:56,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:57:56,854] {logging_mixin.py:104} INFO - [2022-03-18 16:57:56,854] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:56,900] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:57:56,942] {logging_mixin.py:104} INFO - [2022-03-18 16:57:56,942] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:57:56,981] {logging_mixin.py:104} INFO - [2022-03-18 16:57:56,981] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:57:56,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 16:58:27,442] {scheduler_job.py:182} INFO - Started process (PID=11550) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:27,446] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:58:27,449] {logging_mixin.py:104} INFO - [2022-03-18 16:58:27,448] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:27,497] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:27,543] {logging_mixin.py:104} INFO - [2022-03-18 16:58:27,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:58:27,584] {logging_mixin.py:104} INFO - [2022-03-18 16:58:27,584] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:58:27,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 16:58:58,000] {scheduler_job.py:182} INFO - Started process (PID=11570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:58,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:58:58,008] {logging_mixin.py:104} INFO - [2022-03-18 16:58:58,007] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:58,058] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:58:58,103] {logging_mixin.py:104} INFO - [2022-03-18 16:58:58,102] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:58:58,145] {logging_mixin.py:104} INFO - [2022-03-18 16:58:58,145] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:58:58,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 16:59:28,546] {scheduler_job.py:182} INFO - Started process (PID=11602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:28,552] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:59:28,555] {logging_mixin.py:104} INFO - [2022-03-18 16:59:28,555] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:28,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:28,648] {logging_mixin.py:104} INFO - [2022-03-18 16:59:28,647] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:59:28,686] {logging_mixin.py:104} INFO - [2022-03-18 16:59:28,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:59:28,702] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 16:59:59,127] {scheduler_job.py:182} INFO - Started process (PID=11634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:59,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 16:59:59,134] {logging_mixin.py:104} INFO - [2022-03-18 16:59:59,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:59,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 16:59:59,228] {logging_mixin.py:104} INFO - [2022-03-18 16:59:59,228] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 16:59:59,268] {logging_mixin.py:104} INFO - [2022-03-18 16:59:59,268] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 16:59:59,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:00:29,822] {scheduler_job.py:182} INFO - Started process (PID=11666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:00:29,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:00:29,833] {logging_mixin.py:104} INFO - [2022-03-18 17:00:29,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:00:29,881] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:00:29,922] {logging_mixin.py:104} INFO - [2022-03-18 17:00:29,922] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:00:29,961] {logging_mixin.py:104} INFO - [2022-03-18 17:00:29,960] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:00:29,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:01:00,400] {scheduler_job.py:182} INFO - Started process (PID=11698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:00,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:01:00,409] {logging_mixin.py:104} INFO - [2022-03-18 17:01:00,408] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:00,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:00,502] {logging_mixin.py:104} INFO - [2022-03-18 17:01:00,502] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:01:00,541] {logging_mixin.py:104} INFO - [2022-03-18 17:01:00,540] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:01:00,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 17:01:31,105] {scheduler_job.py:182} INFO - Started process (PID=11730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:31,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:01:31,114] {logging_mixin.py:104} INFO - [2022-03-18 17:01:31,113] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:31,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:01:31,210] {logging_mixin.py:104} INFO - [2022-03-18 17:01:31,210] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:01:31,249] {logging_mixin.py:104} INFO - [2022-03-18 17:01:31,249] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:01:31,263] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 17:02:01,726] {scheduler_job.py:182} INFO - Started process (PID=11762) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:01,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:02:01,732] {logging_mixin.py:104} INFO - [2022-03-18 17:02:01,732] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:01,778] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:01,819] {logging_mixin.py:104} INFO - [2022-03-18 17:02:01,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:02:01,859] {logging_mixin.py:104} INFO - [2022-03-18 17:02:01,859] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:02:01,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:02:32,414] {scheduler_job.py:182} INFO - Started process (PID=11792) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:32,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:02:32,421] {logging_mixin.py:104} INFO - [2022-03-18 17:02:32,421] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:32,471] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:02:32,516] {logging_mixin.py:104} INFO - [2022-03-18 17:02:32,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:02:32,560] {logging_mixin.py:104} INFO - [2022-03-18 17:02:32,559] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:02:32,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 17:03:03,112] {scheduler_job.py:182} INFO - Started process (PID=11817) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:03,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:03:03,120] {logging_mixin.py:104} INFO - [2022-03-18 17:03:03,120] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:03,171] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:03,216] {logging_mixin.py:104} INFO - [2022-03-18 17:03:03,215] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:03:03,259] {logging_mixin.py:104} INFO - [2022-03-18 17:03:03,259] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:03:03,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 17:03:33,586] {scheduler_job.py:182} INFO - Started process (PID=11844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:33,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:03:33,593] {logging_mixin.py:104} INFO - [2022-03-18 17:03:33,592] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:33,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:03:33,680] {logging_mixin.py:104} INFO - [2022-03-18 17:03:33,680] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:03:33,718] {logging_mixin.py:104} INFO - [2022-03-18 17:03:33,718] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:03:33,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-18 17:04:04,136] {scheduler_job.py:182} INFO - Started process (PID=11876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:04,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:04:04,144] {logging_mixin.py:104} INFO - [2022-03-18 17:04:04,143] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:04,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:04,238] {logging_mixin.py:104} INFO - [2022-03-18 17:04:04,237] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:04:04,278] {logging_mixin.py:104} INFO - [2022-03-18 17:04:04,277] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:04:04,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:04:34,788] {scheduler_job.py:182} INFO - Started process (PID=11908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:34,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:04:34,797] {logging_mixin.py:104} INFO - [2022-03-18 17:04:34,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:34,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:04:34,888] {logging_mixin.py:104} INFO - [2022-03-18 17:04:34,888] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:04:34,927] {logging_mixin.py:104} INFO - [2022-03-18 17:04:34,926] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:04:34,942] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:05:05,417] {scheduler_job.py:182} INFO - Started process (PID=11940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:05,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:05:05,425] {logging_mixin.py:104} INFO - [2022-03-18 17:05:05,424] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:05,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:05,512] {logging_mixin.py:104} INFO - [2022-03-18 17:05:05,512] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:05:05,550] {logging_mixin.py:104} INFO - [2022-03-18 17:05:05,550] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:05:05,564] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 17:05:36,131] {scheduler_job.py:182} INFO - Started process (PID=11972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:36,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:05:36,138] {logging_mixin.py:104} INFO - [2022-03-18 17:05:36,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:36,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:05:36,227] {logging_mixin.py:104} INFO - [2022-03-18 17:05:36,227] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:05:36,265] {logging_mixin.py:104} INFO - [2022-03-18 17:05:36,265] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:05:36,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:06:06,807] {scheduler_job.py:182} INFO - Started process (PID=12004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:06,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:06:06,815] {logging_mixin.py:104} INFO - [2022-03-18 17:06:06,815] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:06,863] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:06,904] {logging_mixin.py:104} INFO - [2022-03-18 17:06:06,903] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:06:06,941] {logging_mixin.py:104} INFO - [2022-03-18 17:06:06,941] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:06:06,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:06:37,324] {scheduler_job.py:182} INFO - Started process (PID=12036) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:37,329] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:06:37,331] {logging_mixin.py:104} INFO - [2022-03-18 17:06:37,331] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:37,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:06:37,421] {logging_mixin.py:104} INFO - [2022-03-18 17:06:37,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:06:37,459] {logging_mixin.py:104} INFO - [2022-03-18 17:06:37,458] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:06:37,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:07:07,918] {scheduler_job.py:182} INFO - Started process (PID=12066) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:07,922] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:07:07,924] {logging_mixin.py:104} INFO - [2022-03-18 17:07:07,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:07,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:08,018] {logging_mixin.py:104} INFO - [2022-03-18 17:07:08,018] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:07:08,059] {logging_mixin.py:104} INFO - [2022-03-18 17:07:08,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:07:08,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 17:07:38,643] {scheduler_job.py:182} INFO - Started process (PID=12086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:38,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:07:38,650] {logging_mixin.py:104} INFO - [2022-03-18 17:07:38,649] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:38,700] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:07:38,745] {logging_mixin.py:104} INFO - [2022-03-18 17:07:38,745] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:07:38,788] {logging_mixin.py:104} INFO - [2022-03-18 17:07:38,788] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:07:38,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 17:08:09,108] {scheduler_job.py:182} INFO - Started process (PID=12118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:09,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:08:09,116] {logging_mixin.py:104} INFO - [2022-03-18 17:08:09,116] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:09,163] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:09,206] {logging_mixin.py:104} INFO - [2022-03-18 17:08:09,206] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:08:09,245] {logging_mixin.py:104} INFO - [2022-03-18 17:08:09,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:08:09,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:08:39,541] {scheduler_job.py:182} INFO - Started process (PID=12150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:39,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:08:39,549] {logging_mixin.py:104} INFO - [2022-03-18 17:08:39,549] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:39,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:08:39,636] {logging_mixin.py:104} INFO - [2022-03-18 17:08:39,636] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:08:39,674] {logging_mixin.py:104} INFO - [2022-03-18 17:08:39,674] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:08:39,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:09:10,098] {scheduler_job.py:182} INFO - Started process (PID=12182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:10,103] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:09:10,107] {logging_mixin.py:104} INFO - [2022-03-18 17:09:10,107] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:10,153] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:10,194] {logging_mixin.py:104} INFO - [2022-03-18 17:09:10,194] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:09:10,236] {logging_mixin.py:104} INFO - [2022-03-18 17:09:10,236] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:09:10,252] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 17:09:40,496] {scheduler_job.py:182} INFO - Started process (PID=12214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:40,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:09:40,504] {logging_mixin.py:104} INFO - [2022-03-18 17:09:40,504] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:40,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:09:40,594] {logging_mixin.py:104} INFO - [2022-03-18 17:09:40,593] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:09:40,632] {logging_mixin.py:104} INFO - [2022-03-18 17:09:40,631] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:09:40,648] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:10:10,888] {scheduler_job.py:182} INFO - Started process (PID=12246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:10,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:10:10,897] {logging_mixin.py:104} INFO - [2022-03-18 17:10:10,897] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:10,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:10,990] {logging_mixin.py:104} INFO - [2022-03-18 17:10:10,989] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:10:11,028] {logging_mixin.py:104} INFO - [2022-03-18 17:10:11,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:10:11,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 17:10:41,393] {scheduler_job.py:182} INFO - Started process (PID=12278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:41,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:10:41,401] {logging_mixin.py:104} INFO - [2022-03-18 17:10:41,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:41,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:10:41,501] {logging_mixin.py:104} INFO - [2022-03-18 17:10:41,500] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:10:41,542] {logging_mixin.py:104} INFO - [2022-03-18 17:10:41,542] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:10:41,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 17:11:11,885] {scheduler_job.py:182} INFO - Started process (PID=12308) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:11,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:11:11,892] {logging_mixin.py:104} INFO - [2022-03-18 17:11:11,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:11,938] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:11,985] {logging_mixin.py:104} INFO - [2022-03-18 17:11:11,984] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:11:12,027] {logging_mixin.py:104} INFO - [2022-03-18 17:11:12,027] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:11:12,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 17:11:42,289] {scheduler_job.py:182} INFO - Started process (PID=12333) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:42,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:11:42,297] {logging_mixin.py:104} INFO - [2022-03-18 17:11:42,296] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:42,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:11:42,395] {logging_mixin.py:104} INFO - [2022-03-18 17:11:42,395] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:11:42,437] {logging_mixin.py:104} INFO - [2022-03-18 17:11:42,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:11:42,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 17:12:12,786] {scheduler_job.py:182} INFO - Started process (PID=12360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:12,791] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:12:12,794] {logging_mixin.py:104} INFO - [2022-03-18 17:12:12,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:12,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:12,881] {logging_mixin.py:104} INFO - [2022-03-18 17:12:12,880] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:12:12,918] {logging_mixin.py:104} INFO - [2022-03-18 17:12:12,918] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:12:12,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 17:12:43,597] {scheduler_job.py:182} INFO - Started process (PID=12392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:43,602] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:12:43,605] {logging_mixin.py:104} INFO - [2022-03-18 17:12:43,604] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:43,653] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:12:43,699] {logging_mixin.py:104} INFO - [2022-03-18 17:12:43,698] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:12:43,739] {logging_mixin.py:104} INFO - [2022-03-18 17:12:43,739] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:12:43,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:13:14,222] {scheduler_job.py:182} INFO - Started process (PID=12424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:14,227] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:13:14,230] {logging_mixin.py:104} INFO - [2022-03-18 17:13:14,230] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:14,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:14,319] {logging_mixin.py:104} INFO - [2022-03-18 17:13:14,319] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:13:14,357] {logging_mixin.py:104} INFO - [2022-03-18 17:13:14,356] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:13:14,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:13:44,830] {scheduler_job.py:182} INFO - Started process (PID=12456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:44,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:13:44,838] {logging_mixin.py:104} INFO - [2022-03-18 17:13:44,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:44,885] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:13:44,926] {logging_mixin.py:104} INFO - [2022-03-18 17:13:44,926] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:13:44,964] {logging_mixin.py:104} INFO - [2022-03-18 17:13:44,964] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:13:44,979] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:14:15,402] {scheduler_job.py:182} INFO - Started process (PID=12488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:15,407] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:14:15,410] {logging_mixin.py:104} INFO - [2022-03-18 17:14:15,410] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:15,456] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:15,499] {logging_mixin.py:104} INFO - [2022-03-18 17:14:15,499] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:14:15,538] {logging_mixin.py:104} INFO - [2022-03-18 17:14:15,537] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:14:15,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:14:46,012] {scheduler_job.py:182} INFO - Started process (PID=12520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:46,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:14:46,020] {logging_mixin.py:104} INFO - [2022-03-18 17:14:46,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:46,067] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:14:46,110] {logging_mixin.py:104} INFO - [2022-03-18 17:14:46,109] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:14:46,150] {logging_mixin.py:104} INFO - [2022-03-18 17:14:46,150] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:14:46,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:15:16,611] {scheduler_job.py:182} INFO - Started process (PID=12552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:16,635] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:15:16,638] {logging_mixin.py:104} INFO - [2022-03-18 17:15:16,638] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:16,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:16,733] {logging_mixin.py:104} INFO - [2022-03-18 17:15:16,733] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:15:16,771] {logging_mixin.py:104} INFO - [2022-03-18 17:15:16,771] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:15:16,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 17:15:47,266] {scheduler_job.py:182} INFO - Started process (PID=12582) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:47,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:15:47,273] {logging_mixin.py:104} INFO - [2022-03-18 17:15:47,273] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:47,323] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:15:47,371] {logging_mixin.py:104} INFO - [2022-03-18 17:15:47,370] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:15:47,412] {logging_mixin.py:104} INFO - [2022-03-18 17:15:47,412] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:15:47,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 17:16:18,103] {scheduler_job.py:182} INFO - Started process (PID=12606) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:18,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:16:18,109] {logging_mixin.py:104} INFO - [2022-03-18 17:16:18,109] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:18,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:18,207] {logging_mixin.py:104} INFO - [2022-03-18 17:16:18,207] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:16:18,252] {logging_mixin.py:104} INFO - [2022-03-18 17:16:18,252] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:16:18,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 17:16:48,712] {scheduler_job.py:182} INFO - Started process (PID=12634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:48,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:16:48,720] {logging_mixin.py:104} INFO - [2022-03-18 17:16:48,720] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:48,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:16:48,811] {logging_mixin.py:104} INFO - [2022-03-18 17:16:48,810] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:16:48,853] {logging_mixin.py:104} INFO - [2022-03-18 17:16:48,853] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:16:48,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:17:19,505] {scheduler_job.py:182} INFO - Started process (PID=12666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:19,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:17:19,513] {logging_mixin.py:104} INFO - [2022-03-18 17:17:19,513] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:19,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:19,603] {logging_mixin.py:104} INFO - [2022-03-18 17:17:19,602] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:17:19,641] {logging_mixin.py:104} INFO - [2022-03-18 17:17:19,641] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:17:19,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:17:49,898] {scheduler_job.py:182} INFO - Started process (PID=12698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:49,904] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:17:49,907] {logging_mixin.py:104} INFO - [2022-03-18 17:17:49,907] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:49,955] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:17:49,996] {logging_mixin.py:104} INFO - [2022-03-18 17:17:49,995] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:17:50,035] {logging_mixin.py:104} INFO - [2022-03-18 17:17:50,035] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:17:50,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:18:20,291] {scheduler_job.py:182} INFO - Started process (PID=12730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:20,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:18:20,300] {logging_mixin.py:104} INFO - [2022-03-18 17:18:20,300] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:20,345] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:20,389] {logging_mixin.py:104} INFO - [2022-03-18 17:18:20,388] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:18:20,430] {logging_mixin.py:104} INFO - [2022-03-18 17:18:20,429] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:18:20,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 17:18:50,977] {scheduler_job.py:182} INFO - Started process (PID=12762) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:50,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:18:50,985] {logging_mixin.py:104} INFO - [2022-03-18 17:18:50,985] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:51,035] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:18:51,078] {logging_mixin.py:104} INFO - [2022-03-18 17:18:51,078] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:18:51,118] {logging_mixin.py:104} INFO - [2022-03-18 17:18:51,118] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:18:51,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 17:19:21,308] {scheduler_job.py:182} INFO - Started process (PID=12794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:21,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:19:21,315] {logging_mixin.py:104} INFO - [2022-03-18 17:19:21,314] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:21,362] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:21,407] {logging_mixin.py:104} INFO - [2022-03-18 17:19:21,406] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:19:21,447] {logging_mixin.py:104} INFO - [2022-03-18 17:19:21,447] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:19:21,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 17:19:51,765] {scheduler_job.py:182} INFO - Started process (PID=12826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:51,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:19:51,773] {logging_mixin.py:104} INFO - [2022-03-18 17:19:51,772] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:51,821] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:19:51,868] {logging_mixin.py:104} INFO - [2022-03-18 17:19:51,868] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:19:51,913] {logging_mixin.py:104} INFO - [2022-03-18 17:19:51,913] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:19:51,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 17:20:22,381] {scheduler_job.py:182} INFO - Started process (PID=12856) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:22,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:20:22,389] {logging_mixin.py:104} INFO - [2022-03-18 17:20:22,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:22,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:22,488] {logging_mixin.py:104} INFO - [2022-03-18 17:20:22,487] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:20:22,532] {logging_mixin.py:104} INFO - [2022-03-18 17:20:22,531] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:20:22,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 17:20:53,188] {scheduler_job.py:182} INFO - Started process (PID=12880) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:53,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:20:53,195] {logging_mixin.py:104} INFO - [2022-03-18 17:20:53,195] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:53,244] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:20:53,291] {logging_mixin.py:104} INFO - [2022-03-18 17:20:53,290] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:20:53,334] {logging_mixin.py:104} INFO - [2022-03-18 17:20:53,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:20:53,350] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 17:21:23,800] {scheduler_job.py:182} INFO - Started process (PID=12908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:23,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:21:23,807] {logging_mixin.py:104} INFO - [2022-03-18 17:21:23,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:23,855] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:23,898] {logging_mixin.py:104} INFO - [2022-03-18 17:21:23,898] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:21:23,938] {logging_mixin.py:104} INFO - [2022-03-18 17:21:23,938] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:21:23,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:21:54,332] {scheduler_job.py:182} INFO - Started process (PID=12940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:54,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:21:54,341] {logging_mixin.py:104} INFO - [2022-03-18 17:21:54,340] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:54,390] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:21:54,432] {logging_mixin.py:104} INFO - [2022-03-18 17:21:54,431] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:21:54,472] {logging_mixin.py:104} INFO - [2022-03-18 17:21:54,472] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:21:54,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 17:22:24,725] {scheduler_job.py:182} INFO - Started process (PID=12972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:24,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:22:24,733] {logging_mixin.py:104} INFO - [2022-03-18 17:22:24,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:24,781] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:24,823] {logging_mixin.py:104} INFO - [2022-03-18 17:22:24,822] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:22:24,862] {logging_mixin.py:104} INFO - [2022-03-18 17:22:24,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:22:24,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:22:55,178] {scheduler_job.py:182} INFO - Started process (PID=13004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:55,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:22:55,187] {logging_mixin.py:104} INFO - [2022-03-18 17:22:55,186] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:55,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:22:55,276] {logging_mixin.py:104} INFO - [2022-03-18 17:22:55,275] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:22:55,317] {logging_mixin.py:104} INFO - [2022-03-18 17:22:55,316] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:22:55,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:23:25,563] {scheduler_job.py:182} INFO - Started process (PID=13036) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:25,568] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:23:25,571] {logging_mixin.py:104} INFO - [2022-03-18 17:23:25,570] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:25,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:25,662] {logging_mixin.py:104} INFO - [2022-03-18 17:23:25,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:23:25,701] {logging_mixin.py:104} INFO - [2022-03-18 17:23:25,701] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:23:25,717] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 17:23:56,081] {scheduler_job.py:182} INFO - Started process (PID=13068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:56,088] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:23:56,092] {logging_mixin.py:104} INFO - [2022-03-18 17:23:56,092] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:56,139] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:23:56,181] {logging_mixin.py:104} INFO - [2022-03-18 17:23:56,181] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:23:56,219] {logging_mixin.py:104} INFO - [2022-03-18 17:23:56,219] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:23:56,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 17:24:26,635] {scheduler_job.py:182} INFO - Started process (PID=13100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:26,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:24:26,641] {logging_mixin.py:104} INFO - [2022-03-18 17:24:26,640] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:26,687] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:26,728] {logging_mixin.py:104} INFO - [2022-03-18 17:24:26,728] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:24:26,766] {logging_mixin.py:104} INFO - [2022-03-18 17:24:26,766] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:24:26,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-18 17:24:57,382] {scheduler_job.py:182} INFO - Started process (PID=13130) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:57,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:24:57,389] {logging_mixin.py:104} INFO - [2022-03-18 17:24:57,388] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:57,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:24:57,485] {logging_mixin.py:104} INFO - [2022-03-18 17:24:57,484] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:24:57,525] {logging_mixin.py:104} INFO - [2022-03-18 17:24:57,525] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:24:57,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 17:25:28,243] {scheduler_job.py:182} INFO - Started process (PID=13150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:28,247] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:25:28,250] {logging_mixin.py:104} INFO - [2022-03-18 17:25:28,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:28,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:28,343] {logging_mixin.py:104} INFO - [2022-03-18 17:25:28,343] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:25:28,387] {logging_mixin.py:104} INFO - [2022-03-18 17:25:28,387] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:25:28,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:25:58,846] {scheduler_job.py:182} INFO - Started process (PID=13182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:58,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:25:58,855] {logging_mixin.py:104} INFO - [2022-03-18 17:25:58,854] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:58,902] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:25:58,944] {logging_mixin.py:104} INFO - [2022-03-18 17:25:58,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:25:58,985] {logging_mixin.py:104} INFO - [2022-03-18 17:25:58,985] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:25:59,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 17:26:29,587] {scheduler_job.py:182} INFO - Started process (PID=13214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:26:29,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:26:29,595] {logging_mixin.py:104} INFO - [2022-03-18 17:26:29,595] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:26:29,644] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:26:29,689] {logging_mixin.py:104} INFO - [2022-03-18 17:26:29,688] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:26:29,727] {logging_mixin.py:104} INFO - [2022-03-18 17:26:29,727] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:26:29,741] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:27:00,323] {scheduler_job.py:182} INFO - Started process (PID=13246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:00,329] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:27:00,332] {logging_mixin.py:104} INFO - [2022-03-18 17:27:00,332] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:00,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:00,429] {logging_mixin.py:104} INFO - [2022-03-18 17:27:00,429] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:27:00,467] {logging_mixin.py:104} INFO - [2022-03-18 17:27:00,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:27:00,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:27:30,874] {scheduler_job.py:182} INFO - Started process (PID=13278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:30,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:27:30,883] {logging_mixin.py:104} INFO - [2022-03-18 17:27:30,882] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:30,933] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:27:30,976] {logging_mixin.py:104} INFO - [2022-03-18 17:27:30,975] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:27:31,013] {logging_mixin.py:104} INFO - [2022-03-18 17:27:31,013] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:27:31,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 17:28:01,510] {scheduler_job.py:182} INFO - Started process (PID=13310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:01,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:28:01,519] {logging_mixin.py:104} INFO - [2022-03-18 17:28:01,518] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:01,571] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:01,614] {logging_mixin.py:104} INFO - [2022-03-18 17:28:01,614] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:28:01,652] {logging_mixin.py:104} INFO - [2022-03-18 17:28:01,652] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:28:01,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:28:32,254] {scheduler_job.py:182} INFO - Started process (PID=13342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:32,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:28:32,260] {logging_mixin.py:104} INFO - [2022-03-18 17:28:32,260] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:32,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:28:32,348] {logging_mixin.py:104} INFO - [2022-03-18 17:28:32,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:28:32,386] {logging_mixin.py:104} INFO - [2022-03-18 17:28:32,386] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:28:32,401] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-18 17:29:02,945] {scheduler_job.py:182} INFO - Started process (PID=13372) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:02,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:29:02,953] {logging_mixin.py:104} INFO - [2022-03-18 17:29:02,953] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:03,005] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:03,051] {logging_mixin.py:104} INFO - [2022-03-18 17:29:03,050] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:29:03,092] {logging_mixin.py:104} INFO - [2022-03-18 17:29:03,092] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:29:03,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 17:29:33,676] {scheduler_job.py:182} INFO - Started process (PID=13397) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:33,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:29:33,684] {logging_mixin.py:104} INFO - [2022-03-18 17:29:33,683] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:33,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:29:33,779] {logging_mixin.py:104} INFO - [2022-03-18 17:29:33,779] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:29:33,821] {logging_mixin.py:104} INFO - [2022-03-18 17:29:33,820] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:29:33,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:30:04,305] {scheduler_job.py:182} INFO - Started process (PID=13424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:04,310] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:30:04,312] {logging_mixin.py:104} INFO - [2022-03-18 17:30:04,312] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:04,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:04,401] {logging_mixin.py:104} INFO - [2022-03-18 17:30:04,401] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:30:04,441] {logging_mixin.py:104} INFO - [2022-03-18 17:30:04,440] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:30:04,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:30:35,127] {scheduler_job.py:182} INFO - Started process (PID=13456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:35,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:30:35,135] {logging_mixin.py:104} INFO - [2022-03-18 17:30:35,134] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:35,182] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:30:35,223] {logging_mixin.py:104} INFO - [2022-03-18 17:30:35,223] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:30:35,261] {logging_mixin.py:104} INFO - [2022-03-18 17:30:35,261] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:30:35,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:31:05,505] {scheduler_job.py:182} INFO - Started process (PID=13488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:05,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:31:05,511] {logging_mixin.py:104} INFO - [2022-03-18 17:31:05,511] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:05,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:05,598] {logging_mixin.py:104} INFO - [2022-03-18 17:31:05,597] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:31:05,636] {logging_mixin.py:104} INFO - [2022-03-18 17:31:05,636] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:31:05,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:31:35,877] {scheduler_job.py:182} INFO - Started process (PID=13520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:35,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:31:35,885] {logging_mixin.py:104} INFO - [2022-03-18 17:31:35,885] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:35,941] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:31:35,982] {logging_mixin.py:104} INFO - [2022-03-18 17:31:35,982] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:31:36,022] {logging_mixin.py:104} INFO - [2022-03-18 17:31:36,021] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:31:36,037] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 17:32:06,266] {scheduler_job.py:182} INFO - Started process (PID=13552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:06,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:32:06,274] {logging_mixin.py:104} INFO - [2022-03-18 17:32:06,274] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:06,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:06,360] {logging_mixin.py:104} INFO - [2022-03-18 17:32:06,360] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:32:06,400] {logging_mixin.py:104} INFO - [2022-03-18 17:32:06,400] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:32:06,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:32:36,684] {scheduler_job.py:182} INFO - Started process (PID=13584) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:36,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:32:36,694] {logging_mixin.py:104} INFO - [2022-03-18 17:32:36,694] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:36,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:32:36,784] {logging_mixin.py:104} INFO - [2022-03-18 17:32:36,783] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:32:36,822] {logging_mixin.py:104} INFO - [2022-03-18 17:32:36,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:32:36,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 17:33:07,261] {scheduler_job.py:182} INFO - Started process (PID=13616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:07,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:33:07,267] {logging_mixin.py:104} INFO - [2022-03-18 17:33:07,267] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:07,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:07,353] {logging_mixin.py:104} INFO - [2022-03-18 17:33:07,353] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:33:07,391] {logging_mixin.py:104} INFO - [2022-03-18 17:33:07,391] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:33:07,405] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.152 seconds
[2022-03-18 17:33:37,900] {scheduler_job.py:182} INFO - Started process (PID=13646) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:37,904] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:33:37,907] {logging_mixin.py:104} INFO - [2022-03-18 17:33:37,906] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:37,957] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:33:38,005] {logging_mixin.py:104} INFO - [2022-03-18 17:33:38,004] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:33:38,047] {logging_mixin.py:104} INFO - [2022-03-18 17:33:38,047] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:33:38,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 17:34:08,391] {scheduler_job.py:182} INFO - Started process (PID=13671) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:08,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:34:08,400] {logging_mixin.py:104} INFO - [2022-03-18 17:34:08,400] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:08,462] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:08,518] {logging_mixin.py:104} INFO - [2022-03-18 17:34:08,517] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:34:08,576] {logging_mixin.py:104} INFO - [2022-03-18 17:34:08,575] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:34:08,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.212 seconds
[2022-03-18 17:34:38,879] {scheduler_job.py:182} INFO - Started process (PID=13698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:38,882] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:34:38,885] {logging_mixin.py:104} INFO - [2022-03-18 17:34:38,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:38,932] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:34:38,973] {logging_mixin.py:104} INFO - [2022-03-18 17:34:38,973] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:34:39,012] {logging_mixin.py:104} INFO - [2022-03-18 17:34:39,011] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:34:39,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 17:35:09,300] {scheduler_job.py:182} INFO - Started process (PID=13730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:09,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:35:09,308] {logging_mixin.py:104} INFO - [2022-03-18 17:35:09,308] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:09,355] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:09,397] {logging_mixin.py:104} INFO - [2022-03-18 17:35:09,396] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:35:09,438] {logging_mixin.py:104} INFO - [2022-03-18 17:35:09,438] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:35:09,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:35:39,828] {scheduler_job.py:182} INFO - Started process (PID=13762) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:39,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:35:39,837] {logging_mixin.py:104} INFO - [2022-03-18 17:35:39,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:39,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:35:39,925] {logging_mixin.py:104} INFO - [2022-03-18 17:35:39,924] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:35:39,962] {logging_mixin.py:104} INFO - [2022-03-18 17:35:39,962] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:35:39,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 17:36:10,455] {scheduler_job.py:182} INFO - Started process (PID=13794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:10,461] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:36:10,463] {logging_mixin.py:104} INFO - [2022-03-18 17:36:10,463] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:10,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:10,563] {logging_mixin.py:104} INFO - [2022-03-18 17:36:10,563] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:36:10,608] {logging_mixin.py:104} INFO - [2022-03-18 17:36:10,607] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:36:10,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 17:36:40,953] {scheduler_job.py:182} INFO - Started process (PID=13826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:40,958] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:36:40,960] {logging_mixin.py:104} INFO - [2022-03-18 17:36:40,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:41,006] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:36:41,049] {logging_mixin.py:104} INFO - [2022-03-18 17:36:41,049] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:36:41,090] {logging_mixin.py:104} INFO - [2022-03-18 17:36:41,089] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:36:41,105] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:37:11,645] {scheduler_job.py:182} INFO - Started process (PID=13858) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:11,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:37:11,654] {logging_mixin.py:104} INFO - [2022-03-18 17:37:11,653] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:11,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:11,744] {logging_mixin.py:104} INFO - [2022-03-18 17:37:11,744] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:37:11,783] {logging_mixin.py:104} INFO - [2022-03-18 17:37:11,782] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:37:11,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 17:37:42,098] {scheduler_job.py:182} INFO - Started process (PID=13890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:42,104] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:37:42,107] {logging_mixin.py:104} INFO - [2022-03-18 17:37:42,106] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:42,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:37:42,193] {logging_mixin.py:104} INFO - [2022-03-18 17:37:42,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:37:42,231] {logging_mixin.py:104} INFO - [2022-03-18 17:37:42,231] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:37:42,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:38:12,531] {scheduler_job.py:182} INFO - Started process (PID=13920) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:12,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:38:12,539] {logging_mixin.py:104} INFO - [2022-03-18 17:38:12,539] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:12,588] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:12,632] {logging_mixin.py:104} INFO - [2022-03-18 17:38:12,631] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:38:12,675] {logging_mixin.py:104} INFO - [2022-03-18 17:38:12,674] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:38:12,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:38:43,388] {scheduler_job.py:182} INFO - Started process (PID=13945) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:43,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:38:43,396] {logging_mixin.py:104} INFO - [2022-03-18 17:38:43,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:43,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:38:43,490] {logging_mixin.py:104} INFO - [2022-03-18 17:38:43,490] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:38:43,532] {logging_mixin.py:104} INFO - [2022-03-18 17:38:43,532] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:38:43,549] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 17:39:14,061] {scheduler_job.py:182} INFO - Started process (PID=13972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:14,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:39:14,070] {logging_mixin.py:104} INFO - [2022-03-18 17:39:14,069] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:14,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:14,163] {logging_mixin.py:104} INFO - [2022-03-18 17:39:14,163] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:39:14,205] {logging_mixin.py:104} INFO - [2022-03-18 17:39:14,205] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:39:14,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:39:44,447] {scheduler_job.py:182} INFO - Started process (PID=14004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:44,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:39:44,454] {logging_mixin.py:104} INFO - [2022-03-18 17:39:44,454] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:44,505] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:39:44,550] {logging_mixin.py:104} INFO - [2022-03-18 17:39:44,550] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:39:44,588] {logging_mixin.py:104} INFO - [2022-03-18 17:39:44,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:39:44,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 17:40:14,862] {scheduler_job.py:182} INFO - Started process (PID=14036) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:14,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:40:14,870] {logging_mixin.py:104} INFO - [2022-03-18 17:40:14,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:14,918] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:14,961] {logging_mixin.py:104} INFO - [2022-03-18 17:40:14,961] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:40:15,004] {logging_mixin.py:104} INFO - [2022-03-18 17:40:15,003] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:40:15,021] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 17:40:45,182] {scheduler_job.py:182} INFO - Started process (PID=14068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:45,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:40:45,189] {logging_mixin.py:104} INFO - [2022-03-18 17:40:45,188] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:45,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:40:45,279] {logging_mixin.py:104} INFO - [2022-03-18 17:40:45,278] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:40:45,318] {logging_mixin.py:104} INFO - [2022-03-18 17:40:45,317] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:40:45,334] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:41:15,617] {scheduler_job.py:182} INFO - Started process (PID=14100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:15,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:41:15,624] {logging_mixin.py:104} INFO - [2022-03-18 17:41:15,623] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:15,671] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:15,712] {logging_mixin.py:104} INFO - [2022-03-18 17:41:15,711] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:41:15,750] {logging_mixin.py:104} INFO - [2022-03-18 17:41:15,750] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:41:15,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 17:41:46,480] {scheduler_job.py:182} INFO - Started process (PID=14132) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:46,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:41:46,487] {logging_mixin.py:104} INFO - [2022-03-18 17:41:46,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:46,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:41:46,576] {logging_mixin.py:104} INFO - [2022-03-18 17:41:46,575] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:41:46,613] {logging_mixin.py:104} INFO - [2022-03-18 17:41:46,613] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:41:46,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 17:42:17,013] {scheduler_job.py:182} INFO - Started process (PID=14164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:17,018] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:42:17,020] {logging_mixin.py:104} INFO - [2022-03-18 17:42:17,020] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:17,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:17,112] {logging_mixin.py:104} INFO - [2022-03-18 17:42:17,112] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:42:17,150] {logging_mixin.py:104} INFO - [2022-03-18 17:42:17,150] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:42:17,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:42:47,748] {scheduler_job.py:182} INFO - Started process (PID=14194) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:47,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:42:47,755] {logging_mixin.py:104} INFO - [2022-03-18 17:42:47,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:47,804] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:42:47,851] {logging_mixin.py:104} INFO - [2022-03-18 17:42:47,850] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:42:47,898] {logging_mixin.py:104} INFO - [2022-03-18 17:42:47,897] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:42:47,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 17:43:18,004] {scheduler_job.py:182} INFO - Started process (PID=14219) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:18,008] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:43:18,011] {logging_mixin.py:104} INFO - [2022-03-18 17:43:18,011] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:18,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:18,110] {logging_mixin.py:104} INFO - [2022-03-18 17:43:18,110] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:43:18,152] {logging_mixin.py:104} INFO - [2022-03-18 17:43:18,152] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:43:18,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 17:43:48,421] {scheduler_job.py:182} INFO - Started process (PID=14246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:48,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:43:48,428] {logging_mixin.py:104} INFO - [2022-03-18 17:43:48,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:48,473] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:43:48,516] {logging_mixin.py:104} INFO - [2022-03-18 17:43:48,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:43:48,555] {logging_mixin.py:104} INFO - [2022-03-18 17:43:48,554] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:43:48,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 17:44:18,804] {scheduler_job.py:182} INFO - Started process (PID=14278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:18,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:44:18,813] {logging_mixin.py:104} INFO - [2022-03-18 17:44:18,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:18,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:18,901] {logging_mixin.py:104} INFO - [2022-03-18 17:44:18,900] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:44:18,939] {logging_mixin.py:104} INFO - [2022-03-18 17:44:18,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:44:18,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 17:44:49,249] {scheduler_job.py:182} INFO - Started process (PID=14310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:49,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:44:49,257] {logging_mixin.py:104} INFO - [2022-03-18 17:44:49,257] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:49,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:44:49,348] {logging_mixin.py:104} INFO - [2022-03-18 17:44:49,348] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:44:49,386] {logging_mixin.py:104} INFO - [2022-03-18 17:44:49,385] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:44:49,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:45:19,715] {scheduler_job.py:182} INFO - Started process (PID=14342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:19,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:45:19,724] {logging_mixin.py:104} INFO - [2022-03-18 17:45:19,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:19,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:19,819] {logging_mixin.py:104} INFO - [2022-03-18 17:45:19,818] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:45:19,857] {logging_mixin.py:104} INFO - [2022-03-18 17:45:19,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:45:19,873] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 17:45:50,141] {scheduler_job.py:182} INFO - Started process (PID=14374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:50,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:45:50,148] {logging_mixin.py:104} INFO - [2022-03-18 17:45:50,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:50,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:45:50,237] {logging_mixin.py:104} INFO - [2022-03-18 17:45:50,237] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:45:50,276] {logging_mixin.py:104} INFO - [2022-03-18 17:45:50,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:45:50,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 17:46:20,423] {scheduler_job.py:182} INFO - Started process (PID=14406) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:20,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:46:20,430] {logging_mixin.py:104} INFO - [2022-03-18 17:46:20,429] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:20,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:20,516] {logging_mixin.py:104} INFO - [2022-03-18 17:46:20,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:46:20,555] {logging_mixin.py:104} INFO - [2022-03-18 17:46:20,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:46:20,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:46:50,864] {scheduler_job.py:182} INFO - Started process (PID=14438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:50,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:46:50,870] {logging_mixin.py:104} INFO - [2022-03-18 17:46:50,870] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:50,918] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:46:50,960] {logging_mixin.py:104} INFO - [2022-03-18 17:46:50,959] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:46:51,018] {logging_mixin.py:104} INFO - [2022-03-18 17:46:51,018] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:46:51,035] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 17:47:21,521] {scheduler_job.py:182} INFO - Started process (PID=14468) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:21,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:47:21,529] {logging_mixin.py:104} INFO - [2022-03-18 17:47:21,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:21,580] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:21,647] {logging_mixin.py:104} INFO - [2022-03-18 17:47:21,646] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:47:21,691] {logging_mixin.py:104} INFO - [2022-03-18 17:47:21,691] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:47:21,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-18 17:47:52,345] {scheduler_job.py:182} INFO - Started process (PID=14492) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:52,349] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:47:52,352] {logging_mixin.py:104} INFO - [2022-03-18 17:47:52,351] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:52,401] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:47:52,446] {logging_mixin.py:104} INFO - [2022-03-18 17:47:52,445] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:47:52,488] {logging_mixin.py:104} INFO - [2022-03-18 17:47:52,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:47:52,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 17:48:22,916] {scheduler_job.py:182} INFO - Started process (PID=14520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:22,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:48:22,924] {logging_mixin.py:104} INFO - [2022-03-18 17:48:22,924] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:22,973] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:23,016] {logging_mixin.py:104} INFO - [2022-03-18 17:48:23,015] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:48:23,053] {logging_mixin.py:104} INFO - [2022-03-18 17:48:23,053] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:48:23,068] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 17:48:53,721] {scheduler_job.py:182} INFO - Started process (PID=14552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:53,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:48:53,730] {logging_mixin.py:104} INFO - [2022-03-18 17:48:53,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:53,777] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:48:53,819] {logging_mixin.py:104} INFO - [2022-03-18 17:48:53,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:48:53,857] {logging_mixin.py:104} INFO - [2022-03-18 17:48:53,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:48:53,874] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:49:24,182] {scheduler_job.py:182} INFO - Started process (PID=14584) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:24,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:49:24,191] {logging_mixin.py:104} INFO - [2022-03-18 17:49:24,191] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:24,240] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:24,284] {logging_mixin.py:104} INFO - [2022-03-18 17:49:24,284] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:49:24,331] {logging_mixin.py:104} INFO - [2022-03-18 17:49:24,331] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:49:24,381] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.207 seconds
[2022-03-18 17:49:54,869] {scheduler_job.py:182} INFO - Started process (PID=14616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:54,874] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:49:54,877] {logging_mixin.py:104} INFO - [2022-03-18 17:49:54,876] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:54,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:49:54,963] {logging_mixin.py:104} INFO - [2022-03-18 17:49:54,963] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:49:55,002] {logging_mixin.py:104} INFO - [2022-03-18 17:49:55,002] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:49:55,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 17:50:25,583] {scheduler_job.py:182} INFO - Started process (PID=14648) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:25,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:50:25,591] {logging_mixin.py:104} INFO - [2022-03-18 17:50:25,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:25,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:25,681] {logging_mixin.py:104} INFO - [2022-03-18 17:50:25,680] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:50:25,724] {logging_mixin.py:104} INFO - [2022-03-18 17:50:25,723] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:50:25,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 17:50:56,481] {scheduler_job.py:182} INFO - Started process (PID=14680) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:56,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:50:56,487] {logging_mixin.py:104} INFO - [2022-03-18 17:50:56,487] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:56,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:50:56,576] {logging_mixin.py:104} INFO - [2022-03-18 17:50:56,576] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:50:56,616] {logging_mixin.py:104} INFO - [2022-03-18 17:50:56,616] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:50:56,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:51:27,227] {scheduler_job.py:182} INFO - Started process (PID=14712) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:27,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:51:27,234] {logging_mixin.py:104} INFO - [2022-03-18 17:51:27,234] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:27,281] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:27,323] {logging_mixin.py:104} INFO - [2022-03-18 17:51:27,322] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:51:27,361] {logging_mixin.py:104} INFO - [2022-03-18 17:51:27,361] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:51:27,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 17:51:58,059] {scheduler_job.py:182} INFO - Started process (PID=14742) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:58,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:51:58,066] {logging_mixin.py:104} INFO - [2022-03-18 17:51:58,066] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:58,114] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:51:58,159] {logging_mixin.py:104} INFO - [2022-03-18 17:51:58,158] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:51:58,207] {logging_mixin.py:104} INFO - [2022-03-18 17:51:58,207] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:51:58,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 17:52:28,781] {scheduler_job.py:182} INFO - Started process (PID=14767) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:28,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:52:28,788] {logging_mixin.py:104} INFO - [2022-03-18 17:52:28,788] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:28,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:28,896] {logging_mixin.py:104} INFO - [2022-03-18 17:52:28,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:52:28,942] {logging_mixin.py:104} INFO - [2022-03-18 17:52:28,942] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:52:28,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-18 17:52:59,235] {scheduler_job.py:182} INFO - Started process (PID=14794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:59,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:52:59,244] {logging_mixin.py:104} INFO - [2022-03-18 17:52:59,243] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:59,292] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:52:59,336] {logging_mixin.py:104} INFO - [2022-03-18 17:52:59,336] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:52:59,390] {logging_mixin.py:104} INFO - [2022-03-18 17:52:59,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:52:59,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 17:53:29,986] {scheduler_job.py:182} INFO - Started process (PID=14826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:53:29,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:53:29,998] {logging_mixin.py:104} INFO - [2022-03-18 17:53:29,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:53:30,048] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:53:30,092] {logging_mixin.py:104} INFO - [2022-03-18 17:53:30,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:53:30,133] {logging_mixin.py:104} INFO - [2022-03-18 17:53:30,132] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:53:30,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 17:54:00,461] {scheduler_job.py:182} INFO - Started process (PID=14858) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:00,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:54:00,469] {logging_mixin.py:104} INFO - [2022-03-18 17:54:00,468] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:00,527] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:00,569] {logging_mixin.py:104} INFO - [2022-03-18 17:54:00,569] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:54:00,610] {logging_mixin.py:104} INFO - [2022-03-18 17:54:00,610] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:54:00,626] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 17:54:31,262] {scheduler_job.py:182} INFO - Started process (PID=14890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:31,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:54:31,282] {logging_mixin.py:104} INFO - [2022-03-18 17:54:31,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:31,334] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:54:31,380] {logging_mixin.py:104} INFO - [2022-03-18 17:54:31,380] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:54:31,418] {logging_mixin.py:104} INFO - [2022-03-18 17:54:31,418] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:54:31,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 17:55:01,991] {scheduler_job.py:182} INFO - Started process (PID=14922) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:01,996] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:55:01,999] {logging_mixin.py:104} INFO - [2022-03-18 17:55:01,999] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:02,050] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:02,093] {logging_mixin.py:104} INFO - [2022-03-18 17:55:02,092] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:55:02,131] {logging_mixin.py:104} INFO - [2022-03-18 17:55:02,130] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:55:02,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:55:32,804] {scheduler_job.py:182} INFO - Started process (PID=14954) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:32,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:55:32,813] {logging_mixin.py:104} INFO - [2022-03-18 17:55:32,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:32,863] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:55:32,904] {logging_mixin.py:104} INFO - [2022-03-18 17:55:32,904] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:55:32,942] {logging_mixin.py:104} INFO - [2022-03-18 17:55:32,942] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:55:32,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:56:03,547] {scheduler_job.py:182} INFO - Started process (PID=14986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:03,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:56:03,557] {logging_mixin.py:104} INFO - [2022-03-18 17:56:03,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:03,611] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:03,655] {logging_mixin.py:104} INFO - [2022-03-18 17:56:03,654] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:56:03,694] {logging_mixin.py:104} INFO - [2022-03-18 17:56:03,693] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:56:03,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 17:56:34,186] {scheduler_job.py:182} INFO - Started process (PID=15016) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:34,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:56:34,194] {logging_mixin.py:104} INFO - [2022-03-18 17:56:34,193] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:34,242] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:56:34,286] {logging_mixin.py:104} INFO - [2022-03-18 17:56:34,285] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:56:34,332] {logging_mixin.py:104} INFO - [2022-03-18 17:56:34,332] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:56:34,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 17:57:04,989] {scheduler_job.py:182} INFO - Started process (PID=15040) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:04,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:57:04,996] {logging_mixin.py:104} INFO - [2022-03-18 17:57:04,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:05,045] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:05,091] {logging_mixin.py:104} INFO - [2022-03-18 17:57:05,091] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:57:05,135] {logging_mixin.py:104} INFO - [2022-03-18 17:57:05,135] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:57:05,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 17:57:35,597] {scheduler_job.py:182} INFO - Started process (PID=15068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:35,602] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:57:35,605] {logging_mixin.py:104} INFO - [2022-03-18 17:57:35,605] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:35,652] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:57:35,693] {logging_mixin.py:104} INFO - [2022-03-18 17:57:35,693] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:57:35,731] {logging_mixin.py:104} INFO - [2022-03-18 17:57:35,731] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:57:35,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 17:58:05,989] {scheduler_job.py:182} INFO - Started process (PID=15100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:05,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:58:05,996] {logging_mixin.py:104} INFO - [2022-03-18 17:58:05,996] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:06,042] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:06,084] {logging_mixin.py:104} INFO - [2022-03-18 17:58:06,083] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:58:06,122] {logging_mixin.py:104} INFO - [2022-03-18 17:58:06,122] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:58:06,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 17:58:36,647] {scheduler_job.py:182} INFO - Started process (PID=15132) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:36,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:58:36,656] {logging_mixin.py:104} INFO - [2022-03-18 17:58:36,656] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:36,706] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:58:36,749] {logging_mixin.py:104} INFO - [2022-03-18 17:58:36,748] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:58:36,787] {logging_mixin.py:104} INFO - [2022-03-18 17:58:36,786] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:58:36,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 17:59:06,993] {scheduler_job.py:182} INFO - Started process (PID=15164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:06,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:59:07,001] {logging_mixin.py:104} INFO - [2022-03-18 17:59:07,001] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:07,050] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:07,092] {logging_mixin.py:104} INFO - [2022-03-18 17:59:07,092] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:59:07,132] {logging_mixin.py:104} INFO - [2022-03-18 17:59:07,131] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:59:07,146] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 17:59:37,453] {scheduler_job.py:182} INFO - Started process (PID=15196) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:37,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 17:59:37,461] {logging_mixin.py:104} INFO - [2022-03-18 17:59:37,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:37,506] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 17:59:37,546] {logging_mixin.py:104} INFO - [2022-03-18 17:59:37,546] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 17:59:37,586] {logging_mixin.py:104} INFO - [2022-03-18 17:59:37,586] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 17:59:37,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 18:00:07,976] {scheduler_job.py:182} INFO - Started process (PID=15228) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:07,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:00:07,984] {logging_mixin.py:104} INFO - [2022-03-18 18:00:07,984] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:08,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:08,071] {logging_mixin.py:104} INFO - [2022-03-18 18:00:08,071] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:00:08,109] {logging_mixin.py:104} INFO - [2022-03-18 18:00:08,108] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:00:08,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.154 seconds
[2022-03-18 18:00:38,622] {scheduler_job.py:182} INFO - Started process (PID=15260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:38,626] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:00:38,628] {logging_mixin.py:104} INFO - [2022-03-18 18:00:38,628] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:38,673] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:00:38,717] {logging_mixin.py:104} INFO - [2022-03-18 18:00:38,716] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:00:38,755] {logging_mixin.py:104} INFO - [2022-03-18 18:00:38,755] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:00:38,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.155 seconds
[2022-03-18 18:01:09,458] {scheduler_job.py:182} INFO - Started process (PID=15290) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:09,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:01:09,465] {logging_mixin.py:104} INFO - [2022-03-18 18:01:09,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:09,516] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:09,563] {logging_mixin.py:104} INFO - [2022-03-18 18:01:09,562] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:01:09,605] {logging_mixin.py:104} INFO - [2022-03-18 18:01:09,605] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:01:09,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 18:01:40,279] {scheduler_job.py:182} INFO - Started process (PID=15310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:40,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:01:40,289] {logging_mixin.py:104} INFO - [2022-03-18 18:01:40,288] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:40,339] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:01:40,386] {logging_mixin.py:104} INFO - [2022-03-18 18:01:40,385] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:01:40,429] {logging_mixin.py:104} INFO - [2022-03-18 18:01:40,429] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:01:40,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 18:02:10,593] {scheduler_job.py:182} INFO - Started process (PID=15342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:10,599] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:02:10,602] {logging_mixin.py:104} INFO - [2022-03-18 18:02:10,602] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:10,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:10,691] {logging_mixin.py:104} INFO - [2022-03-18 18:02:10,691] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:02:10,730] {logging_mixin.py:104} INFO - [2022-03-18 18:02:10,730] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:02:10,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:02:41,381] {scheduler_job.py:182} INFO - Started process (PID=15374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:41,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:02:41,389] {logging_mixin.py:104} INFO - [2022-03-18 18:02:41,389] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:41,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:02:41,477] {logging_mixin.py:104} INFO - [2022-03-18 18:02:41,476] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:02:41,515] {logging_mixin.py:104} INFO - [2022-03-18 18:02:41,514] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:02:41,529] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 18:03:12,051] {scheduler_job.py:182} INFO - Started process (PID=15406) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:12,056] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:03:12,059] {logging_mixin.py:104} INFO - [2022-03-18 18:03:12,059] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:12,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:12,147] {logging_mixin.py:104} INFO - [2022-03-18 18:03:12,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:03:12,186] {logging_mixin.py:104} INFO - [2022-03-18 18:03:12,186] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:03:12,204] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 18:03:42,778] {scheduler_job.py:182} INFO - Started process (PID=15438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:42,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:03:42,784] {logging_mixin.py:104} INFO - [2022-03-18 18:03:42,784] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:42,831] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:03:42,874] {logging_mixin.py:104} INFO - [2022-03-18 18:03:42,873] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:03:42,914] {logging_mixin.py:104} INFO - [2022-03-18 18:03:42,913] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:03:42,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 18:04:13,549] {scheduler_job.py:182} INFO - Started process (PID=15470) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:13,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:04:13,557] {logging_mixin.py:104} INFO - [2022-03-18 18:04:13,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:13,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:13,648] {logging_mixin.py:104} INFO - [2022-03-18 18:04:13,647] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:04:13,686] {logging_mixin.py:104} INFO - [2022-03-18 18:04:13,686] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:04:13,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 18:04:44,366] {scheduler_job.py:182} INFO - Started process (PID=15502) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:44,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:04:44,375] {logging_mixin.py:104} INFO - [2022-03-18 18:04:44,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:44,426] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:04:44,470] {logging_mixin.py:104} INFO - [2022-03-18 18:04:44,470] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:04:44,510] {logging_mixin.py:104} INFO - [2022-03-18 18:04:44,510] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:04:44,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:05:15,109] {scheduler_job.py:182} INFO - Started process (PID=15532) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:15,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:05:15,117] {logging_mixin.py:104} INFO - [2022-03-18 18:05:15,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:15,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:15,212] {logging_mixin.py:104} INFO - [2022-03-18 18:05:15,211] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:05:15,255] {logging_mixin.py:104} INFO - [2022-03-18 18:05:15,254] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:05:15,272] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:05:45,889] {scheduler_job.py:182} INFO - Started process (PID=15557) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:45,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:05:45,896] {logging_mixin.py:104} INFO - [2022-03-18 18:05:45,895] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:45,946] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:05:45,992] {logging_mixin.py:104} INFO - [2022-03-18 18:05:45,992] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:05:46,033] {logging_mixin.py:104} INFO - [2022-03-18 18:05:46,033] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:05:46,052] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:06:16,498] {scheduler_job.py:182} INFO - Started process (PID=15584) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:16,503] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:06:16,506] {logging_mixin.py:104} INFO - [2022-03-18 18:06:16,506] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:16,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:16,594] {logging_mixin.py:104} INFO - [2022-03-18 18:06:16,594] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:06:16,634] {logging_mixin.py:104} INFO - [2022-03-18 18:06:16,633] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:06:16,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 18:06:47,135] {scheduler_job.py:182} INFO - Started process (PID=15616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:47,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:06:47,143] {logging_mixin.py:104} INFO - [2022-03-18 18:06:47,143] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:47,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:06:47,232] {logging_mixin.py:104} INFO - [2022-03-18 18:06:47,231] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:06:47,270] {logging_mixin.py:104} INFO - [2022-03-18 18:06:47,269] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:06:47,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 18:07:17,740] {scheduler_job.py:182} INFO - Started process (PID=15648) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:17,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:07:17,749] {logging_mixin.py:104} INFO - [2022-03-18 18:07:17,748] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:17,795] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:17,837] {logging_mixin.py:104} INFO - [2022-03-18 18:07:17,837] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:07:17,875] {logging_mixin.py:104} INFO - [2022-03-18 18:07:17,875] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:07:17,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 18:07:48,478] {scheduler_job.py:182} INFO - Started process (PID=15680) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:48,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:07:48,485] {logging_mixin.py:104} INFO - [2022-03-18 18:07:48,485] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:48,556] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:07:48,616] {logging_mixin.py:104} INFO - [2022-03-18 18:07:48,616] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:07:48,657] {logging_mixin.py:104} INFO - [2022-03-18 18:07:48,656] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:07:48,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.202 seconds
[2022-03-18 18:08:18,945] {scheduler_job.py:182} INFO - Started process (PID=15712) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:18,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:08:18,952] {logging_mixin.py:104} INFO - [2022-03-18 18:08:18,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:18,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:19,037] {logging_mixin.py:104} INFO - [2022-03-18 18:08:19,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:08:19,075] {logging_mixin.py:104} INFO - [2022-03-18 18:08:19,074] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:08:19,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.151 seconds
[2022-03-18 18:08:49,598] {scheduler_job.py:182} INFO - Started process (PID=15744) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:49,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:08:49,607] {logging_mixin.py:104} INFO - [2022-03-18 18:08:49,606] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:49,656] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:08:49,697] {logging_mixin.py:104} INFO - [2022-03-18 18:08:49,697] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:08:49,736] {logging_mixin.py:104} INFO - [2022-03-18 18:08:49,735] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:08:49,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-18 18:09:20,322] {scheduler_job.py:182} INFO - Started process (PID=15776) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:20,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:09:20,330] {logging_mixin.py:104} INFO - [2022-03-18 18:09:20,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:20,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:20,424] {logging_mixin.py:104} INFO - [2022-03-18 18:09:20,424] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:09:20,463] {logging_mixin.py:104} INFO - [2022-03-18 18:09:20,463] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:09:20,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 18:09:50,924] {scheduler_job.py:182} INFO - Started process (PID=15806) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:50,928] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:09:50,930] {logging_mixin.py:104} INFO - [2022-03-18 18:09:50,930] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:50,981] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:09:51,027] {logging_mixin.py:104} INFO - [2022-03-18 18:09:51,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:09:51,069] {logging_mixin.py:104} INFO - [2022-03-18 18:09:51,069] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:09:51,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:10:21,442] {scheduler_job.py:182} INFO - Started process (PID=15826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:21,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:10:21,450] {logging_mixin.py:104} INFO - [2022-03-18 18:10:21,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:21,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:21,547] {logging_mixin.py:104} INFO - [2022-03-18 18:10:21,546] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:10:21,590] {logging_mixin.py:104} INFO - [2022-03-18 18:10:21,589] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:10:21,606] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 18:10:51,732] {scheduler_job.py:182} INFO - Started process (PID=15858) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:51,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:10:51,739] {logging_mixin.py:104} INFO - [2022-03-18 18:10:51,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:51,785] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:10:51,826] {logging_mixin.py:104} INFO - [2022-03-18 18:10:51,826] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:10:51,864] {logging_mixin.py:104} INFO - [2022-03-18 18:10:51,864] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:10:51,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.153 seconds
[2022-03-18 18:11:22,329] {scheduler_job.py:182} INFO - Started process (PID=15890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:22,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:11:22,337] {logging_mixin.py:104} INFO - [2022-03-18 18:11:22,336] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:22,382] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:22,424] {logging_mixin.py:104} INFO - [2022-03-18 18:11:22,424] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:11:22,467] {logging_mixin.py:104} INFO - [2022-03-18 18:11:22,467] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:11:22,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 18:11:52,920] {scheduler_job.py:182} INFO - Started process (PID=15922) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:52,925] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:11:52,928] {logging_mixin.py:104} INFO - [2022-03-18 18:11:52,928] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:52,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:11:53,016] {logging_mixin.py:104} INFO - [2022-03-18 18:11:53,015] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:11:53,053] {logging_mixin.py:104} INFO - [2022-03-18 18:11:53,053] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:11:53,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 18:12:23,609] {scheduler_job.py:182} INFO - Started process (PID=15954) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:23,613] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:12:23,616] {logging_mixin.py:104} INFO - [2022-03-18 18:12:23,615] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:23,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:23,707] {logging_mixin.py:104} INFO - [2022-03-18 18:12:23,706] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:12:23,749] {logging_mixin.py:104} INFO - [2022-03-18 18:12:23,748] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:12:23,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 18:12:54,321] {scheduler_job.py:182} INFO - Started process (PID=15986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:54,326] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:12:54,329] {logging_mixin.py:104} INFO - [2022-03-18 18:12:54,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:54,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:12:54,422] {logging_mixin.py:104} INFO - [2022-03-18 18:12:54,422] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:12:54,460] {logging_mixin.py:104} INFO - [2022-03-18 18:12:54,460] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:12:54,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 18:13:24,952] {scheduler_job.py:182} INFO - Started process (PID=16018) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:24,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:13:24,960] {logging_mixin.py:104} INFO - [2022-03-18 18:13:24,960] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:25,023] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:25,076] {logging_mixin.py:104} INFO - [2022-03-18 18:13:25,076] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:13:25,121] {logging_mixin.py:104} INFO - [2022-03-18 18:13:25,121] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:13:25,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.198 seconds
[2022-03-18 18:13:55,892] {scheduler_job.py:182} INFO - Started process (PID=16048) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:55,899] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:13:55,903] {logging_mixin.py:104} INFO - [2022-03-18 18:13:55,903] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:55,960] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:13:56,014] {logging_mixin.py:104} INFO - [2022-03-18 18:13:56,013] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:13:56,064] {logging_mixin.py:104} INFO - [2022-03-18 18:13:56,063] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:13:56,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.201 seconds
[2022-03-18 18:14:26,610] {scheduler_job.py:182} INFO - Started process (PID=16073) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:26,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:14:26,619] {logging_mixin.py:104} INFO - [2022-03-18 18:14:26,619] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:26,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:26,717] {logging_mixin.py:104} INFO - [2022-03-18 18:14:26,717] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:14:26,760] {logging_mixin.py:104} INFO - [2022-03-18 18:14:26,760] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:14:26,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 18:14:57,419] {scheduler_job.py:182} INFO - Started process (PID=16100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:57,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:14:57,428] {logging_mixin.py:104} INFO - [2022-03-18 18:14:57,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:57,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:14:57,516] {logging_mixin.py:104} INFO - [2022-03-18 18:14:57,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:14:57,555] {logging_mixin.py:104} INFO - [2022-03-18 18:14:57,555] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:14:57,570] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:15:28,199] {scheduler_job.py:182} INFO - Started process (PID=16132) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:28,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:15:28,207] {logging_mixin.py:104} INFO - [2022-03-18 18:15:28,207] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:28,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:28,296] {logging_mixin.py:104} INFO - [2022-03-18 18:15:28,295] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:15:28,334] {logging_mixin.py:104} INFO - [2022-03-18 18:15:28,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:15:28,348] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 18:15:59,078] {scheduler_job.py:182} INFO - Started process (PID=16164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:59,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:15:59,087] {logging_mixin.py:104} INFO - [2022-03-18 18:15:59,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:59,135] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:15:59,178] {logging_mixin.py:104} INFO - [2022-03-18 18:15:59,177] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:15:59,219] {logging_mixin.py:104} INFO - [2022-03-18 18:15:59,219] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:15:59,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 18:16:29,722] {scheduler_job.py:182} INFO - Started process (PID=16196) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:16:29,728] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:16:29,730] {logging_mixin.py:104} INFO - [2022-03-18 18:16:29,730] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:16:29,777] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:16:29,819] {logging_mixin.py:104} INFO - [2022-03-18 18:16:29,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:16:29,863] {logging_mixin.py:104} INFO - [2022-03-18 18:16:29,862] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:16:29,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 18:17:00,148] {scheduler_job.py:182} INFO - Started process (PID=16228) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:00,153] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:17:00,156] {logging_mixin.py:104} INFO - [2022-03-18 18:17:00,156] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:00,203] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:00,245] {logging_mixin.py:104} INFO - [2022-03-18 18:17:00,245] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:17:00,285] {logging_mixin.py:104} INFO - [2022-03-18 18:17:00,285] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:17:00,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 18:17:30,913] {scheduler_job.py:182} INFO - Started process (PID=16260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:30,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:17:30,922] {logging_mixin.py:104} INFO - [2022-03-18 18:17:30,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:30,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:17:31,013] {logging_mixin.py:104} INFO - [2022-03-18 18:17:31,013] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:17:31,055] {logging_mixin.py:104} INFO - [2022-03-18 18:17:31,055] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:17:31,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:18:01,437] {scheduler_job.py:182} INFO - Started process (PID=16292) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:01,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:18:01,446] {logging_mixin.py:104} INFO - [2022-03-18 18:18:01,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:01,495] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:01,542] {logging_mixin.py:104} INFO - [2022-03-18 18:18:01,541] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:18:01,581] {logging_mixin.py:104} INFO - [2022-03-18 18:18:01,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:18:01,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:18:32,141] {scheduler_job.py:182} INFO - Started process (PID=16322) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:32,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:18:32,148] {logging_mixin.py:104} INFO - [2022-03-18 18:18:32,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:32,199] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:18:32,247] {logging_mixin.py:104} INFO - [2022-03-18 18:18:32,246] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:18:32,288] {logging_mixin.py:104} INFO - [2022-03-18 18:18:32,288] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:18:32,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:19:02,876] {scheduler_job.py:182} INFO - Started process (PID=16346) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:02,881] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:19:02,884] {logging_mixin.py:104} INFO - [2022-03-18 18:19:02,884] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:02,936] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:02,983] {logging_mixin.py:104} INFO - [2022-03-18 18:19:02,983] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:19:03,027] {logging_mixin.py:104} INFO - [2022-03-18 18:19:03,026] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:19:03,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 18:19:33,508] {scheduler_job.py:182} INFO - Started process (PID=16374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:33,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:19:33,516] {logging_mixin.py:104} INFO - [2022-03-18 18:19:33,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:33,564] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:19:33,606] {logging_mixin.py:104} INFO - [2022-03-18 18:19:33,606] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:19:33,645] {logging_mixin.py:104} INFO - [2022-03-18 18:19:33,644] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:19:33,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 18:20:04,290] {scheduler_job.py:182} INFO - Started process (PID=16406) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:04,294] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:20:04,297] {logging_mixin.py:104} INFO - [2022-03-18 18:20:04,297] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:04,345] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:04,391] {logging_mixin.py:104} INFO - [2022-03-18 18:20:04,390] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:20:04,435] {logging_mixin.py:104} INFO - [2022-03-18 18:20:04,435] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:20:04,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:20:35,165] {scheduler_job.py:182} INFO - Started process (PID=16438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:35,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:20:35,174] {logging_mixin.py:104} INFO - [2022-03-18 18:20:35,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:35,222] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:20:35,265] {logging_mixin.py:104} INFO - [2022-03-18 18:20:35,265] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:20:35,305] {logging_mixin.py:104} INFO - [2022-03-18 18:20:35,304] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:20:35,320] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 18:21:05,932] {scheduler_job.py:182} INFO - Started process (PID=16470) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:05,938] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:21:05,941] {logging_mixin.py:104} INFO - [2022-03-18 18:21:05,940] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:05,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:06,037] {logging_mixin.py:104} INFO - [2022-03-18 18:21:06,036] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:21:06,078] {logging_mixin.py:104} INFO - [2022-03-18 18:21:06,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:21:06,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:21:36,577] {scheduler_job.py:182} INFO - Started process (PID=16502) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:36,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:21:36,585] {logging_mixin.py:104} INFO - [2022-03-18 18:21:36,584] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:36,631] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:21:36,677] {logging_mixin.py:104} INFO - [2022-03-18 18:21:36,676] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:21:36,716] {logging_mixin.py:104} INFO - [2022-03-18 18:21:36,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:21:36,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:22:07,342] {scheduler_job.py:182} INFO - Started process (PID=16534) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:07,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:22:07,350] {logging_mixin.py:104} INFO - [2022-03-18 18:22:07,349] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:07,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:07,443] {logging_mixin.py:104} INFO - [2022-03-18 18:22:07,443] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:22:07,482] {logging_mixin.py:104} INFO - [2022-03-18 18:22:07,482] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:22:07,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 18:22:37,544] {scheduler_job.py:182} INFO - Started process (PID=16564) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:37,549] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:22:37,551] {logging_mixin.py:104} INFO - [2022-03-18 18:22:37,551] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:37,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:22:37,649] {logging_mixin.py:104} INFO - [2022-03-18 18:22:37,649] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:22:37,691] {logging_mixin.py:104} INFO - [2022-03-18 18:22:37,691] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:22:37,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 18:39:02,817] {scheduler_job.py:182} INFO - Started process (PID=16588) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:02,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:39:02,844] {logging_mixin.py:104} INFO - [2022-03-18 18:39:02,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:02,971] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:03,085] {logging_mixin.py:104} INFO - [2022-03-18 18:39:03,084] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:39:03,189] {logging_mixin.py:104} INFO - [2022-03-18 18:39:03,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:39:03,248] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.445 seconds
[2022-03-18 18:39:33,665] {scheduler_job.py:182} INFO - Started process (PID=16616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:33,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:39:33,679] {logging_mixin.py:104} INFO - [2022-03-18 18:39:33,679] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:33,794] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:39:33,859] {logging_mixin.py:104} INFO - [2022-03-18 18:39:33,859] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:39:33,912] {logging_mixin.py:104} INFO - [2022-03-18 18:39:33,912] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:39:33,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.300 seconds
[2022-03-18 18:40:04,835] {scheduler_job.py:182} INFO - Started process (PID=16652) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:04,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:40:04,842] {logging_mixin.py:104} INFO - [2022-03-18 18:40:04,841] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:04,895] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:04,937] {logging_mixin.py:104} INFO - [2022-03-18 18:40:04,936] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:40:04,975] {logging_mixin.py:104} INFO - [2022-03-18 18:40:04,975] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:40:04,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:40:35,663] {scheduler_job.py:182} INFO - Started process (PID=16684) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:35,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:40:35,670] {logging_mixin.py:104} INFO - [2022-03-18 18:40:35,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:35,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:40:35,761] {logging_mixin.py:104} INFO - [2022-03-18 18:40:35,760] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:40:35,799] {logging_mixin.py:104} INFO - [2022-03-18 18:40:35,799] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:40:35,815] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 18:41:06,429] {scheduler_job.py:182} INFO - Started process (PID=16716) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:06,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:41:06,436] {logging_mixin.py:104} INFO - [2022-03-18 18:41:06,436] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:06,484] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:06,533] {logging_mixin.py:104} INFO - [2022-03-18 18:41:06,533] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:41:06,571] {logging_mixin.py:104} INFO - [2022-03-18 18:41:06,571] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:41:06,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 18:41:37,251] {scheduler_job.py:182} INFO - Started process (PID=16748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:37,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:41:37,258] {logging_mixin.py:104} INFO - [2022-03-18 18:41:37,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:37,308] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:41:37,351] {logging_mixin.py:104} INFO - [2022-03-18 18:41:37,350] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:41:37,389] {logging_mixin.py:104} INFO - [2022-03-18 18:41:37,388] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:41:37,405] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 18:42:08,070] {scheduler_job.py:182} INFO - Started process (PID=16780) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:08,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:42:08,077] {logging_mixin.py:104} INFO - [2022-03-18 18:42:08,076] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:08,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:08,171] {logging_mixin.py:104} INFO - [2022-03-18 18:42:08,171] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:42:08,211] {logging_mixin.py:104} INFO - [2022-03-18 18:42:08,210] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:42:08,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:42:38,858] {scheduler_job.py:182} INFO - Started process (PID=16812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:38,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:42:38,866] {logging_mixin.py:104} INFO - [2022-03-18 18:42:38,865] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:38,916] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:42:38,961] {logging_mixin.py:104} INFO - [2022-03-18 18:42:38,961] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:42:39,002] {logging_mixin.py:104} INFO - [2022-03-18 18:42:39,002] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:42:39,020] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:43:09,697] {scheduler_job.py:182} INFO - Started process (PID=16831) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:09,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:43:09,705] {logging_mixin.py:104} INFO - [2022-03-18 18:43:09,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:09,754] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:09,800] {logging_mixin.py:104} INFO - [2022-03-18 18:43:09,799] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:43:09,843] {logging_mixin.py:104} INFO - [2022-03-18 18:43:09,843] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:43:09,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:43:40,863] {scheduler_job.py:182} INFO - Started process (PID=16862) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:40,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:43:40,870] {logging_mixin.py:104} INFO - [2022-03-18 18:43:40,869] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:40,921] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:43:40,968] {logging_mixin.py:104} INFO - [2022-03-18 18:43:40,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:43:41,009] {logging_mixin.py:104} INFO - [2022-03-18 18:43:41,009] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:43:41,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 18:48:10,400] {scheduler_job.py:182} INFO - Started process (PID=16894) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:10,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:48:10,419] {logging_mixin.py:104} INFO - [2022-03-18 18:48:10,418] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:10,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:10,640] {logging_mixin.py:104} INFO - [2022-03-18 18:48:10,640] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:48:10,706] {logging_mixin.py:104} INFO - [2022-03-18 18:48:10,705] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:48:10,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.346 seconds
[2022-03-18 18:48:41,128] {scheduler_job.py:182} INFO - Started process (PID=16917) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:41,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:48:41,147] {logging_mixin.py:104} INFO - [2022-03-18 18:48:41,146] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:41,283] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:48:41,358] {logging_mixin.py:104} INFO - [2022-03-18 18:48:41,357] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:48:41,455] {logging_mixin.py:104} INFO - [2022-03-18 18:48:41,455] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:48:41,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.381 seconds
[2022-03-18 18:49:12,458] {scheduler_job.py:182} INFO - Started process (PID=16958) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:12,475] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:49:12,479] {logging_mixin.py:104} INFO - [2022-03-18 18:49:12,478] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:12,539] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:12,582] {logging_mixin.py:104} INFO - [2022-03-18 18:49:12,581] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:49:12,624] {logging_mixin.py:104} INFO - [2022-03-18 18:49:12,624] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:49:12,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-18 18:49:43,444] {scheduler_job.py:182} INFO - Started process (PID=16990) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:43,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:49:43,451] {logging_mixin.py:104} INFO - [2022-03-18 18:49:43,451] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:43,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:49:43,545] {logging_mixin.py:104} INFO - [2022-03-18 18:49:43,545] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:49:43,589] {logging_mixin.py:104} INFO - [2022-03-18 18:49:43,588] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:49:43,609] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 18:50:14,308] {scheduler_job.py:182} INFO - Started process (PID=17022) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:14,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:50:14,319] {logging_mixin.py:104} INFO - [2022-03-18 18:50:14,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:14,372] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:14,416] {logging_mixin.py:104} INFO - [2022-03-18 18:50:14,416] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:50:14,457] {logging_mixin.py:104} INFO - [2022-03-18 18:50:14,456] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:50:14,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 18:50:45,070] {scheduler_job.py:182} INFO - Started process (PID=17054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:45,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:50:45,077] {logging_mixin.py:104} INFO - [2022-03-18 18:50:45,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:45,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:50:45,174] {logging_mixin.py:104} INFO - [2022-03-18 18:50:45,173] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:50:45,213] {logging_mixin.py:104} INFO - [2022-03-18 18:50:45,213] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:50:45,230] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 18:51:15,927] {scheduler_job.py:182} INFO - Started process (PID=17086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:15,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:51:15,935] {logging_mixin.py:104} INFO - [2022-03-18 18:51:15,934] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:15,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:16,027] {logging_mixin.py:104} INFO - [2022-03-18 18:51:16,027] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:51:16,068] {logging_mixin.py:104} INFO - [2022-03-18 18:51:16,068] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:51:16,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 18:51:47,076] {scheduler_job.py:182} INFO - Started process (PID=17118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:47,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:51:47,083] {logging_mixin.py:104} INFO - [2022-03-18 18:51:47,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:47,145] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:51:47,209] {logging_mixin.py:104} INFO - [2022-03-18 18:51:47,209] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:51:47,262] {logging_mixin.py:104} INFO - [2022-03-18 18:51:47,261] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:51:47,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.213 seconds
[2022-03-18 18:52:17,473] {scheduler_job.py:182} INFO - Started process (PID=17142) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:17,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:52:17,482] {logging_mixin.py:104} INFO - [2022-03-18 18:52:17,481] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:17,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:17,601] {logging_mixin.py:104} INFO - [2022-03-18 18:52:17,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:52:17,650] {logging_mixin.py:104} INFO - [2022-03-18 18:52:17,650] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:52:17,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.205 seconds
[2022-03-18 18:52:47,956] {scheduler_job.py:182} INFO - Started process (PID=17168) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:47,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:52:47,980] {logging_mixin.py:104} INFO - [2022-03-18 18:52:47,980] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:48,031] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:52:48,078] {logging_mixin.py:104} INFO - [2022-03-18 18:52:48,077] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:52:48,119] {logging_mixin.py:104} INFO - [2022-03-18 18:52:48,119] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:52:48,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 18:53:19,048] {scheduler_job.py:182} INFO - Started process (PID=17200) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:19,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:53:19,056] {logging_mixin.py:104} INFO - [2022-03-18 18:53:19,056] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:19,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:19,161] {logging_mixin.py:104} INFO - [2022-03-18 18:53:19,161] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:53:19,205] {logging_mixin.py:104} INFO - [2022-03-18 18:53:19,205] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:53:19,222] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 18:53:49,939] {scheduler_job.py:182} INFO - Started process (PID=17232) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:49,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:53:49,947] {logging_mixin.py:104} INFO - [2022-03-18 18:53:49,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:49,997] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:53:50,038] {logging_mixin.py:104} INFO - [2022-03-18 18:53:50,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:53:50,076] {logging_mixin.py:104} INFO - [2022-03-18 18:53:50,075] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:53:50,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 18:54:20,802] {scheduler_job.py:182} INFO - Started process (PID=17264) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:20,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:54:20,808] {logging_mixin.py:104} INFO - [2022-03-18 18:54:20,808] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:20,857] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:20,899] {logging_mixin.py:104} INFO - [2022-03-18 18:54:20,899] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:54:20,940] {logging_mixin.py:104} INFO - [2022-03-18 18:54:20,940] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:54:20,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 18:54:51,543] {scheduler_job.py:182} INFO - Started process (PID=17296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:51,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:54:51,550] {logging_mixin.py:104} INFO - [2022-03-18 18:54:51,549] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:51,601] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:54:51,645] {logging_mixin.py:104} INFO - [2022-03-18 18:54:51,644] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:54:51,685] {logging_mixin.py:104} INFO - [2022-03-18 18:54:51,685] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:54:51,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 18:55:22,264] {scheduler_job.py:182} INFO - Started process (PID=17328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:22,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:55:22,272] {logging_mixin.py:104} INFO - [2022-03-18 18:55:22,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:22,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:22,368] {logging_mixin.py:104} INFO - [2022-03-18 18:55:22,367] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:55:22,405] {logging_mixin.py:104} INFO - [2022-03-18 18:55:22,405] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:55:22,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 18:55:52,963] {scheduler_job.py:182} INFO - Started process (PID=17360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:52,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:55:52,969] {logging_mixin.py:104} INFO - [2022-03-18 18:55:52,969] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:53,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:55:53,064] {logging_mixin.py:104} INFO - [2022-03-18 18:55:53,064] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:55:53,103] {logging_mixin.py:104} INFO - [2022-03-18 18:55:53,103] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:55:53,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 18:56:24,883] {scheduler_job.py:182} INFO - Started process (PID=17392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:24,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:56:24,889] {logging_mixin.py:104} INFO - [2022-03-18 18:56:24,889] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:24,940] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:24,986] {logging_mixin.py:104} INFO - [2022-03-18 18:56:24,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:56:25,027] {logging_mixin.py:104} INFO - [2022-03-18 18:56:25,026] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:56:25,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 18:56:55,504] {scheduler_job.py:182} INFO - Started process (PID=17416) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:55,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:56:55,510] {logging_mixin.py:104} INFO - [2022-03-18 18:56:55,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:55,562] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:56:55,609] {logging_mixin.py:104} INFO - [2022-03-18 18:56:55,608] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:56:55,656] {logging_mixin.py:104} INFO - [2022-03-18 18:56:55,655] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:56:55,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 18:57:26,534] {scheduler_job.py:182} INFO - Started process (PID=17442) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:26,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:57:26,542] {logging_mixin.py:104} INFO - [2022-03-18 18:57:26,542] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:26,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:26,650] {logging_mixin.py:104} INFO - [2022-03-18 18:57:26,649] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:57:26,692] {logging_mixin.py:104} INFO - [2022-03-18 18:57:26,692] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:57:26,709] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 18:57:57,484] {scheduler_job.py:182} INFO - Started process (PID=17474) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:57,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:57:57,491] {logging_mixin.py:104} INFO - [2022-03-18 18:57:57,491] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:57,545] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:57:57,587] {logging_mixin.py:104} INFO - [2022-03-18 18:57:57,586] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:57:57,627] {logging_mixin.py:104} INFO - [2022-03-18 18:57:57,627] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:57:57,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 18:58:28,355] {scheduler_job.py:182} INFO - Started process (PID=17506) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:28,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:58:28,365] {logging_mixin.py:104} INFO - [2022-03-18 18:58:28,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:28,416] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:28,461] {logging_mixin.py:104} INFO - [2022-03-18 18:58:28,461] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:58:28,506] {logging_mixin.py:104} INFO - [2022-03-18 18:58:28,506] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:58:28,522] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 18:58:59,277] {scheduler_job.py:182} INFO - Started process (PID=17538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:59,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:58:59,285] {logging_mixin.py:104} INFO - [2022-03-18 18:58:59,284] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:59,338] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:58:59,383] {logging_mixin.py:104} INFO - [2022-03-18 18:58:59,383] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:58:59,425] {logging_mixin.py:104} INFO - [2022-03-18 18:58:59,424] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:58:59,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 18:59:30,130] {scheduler_job.py:182} INFO - Started process (PID=17570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 18:59:30,133] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 18:59:30,136] {logging_mixin.py:104} INFO - [2022-03-18 18:59:30,135] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 18:59:30,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 18:59:30,234] {logging_mixin.py:104} INFO - [2022-03-18 18:59:30,234] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 18:59:30,277] {logging_mixin.py:104} INFO - [2022-03-18 18:59:30,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 18:59:30,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:00:00,913] {scheduler_job.py:182} INFO - Started process (PID=17602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:00,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:00:00,921] {logging_mixin.py:104} INFO - [2022-03-18 19:00:00,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:00,983] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:01,031] {logging_mixin.py:104} INFO - [2022-03-18 19:00:01,031] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:00:01,075] {logging_mixin.py:104} INFO - [2022-03-18 19:00:01,075] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:00:01,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 19:00:31,731] {scheduler_job.py:182} INFO - Started process (PID=17634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:31,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:00:31,739] {logging_mixin.py:104} INFO - [2022-03-18 19:00:31,738] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:31,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:00:31,832] {logging_mixin.py:104} INFO - [2022-03-18 19:00:31,832] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:00:31,872] {logging_mixin.py:104} INFO - [2022-03-18 19:00:31,871] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:00:31,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:01:02,674] {scheduler_job.py:182} INFO - Started process (PID=17666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:02,678] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:01:02,681] {logging_mixin.py:104} INFO - [2022-03-18 19:01:02,680] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:02,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:02,778] {logging_mixin.py:104} INFO - [2022-03-18 19:01:02,777] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:01:02,820] {logging_mixin.py:104} INFO - [2022-03-18 19:01:02,820] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:01:02,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 19:01:33,374] {scheduler_job.py:182} INFO - Started process (PID=17690) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:33,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:01:33,382] {logging_mixin.py:104} INFO - [2022-03-18 19:01:33,381] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:33,432] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:01:33,479] {logging_mixin.py:104} INFO - [2022-03-18 19:01:33,479] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:01:33,523] {logging_mixin.py:104} INFO - [2022-03-18 19:01:33,522] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:01:33,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 19:02:04,398] {scheduler_job.py:182} INFO - Started process (PID=17716) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:04,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:02:04,404] {logging_mixin.py:104} INFO - [2022-03-18 19:02:04,404] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:04,457] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:04,499] {logging_mixin.py:104} INFO - [2022-03-18 19:02:04,498] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:02:04,538] {logging_mixin.py:104} INFO - [2022-03-18 19:02:04,537] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:02:04,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:02:35,052] {scheduler_job.py:182} INFO - Started process (PID=17748) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:35,057] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:02:35,059] {logging_mixin.py:104} INFO - [2022-03-18 19:02:35,059] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:35,113] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:02:35,155] {logging_mixin.py:104} INFO - [2022-03-18 19:02:35,155] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:02:35,195] {logging_mixin.py:104} INFO - [2022-03-18 19:02:35,194] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:02:35,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:03:05,650] {scheduler_job.py:182} INFO - Started process (PID=17780) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:05,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:03:05,657] {logging_mixin.py:104} INFO - [2022-03-18 19:03:05,657] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:05,712] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:05,756] {logging_mixin.py:104} INFO - [2022-03-18 19:03:05,756] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:03:05,795] {logging_mixin.py:104} INFO - [2022-03-18 19:03:05,795] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:03:05,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:03:36,341] {scheduler_job.py:182} INFO - Started process (PID=17812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:36,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:03:36,348] {logging_mixin.py:104} INFO - [2022-03-18 19:03:36,347] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:36,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:03:36,441] {logging_mixin.py:104} INFO - [2022-03-18 19:03:36,441] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:03:36,481] {logging_mixin.py:104} INFO - [2022-03-18 19:03:36,481] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:03:36,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:04:06,827] {scheduler_job.py:182} INFO - Started process (PID=17844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:06,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:04:06,835] {logging_mixin.py:104} INFO - [2022-03-18 19:04:06,835] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:06,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:06,924] {logging_mixin.py:104} INFO - [2022-03-18 19:04:06,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:04:06,963] {logging_mixin.py:104} INFO - [2022-03-18 19:04:06,963] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:04:06,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 19:04:37,293] {scheduler_job.py:182} INFO - Started process (PID=17876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:37,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:04:37,299] {logging_mixin.py:104} INFO - [2022-03-18 19:04:37,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:37,350] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:04:37,393] {logging_mixin.py:104} INFO - [2022-03-18 19:04:37,393] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:04:37,432] {logging_mixin.py:104} INFO - [2022-03-18 19:04:37,432] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:04:37,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:05:07,705] {scheduler_job.py:182} INFO - Started process (PID=17908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:07,710] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:05:07,713] {logging_mixin.py:104} INFO - [2022-03-18 19:05:07,712] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:07,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:07,805] {logging_mixin.py:104} INFO - [2022-03-18 19:05:07,805] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:05:07,844] {logging_mixin.py:104} INFO - [2022-03-18 19:05:07,844] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:05:07,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:05:38,323] {scheduler_job.py:182} INFO - Started process (PID=17939) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:38,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:05:38,330] {logging_mixin.py:104} INFO - [2022-03-18 19:05:38,329] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:38,380] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:05:38,426] {logging_mixin.py:104} INFO - [2022-03-18 19:05:38,425] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:05:38,470] {logging_mixin.py:104} INFO - [2022-03-18 19:05:38,469] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:05:38,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 19:06:09,042] {scheduler_job.py:182} INFO - Started process (PID=17964) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:09,046] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:06:09,049] {logging_mixin.py:104} INFO - [2022-03-18 19:06:09,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:09,100] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:09,147] {logging_mixin.py:104} INFO - [2022-03-18 19:06:09,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:06:09,190] {logging_mixin.py:104} INFO - [2022-03-18 19:06:09,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:06:09,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:06:39,518] {scheduler_job.py:182} INFO - Started process (PID=17990) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:39,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:06:39,525] {logging_mixin.py:104} INFO - [2022-03-18 19:06:39,525] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:39,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:06:39,620] {logging_mixin.py:104} INFO - [2022-03-18 19:06:39,620] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:06:39,663] {logging_mixin.py:104} INFO - [2022-03-18 19:06:39,663] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:06:39,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:07:10,114] {scheduler_job.py:182} INFO - Started process (PID=18022) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:10,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:07:10,123] {logging_mixin.py:104} INFO - [2022-03-18 19:07:10,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:10,174] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:10,219] {logging_mixin.py:104} INFO - [2022-03-18 19:07:10,219] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:07:10,260] {logging_mixin.py:104} INFO - [2022-03-18 19:07:10,259] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:07:10,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:07:40,689] {scheduler_job.py:182} INFO - Started process (PID=18054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:40,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:07:40,696] {logging_mixin.py:104} INFO - [2022-03-18 19:07:40,695] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:40,749] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:07:40,793] {logging_mixin.py:104} INFO - [2022-03-18 19:07:40,793] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:07:40,832] {logging_mixin.py:104} INFO - [2022-03-18 19:07:40,832] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:07:40,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:08:11,235] {scheduler_job.py:182} INFO - Started process (PID=18086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:11,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:08:11,242] {logging_mixin.py:104} INFO - [2022-03-18 19:08:11,241] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:11,294] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:11,339] {logging_mixin.py:104} INFO - [2022-03-18 19:08:11,339] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:08:11,378] {logging_mixin.py:104} INFO - [2022-03-18 19:08:11,377] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:08:11,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:08:41,831] {scheduler_job.py:182} INFO - Started process (PID=18118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:41,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:08:41,838] {logging_mixin.py:104} INFO - [2022-03-18 19:08:41,838] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:41,889] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:08:41,933] {logging_mixin.py:104} INFO - [2022-03-18 19:08:41,932] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:08:41,976] {logging_mixin.py:104} INFO - [2022-03-18 19:08:41,975] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:08:41,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 19:09:12,377] {scheduler_job.py:182} INFO - Started process (PID=18150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:12,381] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:09:12,384] {logging_mixin.py:104} INFO - [2022-03-18 19:09:12,383] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:12,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:12,481] {logging_mixin.py:104} INFO - [2022-03-18 19:09:12,481] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:09:12,521] {logging_mixin.py:104} INFO - [2022-03-18 19:09:12,521] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:09:12,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 19:09:43,252] {scheduler_job.py:182} INFO - Started process (PID=18182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:43,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:09:43,259] {logging_mixin.py:104} INFO - [2022-03-18 19:09:43,258] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:43,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:09:43,350] {logging_mixin.py:104} INFO - [2022-03-18 19:09:43,349] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:09:43,394] {logging_mixin.py:104} INFO - [2022-03-18 19:09:43,394] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:09:43,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:10:13,785] {scheduler_job.py:182} INFO - Started process (PID=18207) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:13,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:10:13,793] {logging_mixin.py:104} INFO - [2022-03-18 19:10:13,793] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:13,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:13,891] {logging_mixin.py:104} INFO - [2022-03-18 19:10:13,890] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:10:13,933] {logging_mixin.py:104} INFO - [2022-03-18 19:10:13,933] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:10:13,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:10:44,506] {scheduler_job.py:182} INFO - Started process (PID=18232) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:44,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:10:44,513] {logging_mixin.py:104} INFO - [2022-03-18 19:10:44,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:44,566] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:10:44,608] {logging_mixin.py:104} INFO - [2022-03-18 19:10:44,608] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:10:44,647] {logging_mixin.py:104} INFO - [2022-03-18 19:10:44,646] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:10:44,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:11:15,216] {scheduler_job.py:182} INFO - Started process (PID=18264) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:15,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:11:15,223] {logging_mixin.py:104} INFO - [2022-03-18 19:11:15,223] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:15,279] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:15,321] {logging_mixin.py:104} INFO - [2022-03-18 19:11:15,321] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:11:15,360] {logging_mixin.py:104} INFO - [2022-03-18 19:11:15,359] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:11:15,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:11:45,852] {scheduler_job.py:182} INFO - Started process (PID=18296) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:45,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:11:45,860] {logging_mixin.py:104} INFO - [2022-03-18 19:11:45,859] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:45,911] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:11:45,952] {logging_mixin.py:104} INFO - [2022-03-18 19:11:45,952] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:11:45,991] {logging_mixin.py:104} INFO - [2022-03-18 19:11:45,990] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:11:46,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:12:16,454] {scheduler_job.py:182} INFO - Started process (PID=18328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:16,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:12:16,460] {logging_mixin.py:104} INFO - [2022-03-18 19:12:16,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:16,510] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:16,553] {logging_mixin.py:104} INFO - [2022-03-18 19:12:16,553] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:12:16,593] {logging_mixin.py:104} INFO - [2022-03-18 19:12:16,593] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:12:16,609] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:12:47,141] {scheduler_job.py:182} INFO - Started process (PID=18360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:47,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:12:47,149] {logging_mixin.py:104} INFO - [2022-03-18 19:12:47,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:47,202] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:12:47,243] {logging_mixin.py:104} INFO - [2022-03-18 19:12:47,243] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:12:47,282] {logging_mixin.py:104} INFO - [2022-03-18 19:12:47,282] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:12:47,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:13:17,675] {scheduler_job.py:182} INFO - Started process (PID=18392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:17,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:13:17,683] {logging_mixin.py:104} INFO - [2022-03-18 19:13:17,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:17,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:17,777] {logging_mixin.py:104} INFO - [2022-03-18 19:13:17,776] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:13:17,815] {logging_mixin.py:104} INFO - [2022-03-18 19:13:17,815] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:13:17,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:13:48,175] {scheduler_job.py:182} INFO - Started process (PID=18424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:48,179] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:13:48,182] {logging_mixin.py:104} INFO - [2022-03-18 19:13:48,182] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:48,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:13:48,279] {logging_mixin.py:104} INFO - [2022-03-18 19:13:48,279] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:13:48,319] {logging_mixin.py:104} INFO - [2022-03-18 19:13:48,319] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:13:48,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:14:19,047] {scheduler_job.py:182} INFO - Started process (PID=18455) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:19,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:14:19,054] {logging_mixin.py:104} INFO - [2022-03-18 19:14:19,053] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:19,107] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:19,153] {logging_mixin.py:104} INFO - [2022-03-18 19:14:19,153] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:14:19,198] {logging_mixin.py:104} INFO - [2022-03-18 19:14:19,197] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:14:19,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 19:14:49,960] {scheduler_job.py:182} INFO - Started process (PID=18480) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:49,964] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:14:49,967] {logging_mixin.py:104} INFO - [2022-03-18 19:14:49,966] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:50,021] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:14:50,068] {logging_mixin.py:104} INFO - [2022-03-18 19:14:50,068] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:14:50,111] {logging_mixin.py:104} INFO - [2022-03-18 19:14:50,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:14:50,127] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:15:20,794] {scheduler_job.py:182} INFO - Started process (PID=18506) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:20,798] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:15:20,802] {logging_mixin.py:104} INFO - [2022-03-18 19:15:20,801] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:20,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:20,895] {logging_mixin.py:104} INFO - [2022-03-18 19:15:20,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:15:20,935] {logging_mixin.py:104} INFO - [2022-03-18 19:15:20,935] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:15:20,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:15:51,242] {scheduler_job.py:182} INFO - Started process (PID=18538) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:51,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:15:51,250] {logging_mixin.py:104} INFO - [2022-03-18 19:15:51,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:51,302] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:15:51,344] {logging_mixin.py:104} INFO - [2022-03-18 19:15:51,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:15:51,384] {logging_mixin.py:104} INFO - [2022-03-18 19:15:51,384] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:15:51,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:16:21,712] {scheduler_job.py:182} INFO - Started process (PID=18570) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:21,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:16:21,720] {logging_mixin.py:104} INFO - [2022-03-18 19:16:21,720] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:21,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:21,808] {logging_mixin.py:104} INFO - [2022-03-18 19:16:21,808] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:16:21,846] {logging_mixin.py:104} INFO - [2022-03-18 19:16:21,846] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:16:21,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 19:16:52,197] {scheduler_job.py:182} INFO - Started process (PID=18602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:52,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:16:52,203] {logging_mixin.py:104} INFO - [2022-03-18 19:16:52,202] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:52,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:16:52,296] {logging_mixin.py:104} INFO - [2022-03-18 19:16:52,295] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:16:52,334] {logging_mixin.py:104} INFO - [2022-03-18 19:16:52,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:16:52,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 19:17:22,760] {scheduler_job.py:182} INFO - Started process (PID=18634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:22,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:17:22,767] {logging_mixin.py:104} INFO - [2022-03-18 19:17:22,766] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:22,820] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:22,863] {logging_mixin.py:104} INFO - [2022-03-18 19:17:22,863] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:17:22,902] {logging_mixin.py:104} INFO - [2022-03-18 19:17:22,902] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:17:22,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:17:53,496] {scheduler_job.py:182} INFO - Started process (PID=18666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:53,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:17:53,504] {logging_mixin.py:104} INFO - [2022-03-18 19:17:53,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:53,560] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:17:53,606] {logging_mixin.py:104} INFO - [2022-03-18 19:17:53,605] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:17:53,647] {logging_mixin.py:104} INFO - [2022-03-18 19:17:53,646] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:17:53,663] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:18:24,496] {scheduler_job.py:182} INFO - Started process (PID=18698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:24,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:18:24,504] {logging_mixin.py:104} INFO - [2022-03-18 19:18:24,503] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:24,554] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:24,602] {logging_mixin.py:104} INFO - [2022-03-18 19:18:24,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:18:24,646] {logging_mixin.py:104} INFO - [2022-03-18 19:18:24,646] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:18:24,664] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:18:54,871] {scheduler_job.py:182} INFO - Started process (PID=18723) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:54,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:18:54,878] {logging_mixin.py:104} INFO - [2022-03-18 19:18:54,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:54,931] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:18:54,974] {logging_mixin.py:104} INFO - [2022-03-18 19:18:54,974] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:18:55,014] {logging_mixin.py:104} INFO - [2022-03-18 19:18:55,013] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:18:55,029] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:19:25,799] {scheduler_job.py:182} INFO - Started process (PID=18754) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:25,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:19:25,807] {logging_mixin.py:104} INFO - [2022-03-18 19:19:25,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:25,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:25,898] {logging_mixin.py:104} INFO - [2022-03-18 19:19:25,898] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:19:25,939] {logging_mixin.py:104} INFO - [2022-03-18 19:19:25,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:19:25,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:19:56,817] {scheduler_job.py:182} INFO - Started process (PID=18780) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:56,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:19:56,825] {logging_mixin.py:104} INFO - [2022-03-18 19:19:56,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:56,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:19:56,938] {logging_mixin.py:104} INFO - [2022-03-18 19:19:56,938] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:19:56,980] {logging_mixin.py:104} INFO - [2022-03-18 19:19:56,980] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:19:56,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 19:20:27,464] {scheduler_job.py:182} INFO - Started process (PID=18812) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:27,468] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:20:27,470] {logging_mixin.py:104} INFO - [2022-03-18 19:20:27,470] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:27,523] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:27,571] {logging_mixin.py:104} INFO - [2022-03-18 19:20:27,571] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:20:27,613] {logging_mixin.py:104} INFO - [2022-03-18 19:20:27,612] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:20:27,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:20:58,038] {scheduler_job.py:182} INFO - Started process (PID=18844) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:58,042] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:20:58,045] {logging_mixin.py:104} INFO - [2022-03-18 19:20:58,044] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:58,099] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:20:58,142] {logging_mixin.py:104} INFO - [2022-03-18 19:20:58,141] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:20:58,185] {logging_mixin.py:104} INFO - [2022-03-18 19:20:58,185] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:20:58,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:21:28,816] {scheduler_job.py:182} INFO - Started process (PID=18876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:28,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:21:28,823] {logging_mixin.py:104} INFO - [2022-03-18 19:21:28,822] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:28,872] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:28,914] {logging_mixin.py:104} INFO - [2022-03-18 19:21:28,914] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:21:28,953] {logging_mixin.py:104} INFO - [2022-03-18 19:21:28,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:21:28,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:21:59,359] {scheduler_job.py:182} INFO - Started process (PID=18908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:59,363] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:21:59,366] {logging_mixin.py:104} INFO - [2022-03-18 19:21:59,365] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:59,421] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:21:59,464] {logging_mixin.py:104} INFO - [2022-03-18 19:21:59,464] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:21:59,504] {logging_mixin.py:104} INFO - [2022-03-18 19:21:59,504] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:21:59,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:22:29,874] {scheduler_job.py:182} INFO - Started process (PID=18940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:22:29,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:22:29,881] {logging_mixin.py:104} INFO - [2022-03-18 19:22:29,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:22:29,934] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:22:29,977] {logging_mixin.py:104} INFO - [2022-03-18 19:22:29,977] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:22:30,019] {logging_mixin.py:104} INFO - [2022-03-18 19:22:30,019] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:22:30,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 19:23:00,748] {scheduler_job.py:182} INFO - Started process (PID=18972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:00,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:23:00,755] {logging_mixin.py:104} INFO - [2022-03-18 19:23:00,755] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:00,806] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:00,853] {logging_mixin.py:104} INFO - [2022-03-18 19:23:00,852] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:23:00,897] {logging_mixin.py:104} INFO - [2022-03-18 19:23:00,896] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:23:00,913] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 19:23:31,087] {scheduler_job.py:182} INFO - Started process (PID=18997) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:31,091] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:23:31,094] {logging_mixin.py:104} INFO - [2022-03-18 19:23:31,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:31,149] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:23:31,192] {logging_mixin.py:104} INFO - [2022-03-18 19:23:31,191] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:23:31,232] {logging_mixin.py:104} INFO - [2022-03-18 19:23:31,232] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:23:31,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:24:02,019] {scheduler_job.py:182} INFO - Started process (PID=19028) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:02,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:24:02,025] {logging_mixin.py:104} INFO - [2022-03-18 19:24:02,025] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:02,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:02,124] {logging_mixin.py:104} INFO - [2022-03-18 19:24:02,123] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:24:02,169] {logging_mixin.py:104} INFO - [2022-03-18 19:24:02,168] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:24:02,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 19:24:33,019] {scheduler_job.py:182} INFO - Started process (PID=19054) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:33,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:24:33,026] {logging_mixin.py:104} INFO - [2022-03-18 19:24:33,026] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:33,083] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:24:33,124] {logging_mixin.py:104} INFO - [2022-03-18 19:24:33,124] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:24:33,165] {logging_mixin.py:104} INFO - [2022-03-18 19:24:33,164] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:24:33,180] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 19:25:03,715] {scheduler_job.py:182} INFO - Started process (PID=19086) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:03,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:25:03,724] {logging_mixin.py:104} INFO - [2022-03-18 19:25:03,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:03,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:03,820] {logging_mixin.py:104} INFO - [2022-03-18 19:25:03,819] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:25:03,860] {logging_mixin.py:104} INFO - [2022-03-18 19:25:03,859] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:25:03,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 19:25:34,240] {scheduler_job.py:182} INFO - Started process (PID=19118) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:34,245] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:25:34,247] {logging_mixin.py:104} INFO - [2022-03-18 19:25:34,247] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:34,298] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:25:34,345] {logging_mixin.py:104} INFO - [2022-03-18 19:25:34,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:25:34,389] {logging_mixin.py:104} INFO - [2022-03-18 19:25:34,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:25:34,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:26:05,012] {scheduler_job.py:182} INFO - Started process (PID=19150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:05,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:26:05,019] {logging_mixin.py:104} INFO - [2022-03-18 19:26:05,018] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:05,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:05,112] {logging_mixin.py:104} INFO - [2022-03-18 19:26:05,111] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:26:05,149] {logging_mixin.py:104} INFO - [2022-03-18 19:26:05,149] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:26:05,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 19:26:35,662] {scheduler_job.py:182} INFO - Started process (PID=19182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:35,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:26:35,669] {logging_mixin.py:104} INFO - [2022-03-18 19:26:35,668] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:35,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:26:35,763] {logging_mixin.py:104} INFO - [2022-03-18 19:26:35,763] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:26:35,801] {logging_mixin.py:104} INFO - [2022-03-18 19:26:35,801] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:26:35,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:27:06,331] {scheduler_job.py:182} INFO - Started process (PID=19214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:06,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:27:06,337] {logging_mixin.py:104} INFO - [2022-03-18 19:27:06,337] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:06,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:06,437] {logging_mixin.py:104} INFO - [2022-03-18 19:27:06,436] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:27:06,479] {logging_mixin.py:104} INFO - [2022-03-18 19:27:06,479] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:27:06,496] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 19:27:37,114] {scheduler_job.py:182} INFO - Started process (PID=19246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:37,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:27:37,120] {logging_mixin.py:104} INFO - [2022-03-18 19:27:37,119] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:37,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:27:37,217] {logging_mixin.py:104} INFO - [2022-03-18 19:27:37,217] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:27:37,260] {logging_mixin.py:104} INFO - [2022-03-18 19:27:37,259] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:27:37,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:28:07,384] {scheduler_job.py:182} INFO - Started process (PID=19267) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:07,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:28:07,392] {logging_mixin.py:104} INFO - [2022-03-18 19:28:07,391] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:07,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:07,488] {logging_mixin.py:104} INFO - [2022-03-18 19:28:07,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:28:07,530] {logging_mixin.py:104} INFO - [2022-03-18 19:28:07,530] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:28:07,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:28:38,451] {scheduler_job.py:182} INFO - Started process (PID=19302) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:38,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:28:38,457] {logging_mixin.py:104} INFO - [2022-03-18 19:28:38,457] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:38,507] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:28:38,555] {logging_mixin.py:104} INFO - [2022-03-18 19:28:38,554] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:28:38,597] {logging_mixin.py:104} INFO - [2022-03-18 19:28:38,597] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:28:38,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 19:29:09,395] {scheduler_job.py:182} INFO - Started process (PID=19328) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:09,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:29:09,402] {logging_mixin.py:104} INFO - [2022-03-18 19:29:09,402] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:09,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:09,508] {logging_mixin.py:104} INFO - [2022-03-18 19:29:09,508] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:29:09,550] {logging_mixin.py:104} INFO - [2022-03-18 19:29:09,550] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:29:09,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 19:29:40,168] {scheduler_job.py:182} INFO - Started process (PID=19360) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:40,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:29:40,176] {logging_mixin.py:104} INFO - [2022-03-18 19:29:40,176] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:40,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:29:40,270] {logging_mixin.py:104} INFO - [2022-03-18 19:29:40,269] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:29:40,309] {logging_mixin.py:104} INFO - [2022-03-18 19:29:40,308] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:29:40,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:30:10,885] {scheduler_job.py:182} INFO - Started process (PID=19392) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:10,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:30:10,891] {logging_mixin.py:104} INFO - [2022-03-18 19:30:10,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:10,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:10,985] {logging_mixin.py:104} INFO - [2022-03-18 19:30:10,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:30:11,023] {logging_mixin.py:104} INFO - [2022-03-18 19:30:11,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:30:11,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 19:30:41,412] {scheduler_job.py:182} INFO - Started process (PID=19424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:41,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:30:41,420] {logging_mixin.py:104} INFO - [2022-03-18 19:30:41,420] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:41,472] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:30:41,513] {logging_mixin.py:104} INFO - [2022-03-18 19:30:41,513] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:30:41,552] {logging_mixin.py:104} INFO - [2022-03-18 19:30:41,552] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:30:41,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:31:11,936] {scheduler_job.py:182} INFO - Started process (PID=19456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:11,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:31:11,944] {logging_mixin.py:104} INFO - [2022-03-18 19:31:11,944] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:11,997] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:12,040] {logging_mixin.py:104} INFO - [2022-03-18 19:31:12,039] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:31:12,078] {logging_mixin.py:104} INFO - [2022-03-18 19:31:12,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:31:12,093] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:31:42,525] {scheduler_job.py:182} INFO - Started process (PID=19488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:42,529] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:31:42,533] {logging_mixin.py:104} INFO - [2022-03-18 19:31:42,532] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:42,582] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:31:42,625] {logging_mixin.py:104} INFO - [2022-03-18 19:31:42,624] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:31:42,664] {logging_mixin.py:104} INFO - [2022-03-18 19:31:42,664] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:31:42,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:32:13,386] {scheduler_job.py:182} INFO - Started process (PID=19519) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:13,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:32:13,394] {logging_mixin.py:104} INFO - [2022-03-18 19:32:13,393] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:13,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:13,497] {logging_mixin.py:104} INFO - [2022-03-18 19:32:13,496] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:32:13,541] {logging_mixin.py:104} INFO - [2022-03-18 19:32:13,541] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:32:13,559] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 19:32:43,819] {scheduler_job.py:182} INFO - Started process (PID=19545) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:43,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:32:43,825] {logging_mixin.py:104} INFO - [2022-03-18 19:32:43,825] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:43,879] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:32:43,923] {logging_mixin.py:104} INFO - [2022-03-18 19:32:43,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:32:43,962] {logging_mixin.py:104} INFO - [2022-03-18 19:32:43,961] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:32:43,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:33:14,675] {scheduler_job.py:182} INFO - Started process (PID=19576) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:14,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:33:14,681] {logging_mixin.py:104} INFO - [2022-03-18 19:33:14,681] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:14,731] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:14,778] {logging_mixin.py:104} INFO - [2022-03-18 19:33:14,778] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:33:14,822] {logging_mixin.py:104} INFO - [2022-03-18 19:33:14,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:33:14,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:33:45,110] {scheduler_job.py:182} INFO - Started process (PID=19602) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:45,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:33:45,118] {logging_mixin.py:104} INFO - [2022-03-18 19:33:45,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:45,169] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:33:45,211] {logging_mixin.py:104} INFO - [2022-03-18 19:33:45,211] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:33:45,251] {logging_mixin.py:104} INFO - [2022-03-18 19:33:45,251] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:33:45,266] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:34:15,622] {scheduler_job.py:182} INFO - Started process (PID=19634) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:15,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:34:15,628] {logging_mixin.py:104} INFO - [2022-03-18 19:34:15,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:15,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:15,723] {logging_mixin.py:104} INFO - [2022-03-18 19:34:15,723] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:34:15,762] {logging_mixin.py:104} INFO - [2022-03-18 19:34:15,762] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:34:15,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:34:46,275] {scheduler_job.py:182} INFO - Started process (PID=19666) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:46,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:34:46,281] {logging_mixin.py:104} INFO - [2022-03-18 19:34:46,281] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:46,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:34:46,375] {logging_mixin.py:104} INFO - [2022-03-18 19:34:46,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:34:46,414] {logging_mixin.py:104} INFO - [2022-03-18 19:34:46,413] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:34:46,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 19:35:16,795] {scheduler_job.py:182} INFO - Started process (PID=19698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:16,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:35:16,802] {logging_mixin.py:104} INFO - [2022-03-18 19:35:16,801] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:16,853] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:16,896] {logging_mixin.py:104} INFO - [2022-03-18 19:35:16,895] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:35:16,937] {logging_mixin.py:104} INFO - [2022-03-18 19:35:16,937] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:35:16,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:35:47,313] {scheduler_job.py:182} INFO - Started process (PID=19730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:47,317] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:35:47,320] {logging_mixin.py:104} INFO - [2022-03-18 19:35:47,319] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:47,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:35:47,417] {logging_mixin.py:104} INFO - [2022-03-18 19:35:47,417] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:35:47,457] {logging_mixin.py:104} INFO - [2022-03-18 19:35:47,457] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:35:47,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:36:18,129] {scheduler_job.py:182} INFO - Started process (PID=19762) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:18,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:36:18,137] {logging_mixin.py:104} INFO - [2022-03-18 19:36:18,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:18,190] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:18,235] {logging_mixin.py:104} INFO - [2022-03-18 19:36:18,235] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:36:18,279] {logging_mixin.py:104} INFO - [2022-03-18 19:36:18,278] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:36:18,295] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 19:36:48,449] {scheduler_job.py:182} INFO - Started process (PID=19787) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:48,454] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:36:48,457] {logging_mixin.py:104} INFO - [2022-03-18 19:36:48,457] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:48,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:36:48,552] {logging_mixin.py:104} INFO - [2022-03-18 19:36:48,552] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:36:48,591] {logging_mixin.py:104} INFO - [2022-03-18 19:36:48,591] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:36:48,606] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:37:19,450] {scheduler_job.py:182} INFO - Started process (PID=19819) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:19,454] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:37:19,457] {logging_mixin.py:104} INFO - [2022-03-18 19:37:19,456] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:19,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:19,556] {logging_mixin.py:104} INFO - [2022-03-18 19:37:19,556] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:37:19,602] {logging_mixin.py:104} INFO - [2022-03-18 19:37:19,602] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:37:19,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 19:37:49,706] {scheduler_job.py:182} INFO - Started process (PID=19840) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:49,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:37:49,713] {logging_mixin.py:104} INFO - [2022-03-18 19:37:49,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:49,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:37:49,811] {logging_mixin.py:104} INFO - [2022-03-18 19:37:49,810] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:37:49,855] {logging_mixin.py:104} INFO - [2022-03-18 19:37:49,854] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:37:49,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 19:38:20,487] {scheduler_job.py:182} INFO - Started process (PID=19876) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:20,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:38:20,494] {logging_mixin.py:104} INFO - [2022-03-18 19:38:20,493] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:20,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:20,589] {logging_mixin.py:104} INFO - [2022-03-18 19:38:20,589] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:38:20,628] {logging_mixin.py:104} INFO - [2022-03-18 19:38:20,627] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:38:20,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:38:50,943] {scheduler_job.py:182} INFO - Started process (PID=19908) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:50,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:38:50,951] {logging_mixin.py:104} INFO - [2022-03-18 19:38:50,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:51,001] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:38:51,043] {logging_mixin.py:104} INFO - [2022-03-18 19:38:51,042] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:38:51,081] {logging_mixin.py:104} INFO - [2022-03-18 19:38:51,081] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:38:51,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:39:21,551] {scheduler_job.py:182} INFO - Started process (PID=19940) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:21,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:39:21,557] {logging_mixin.py:104} INFO - [2022-03-18 19:39:21,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:21,612] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:21,654] {logging_mixin.py:104} INFO - [2022-03-18 19:39:21,654] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:39:21,693] {logging_mixin.py:104} INFO - [2022-03-18 19:39:21,693] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:39:21,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:39:52,141] {scheduler_job.py:182} INFO - Started process (PID=19972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:52,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:39:52,148] {logging_mixin.py:104} INFO - [2022-03-18 19:39:52,148] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:52,201] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:39:52,245] {logging_mixin.py:104} INFO - [2022-03-18 19:39:52,244] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:39:52,284] {logging_mixin.py:104} INFO - [2022-03-18 19:39:52,283] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:39:52,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:40:22,671] {scheduler_job.py:182} INFO - Started process (PID=20004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:22,675] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:40:22,677] {logging_mixin.py:104} INFO - [2022-03-18 19:40:22,677] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:22,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:22,774] {logging_mixin.py:104} INFO - [2022-03-18 19:40:22,774] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:40:22,813] {logging_mixin.py:104} INFO - [2022-03-18 19:40:22,812] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:40:22,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:40:53,453] {scheduler_job.py:182} INFO - Started process (PID=20036) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:53,457] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:40:53,460] {logging_mixin.py:104} INFO - [2022-03-18 19:40:53,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:53,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:40:53,559] {logging_mixin.py:104} INFO - [2022-03-18 19:40:53,558] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:40:53,603] {logging_mixin.py:104} INFO - [2022-03-18 19:40:53,602] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:40:53,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 19:41:23,740] {scheduler_job.py:182} INFO - Started process (PID=20061) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:23,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:41:23,746] {logging_mixin.py:104} INFO - [2022-03-18 19:41:23,746] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:23,800] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:23,843] {logging_mixin.py:104} INFO - [2022-03-18 19:41:23,843] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:41:23,881] {logging_mixin.py:104} INFO - [2022-03-18 19:41:23,881] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:41:23,897] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 19:41:54,682] {scheduler_job.py:182} INFO - Started process (PID=20093) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:54,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:41:54,690] {logging_mixin.py:104} INFO - [2022-03-18 19:41:54,690] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:54,738] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:41:54,783] {logging_mixin.py:104} INFO - [2022-03-18 19:41:54,782] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:41:54,826] {logging_mixin.py:104} INFO - [2022-03-18 19:41:54,826] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:41:54,843] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:42:24,993] {scheduler_job.py:182} INFO - Started process (PID=20114) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:24,997] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:42:25,000] {logging_mixin.py:104} INFO - [2022-03-18 19:42:24,999] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:25,052] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:25,097] {logging_mixin.py:104} INFO - [2022-03-18 19:42:25,096] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:42:25,139] {logging_mixin.py:104} INFO - [2022-03-18 19:42:25,138] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:42:25,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 19:42:55,637] {scheduler_job.py:182} INFO - Started process (PID=20150) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:55,643] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:42:55,646] {logging_mixin.py:104} INFO - [2022-03-18 19:42:55,645] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:55,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:42:55,740] {logging_mixin.py:104} INFO - [2022-03-18 19:42:55,740] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:42:55,782] {logging_mixin.py:104} INFO - [2022-03-18 19:42:55,781] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:42:55,796] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:43:26,299] {scheduler_job.py:182} INFO - Started process (PID=20182) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:26,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:43:26,306] {logging_mixin.py:104} INFO - [2022-03-18 19:43:26,306] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:26,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:26,400] {logging_mixin.py:104} INFO - [2022-03-18 19:43:26,400] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:43:26,439] {logging_mixin.py:104} INFO - [2022-03-18 19:43:26,438] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:43:26,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:43:56,693] {scheduler_job.py:182} INFO - Started process (PID=20214) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:56,697] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:43:56,700] {logging_mixin.py:104} INFO - [2022-03-18 19:43:56,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:56,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:43:56,795] {logging_mixin.py:104} INFO - [2022-03-18 19:43:56,795] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:43:56,833] {logging_mixin.py:104} INFO - [2022-03-18 19:43:56,833] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:43:56,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:44:27,182] {scheduler_job.py:182} INFO - Started process (PID=20246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:27,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:44:27,189] {logging_mixin.py:104} INFO - [2022-03-18 19:44:27,188] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:27,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:27,283] {logging_mixin.py:104} INFO - [2022-03-18 19:44:27,283] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:44:27,321] {logging_mixin.py:104} INFO - [2022-03-18 19:44:27,321] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:44:27,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:44:57,733] {scheduler_job.py:182} INFO - Started process (PID=20278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:57,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:44:57,740] {logging_mixin.py:104} INFO - [2022-03-18 19:44:57,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:57,796] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:44:57,842] {logging_mixin.py:104} INFO - [2022-03-18 19:44:57,842] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:44:57,883] {logging_mixin.py:104} INFO - [2022-03-18 19:44:57,883] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:44:57,899] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 19:45:28,603] {scheduler_job.py:182} INFO - Started process (PID=20310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:28,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:45:28,610] {logging_mixin.py:104} INFO - [2022-03-18 19:45:28,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:28,661] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:28,705] {logging_mixin.py:104} INFO - [2022-03-18 19:45:28,705] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:45:28,749] {logging_mixin.py:104} INFO - [2022-03-18 19:45:28,749] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:45:28,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 19:45:59,045] {scheduler_job.py:182} INFO - Started process (PID=20335) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:59,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:45:59,053] {logging_mixin.py:104} INFO - [2022-03-18 19:45:59,053] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:59,107] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:45:59,151] {logging_mixin.py:104} INFO - [2022-03-18 19:45:59,151] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:45:59,189] {logging_mixin.py:104} INFO - [2022-03-18 19:45:59,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:45:59,204] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:46:30,153] {scheduler_job.py:182} INFO - Started process (PID=20367) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:46:30,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:46:30,160] {logging_mixin.py:104} INFO - [2022-03-18 19:46:30,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:46:30,210] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:46:30,256] {logging_mixin.py:104} INFO - [2022-03-18 19:46:30,256] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:46:30,301] {logging_mixin.py:104} INFO - [2022-03-18 19:46:30,301] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:46:30,320] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 19:47:00,401] {scheduler_job.py:182} INFO - Started process (PID=20394) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:00,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:47:00,407] {logging_mixin.py:104} INFO - [2022-03-18 19:47:00,406] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:00,453] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:00,501] {logging_mixin.py:104} INFO - [2022-03-18 19:47:00,500] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:47:00,544] {logging_mixin.py:104} INFO - [2022-03-18 19:47:00,544] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:47:00,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:47:31,212] {scheduler_job.py:182} INFO - Started process (PID=20424) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:31,217] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:47:31,220] {logging_mixin.py:104} INFO - [2022-03-18 19:47:31,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:31,270] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:47:31,316] {logging_mixin.py:104} INFO - [2022-03-18 19:47:31,315] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:47:31,357] {logging_mixin.py:104} INFO - [2022-03-18 19:47:31,357] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:47:31,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 19:48:02,046] {scheduler_job.py:182} INFO - Started process (PID=20456) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:02,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:48:02,053] {logging_mixin.py:104} INFO - [2022-03-18 19:48:02,052] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:02,105] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:02,148] {logging_mixin.py:104} INFO - [2022-03-18 19:48:02,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:48:02,187] {logging_mixin.py:104} INFO - [2022-03-18 19:48:02,186] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:48:02,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:48:32,663] {scheduler_job.py:182} INFO - Started process (PID=20488) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:32,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:48:32,669] {logging_mixin.py:104} INFO - [2022-03-18 19:48:32,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:32,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:48:32,764] {logging_mixin.py:104} INFO - [2022-03-18 19:48:32,764] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:48:32,804] {logging_mixin.py:104} INFO - [2022-03-18 19:48:32,803] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:48:32,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:49:03,220] {scheduler_job.py:182} INFO - Started process (PID=20520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:03,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:49:03,228] {logging_mixin.py:104} INFO - [2022-03-18 19:49:03,228] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:03,278] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:03,320] {logging_mixin.py:104} INFO - [2022-03-18 19:49:03,319] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:49:03,360] {logging_mixin.py:104} INFO - [2022-03-18 19:49:03,359] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:49:03,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:49:33,840] {scheduler_job.py:182} INFO - Started process (PID=20552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:33,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:49:33,849] {logging_mixin.py:104} INFO - [2022-03-18 19:49:33,849] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:33,903] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:49:33,946] {logging_mixin.py:104} INFO - [2022-03-18 19:49:33,945] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:49:33,984] {logging_mixin.py:104} INFO - [2022-03-18 19:49:33,984] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:49:34,000] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:50:04,702] {scheduler_job.py:182} INFO - Started process (PID=20584) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:04,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:50:04,708] {logging_mixin.py:104} INFO - [2022-03-18 19:50:04,708] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:04,760] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:04,808] {logging_mixin.py:104} INFO - [2022-03-18 19:50:04,808] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:50:04,856] {logging_mixin.py:104} INFO - [2022-03-18 19:50:04,855] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:50:04,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 19:50:35,106] {scheduler_job.py:182} INFO - Started process (PID=20609) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:35,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:50:35,112] {logging_mixin.py:104} INFO - [2022-03-18 19:50:35,112] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:35,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:50:35,212] {logging_mixin.py:104} INFO - [2022-03-18 19:50:35,211] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:50:35,253] {logging_mixin.py:104} INFO - [2022-03-18 19:50:35,253] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:50:35,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:51:05,651] {scheduler_job.py:182} INFO - Started process (PID=20641) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:05,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:51:05,658] {logging_mixin.py:104} INFO - [2022-03-18 19:51:05,658] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:05,711] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:05,754] {logging_mixin.py:104} INFO - [2022-03-18 19:51:05,753] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:51:05,792] {logging_mixin.py:104} INFO - [2022-03-18 19:51:05,792] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:51:05,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:51:36,361] {scheduler_job.py:182} INFO - Started process (PID=20672) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:36,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:51:36,367] {logging_mixin.py:104} INFO - [2022-03-18 19:51:36,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:36,419] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:51:36,464] {logging_mixin.py:104} INFO - [2022-03-18 19:51:36,464] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:51:36,506] {logging_mixin.py:104} INFO - [2022-03-18 19:51:36,506] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:51:36,522] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 19:52:06,930] {scheduler_job.py:182} INFO - Started process (PID=20698) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:06,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:52:06,938] {logging_mixin.py:104} INFO - [2022-03-18 19:52:06,938] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:06,990] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:07,033] {logging_mixin.py:104} INFO - [2022-03-18 19:52:07,032] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:52:07,071] {logging_mixin.py:104} INFO - [2022-03-18 19:52:07,071] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:52:07,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:52:37,563] {scheduler_job.py:182} INFO - Started process (PID=20730) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:37,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:52:37,570] {logging_mixin.py:104} INFO - [2022-03-18 19:52:37,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:37,621] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:52:37,665] {logging_mixin.py:104} INFO - [2022-03-18 19:52:37,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:52:37,703] {logging_mixin.py:104} INFO - [2022-03-18 19:52:37,703] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:52:37,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:53:08,015] {scheduler_job.py:182} INFO - Started process (PID=20762) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:08,019] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:53:08,022] {logging_mixin.py:104} INFO - [2022-03-18 19:53:08,021] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:08,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:08,117] {logging_mixin.py:104} INFO - [2022-03-18 19:53:08,117] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:53:08,155] {logging_mixin.py:104} INFO - [2022-03-18 19:53:08,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:53:08,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 19:53:38,619] {scheduler_job.py:182} INFO - Started process (PID=20794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:38,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:53:38,626] {logging_mixin.py:104} INFO - [2022-03-18 19:53:38,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:38,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:53:38,725] {logging_mixin.py:104} INFO - [2022-03-18 19:53:38,725] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:53:38,765] {logging_mixin.py:104} INFO - [2022-03-18 19:53:38,764] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:53:38,779] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 19:54:08,994] {scheduler_job.py:182} INFO - Started process (PID=20826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:09,014] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:54:09,017] {logging_mixin.py:104} INFO - [2022-03-18 19:54:09,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:09,070] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:09,113] {logging_mixin.py:104} INFO - [2022-03-18 19:54:09,113] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:54:09,154] {logging_mixin.py:104} INFO - [2022-03-18 19:54:09,153] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:54:09,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 19:54:39,735] {scheduler_job.py:182} INFO - Started process (PID=20857) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:39,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:54:39,742] {logging_mixin.py:104} INFO - [2022-03-18 19:54:39,742] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:39,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:54:39,837] {logging_mixin.py:104} INFO - [2022-03-18 19:54:39,836] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:54:39,881] {logging_mixin.py:104} INFO - [2022-03-18 19:54:39,881] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:54:39,898] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 19:55:10,275] {scheduler_job.py:182} INFO - Started process (PID=20883) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:10,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:55:10,282] {logging_mixin.py:104} INFO - [2022-03-18 19:55:10,282] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:10,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:10,375] {logging_mixin.py:104} INFO - [2022-03-18 19:55:10,375] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:55:10,414] {logging_mixin.py:104} INFO - [2022-03-18 19:55:10,413] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:55:10,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 19:55:41,166] {scheduler_job.py:182} INFO - Started process (PID=20915) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:41,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:55:41,173] {logging_mixin.py:104} INFO - [2022-03-18 19:55:41,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:41,230] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:55:41,279] {logging_mixin.py:104} INFO - [2022-03-18 19:55:41,278] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:55:41,321] {logging_mixin.py:104} INFO - [2022-03-18 19:55:41,320] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:55:41,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 19:56:11,419] {scheduler_job.py:182} INFO - Started process (PID=20942) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:11,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:56:11,425] {logging_mixin.py:104} INFO - [2022-03-18 19:56:11,425] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:11,478] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:11,521] {logging_mixin.py:104} INFO - [2022-03-18 19:56:11,521] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:56:11,562] {logging_mixin.py:104} INFO - [2022-03-18 19:56:11,561] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:56:11,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:56:42,163] {scheduler_job.py:182} INFO - Started process (PID=20972) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:42,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:56:42,173] {logging_mixin.py:104} INFO - [2022-03-18 19:56:42,173] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:42,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:56:42,265] {logging_mixin.py:104} INFO - [2022-03-18 19:56:42,264] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:56:42,302] {logging_mixin.py:104} INFO - [2022-03-18 19:56:42,302] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:56:42,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:57:12,696] {scheduler_job.py:182} INFO - Started process (PID=21004) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:12,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:57:12,703] {logging_mixin.py:104} INFO - [2022-03-18 19:57:12,703] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:12,754] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:12,797] {logging_mixin.py:104} INFO - [2022-03-18 19:57:12,796] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:57:12,836] {logging_mixin.py:104} INFO - [2022-03-18 19:57:12,836] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:57:12,852] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 19:57:43,196] {scheduler_job.py:182} INFO - Started process (PID=21036) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:43,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:57:43,205] {logging_mixin.py:104} INFO - [2022-03-18 19:57:43,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:43,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:57:43,299] {logging_mixin.py:104} INFO - [2022-03-18 19:57:43,298] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:57:43,338] {logging_mixin.py:104} INFO - [2022-03-18 19:57:43,338] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:57:43,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 19:58:13,740] {scheduler_job.py:182} INFO - Started process (PID=21068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:13,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:58:13,748] {logging_mixin.py:104} INFO - [2022-03-18 19:58:13,747] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:13,796] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:13,839] {logging_mixin.py:104} INFO - [2022-03-18 19:58:13,839] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:58:13,878] {logging_mixin.py:104} INFO - [2022-03-18 19:58:13,878] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:58:13,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 19:58:44,517] {scheduler_job.py:182} INFO - Started process (PID=21100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:44,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:58:44,524] {logging_mixin.py:104} INFO - [2022-03-18 19:58:44,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:44,575] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:58:44,623] {logging_mixin.py:104} INFO - [2022-03-18 19:58:44,623] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:58:44,668] {logging_mixin.py:104} INFO - [2022-03-18 19:58:44,668] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:58:44,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 19:59:14,806] {scheduler_job.py:182} INFO - Started process (PID=21125) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:14,811] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:59:14,815] {logging_mixin.py:104} INFO - [2022-03-18 19:59:14,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:14,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:14,911] {logging_mixin.py:104} INFO - [2022-03-18 19:59:14,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:59:14,952] {logging_mixin.py:104} INFO - [2022-03-18 19:59:14,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:59:14,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 19:59:45,719] {scheduler_job.py:182} INFO - Started process (PID=21157) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:45,728] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 19:59:45,734] {logging_mixin.py:104} INFO - [2022-03-18 19:59:45,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:45,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 19:59:45,832] {logging_mixin.py:104} INFO - [2022-03-18 19:59:45,832] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 19:59:45,874] {logging_mixin.py:104} INFO - [2022-03-18 19:59:45,873] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 19:59:45,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 20:00:16,801] {scheduler_job.py:182} INFO - Started process (PID=21189) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:16,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:00:16,807] {logging_mixin.py:104} INFO - [2022-03-18 20:00:16,807] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:16,862] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:16,908] {logging_mixin.py:104} INFO - [2022-03-18 20:00:16,908] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:00:16,955] {logging_mixin.py:104} INFO - [2022-03-18 20:00:16,954] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:00:16,973] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 20:00:47,154] {scheduler_job.py:182} INFO - Started process (PID=21216) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:47,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:00:47,162] {logging_mixin.py:104} INFO - [2022-03-18 20:00:47,162] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:47,209] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:00:47,255] {logging_mixin.py:104} INFO - [2022-03-18 20:00:47,254] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:00:47,296] {logging_mixin.py:104} INFO - [2022-03-18 20:00:47,296] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:00:47,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:01:17,825] {scheduler_job.py:182} INFO - Started process (PID=21246) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:17,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:01:17,832] {logging_mixin.py:104} INFO - [2022-03-18 20:01:17,831] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:17,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:17,929] {logging_mixin.py:104} INFO - [2022-03-18 20:01:17,928] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:01:17,969] {logging_mixin.py:104} INFO - [2022-03-18 20:01:17,968] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:01:17,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:01:48,344] {scheduler_job.py:182} INFO - Started process (PID=21278) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:48,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:01:48,351] {logging_mixin.py:104} INFO - [2022-03-18 20:01:48,351] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:48,403] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:01:48,446] {logging_mixin.py:104} INFO - [2022-03-18 20:01:48,446] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:01:48,484] {logging_mixin.py:104} INFO - [2022-03-18 20:01:48,484] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:01:48,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:02:19,052] {scheduler_job.py:182} INFO - Started process (PID=21310) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:19,056] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:02:19,059] {logging_mixin.py:104} INFO - [2022-03-18 20:02:19,058] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:19,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:19,156] {logging_mixin.py:104} INFO - [2022-03-18 20:02:19,156] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:02:19,196] {logging_mixin.py:104} INFO - [2022-03-18 20:02:19,196] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:02:19,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:02:49,582] {scheduler_job.py:182} INFO - Started process (PID=21342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:49,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:02:49,589] {logging_mixin.py:104} INFO - [2022-03-18 20:02:49,588] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:49,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:02:49,683] {logging_mixin.py:104} INFO - [2022-03-18 20:02:49,683] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:02:49,724] {logging_mixin.py:104} INFO - [2022-03-18 20:02:49,723] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:02:49,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:03:20,438] {scheduler_job.py:182} INFO - Started process (PID=21374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:20,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:03:20,445] {logging_mixin.py:104} INFO - [2022-03-18 20:03:20,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:20,496] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:20,541] {logging_mixin.py:104} INFO - [2022-03-18 20:03:20,541] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:03:20,585] {logging_mixin.py:104} INFO - [2022-03-18 20:03:20,584] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:03:20,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:03:50,825] {scheduler_job.py:182} INFO - Started process (PID=21401) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:50,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:03:50,832] {logging_mixin.py:104} INFO - [2022-03-18 20:03:50,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:50,879] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:03:50,921] {logging_mixin.py:104} INFO - [2022-03-18 20:03:50,921] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:03:50,960] {logging_mixin.py:104} INFO - [2022-03-18 20:03:50,960] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:03:50,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 20:04:21,725] {scheduler_job.py:182} INFO - Started process (PID=21431) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:21,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:04:21,733] {logging_mixin.py:104} INFO - [2022-03-18 20:04:21,733] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:21,785] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:21,827] {logging_mixin.py:104} INFO - [2022-03-18 20:04:21,827] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:04:21,866] {logging_mixin.py:104} INFO - [2022-03-18 20:04:21,866] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:04:21,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:04:52,765] {scheduler_job.py:182} INFO - Started process (PID=21463) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:52,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:04:52,771] {logging_mixin.py:104} INFO - [2022-03-18 20:04:52,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:52,826] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:04:52,875] {logging_mixin.py:104} INFO - [2022-03-18 20:04:52,875] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:04:52,919] {logging_mixin.py:104} INFO - [2022-03-18 20:04:52,919] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:04:52,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 20:05:23,013] {scheduler_job.py:182} INFO - Started process (PID=21484) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:23,017] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:05:23,019] {logging_mixin.py:104} INFO - [2022-03-18 20:05:23,019] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:23,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:23,116] {logging_mixin.py:104} INFO - [2022-03-18 20:05:23,115] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:05:23,155] {logging_mixin.py:104} INFO - [2022-03-18 20:05:23,155] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:05:23,172] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:05:53,791] {scheduler_job.py:182} INFO - Started process (PID=21520) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:53,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:05:53,798] {logging_mixin.py:104} INFO - [2022-03-18 20:05:53,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:53,851] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:05:53,896] {logging_mixin.py:104} INFO - [2022-03-18 20:05:53,896] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:05:53,938] {logging_mixin.py:104} INFO - [2022-03-18 20:05:53,938] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:05:53,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:06:24,442] {scheduler_job.py:182} INFO - Started process (PID=21552) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:24,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:06:24,450] {logging_mixin.py:104} INFO - [2022-03-18 20:06:24,450] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:24,500] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:24,541] {logging_mixin.py:104} INFO - [2022-03-18 20:06:24,541] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:06:24,580] {logging_mixin.py:104} INFO - [2022-03-18 20:06:24,580] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:06:24,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:06:54,948] {scheduler_job.py:182} INFO - Started process (PID=21584) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:54,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:06:54,957] {logging_mixin.py:104} INFO - [2022-03-18 20:06:54,956] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:55,011] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:06:55,053] {logging_mixin.py:104} INFO - [2022-03-18 20:06:55,053] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:06:55,093] {logging_mixin.py:104} INFO - [2022-03-18 20:06:55,093] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:06:55,108] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:07:25,483] {scheduler_job.py:182} INFO - Started process (PID=21616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:25,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:07:25,491] {logging_mixin.py:104} INFO - [2022-03-18 20:07:25,490] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:25,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:25,585] {logging_mixin.py:104} INFO - [2022-03-18 20:07:25,584] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:07:25,625] {logging_mixin.py:104} INFO - [2022-03-18 20:07:25,624] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:07:25,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:07:56,421] {scheduler_job.py:182} INFO - Started process (PID=21648) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:56,425] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:07:56,427] {logging_mixin.py:104} INFO - [2022-03-18 20:07:56,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:56,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:07:56,522] {logging_mixin.py:104} INFO - [2022-03-18 20:07:56,522] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:07:56,564] {logging_mixin.py:104} INFO - [2022-03-18 20:07:56,564] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:07:56,580] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:08:26,733] {scheduler_job.py:182} INFO - Started process (PID=21673) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:26,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:08:26,740] {logging_mixin.py:104} INFO - [2022-03-18 20:08:26,740] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:26,792] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:26,835] {logging_mixin.py:104} INFO - [2022-03-18 20:08:26,834] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:08:26,874] {logging_mixin.py:104} INFO - [2022-03-18 20:08:26,874] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:08:26,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:08:57,282] {scheduler_job.py:182} INFO - Started process (PID=21705) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:57,286] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:08:57,289] {logging_mixin.py:104} INFO - [2022-03-18 20:08:57,289] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:57,339] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:08:57,381] {logging_mixin.py:104} INFO - [2022-03-18 20:08:57,380] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:08:57,419] {logging_mixin.py:104} INFO - [2022-03-18 20:08:57,418] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:08:57,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 20:09:28,395] {scheduler_job.py:182} INFO - Started process (PID=21737) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:28,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:09:28,402] {logging_mixin.py:104} INFO - [2022-03-18 20:09:28,401] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:28,453] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:28,497] {logging_mixin.py:104} INFO - [2022-03-18 20:09:28,497] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:09:28,539] {logging_mixin.py:104} INFO - [2022-03-18 20:09:28,538] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:09:28,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:09:58,635] {scheduler_job.py:182} INFO - Started process (PID=21758) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:58,640] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:09:58,643] {logging_mixin.py:104} INFO - [2022-03-18 20:09:58,642] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:58,699] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:09:58,744] {logging_mixin.py:104} INFO - [2022-03-18 20:09:58,744] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:09:58,793] {logging_mixin.py:104} INFO - [2022-03-18 20:09:58,793] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:09:58,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 20:10:29,292] {scheduler_job.py:182} INFO - Started process (PID=21794) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:29,298] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:10:29,301] {logging_mixin.py:104} INFO - [2022-03-18 20:10:29,300] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:29,350] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:29,394] {logging_mixin.py:104} INFO - [2022-03-18 20:10:29,393] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:10:29,435] {logging_mixin.py:104} INFO - [2022-03-18 20:10:29,434] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:10:29,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:10:59,849] {scheduler_job.py:182} INFO - Started process (PID=21826) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:59,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:10:59,855] {logging_mixin.py:104} INFO - [2022-03-18 20:10:59,855] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:59,910] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:10:59,955] {logging_mixin.py:104} INFO - [2022-03-18 20:10:59,954] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:10:59,996] {logging_mixin.py:104} INFO - [2022-03-18 20:10:59,996] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:11:00,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:11:30,440] {scheduler_job.py:182} INFO - Started process (PID=21858) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:11:30,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:11:30,446] {logging_mixin.py:104} INFO - [2022-03-18 20:11:30,446] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:11:30,498] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:11:30,540] {logging_mixin.py:104} INFO - [2022-03-18 20:11:30,539] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:11:30,579] {logging_mixin.py:104} INFO - [2022-03-18 20:11:30,578] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:11:30,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 20:12:00,992] {scheduler_job.py:182} INFO - Started process (PID=21890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:00,997] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:12:00,999] {logging_mixin.py:104} INFO - [2022-03-18 20:12:00,999] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:01,050] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:01,095] {logging_mixin.py:104} INFO - [2022-03-18 20:12:01,094] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:12:01,136] {logging_mixin.py:104} INFO - [2022-03-18 20:12:01,136] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:12:01,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:12:31,860] {scheduler_job.py:182} INFO - Started process (PID=21922) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:31,864] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:12:31,866] {logging_mixin.py:104} INFO - [2022-03-18 20:12:31,866] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:31,917] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:12:31,963] {logging_mixin.py:104} INFO - [2022-03-18 20:12:31,963] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:12:32,007] {logging_mixin.py:104} INFO - [2022-03-18 20:12:32,007] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:12:32,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 20:13:02,133] {scheduler_job.py:182} INFO - Started process (PID=21947) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:02,138] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:13:02,140] {logging_mixin.py:104} INFO - [2022-03-18 20:13:02,140] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:02,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:02,234] {logging_mixin.py:104} INFO - [2022-03-18 20:13:02,234] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:13:02,274] {logging_mixin.py:104} INFO - [2022-03-18 20:13:02,273] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:13:02,288] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:13:32,798] {scheduler_job.py:182} INFO - Started process (PID=21979) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:32,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:13:32,805] {logging_mixin.py:104} INFO - [2022-03-18 20:13:32,805] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:32,858] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:13:32,901] {logging_mixin.py:104} INFO - [2022-03-18 20:13:32,901] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:13:32,939] {logging_mixin.py:104} INFO - [2022-03-18 20:13:32,939] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:13:32,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 20:14:03,843] {scheduler_job.py:182} INFO - Started process (PID=22011) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:03,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:14:03,850] {logging_mixin.py:104} INFO - [2022-03-18 20:14:03,850] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:03,900] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:03,945] {logging_mixin.py:104} INFO - [2022-03-18 20:14:03,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:14:03,989] {logging_mixin.py:104} INFO - [2022-03-18 20:14:03,988] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:14:04,006] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 20:14:34,205] {scheduler_job.py:182} INFO - Started process (PID=22038) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:34,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:14:34,211] {logging_mixin.py:104} INFO - [2022-03-18 20:14:34,210] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:34,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:14:34,306] {logging_mixin.py:104} INFO - [2022-03-18 20:14:34,306] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:14:34,345] {logging_mixin.py:104} INFO - [2022-03-18 20:14:34,345] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:14:34,360] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:15:04,819] {scheduler_job.py:182} INFO - Started process (PID=22068) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:04,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:15:04,827] {logging_mixin.py:104} INFO - [2022-03-18 20:15:04,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:04,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:04,922] {logging_mixin.py:104} INFO - [2022-03-18 20:15:04,921] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:15:04,962] {logging_mixin.py:104} INFO - [2022-03-18 20:15:04,961] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:15:04,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:15:35,244] {scheduler_job.py:182} INFO - Started process (PID=22100) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:35,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:15:35,251] {logging_mixin.py:104} INFO - [2022-03-18 20:15:35,251] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:35,304] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:15:35,347] {logging_mixin.py:104} INFO - [2022-03-18 20:15:35,347] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:15:35,387] {logging_mixin.py:104} INFO - [2022-03-18 20:15:35,387] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:15:35,403] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:16:05,787] {scheduler_job.py:182} INFO - Started process (PID=22132) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:05,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:16:05,793] {logging_mixin.py:104} INFO - [2022-03-18 20:16:05,792] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:05,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:05,889] {logging_mixin.py:104} INFO - [2022-03-18 20:16:05,889] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:16:05,929] {logging_mixin.py:104} INFO - [2022-03-18 20:16:05,929] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:16:05,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:16:36,201] {scheduler_job.py:182} INFO - Started process (PID=22164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:36,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:16:36,208] {logging_mixin.py:104} INFO - [2022-03-18 20:16:36,208] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:36,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:16:36,301] {logging_mixin.py:104} INFO - [2022-03-18 20:16:36,301] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:16:36,342] {logging_mixin.py:104} INFO - [2022-03-18 20:16:36,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:16:36,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:17:06,920] {scheduler_job.py:182} INFO - Started process (PID=22195) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:06,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:17:06,927] {logging_mixin.py:104} INFO - [2022-03-18 20:17:06,927] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:06,978] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:07,025] {logging_mixin.py:104} INFO - [2022-03-18 20:17:07,025] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:17:07,068] {logging_mixin.py:104} INFO - [2022-03-18 20:17:07,068] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:17:07,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 20:17:37,365] {scheduler_job.py:182} INFO - Started process (PID=22221) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:37,369] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:17:37,371] {logging_mixin.py:104} INFO - [2022-03-18 20:17:37,371] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:37,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:17:37,465] {logging_mixin.py:104} INFO - [2022-03-18 20:17:37,465] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:17:37,505] {logging_mixin.py:104} INFO - [2022-03-18 20:17:37,505] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:17:37,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 20:18:07,998] {scheduler_job.py:182} INFO - Started process (PID=22253) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:08,003] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:18:08,006] {logging_mixin.py:104} INFO - [2022-03-18 20:18:08,006] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:08,060] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:08,101] {logging_mixin.py:104} INFO - [2022-03-18 20:18:08,101] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:18:08,143] {logging_mixin.py:104} INFO - [2022-03-18 20:18:08,142] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:18:08,158] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:18:38,979] {scheduler_job.py:182} INFO - Started process (PID=22284) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:38,984] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:18:38,986] {logging_mixin.py:104} INFO - [2022-03-18 20:18:38,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:39,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:18:39,083] {logging_mixin.py:104} INFO - [2022-03-18 20:18:39,083] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:18:39,126] {logging_mixin.py:104} INFO - [2022-03-18 20:18:39,125] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:18:39,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:19:09,373] {scheduler_job.py:182} INFO - Started process (PID=22312) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:09,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:19:09,379] {logging_mixin.py:104} INFO - [2022-03-18 20:19:09,379] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:09,425] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:09,468] {logging_mixin.py:104} INFO - [2022-03-18 20:19:09,468] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:19:09,506] {logging_mixin.py:104} INFO - [2022-03-18 20:19:09,506] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:19:09,523] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 20:19:40,201] {scheduler_job.py:182} INFO - Started process (PID=22342) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:40,205] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:19:40,207] {logging_mixin.py:104} INFO - [2022-03-18 20:19:40,207] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:40,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:19:40,301] {logging_mixin.py:104} INFO - [2022-03-18 20:19:40,301] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:19:40,342] {logging_mixin.py:104} INFO - [2022-03-18 20:19:40,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:19:40,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:20:11,219] {scheduler_job.py:182} INFO - Started process (PID=22374) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:11,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:20:11,226] {logging_mixin.py:104} INFO - [2022-03-18 20:20:11,225] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:11,278] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:11,320] {logging_mixin.py:104} INFO - [2022-03-18 20:20:11,319] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:20:11,358] {logging_mixin.py:104} INFO - [2022-03-18 20:20:11,358] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:20:11,374] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:20:41,718] {scheduler_job.py:182} INFO - Started process (PID=22406) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:41,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:20:41,726] {logging_mixin.py:104} INFO - [2022-03-18 20:20:41,725] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:41,777] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:20:41,818] {logging_mixin.py:104} INFO - [2022-03-18 20:20:41,818] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:20:41,857] {logging_mixin.py:104} INFO - [2022-03-18 20:20:41,857] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:20:41,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:21:12,312] {scheduler_job.py:182} INFO - Started process (PID=22438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:12,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:21:12,318] {logging_mixin.py:104} INFO - [2022-03-18 20:21:12,318] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:12,371] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:12,413] {logging_mixin.py:104} INFO - [2022-03-18 20:21:12,413] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:21:12,454] {logging_mixin.py:104} INFO - [2022-03-18 20:21:12,453] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:21:12,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:21:43,257] {scheduler_job.py:182} INFO - Started process (PID=22469) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:43,262] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:21:43,264] {logging_mixin.py:104} INFO - [2022-03-18 20:21:43,264] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:43,317] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:21:43,363] {logging_mixin.py:104} INFO - [2022-03-18 20:21:43,363] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:21:43,405] {logging_mixin.py:104} INFO - [2022-03-18 20:21:43,405] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:21:43,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.207 seconds
[2022-03-18 20:22:13,731] {scheduler_job.py:182} INFO - Started process (PID=22495) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:13,735] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:22:13,737] {logging_mixin.py:104} INFO - [2022-03-18 20:22:13,737] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:13,790] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:13,832] {logging_mixin.py:104} INFO - [2022-03-18 20:22:13,832] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:22:13,871] {logging_mixin.py:104} INFO - [2022-03-18 20:22:13,871] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:22:13,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:22:44,567] {scheduler_job.py:182} INFO - Started process (PID=22527) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:44,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:22:44,574] {logging_mixin.py:104} INFO - [2022-03-18 20:22:44,573] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:44,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:22:44,677] {logging_mixin.py:104} INFO - [2022-03-18 20:22:44,677] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:22:44,716] {logging_mixin.py:104} INFO - [2022-03-18 20:22:44,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:22:44,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:23:15,823] {scheduler_job.py:182} INFO - Started process (PID=22558) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:15,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:23:15,830] {logging_mixin.py:104} INFO - [2022-03-18 20:23:15,829] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:15,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:15,925] {logging_mixin.py:104} INFO - [2022-03-18 20:23:15,924] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:23:15,967] {logging_mixin.py:104} INFO - [2022-03-18 20:23:15,966] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:23:15,983] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:23:46,066] {scheduler_job.py:182} INFO - Started process (PID=22586) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:46,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:23:46,072] {logging_mixin.py:104} INFO - [2022-03-18 20:23:46,072] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:46,120] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:23:46,162] {logging_mixin.py:104} INFO - [2022-03-18 20:23:46,162] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:23:46,200] {logging_mixin.py:104} INFO - [2022-03-18 20:23:46,200] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:23:46,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 20:24:16,811] {scheduler_job.py:182} INFO - Started process (PID=22616) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:16,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:24:16,818] {logging_mixin.py:104} INFO - [2022-03-18 20:24:16,818] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:16,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:16,915] {logging_mixin.py:104} INFO - [2022-03-18 20:24:16,915] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:24:16,955] {logging_mixin.py:104} INFO - [2022-03-18 20:24:16,955] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:24:16,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:24:47,586] {scheduler_job.py:182} INFO - Started process (PID=22648) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:47,590] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:24:47,593] {logging_mixin.py:104} INFO - [2022-03-18 20:24:47,593] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:47,645] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:24:47,689] {logging_mixin.py:104} INFO - [2022-03-18 20:24:47,689] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:24:47,728] {logging_mixin.py:104} INFO - [2022-03-18 20:24:47,728] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:24:47,743] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:25:18,117] {scheduler_job.py:182} INFO - Started process (PID=22680) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:18,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:25:18,124] {logging_mixin.py:104} INFO - [2022-03-18 20:25:18,123] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:18,175] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:18,217] {logging_mixin.py:104} INFO - [2022-03-18 20:25:18,216] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:25:18,255] {logging_mixin.py:104} INFO - [2022-03-18 20:25:18,255] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:25:18,270] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 20:25:48,911] {scheduler_job.py:182} INFO - Started process (PID=22712) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:48,915] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:25:48,918] {logging_mixin.py:104} INFO - [2022-03-18 20:25:48,917] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:48,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:25:49,012] {logging_mixin.py:104} INFO - [2022-03-18 20:25:49,012] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:25:49,055] {logging_mixin.py:104} INFO - [2022-03-18 20:25:49,055] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:25:49,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:26:19,208] {scheduler_job.py:182} INFO - Started process (PID=22737) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:19,212] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:26:19,215] {logging_mixin.py:104} INFO - [2022-03-18 20:26:19,214] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:19,267] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:19,314] {logging_mixin.py:104} INFO - [2022-03-18 20:26:19,313] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:26:19,355] {logging_mixin.py:104} INFO - [2022-03-18 20:26:19,355] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:26:19,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 20:26:49,930] {scheduler_job.py:182} INFO - Started process (PID=22769) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:49,933] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:26:49,936] {logging_mixin.py:104} INFO - [2022-03-18 20:26:49,936] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:49,990] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:26:50,035] {logging_mixin.py:104} INFO - [2022-03-18 20:26:50,034] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:26:50,074] {logging_mixin.py:104} INFO - [2022-03-18 20:26:50,073] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:26:50,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:27:20,460] {scheduler_job.py:182} INFO - Started process (PID=22801) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:20,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:27:20,468] {logging_mixin.py:104} INFO - [2022-03-18 20:27:20,467] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:20,519] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:20,561] {logging_mixin.py:104} INFO - [2022-03-18 20:27:20,561] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:27:20,602] {logging_mixin.py:104} INFO - [2022-03-18 20:27:20,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:27:20,617] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:27:51,494] {scheduler_job.py:182} INFO - Started process (PID=22832) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:51,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:27:51,501] {logging_mixin.py:104} INFO - [2022-03-18 20:27:51,500] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:51,551] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:27:51,597] {logging_mixin.py:104} INFO - [2022-03-18 20:27:51,596] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:27:51,640] {logging_mixin.py:104} INFO - [2022-03-18 20:27:51,639] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:27:51,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 20:28:21,888] {scheduler_job.py:182} INFO - Started process (PID=22860) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:21,892] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:28:21,894] {logging_mixin.py:104} INFO - [2022-03-18 20:28:21,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:21,943] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:21,986] {logging_mixin.py:104} INFO - [2022-03-18 20:28:21,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:28:22,023] {logging_mixin.py:104} INFO - [2022-03-18 20:28:22,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:28:22,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 20:28:52,569] {scheduler_job.py:182} INFO - Started process (PID=22890) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:52,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:28:52,592] {logging_mixin.py:104} INFO - [2022-03-18 20:28:52,592] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:52,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:28:52,692] {logging_mixin.py:104} INFO - [2022-03-18 20:28:52,692] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:28:52,731] {logging_mixin.py:104} INFO - [2022-03-18 20:28:52,731] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:28:52,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 20:29:23,112] {scheduler_job.py:182} INFO - Started process (PID=22922) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:23,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:29:23,118] {logging_mixin.py:104} INFO - [2022-03-18 20:29:23,118] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:23,171] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:23,213] {logging_mixin.py:104} INFO - [2022-03-18 20:29:23,213] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:29:23,253] {logging_mixin.py:104} INFO - [2022-03-18 20:29:23,252] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:29:23,269] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:29:53,756] {scheduler_job.py:182} INFO - Started process (PID=22954) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:53,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:29:53,762] {logging_mixin.py:104} INFO - [2022-03-18 20:29:53,762] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:53,819] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:29:53,861] {logging_mixin.py:104} INFO - [2022-03-18 20:29:53,860] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:29:53,899] {logging_mixin.py:104} INFO - [2022-03-18 20:29:53,899] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:29:53,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:30:24,556] {scheduler_job.py:182} INFO - Started process (PID=22986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:24,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:30:24,563] {logging_mixin.py:104} INFO - [2022-03-18 20:30:24,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:24,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:24,656] {logging_mixin.py:104} INFO - [2022-03-18 20:30:24,656] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:30:24,697] {logging_mixin.py:104} INFO - [2022-03-18 20:30:24,697] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:30:24,715] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:30:55,011] {scheduler_job.py:182} INFO - Started process (PID=23011) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:55,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:30:55,017] {logging_mixin.py:104} INFO - [2022-03-18 20:30:55,017] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:55,068] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:30:55,111] {logging_mixin.py:104} INFO - [2022-03-18 20:30:55,111] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:30:55,151] {logging_mixin.py:104} INFO - [2022-03-18 20:30:55,151] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:30:55,167] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:31:25,473] {scheduler_job.py:182} INFO - Started process (PID=23043) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:25,477] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:31:25,480] {logging_mixin.py:104} INFO - [2022-03-18 20:31:25,480] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:25,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:25,581] {logging_mixin.py:104} INFO - [2022-03-18 20:31:25,580] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:31:25,619] {logging_mixin.py:104} INFO - [2022-03-18 20:31:25,619] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:31:25,634] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:31:56,075] {scheduler_job.py:182} INFO - Started process (PID=23075) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:56,079] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:31:56,082] {logging_mixin.py:104} INFO - [2022-03-18 20:31:56,081] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:56,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:31:56,179] {logging_mixin.py:104} INFO - [2022-03-18 20:31:56,178] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:31:56,220] {logging_mixin.py:104} INFO - [2022-03-18 20:31:56,219] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:31:56,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 20:32:27,243] {scheduler_job.py:182} INFO - Started process (PID=23106) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:27,248] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:32:27,250] {logging_mixin.py:104} INFO - [2022-03-18 20:32:27,250] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:27,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:27,345] {logging_mixin.py:104} INFO - [2022-03-18 20:32:27,344] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:32:27,388] {logging_mixin.py:104} INFO - [2022-03-18 20:32:27,388] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:32:27,405] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 20:32:58,036] {scheduler_job.py:182} INFO - Started process (PID=23132) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:58,040] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:32:58,043] {logging_mixin.py:104} INFO - [2022-03-18 20:32:58,043] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:58,098] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:32:58,138] {logging_mixin.py:104} INFO - [2022-03-18 20:32:58,138] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:32:58,177] {logging_mixin.py:104} INFO - [2022-03-18 20:32:58,177] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:32:58,192] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:33:28,515] {scheduler_job.py:182} INFO - Started process (PID=23164) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:28,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:33:28,523] {logging_mixin.py:104} INFO - [2022-03-18 20:33:28,523] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:28,573] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:28,615] {logging_mixin.py:104} INFO - [2022-03-18 20:33:28,615] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:33:28,656] {logging_mixin.py:104} INFO - [2022-03-18 20:33:28,656] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:33:28,672] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:33:59,040] {scheduler_job.py:182} INFO - Started process (PID=23196) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:59,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:33:59,047] {logging_mixin.py:104} INFO - [2022-03-18 20:33:59,046] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:59,102] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:33:59,148] {logging_mixin.py:104} INFO - [2022-03-18 20:33:59,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:33:59,188] {logging_mixin.py:104} INFO - [2022-03-18 20:33:59,188] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:33:59,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 20:34:29,550] {scheduler_job.py:182} INFO - Started process (PID=23228) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:34:29,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:34:29,557] {logging_mixin.py:104} INFO - [2022-03-18 20:34:29,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:34:29,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:34:29,651] {logging_mixin.py:104} INFO - [2022-03-18 20:34:29,650] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:34:29,690] {logging_mixin.py:104} INFO - [2022-03-18 20:34:29,690] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:34:29,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:35:00,454] {scheduler_job.py:182} INFO - Started process (PID=23260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:00,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:35:00,461] {logging_mixin.py:104} INFO - [2022-03-18 20:35:00,461] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:00,511] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:00,558] {logging_mixin.py:104} INFO - [2022-03-18 20:35:00,557] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:35:00,605] {logging_mixin.py:104} INFO - [2022-03-18 20:35:00,604] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:35:00,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 20:35:30,752] {scheduler_job.py:182} INFO - Started process (PID=23285) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:30,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:35:30,760] {logging_mixin.py:104} INFO - [2022-03-18 20:35:30,760] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:30,810] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:35:30,852] {logging_mixin.py:104} INFO - [2022-03-18 20:35:30,852] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:35:30,891] {logging_mixin.py:104} INFO - [2022-03-18 20:35:30,891] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:35:30,906] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 20:36:01,339] {scheduler_job.py:182} INFO - Started process (PID=23317) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:01,342] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:36:01,345] {logging_mixin.py:104} INFO - [2022-03-18 20:36:01,345] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:01,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:01,438] {logging_mixin.py:104} INFO - [2022-03-18 20:36:01,437] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:36:01,479] {logging_mixin.py:104} INFO - [2022-03-18 20:36:01,479] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:36:01,494] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 20:36:31,840] {scheduler_job.py:182} INFO - Started process (PID=23349) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:31,846] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:36:31,849] {logging_mixin.py:104} INFO - [2022-03-18 20:36:31,848] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:31,904] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:36:31,949] {logging_mixin.py:104} INFO - [2022-03-18 20:36:31,948] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:36:31,990] {logging_mixin.py:104} INFO - [2022-03-18 20:36:31,989] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:36:32,006] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 20:37:02,917] {scheduler_job.py:182} INFO - Started process (PID=23380) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:02,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:37:02,923] {logging_mixin.py:104} INFO - [2022-03-18 20:37:02,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:02,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:03,020] {logging_mixin.py:104} INFO - [2022-03-18 20:37:03,020] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:37:03,062] {logging_mixin.py:104} INFO - [2022-03-18 20:37:03,062] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:37:03,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 20:37:33,310] {scheduler_job.py:182} INFO - Started process (PID=23408) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:33,314] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:37:33,317] {logging_mixin.py:104} INFO - [2022-03-18 20:37:33,316] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:33,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:37:33,408] {logging_mixin.py:104} INFO - [2022-03-18 20:37:33,407] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:37:33,446] {logging_mixin.py:104} INFO - [2022-03-18 20:37:33,445] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:37:33,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.157 seconds
[2022-03-18 20:38:04,110] {scheduler_job.py:182} INFO - Started process (PID=23438) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:04,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:38:04,116] {logging_mixin.py:104} INFO - [2022-03-18 20:38:04,116] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:04,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:04,211] {logging_mixin.py:104} INFO - [2022-03-18 20:38:04,211] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:38:04,250] {logging_mixin.py:104} INFO - [2022-03-18 20:38:04,250] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:38:04,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:38:34,901] {scheduler_job.py:182} INFO - Started process (PID=23470) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:34,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:38:34,910] {logging_mixin.py:104} INFO - [2022-03-18 20:38:34,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:34,963] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:38:35,007] {logging_mixin.py:104} INFO - [2022-03-18 20:38:35,007] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:38:35,046] {logging_mixin.py:104} INFO - [2022-03-18 20:38:35,045] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:38:35,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:39:05,385] {scheduler_job.py:182} INFO - Started process (PID=23502) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:05,391] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:39:05,394] {logging_mixin.py:104} INFO - [2022-03-18 20:39:05,394] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:05,443] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:05,485] {logging_mixin.py:104} INFO - [2022-03-18 20:39:05,485] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:39:05,528] {logging_mixin.py:104} INFO - [2022-03-18 20:39:05,528] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:39:05,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:39:36,089] {scheduler_job.py:182} INFO - Started process (PID=23533) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:36,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:39:36,095] {logging_mixin.py:104} INFO - [2022-03-18 20:39:36,095] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:36,149] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:39:36,198] {logging_mixin.py:104} INFO - [2022-03-18 20:39:36,197] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:39:36,241] {logging_mixin.py:104} INFO - [2022-03-18 20:39:36,241] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:39:36,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 20:40:06,500] {scheduler_job.py:182} INFO - Started process (PID=23559) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:06,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:40:06,507] {logging_mixin.py:104} INFO - [2022-03-18 20:40:06,506] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:06,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:06,599] {logging_mixin.py:104} INFO - [2022-03-18 20:40:06,599] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:40:06,638] {logging_mixin.py:104} INFO - [2022-03-18 20:40:06,637] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:40:06,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:40:37,045] {scheduler_job.py:182} INFO - Started process (PID=23591) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:37,049] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:40:37,051] {logging_mixin.py:104} INFO - [2022-03-18 20:40:37,051] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:37,106] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:40:37,147] {logging_mixin.py:104} INFO - [2022-03-18 20:40:37,147] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:40:37,186] {logging_mixin.py:104} INFO - [2022-03-18 20:40:37,186] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:40:37,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:41:07,706] {scheduler_job.py:182} INFO - Started process (PID=23623) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:07,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:41:07,714] {logging_mixin.py:104} INFO - [2022-03-18 20:41:07,713] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:07,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:07,813] {logging_mixin.py:104} INFO - [2022-03-18 20:41:07,812] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:41:07,854] {logging_mixin.py:104} INFO - [2022-03-18 20:41:07,854] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:41:07,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:41:38,458] {scheduler_job.py:182} INFO - Started process (PID=23654) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:38,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:41:38,464] {logging_mixin.py:104} INFO - [2022-03-18 20:41:38,464] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:38,521] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:41:38,570] {logging_mixin.py:104} INFO - [2022-03-18 20:41:38,569] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:41:38,616] {logging_mixin.py:104} INFO - [2022-03-18 20:41:38,615] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:41:38,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 20:42:09,052] {scheduler_job.py:182} INFO - Started process (PID=23680) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:09,058] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:42:09,062] {logging_mixin.py:104} INFO - [2022-03-18 20:42:09,061] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:09,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:09,152] {logging_mixin.py:104} INFO - [2022-03-18 20:42:09,151] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:42:09,191] {logging_mixin.py:104} INFO - [2022-03-18 20:42:09,191] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:42:09,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:42:39,665] {scheduler_job.py:182} INFO - Started process (PID=23712) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:39,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:42:39,672] {logging_mixin.py:104} INFO - [2022-03-18 20:42:39,672] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:39,723] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:42:39,765] {logging_mixin.py:104} INFO - [2022-03-18 20:42:39,764] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:42:39,807] {logging_mixin.py:104} INFO - [2022-03-18 20:42:39,806] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:42:39,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 20:43:10,225] {scheduler_job.py:182} INFO - Started process (PID=23744) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:10,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:43:10,233] {logging_mixin.py:104} INFO - [2022-03-18 20:43:10,232] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:10,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:10,324] {logging_mixin.py:104} INFO - [2022-03-18 20:43:10,324] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:43:10,364] {logging_mixin.py:104} INFO - [2022-03-18 20:43:10,364] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:43:10,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:43:41,136] {scheduler_job.py:182} INFO - Started process (PID=23776) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:41,140] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:43:41,143] {logging_mixin.py:104} INFO - [2022-03-18 20:43:41,143] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:41,199] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:43:41,249] {logging_mixin.py:104} INFO - [2022-03-18 20:43:41,249] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:43:41,296] {logging_mixin.py:104} INFO - [2022-03-18 20:43:41,296] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:43:41,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 20:44:11,498] {scheduler_job.py:182} INFO - Started process (PID=23801) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:11,502] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:44:11,505] {logging_mixin.py:104} INFO - [2022-03-18 20:44:11,505] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:11,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:11,606] {logging_mixin.py:104} INFO - [2022-03-18 20:44:11,605] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:44:11,647] {logging_mixin.py:104} INFO - [2022-03-18 20:44:11,646] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:44:11,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 20:44:41,990] {scheduler_job.py:182} INFO - Started process (PID=23833) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:41,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:44:41,998] {logging_mixin.py:104} INFO - [2022-03-18 20:44:41,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:42,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:44:42,096] {logging_mixin.py:104} INFO - [2022-03-18 20:44:42,096] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:44:42,136] {logging_mixin.py:104} INFO - [2022-03-18 20:44:42,135] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:44:42,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 20:45:12,642] {scheduler_job.py:182} INFO - Started process (PID=23865) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:12,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:45:12,649] {logging_mixin.py:104} INFO - [2022-03-18 20:45:12,649] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:12,703] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:12,748] {logging_mixin.py:104} INFO - [2022-03-18 20:45:12,748] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:45:12,787] {logging_mixin.py:104} INFO - [2022-03-18 20:45:12,787] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:45:12,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:45:43,661] {scheduler_job.py:182} INFO - Started process (PID=23897) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:43,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:45:43,667] {logging_mixin.py:104} INFO - [2022-03-18 20:45:43,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:43,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:45:43,769] {logging_mixin.py:104} INFO - [2022-03-18 20:45:43,769] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:45:43,813] {logging_mixin.py:104} INFO - [2022-03-18 20:45:43,813] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:45:43,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 20:46:14,717] {scheduler_job.py:182} INFO - Started process (PID=23928) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:14,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:46:14,724] {logging_mixin.py:104} INFO - [2022-03-18 20:46:14,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:14,780] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:14,829] {logging_mixin.py:104} INFO - [2022-03-18 20:46:14,828] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:46:14,871] {logging_mixin.py:104} INFO - [2022-03-18 20:46:14,871] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:46:14,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 20:46:45,390] {scheduler_job.py:182} INFO - Started process (PID=23954) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:45,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:46:45,397] {logging_mixin.py:104} INFO - [2022-03-18 20:46:45,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:45,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:46:45,488] {logging_mixin.py:104} INFO - [2022-03-18 20:46:45,488] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:46:45,528] {logging_mixin.py:104} INFO - [2022-03-18 20:46:45,528] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:46:45,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:47:15,991] {scheduler_job.py:182} INFO - Started process (PID=23986) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:15,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:47:15,997] {logging_mixin.py:104} INFO - [2022-03-18 20:47:15,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:16,049] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:16,096] {logging_mixin.py:104} INFO - [2022-03-18 20:47:16,096] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:47:16,144] {logging_mixin.py:104} INFO - [2022-03-18 20:47:16,143] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:47:16,160] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 20:47:46,382] {scheduler_job.py:182} INFO - Started process (PID=24018) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:46,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:47:46,390] {logging_mixin.py:104} INFO - [2022-03-18 20:47:46,389] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:46,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:47:46,484] {logging_mixin.py:104} INFO - [2022-03-18 20:47:46,484] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:47:46,523] {logging_mixin.py:104} INFO - [2022-03-18 20:47:46,523] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:47:46,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:48:17,240] {scheduler_job.py:182} INFO - Started process (PID=24050) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:17,244] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:48:17,247] {logging_mixin.py:104} INFO - [2022-03-18 20:48:17,246] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:17,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:17,346] {logging_mixin.py:104} INFO - [2022-03-18 20:48:17,345] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:48:17,390] {logging_mixin.py:104} INFO - [2022-03-18 20:48:17,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:48:17,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 20:48:47,627] {scheduler_job.py:182} INFO - Started process (PID=24077) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:47,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:48:47,633] {logging_mixin.py:104} INFO - [2022-03-18 20:48:47,633] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:47,683] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:48:47,726] {logging_mixin.py:104} INFO - [2022-03-18 20:48:47,726] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:48:47,767] {logging_mixin.py:104} INFO - [2022-03-18 20:48:47,766] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:48:47,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:49:18,165] {scheduler_job.py:182} INFO - Started process (PID=24107) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:18,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:49:18,172] {logging_mixin.py:104} INFO - [2022-03-18 20:49:18,171] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:18,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:18,267] {logging_mixin.py:104} INFO - [2022-03-18 20:49:18,267] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:49:18,306] {logging_mixin.py:104} INFO - [2022-03-18 20:49:18,306] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:49:18,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:49:48,697] {scheduler_job.py:182} INFO - Started process (PID=24139) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:48,702] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:49:48,706] {logging_mixin.py:104} INFO - [2022-03-18 20:49:48,705] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:48,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:49:48,796] {logging_mixin.py:104} INFO - [2022-03-18 20:49:48,796] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:49:48,834] {logging_mixin.py:104} INFO - [2022-03-18 20:49:48,834] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:49:48,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:50:19,946] {scheduler_job.py:182} INFO - Started process (PID=24171) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:19,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:50:19,952] {logging_mixin.py:104} INFO - [2022-03-18 20:50:19,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:20,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:20,051] {logging_mixin.py:104} INFO - [2022-03-18 20:50:20,050] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:50:20,096] {logging_mixin.py:104} INFO - [2022-03-18 20:50:20,095] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:50:20,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 20:50:50,247] {scheduler_job.py:182} INFO - Started process (PID=24196) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:50,253] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:50:50,256] {logging_mixin.py:104} INFO - [2022-03-18 20:50:50,256] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:50,307] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:50:50,350] {logging_mixin.py:104} INFO - [2022-03-18 20:50:50,350] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:50:50,390] {logging_mixin.py:104} INFO - [2022-03-18 20:50:50,389] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:50:50,405] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:51:20,946] {scheduler_job.py:182} INFO - Started process (PID=24228) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:20,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:51:20,953] {logging_mixin.py:104} INFO - [2022-03-18 20:51:20,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:21,008] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:21,054] {logging_mixin.py:104} INFO - [2022-03-18 20:51:21,054] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:51:21,095] {logging_mixin.py:104} INFO - [2022-03-18 20:51:21,095] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:51:21,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 20:51:51,509] {scheduler_job.py:182} INFO - Started process (PID=24260) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:51,513] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:51:51,516] {logging_mixin.py:104} INFO - [2022-03-18 20:51:51,516] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:51,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:51:51,611] {logging_mixin.py:104} INFO - [2022-03-18 20:51:51,610] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:51:51,649] {logging_mixin.py:104} INFO - [2022-03-18 20:51:51,649] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:51:51,665] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:52:21,945] {scheduler_job.py:182} INFO - Started process (PID=24292) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:21,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:52:21,952] {logging_mixin.py:104} INFO - [2022-03-18 20:52:21,952] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:22,006] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:22,048] {logging_mixin.py:104} INFO - [2022-03-18 20:52:22,047] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:52:22,087] {logging_mixin.py:104} INFO - [2022-03-18 20:52:22,087] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:52:22,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:52:52,676] {scheduler_job.py:182} INFO - Started process (PID=24324) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:52,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:52:52,682] {logging_mixin.py:104} INFO - [2022-03-18 20:52:52,682] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:52,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:52:52,778] {logging_mixin.py:104} INFO - [2022-03-18 20:52:52,778] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:52:52,820] {logging_mixin.py:104} INFO - [2022-03-18 20:52:52,820] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:52:52,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 20:53:22,936] {scheduler_job.py:182} INFO - Started process (PID=24345) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:22,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:53:22,943] {logging_mixin.py:104} INFO - [2022-03-18 20:53:22,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:22,994] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:23,037] {logging_mixin.py:104} INFO - [2022-03-18 20:53:23,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:53:23,080] {logging_mixin.py:104} INFO - [2022-03-18 20:53:23,080] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:53:23,095] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 20:53:53,550] {scheduler_job.py:182} INFO - Started process (PID=24381) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:53,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:53:53,558] {logging_mixin.py:104} INFO - [2022-03-18 20:53:53,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:53,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:53:53,651] {logging_mixin.py:104} INFO - [2022-03-18 20:53:53,651] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:53:53,690] {logging_mixin.py:104} INFO - [2022-03-18 20:53:53,689] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:53:53,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 20:54:24,130] {scheduler_job.py:182} INFO - Started process (PID=24413) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:24,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:54:24,137] {logging_mixin.py:104} INFO - [2022-03-18 20:54:24,136] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:24,189] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:24,231] {logging_mixin.py:104} INFO - [2022-03-18 20:54:24,231] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:54:24,270] {logging_mixin.py:104} INFO - [2022-03-18 20:54:24,270] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:54:24,287] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 20:54:55,179] {scheduler_job.py:182} INFO - Started process (PID=24445) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:55,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:54:55,186] {logging_mixin.py:104} INFO - [2022-03-18 20:54:55,185] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:55,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:54:55,280] {logging_mixin.py:104} INFO - [2022-03-18 20:54:55,280] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:54:55,323] {logging_mixin.py:104} INFO - [2022-03-18 20:54:55,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:54:55,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:55:25,446] {scheduler_job.py:182} INFO - Started process (PID=24466) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:25,451] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:55:25,454] {logging_mixin.py:104} INFO - [2022-03-18 20:55:25,453] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:25,505] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:25,551] {logging_mixin.py:104} INFO - [2022-03-18 20:55:25,550] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:55:25,591] {logging_mixin.py:104} INFO - [2022-03-18 20:55:25,591] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:55:25,607] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:55:56,130] {scheduler_job.py:182} INFO - Started process (PID=24502) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:56,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:55:56,138] {logging_mixin.py:104} INFO - [2022-03-18 20:55:56,138] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:56,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:55:56,237] {logging_mixin.py:104} INFO - [2022-03-18 20:55:56,236] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:55:56,277] {logging_mixin.py:104} INFO - [2022-03-18 20:55:56,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:55:56,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 20:56:26,678] {scheduler_job.py:182} INFO - Started process (PID=24534) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:26,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:56:26,685] {logging_mixin.py:104} INFO - [2022-03-18 20:56:26,685] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:26,738] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:26,782] {logging_mixin.py:104} INFO - [2022-03-18 20:56:26,782] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:56:26,823] {logging_mixin.py:104} INFO - [2022-03-18 20:56:26,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:56:26,840] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:56:57,138] {scheduler_job.py:182} INFO - Started process (PID=24566) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:57,142] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:56:57,145] {logging_mixin.py:104} INFO - [2022-03-18 20:56:57,145] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:57,201] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:56:57,243] {logging_mixin.py:104} INFO - [2022-03-18 20:56:57,243] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:56:57,283] {logging_mixin.py:104} INFO - [2022-03-18 20:56:57,283] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:56:57,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 20:57:27,812] {scheduler_job.py:182} INFO - Started process (PID=24597) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:27,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:57:27,818] {logging_mixin.py:104} INFO - [2022-03-18 20:57:27,818] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:27,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:27,916] {logging_mixin.py:104} INFO - [2022-03-18 20:57:27,915] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:57:27,960] {logging_mixin.py:104} INFO - [2022-03-18 20:57:27,959] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:57:27,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 20:57:58,271] {scheduler_job.py:182} INFO - Started process (PID=24623) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:58,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:57:58,278] {logging_mixin.py:104} INFO - [2022-03-18 20:57:58,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:58,329] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:57:58,373] {logging_mixin.py:104} INFO - [2022-03-18 20:57:58,372] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:57:58,413] {logging_mixin.py:104} INFO - [2022-03-18 20:57:58,412] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:57:58,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 20:58:28,886] {scheduler_job.py:182} INFO - Started process (PID=24655) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:28,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:58:28,894] {logging_mixin.py:104} INFO - [2022-03-18 20:58:28,894] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:28,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:28,985] {logging_mixin.py:104} INFO - [2022-03-18 20:58:28,985] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:58:29,023] {logging_mixin.py:104} INFO - [2022-03-18 20:58:29,023] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:58:29,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 20:58:59,387] {scheduler_job.py:182} INFO - Started process (PID=24687) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:59,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:58:59,395] {logging_mixin.py:104} INFO - [2022-03-18 20:58:59,394] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:59,445] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:58:59,486] {logging_mixin.py:104} INFO - [2022-03-18 20:58:59,486] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:58:59,525] {logging_mixin.py:104} INFO - [2022-03-18 20:58:59,525] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:58:59,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 20:59:30,448] {scheduler_job.py:182} INFO - Started process (PID=24718) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 20:59:30,453] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 20:59:30,456] {logging_mixin.py:104} INFO - [2022-03-18 20:59:30,455] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 20:59:30,505] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 20:59:30,549] {logging_mixin.py:104} INFO - [2022-03-18 20:59:30,549] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 20:59:30,591] {logging_mixin.py:104} INFO - [2022-03-18 20:59:30,590] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 20:59:30,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:00:00,832] {scheduler_job.py:182} INFO - Started process (PID=24744) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:00,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:00:00,838] {logging_mixin.py:104} INFO - [2022-03-18 21:00:00,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:00,891] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:00,933] {logging_mixin.py:104} INFO - [2022-03-18 21:00:00,933] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:00:00,972] {logging_mixin.py:104} INFO - [2022-03-18 21:00:00,971] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:00:00,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:00:31,421] {scheduler_job.py:182} INFO - Started process (PID=24776) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:31,425] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:00:31,428] {logging_mixin.py:104} INFO - [2022-03-18 21:00:31,427] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:31,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:00:31,523] {logging_mixin.py:104} INFO - [2022-03-18 21:00:31,523] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:00:31,566] {logging_mixin.py:104} INFO - [2022-03-18 21:00:31,566] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:00:31,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:01:02,018] {scheduler_job.py:182} INFO - Started process (PID=24808) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:02,022] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:01:02,025] {logging_mixin.py:104} INFO - [2022-03-18 21:01:02,024] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:02,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:02,122] {logging_mixin.py:104} INFO - [2022-03-18 21:01:02,122] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:01:02,160] {logging_mixin.py:104} INFO - [2022-03-18 21:01:02,160] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:01:02,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:01:32,825] {scheduler_job.py:182} INFO - Started process (PID=24840) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:32,829] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:01:32,832] {logging_mixin.py:104} INFO - [2022-03-18 21:01:32,832] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:32,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:01:32,936] {logging_mixin.py:104} INFO - [2022-03-18 21:01:32,935] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:01:32,982] {logging_mixin.py:104} INFO - [2022-03-18 21:01:32,982] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:01:33,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-18 21:02:03,884] {scheduler_job.py:182} INFO - Started process (PID=24871) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:03,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:02:03,891] {logging_mixin.py:104} INFO - [2022-03-18 21:02:03,891] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:03,941] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:03,987] {logging_mixin.py:104} INFO - [2022-03-18 21:02:03,987] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:02:04,032] {logging_mixin.py:104} INFO - [2022-03-18 21:02:04,031] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:02:04,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 21:02:34,421] {scheduler_job.py:182} INFO - Started process (PID=24897) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:34,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:02:34,476] {logging_mixin.py:104} INFO - [2022-03-18 21:02:34,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:34,547] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:02:34,601] {logging_mixin.py:104} INFO - [2022-03-18 21:02:34,601] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:02:34,656] {logging_mixin.py:104} INFO - [2022-03-18 21:02:34,655] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:02:34,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.260 seconds
[2022-03-18 21:03:05,176] {scheduler_job.py:182} INFO - Started process (PID=24929) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:05,180] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:03:05,183] {logging_mixin.py:104} INFO - [2022-03-18 21:03:05,183] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:05,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:05,276] {logging_mixin.py:104} INFO - [2022-03-18 21:03:05,276] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:03:05,315] {logging_mixin.py:104} INFO - [2022-03-18 21:03:05,314] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:03:05,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 21:03:35,944] {scheduler_job.py:182} INFO - Started process (PID=24961) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:35,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:03:35,951] {logging_mixin.py:104} INFO - [2022-03-18 21:03:35,950] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:36,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:03:36,045] {logging_mixin.py:104} INFO - [2022-03-18 21:03:36,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:03:36,085] {logging_mixin.py:104} INFO - [2022-03-18 21:03:36,084] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:03:36,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:04:06,981] {scheduler_job.py:182} INFO - Started process (PID=24992) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:06,984] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:04:06,987] {logging_mixin.py:104} INFO - [2022-03-18 21:04:06,986] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:07,034] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:07,079] {logging_mixin.py:104} INFO - [2022-03-18 21:04:07,079] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:04:07,124] {logging_mixin.py:104} INFO - [2022-03-18 21:04:07,123] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:04:07,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:04:37,783] {scheduler_job.py:182} INFO - Started process (PID=25018) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:37,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:04:37,790] {logging_mixin.py:104} INFO - [2022-03-18 21:04:37,789] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:37,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:04:37,883] {logging_mixin.py:104} INFO - [2022-03-18 21:04:37,883] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:04:37,922] {logging_mixin.py:104} INFO - [2022-03-18 21:04:37,922] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:04:37,938] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:05:08,344] {scheduler_job.py:182} INFO - Started process (PID=25050) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:08,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:05:08,351] {logging_mixin.py:104} INFO - [2022-03-18 21:05:08,350] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:08,404] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:08,447] {logging_mixin.py:104} INFO - [2022-03-18 21:05:08,446] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:05:08,486] {logging_mixin.py:104} INFO - [2022-03-18 21:05:08,486] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:05:08,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:05:38,888] {scheduler_job.py:182} INFO - Started process (PID=25082) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:38,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:05:38,896] {logging_mixin.py:104} INFO - [2022-03-18 21:05:38,896] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:38,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:05:38,996] {logging_mixin.py:104} INFO - [2022-03-18 21:05:38,996] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:05:39,036] {logging_mixin.py:104} INFO - [2022-03-18 21:05:39,036] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:05:39,051] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:06:09,811] {scheduler_job.py:182} INFO - Started process (PID=25114) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:09,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:06:09,818] {logging_mixin.py:104} INFO - [2022-03-18 21:06:09,818] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:09,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:09,910] {logging_mixin.py:104} INFO - [2022-03-18 21:06:09,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:06:09,953] {logging_mixin.py:104} INFO - [2022-03-18 21:06:09,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:06:09,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:06:40,302] {scheduler_job.py:182} INFO - Started process (PID=25139) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:40,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:06:40,310] {logging_mixin.py:104} INFO - [2022-03-18 21:06:40,309] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:40,365] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:06:40,408] {logging_mixin.py:104} INFO - [2022-03-18 21:06:40,407] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:06:40,449] {logging_mixin.py:104} INFO - [2022-03-18 21:06:40,449] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:06:40,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 21:07:10,971] {scheduler_job.py:182} INFO - Started process (PID=25171) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:10,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:07:10,979] {logging_mixin.py:104} INFO - [2022-03-18 21:07:10,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:11,029] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:11,071] {logging_mixin.py:104} INFO - [2022-03-18 21:07:11,070] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:07:11,111] {logging_mixin.py:104} INFO - [2022-03-18 21:07:11,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:07:11,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:07:41,575] {scheduler_job.py:182} INFO - Started process (PID=25203) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:41,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:07:41,581] {logging_mixin.py:104} INFO - [2022-03-18 21:07:41,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:41,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:07:41,682] {logging_mixin.py:104} INFO - [2022-03-18 21:07:41,682] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:07:41,726] {logging_mixin.py:104} INFO - [2022-03-18 21:07:41,726] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:07:41,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 21:08:12,281] {scheduler_job.py:182} INFO - Started process (PID=25235) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:12,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:08:12,288] {logging_mixin.py:104} INFO - [2022-03-18 21:08:12,287] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:12,340] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:12,381] {logging_mixin.py:104} INFO - [2022-03-18 21:08:12,380] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:08:12,420] {logging_mixin.py:104} INFO - [2022-03-18 21:08:12,420] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:08:12,435] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:08:43,563] {scheduler_job.py:182} INFO - Started process (PID=25267) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:43,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:08:43,570] {logging_mixin.py:104} INFO - [2022-03-18 21:08:43,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:43,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:08:43,666] {logging_mixin.py:104} INFO - [2022-03-18 21:08:43,665] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:08:43,714] {logging_mixin.py:104} INFO - [2022-03-18 21:08:43,713] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:08:43,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 21:09:13,817] {scheduler_job.py:182} INFO - Started process (PID=25292) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:13,821] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:09:13,824] {logging_mixin.py:104} INFO - [2022-03-18 21:09:13,824] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:13,878] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:13,924] {logging_mixin.py:104} INFO - [2022-03-18 21:09:13,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:09:13,980] {logging_mixin.py:104} INFO - [2022-03-18 21:09:13,979] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:09:13,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 21:09:44,618] {scheduler_job.py:182} INFO - Started process (PID=25324) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:44,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:09:44,627] {logging_mixin.py:104} INFO - [2022-03-18 21:09:44,626] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:44,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:09:44,720] {logging_mixin.py:104} INFO - [2022-03-18 21:09:44,719] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:09:44,759] {logging_mixin.py:104} INFO - [2022-03-18 21:09:44,759] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:09:44,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:10:15,320] {scheduler_job.py:182} INFO - Started process (PID=25356) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:15,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:10:15,327] {logging_mixin.py:104} INFO - [2022-03-18 21:10:15,326] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:15,379] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:15,422] {logging_mixin.py:104} INFO - [2022-03-18 21:10:15,422] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:10:15,462] {logging_mixin.py:104} INFO - [2022-03-18 21:10:15,462] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:10:15,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:10:46,152] {scheduler_job.py:182} INFO - Started process (PID=25388) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:46,155] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:10:46,158] {logging_mixin.py:104} INFO - [2022-03-18 21:10:46,158] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:46,208] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:10:46,253] {logging_mixin.py:104} INFO - [2022-03-18 21:10:46,253] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:10:46,296] {logging_mixin.py:104} INFO - [2022-03-18 21:10:46,296] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:10:46,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 21:11:16,515] {scheduler_job.py:182} INFO - Started process (PID=25413) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:16,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:11:16,523] {logging_mixin.py:104} INFO - [2022-03-18 21:11:16,522] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:16,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:16,623] {logging_mixin.py:104} INFO - [2022-03-18 21:11:16,622] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:11:16,765] {logging_mixin.py:104} INFO - [2022-03-18 21:11:16,763] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:11:16,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.298 seconds
[2022-03-18 21:11:47,635] {scheduler_job.py:182} INFO - Started process (PID=25445) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:47,640] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:11:47,642] {logging_mixin.py:104} INFO - [2022-03-18 21:11:47,642] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:47,694] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:11:47,738] {logging_mixin.py:104} INFO - [2022-03-18 21:11:47,738] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:11:47,777] {logging_mixin.py:104} INFO - [2022-03-18 21:11:47,777] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:11:47,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:12:18,215] {scheduler_job.py:182} INFO - Started process (PID=25477) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:18,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:12:18,222] {logging_mixin.py:104} INFO - [2022-03-18 21:12:18,222] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:18,274] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:18,318] {logging_mixin.py:104} INFO - [2022-03-18 21:12:18,317] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:12:18,358] {logging_mixin.py:104} INFO - [2022-03-18 21:12:18,358] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:12:18,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:12:48,874] {scheduler_job.py:182} INFO - Started process (PID=25509) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:48,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:12:48,881] {logging_mixin.py:104} INFO - [2022-03-18 21:12:48,881] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:48,933] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:12:48,975] {logging_mixin.py:104} INFO - [2022-03-18 21:12:48,975] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:12:49,013] {logging_mixin.py:104} INFO - [2022-03-18 21:12:49,013] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:12:49,029] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:13:19,916] {scheduler_job.py:182} INFO - Started process (PID=25541) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:19,920] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:13:19,923] {logging_mixin.py:104} INFO - [2022-03-18 21:13:19,923] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:19,973] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:20,020] {logging_mixin.py:104} INFO - [2022-03-18 21:13:20,020] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:13:20,063] {logging_mixin.py:104} INFO - [2022-03-18 21:13:20,062] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:13:20,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:13:50,230] {scheduler_job.py:182} INFO - Started process (PID=25568) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:50,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:13:50,236] {logging_mixin.py:104} INFO - [2022-03-18 21:13:50,236] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:50,288] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:13:50,330] {logging_mixin.py:104} INFO - [2022-03-18 21:13:50,330] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:13:50,369] {logging_mixin.py:104} INFO - [2022-03-18 21:13:50,368] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:13:50,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 21:14:20,798] {scheduler_job.py:182} INFO - Started process (PID=25598) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:20,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:14:20,806] {logging_mixin.py:104} INFO - [2022-03-18 21:14:20,806] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:20,860] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:20,904] {logging_mixin.py:104} INFO - [2022-03-18 21:14:20,903] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:14:20,942] {logging_mixin.py:104} INFO - [2022-03-18 21:14:20,942] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:14:20,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:14:51,241] {scheduler_job.py:182} INFO - Started process (PID=25630) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:51,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:14:51,249] {logging_mixin.py:104} INFO - [2022-03-18 21:14:51,248] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:51,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:14:51,346] {logging_mixin.py:104} INFO - [2022-03-18 21:14:51,345] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:14:51,388] {logging_mixin.py:104} INFO - [2022-03-18 21:14:51,387] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:14:51,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:15:22,080] {scheduler_job.py:182} INFO - Started process (PID=25662) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:22,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:15:22,087] {logging_mixin.py:104} INFO - [2022-03-18 21:15:22,087] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:22,144] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:22,193] {logging_mixin.py:104} INFO - [2022-03-18 21:15:22,193] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:15:22,238] {logging_mixin.py:104} INFO - [2022-03-18 21:15:22,237] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:15:22,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 21:15:52,332] {scheduler_job.py:182} INFO - Started process (PID=25687) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:52,336] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:15:52,339] {logging_mixin.py:104} INFO - [2022-03-18 21:15:52,338] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:52,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:15:52,433] {logging_mixin.py:104} INFO - [2022-03-18 21:15:52,432] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:15:52,471] {logging_mixin.py:104} INFO - [2022-03-18 21:15:52,471] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:15:52,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:16:22,871] {scheduler_job.py:182} INFO - Started process (PID=25719) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:22,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:16:22,878] {logging_mixin.py:104} INFO - [2022-03-18 21:16:22,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:22,929] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:22,972] {logging_mixin.py:104} INFO - [2022-03-18 21:16:22,971] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:16:23,012] {logging_mixin.py:104} INFO - [2022-03-18 21:16:23,012] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:16:23,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:16:53,292] {scheduler_job.py:182} INFO - Started process (PID=25751) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:53,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:16:53,299] {logging_mixin.py:104} INFO - [2022-03-18 21:16:53,298] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:53,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:16:53,396] {logging_mixin.py:104} INFO - [2022-03-18 21:16:53,395] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:16:53,437] {logging_mixin.py:104} INFO - [2022-03-18 21:16:53,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:16:53,452] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:17:23,912] {scheduler_job.py:182} INFO - Started process (PID=25783) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:23,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:17:23,921] {logging_mixin.py:104} INFO - [2022-03-18 21:17:23,921] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:23,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:24,019] {logging_mixin.py:104} INFO - [2022-03-18 21:17:24,018] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:17:24,060] {logging_mixin.py:104} INFO - [2022-03-18 21:17:24,059] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:17:24,075] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:17:54,972] {scheduler_job.py:182} INFO - Started process (PID=25815) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:54,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:17:54,979] {logging_mixin.py:104} INFO - [2022-03-18 21:17:54,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:55,028] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:17:55,076] {logging_mixin.py:104} INFO - [2022-03-18 21:17:55,075] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:17:55,119] {logging_mixin.py:104} INFO - [2022-03-18 21:17:55,119] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:17:55,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 21:18:26,022] {scheduler_job.py:182} INFO - Started process (PID=25840) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:26,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:18:26,028] {logging_mixin.py:104} INFO - [2022-03-18 21:18:26,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:26,089] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:26,171] {logging_mixin.py:104} INFO - [2022-03-18 21:18:26,170] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:18:26,213] {logging_mixin.py:104} INFO - [2022-03-18 21:18:26,212] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:18:26,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.213 seconds
[2022-03-18 21:18:56,796] {scheduler_job.py:182} INFO - Started process (PID=25872) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:56,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:18:56,802] {logging_mixin.py:104} INFO - [2022-03-18 21:18:56,802] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:56,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:18:56,905] {logging_mixin.py:104} INFO - [2022-03-18 21:18:56,905] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:18:56,944] {logging_mixin.py:104} INFO - [2022-03-18 21:18:56,944] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:18:56,959] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:19:27,562] {scheduler_job.py:182} INFO - Started process (PID=25904) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:27,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:19:27,569] {logging_mixin.py:104} INFO - [2022-03-18 21:19:27,569] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:27,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:27,662] {logging_mixin.py:104} INFO - [2022-03-18 21:19:27,661] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:19:27,700] {logging_mixin.py:104} INFO - [2022-03-18 21:19:27,700] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:19:27,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 21:19:58,459] {scheduler_job.py:182} INFO - Started process (PID=25936) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:58,465] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:19:58,467] {logging_mixin.py:104} INFO - [2022-03-18 21:19:58,467] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:58,515] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:19:58,562] {logging_mixin.py:104} INFO - [2022-03-18 21:19:58,561] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:19:58,608] {logging_mixin.py:104} INFO - [2022-03-18 21:19:58,608] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:19:58,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 21:20:28,691] {scheduler_job.py:182} INFO - Started process (PID=25963) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:28,695] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:20:28,698] {logging_mixin.py:104} INFO - [2022-03-18 21:20:28,697] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:28,744] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:28,787] {logging_mixin.py:104} INFO - [2022-03-18 21:20:28,787] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:20:28,829] {logging_mixin.py:104} INFO - [2022-03-18 21:20:28,829] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:20:28,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 21:20:59,425] {scheduler_job.py:182} INFO - Started process (PID=25993) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:59,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:20:59,432] {logging_mixin.py:104} INFO - [2022-03-18 21:20:59,431] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:59,488] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:20:59,533] {logging_mixin.py:104} INFO - [2022-03-18 21:20:59,533] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:20:59,572] {logging_mixin.py:104} INFO - [2022-03-18 21:20:59,572] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:20:59,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:21:29,971] {scheduler_job.py:182} INFO - Started process (PID=26025) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:21:29,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:21:29,977] {logging_mixin.py:104} INFO - [2022-03-18 21:21:29,977] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:21:30,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:21:30,075] {logging_mixin.py:104} INFO - [2022-03-18 21:21:30,074] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:21:30,113] {logging_mixin.py:104} INFO - [2022-03-18 21:21:30,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:21:30,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:22:00,504] {scheduler_job.py:182} INFO - Started process (PID=26057) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:00,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:22:00,511] {logging_mixin.py:104} INFO - [2022-03-18 21:22:00,510] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:00,561] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:00,606] {logging_mixin.py:104} INFO - [2022-03-18 21:22:00,606] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:22:00,646] {logging_mixin.py:104} INFO - [2022-03-18 21:22:00,646] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:22:00,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:22:31,411] {scheduler_job.py:182} INFO - Started process (PID=26089) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:31,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:22:31,418] {logging_mixin.py:104} INFO - [2022-03-18 21:22:31,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:31,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:22:31,516] {logging_mixin.py:104} INFO - [2022-03-18 21:22:31,515] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:22:31,559] {logging_mixin.py:104} INFO - [2022-03-18 21:22:31,559] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:22:31,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:23:01,805] {scheduler_job.py:182} INFO - Started process (PID=26116) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:01,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:23:01,814] {logging_mixin.py:104} INFO - [2022-03-18 21:23:01,814] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:01,866] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:01,913] {logging_mixin.py:104} INFO - [2022-03-18 21:23:01,913] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:23:01,953] {logging_mixin.py:104} INFO - [2022-03-18 21:23:01,953] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:23:01,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:23:32,524] {scheduler_job.py:182} INFO - Started process (PID=26146) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:32,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:23:32,530] {logging_mixin.py:104} INFO - [2022-03-18 21:23:32,529] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:32,582] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:23:32,625] {logging_mixin.py:104} INFO - [2022-03-18 21:23:32,625] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:23:32,664] {logging_mixin.py:104} INFO - [2022-03-18 21:23:32,663] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:23:32,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:24:03,095] {scheduler_job.py:182} INFO - Started process (PID=26180) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:03,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:24:03,101] {logging_mixin.py:104} INFO - [2022-03-18 21:24:03,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:03,147] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:03,189] {logging_mixin.py:104} INFO - [2022-03-18 21:24:03,189] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:24:03,229] {logging_mixin.py:104} INFO - [2022-03-18 21:24:03,229] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:24:03,246] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 21:24:33,816] {scheduler_job.py:182} INFO - Started process (PID=26210) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:33,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:24:33,822] {logging_mixin.py:104} INFO - [2022-03-18 21:24:33,822] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:33,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:24:33,916] {logging_mixin.py:104} INFO - [2022-03-18 21:24:33,916] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:24:33,958] {logging_mixin.py:104} INFO - [2022-03-18 21:24:33,957] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:24:33,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 21:25:04,069] {scheduler_job.py:182} INFO - Started process (PID=26231) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:04,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:25:04,076] {logging_mixin.py:104} INFO - [2022-03-18 21:25:04,075] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:04,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:04,169] {logging_mixin.py:104} INFO - [2022-03-18 21:25:04,168] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:25:04,210] {logging_mixin.py:104} INFO - [2022-03-18 21:25:04,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:25:04,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:25:34,768] {scheduler_job.py:182} INFO - Started process (PID=26267) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:34,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:25:34,775] {logging_mixin.py:104} INFO - [2022-03-18 21:25:34,774] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:34,830] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:25:34,871] {logging_mixin.py:104} INFO - [2022-03-18 21:25:34,871] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:25:34,910] {logging_mixin.py:104} INFO - [2022-03-18 21:25:34,909] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:25:34,924] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:26:05,295] {scheduler_job.py:182} INFO - Started process (PID=26299) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:05,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:26:05,302] {logging_mixin.py:104} INFO - [2022-03-18 21:26:05,302] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:05,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:05,398] {logging_mixin.py:104} INFO - [2022-03-18 21:26:05,397] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:26:05,438] {logging_mixin.py:104} INFO - [2022-03-18 21:26:05,437] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:26:05,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:26:35,848] {scheduler_job.py:182} INFO - Started process (PID=26331) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:35,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:26:35,854] {logging_mixin.py:104} INFO - [2022-03-18 21:26:35,854] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:35,906] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:26:35,947] {logging_mixin.py:104} INFO - [2022-03-18 21:26:35,947] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:26:35,986] {logging_mixin.py:104} INFO - [2022-03-18 21:26:35,986] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:26:36,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 21:27:06,823] {scheduler_job.py:182} INFO - Started process (PID=26363) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:06,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:27:06,830] {logging_mixin.py:104} INFO - [2022-03-18 21:27:06,829] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:06,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:06,929] {logging_mixin.py:104} INFO - [2022-03-18 21:27:06,928] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:27:06,972] {logging_mixin.py:104} INFO - [2022-03-18 21:27:06,972] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:27:06,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 21:27:37,849] {scheduler_job.py:182} INFO - Started process (PID=26388) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:37,853] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:27:37,856] {logging_mixin.py:104} INFO - [2022-03-18 21:27:37,855] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:37,908] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:27:37,952] {logging_mixin.py:104} INFO - [2022-03-18 21:27:37,952] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:27:37,994] {logging_mixin.py:104} INFO - [2022-03-18 21:27:37,994] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:27:38,010] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:28:08,345] {scheduler_job.py:182} INFO - Started process (PID=26420) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:08,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:28:08,354] {logging_mixin.py:104} INFO - [2022-03-18 21:28:08,353] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:08,406] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:08,448] {logging_mixin.py:104} INFO - [2022-03-18 21:28:08,448] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:28:08,488] {logging_mixin.py:104} INFO - [2022-03-18 21:28:08,487] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:28:08,503] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:28:39,061] {scheduler_job.py:182} INFO - Started process (PID=26454) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:39,066] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:28:39,068] {logging_mixin.py:104} INFO - [2022-03-18 21:28:39,068] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:39,123] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:28:39,172] {logging_mixin.py:104} INFO - [2022-03-18 21:28:39,172] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:28:39,214] {logging_mixin.py:104} INFO - [2022-03-18 21:28:39,213] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:28:39,230] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 21:29:09,668] {scheduler_job.py:182} INFO - Started process (PID=26483) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:09,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:29:09,676] {logging_mixin.py:104} INFO - [2022-03-18 21:29:09,676] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:09,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:09,776] {logging_mixin.py:104} INFO - [2022-03-18 21:29:09,776] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:29:09,819] {logging_mixin.py:104} INFO - [2022-03-18 21:29:09,819] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:29:09,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 21:29:40,186] {scheduler_job.py:182} INFO - Started process (PID=26509) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:40,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:29:40,192] {logging_mixin.py:104} INFO - [2022-03-18 21:29:40,192] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:40,243] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:29:40,286] {logging_mixin.py:104} INFO - [2022-03-18 21:29:40,285] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:29:40,326] {logging_mixin.py:104} INFO - [2022-03-18 21:29:40,326] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:29:40,341] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:30:10,662] {scheduler_job.py:182} INFO - Started process (PID=26541) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:10,666] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:30:10,669] {logging_mixin.py:104} INFO - [2022-03-18 21:30:10,669] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:10,724] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:10,771] {logging_mixin.py:104} INFO - [2022-03-18 21:30:10,771] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:30:10,817] {logging_mixin.py:104} INFO - [2022-03-18 21:30:10,816] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:30:10,834] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.180 seconds
[2022-03-18 21:30:41,409] {scheduler_job.py:182} INFO - Started process (PID=26573) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:41,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:30:41,416] {logging_mixin.py:104} INFO - [2022-03-18 21:30:41,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:41,475] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:30:41,525] {logging_mixin.py:104} INFO - [2022-03-18 21:30:41,524] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:30:41,570] {logging_mixin.py:104} INFO - [2022-03-18 21:30:41,570] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:30:41,588] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 21:31:12,108] {scheduler_job.py:182} INFO - Started process (PID=26605) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:12,112] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:31:12,115] {logging_mixin.py:104} INFO - [2022-03-18 21:31:12,114] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:12,164] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:12,206] {logging_mixin.py:104} INFO - [2022-03-18 21:31:12,206] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:31:12,244] {logging_mixin.py:104} INFO - [2022-03-18 21:31:12,244] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:31:12,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 21:31:43,149] {scheduler_job.py:182} INFO - Started process (PID=26636) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:43,153] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:31:43,155] {logging_mixin.py:104} INFO - [2022-03-18 21:31:43,155] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:43,206] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:31:43,253] {logging_mixin.py:104} INFO - [2022-03-18 21:31:43,252] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:31:43,298] {logging_mixin.py:104} INFO - [2022-03-18 21:31:43,298] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:31:43,314] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:32:13,410] {scheduler_job.py:182} INFO - Started process (PID=26664) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:13,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:32:13,417] {logging_mixin.py:104} INFO - [2022-03-18 21:32:13,417] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:13,465] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:13,520] {logging_mixin.py:104} INFO - [2022-03-18 21:32:13,519] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:32:13,565] {logging_mixin.py:104} INFO - [2022-03-18 21:32:13,564] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:32:13,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 21:32:44,007] {scheduler_job.py:182} INFO - Started process (PID=26694) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:44,011] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:32:44,014] {logging_mixin.py:104} INFO - [2022-03-18 21:32:44,013] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:44,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:32:44,112] {logging_mixin.py:104} INFO - [2022-03-18 21:32:44,111] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:32:44,151] {logging_mixin.py:104} INFO - [2022-03-18 21:32:44,151] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:32:44,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 21:33:14,765] {scheduler_job.py:182} INFO - Started process (PID=26726) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:14,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:33:14,771] {logging_mixin.py:104} INFO - [2022-03-18 21:33:14,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:14,820] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:14,866] {logging_mixin.py:104} INFO - [2022-03-18 21:33:14,866] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:33:14,908] {logging_mixin.py:104} INFO - [2022-03-18 21:33:14,908] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:33:14,924] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:33:45,280] {scheduler_job.py:182} INFO - Started process (PID=26751) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:45,287] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:33:45,290] {logging_mixin.py:104} INFO - [2022-03-18 21:33:45,290] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:45,343] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:33:45,386] {logging_mixin.py:104} INFO - [2022-03-18 21:33:45,386] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:33:45,425] {logging_mixin.py:104} INFO - [2022-03-18 21:33:45,425] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:33:45,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 21:34:15,813] {scheduler_job.py:182} INFO - Started process (PID=26783) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:15,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:34:15,820] {logging_mixin.py:104} INFO - [2022-03-18 21:34:15,820] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:15,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:15,912] {logging_mixin.py:104} INFO - [2022-03-18 21:34:15,912] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:34:15,951] {logging_mixin.py:104} INFO - [2022-03-18 21:34:15,951] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:34:15,966] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 21:34:46,231] {scheduler_job.py:182} INFO - Started process (PID=26815) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:46,236] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:34:46,239] {logging_mixin.py:104} INFO - [2022-03-18 21:34:46,239] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:46,290] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:34:46,336] {logging_mixin.py:104} INFO - [2022-03-18 21:34:46,335] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:34:46,375] {logging_mixin.py:104} INFO - [2022-03-18 21:34:46,375] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:34:46,390] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:35:16,968] {scheduler_job.py:182} INFO - Started process (PID=26847) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:16,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:35:16,976] {logging_mixin.py:104} INFO - [2022-03-18 21:35:16,975] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:17,036] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:17,082] {logging_mixin.py:104} INFO - [2022-03-18 21:35:17,082] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:35:17,122] {logging_mixin.py:104} INFO - [2022-03-18 21:35:17,121] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:35:17,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 21:35:47,640] {scheduler_job.py:182} INFO - Started process (PID=26879) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:47,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:35:47,647] {logging_mixin.py:104} INFO - [2022-03-18 21:35:47,647] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:47,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:35:47,745] {logging_mixin.py:104} INFO - [2022-03-18 21:35:47,744] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:35:47,785] {logging_mixin.py:104} INFO - [2022-03-18 21:35:47,785] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:35:47,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 21:36:18,562] {scheduler_job.py:182} INFO - Started process (PID=26910) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:18,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:36:18,569] {logging_mixin.py:104} INFO - [2022-03-18 21:36:18,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:18,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:18,667] {logging_mixin.py:104} INFO - [2022-03-18 21:36:18,666] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:36:18,708] {logging_mixin.py:104} INFO - [2022-03-18 21:36:18,707] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:36:18,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:36:49,363] {scheduler_job.py:182} INFO - Started process (PID=26936) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:49,367] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:36:49,370] {logging_mixin.py:104} INFO - [2022-03-18 21:36:49,370] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:49,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:36:49,465] {logging_mixin.py:104} INFO - [2022-03-18 21:36:49,465] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:36:49,505] {logging_mixin.py:104} INFO - [2022-03-18 21:36:49,505] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:36:49,521] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:37:19,972] {scheduler_job.py:182} INFO - Started process (PID=26968) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:19,975] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:37:19,978] {logging_mixin.py:104} INFO - [2022-03-18 21:37:19,978] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:20,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:20,073] {logging_mixin.py:104} INFO - [2022-03-18 21:37:20,073] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:37:20,113] {logging_mixin.py:104} INFO - [2022-03-18 21:37:20,113] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:37:20,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:37:50,836] {scheduler_job.py:182} INFO - Started process (PID=27000) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:50,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:37:50,847] {logging_mixin.py:104} INFO - [2022-03-18 21:37:50,847] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:50,901] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:37:50,958] {logging_mixin.py:104} INFO - [2022-03-18 21:37:50,958] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:37:51,008] {logging_mixin.py:104} INFO - [2022-03-18 21:37:51,008] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:37:51,025] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.198 seconds
[2022-03-18 21:38:21,418] {scheduler_job.py:182} INFO - Started process (PID=27025) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:21,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:38:21,424] {logging_mixin.py:104} INFO - [2022-03-18 21:38:21,424] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:21,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:21,521] {logging_mixin.py:104} INFO - [2022-03-18 21:38:21,520] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:38:21,560] {logging_mixin.py:104} INFO - [2022-03-18 21:38:21,559] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:38:21,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:38:52,271] {scheduler_job.py:182} INFO - Started process (PID=27057) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:52,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:38:52,278] {logging_mixin.py:104} INFO - [2022-03-18 21:38:52,278] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:52,331] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:38:52,376] {logging_mixin.py:104} INFO - [2022-03-18 21:38:52,376] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:38:52,416] {logging_mixin.py:104} INFO - [2022-03-18 21:38:52,415] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:38:52,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 21:39:22,936] {scheduler_job.py:182} INFO - Started process (PID=27089) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:22,940] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:39:22,943] {logging_mixin.py:104} INFO - [2022-03-18 21:39:22,943] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:22,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:23,038] {logging_mixin.py:104} INFO - [2022-03-18 21:39:23,037] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:39:23,078] {logging_mixin.py:104} INFO - [2022-03-18 21:39:23,078] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:39:23,096] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 21:39:53,639] {scheduler_job.py:182} INFO - Started process (PID=27121) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:53,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:39:53,647] {logging_mixin.py:104} INFO - [2022-03-18 21:39:53,647] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:53,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:39:53,746] {logging_mixin.py:104} INFO - [2022-03-18 21:39:53,745] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:39:53,788] {logging_mixin.py:104} INFO - [2022-03-18 21:39:53,787] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:39:53,804] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:40:24,321] {scheduler_job.py:182} INFO - Started process (PID=27153) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:24,325] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:40:24,328] {logging_mixin.py:104} INFO - [2022-03-18 21:40:24,327] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:24,378] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:24,421] {logging_mixin.py:104} INFO - [2022-03-18 21:40:24,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:40:24,459] {logging_mixin.py:104} INFO - [2022-03-18 21:40:24,459] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:40:24,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:40:55,459] {scheduler_job.py:182} INFO - Started process (PID=27184) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:55,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:40:55,466] {logging_mixin.py:104} INFO - [2022-03-18 21:40:55,466] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:55,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:40:55,564] {logging_mixin.py:104} INFO - [2022-03-18 21:40:55,563] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:40:55,607] {logging_mixin.py:104} INFO - [2022-03-18 21:40:55,606] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:40:55,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 21:41:25,819] {scheduler_job.py:182} INFO - Started process (PID=27210) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:25,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:41:25,826] {logging_mixin.py:104} INFO - [2022-03-18 21:41:25,826] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:25,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:25,924] {logging_mixin.py:104} INFO - [2022-03-18 21:41:25,923] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:41:25,964] {logging_mixin.py:104} INFO - [2022-03-18 21:41:25,963] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:41:25,979] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 21:41:56,349] {scheduler_job.py:182} INFO - Started process (PID=27243) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:56,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:41:56,356] {logging_mixin.py:104} INFO - [2022-03-18 21:41:56,355] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:56,403] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:41:56,449] {logging_mixin.py:104} INFO - [2022-03-18 21:41:56,449] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:41:56,492] {logging_mixin.py:104} INFO - [2022-03-18 21:41:56,492] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:41:56,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:42:27,115] {scheduler_job.py:182} INFO - Started process (PID=27273) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:27,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:42:27,122] {logging_mixin.py:104} INFO - [2022-03-18 21:42:27,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:27,175] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:27,225] {logging_mixin.py:104} INFO - [2022-03-18 21:42:27,225] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:42:27,272] {logging_mixin.py:104} INFO - [2022-03-18 21:42:27,272] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:42:27,289] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 21:42:57,825] {scheduler_job.py:182} INFO - Started process (PID=27299) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:57,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:42:57,837] {logging_mixin.py:104} INFO - [2022-03-18 21:42:57,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:57,891] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:42:57,937] {logging_mixin.py:104} INFO - [2022-03-18 21:42:57,937] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:42:57,979] {logging_mixin.py:104} INFO - [2022-03-18 21:42:57,979] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:42:57,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 21:43:28,676] {scheduler_job.py:182} INFO - Started process (PID=27331) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:28,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:43:28,684] {logging_mixin.py:104} INFO - [2022-03-18 21:43:28,684] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:28,739] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:28,783] {logging_mixin.py:104} INFO - [2022-03-18 21:43:28,782] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:43:28,822] {logging_mixin.py:104} INFO - [2022-03-18 21:43:28,822] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:43:28,837] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 21:43:59,661] {scheduler_job.py:182} INFO - Started process (PID=27363) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:59,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:43:59,668] {logging_mixin.py:104} INFO - [2022-03-18 21:43:59,667] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:59,719] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:43:59,762] {logging_mixin.py:104} INFO - [2022-03-18 21:43:59,762] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:43:59,802] {logging_mixin.py:104} INFO - [2022-03-18 21:43:59,801] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:43:59,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:44:30,359] {scheduler_job.py:182} INFO - Started process (PID=27395) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:44:30,364] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:44:30,368] {logging_mixin.py:104} INFO - [2022-03-18 21:44:30,367] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:44:30,419] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:44:30,462] {logging_mixin.py:104} INFO - [2022-03-18 21:44:30,462] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:44:30,504] {logging_mixin.py:104} INFO - [2022-03-18 21:44:30,503] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:44:30,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:45:01,122] {scheduler_job.py:182} INFO - Started process (PID=27427) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:01,127] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:45:01,129] {logging_mixin.py:104} INFO - [2022-03-18 21:45:01,129] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:01,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:01,235] {logging_mixin.py:104} INFO - [2022-03-18 21:45:01,235] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:45:01,278] {logging_mixin.py:104} INFO - [2022-03-18 21:45:01,278] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:45:01,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-18 21:45:32,130] {scheduler_job.py:182} INFO - Started process (PID=27459) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:32,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:45:32,138] {logging_mixin.py:104} INFO - [2022-03-18 21:45:32,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:32,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:45:32,232] {logging_mixin.py:104} INFO - [2022-03-18 21:45:32,232] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:45:32,276] {logging_mixin.py:104} INFO - [2022-03-18 21:45:32,276] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:45:32,293] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:46:02,638] {scheduler_job.py:182} INFO - Started process (PID=27484) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:02,642] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:46:02,645] {logging_mixin.py:104} INFO - [2022-03-18 21:46:02,644] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:02,699] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:02,740] {logging_mixin.py:104} INFO - [2022-03-18 21:46:02,739] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:46:02,779] {logging_mixin.py:104} INFO - [2022-03-18 21:46:02,779] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:46:02,794] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:46:33,573] {scheduler_job.py:182} INFO - Started process (PID=27516) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:33,578] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:46:33,581] {logging_mixin.py:104} INFO - [2022-03-18 21:46:33,581] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:33,634] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:46:33,683] {logging_mixin.py:104} INFO - [2022-03-18 21:46:33,683] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:46:33,730] {logging_mixin.py:104} INFO - [2022-03-18 21:46:33,729] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:46:33,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 21:47:04,151] {scheduler_job.py:182} INFO - Started process (PID=27541) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:04,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:47:04,159] {logging_mixin.py:104} INFO - [2022-03-18 21:47:04,159] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:04,209] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:04,254] {logging_mixin.py:104} INFO - [2022-03-18 21:47:04,253] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:47:04,293] {logging_mixin.py:104} INFO - [2022-03-18 21:47:04,293] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:47:04,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:47:34,816] {scheduler_job.py:182} INFO - Started process (PID=27573) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:34,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:47:34,823] {logging_mixin.py:104} INFO - [2022-03-18 21:47:34,823] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:34,880] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:47:34,927] {logging_mixin.py:104} INFO - [2022-03-18 21:47:34,927] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:47:34,967] {logging_mixin.py:104} INFO - [2022-03-18 21:47:34,967] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:47:34,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 21:48:05,531] {scheduler_job.py:182} INFO - Started process (PID=27605) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:05,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:48:05,537] {logging_mixin.py:104} INFO - [2022-03-18 21:48:05,537] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:05,593] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:05,637] {logging_mixin.py:104} INFO - [2022-03-18 21:48:05,637] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:48:05,677] {logging_mixin.py:104} INFO - [2022-03-18 21:48:05,677] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:48:05,693] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 21:48:36,324] {scheduler_job.py:182} INFO - Started process (PID=27637) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:36,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:48:36,331] {logging_mixin.py:104} INFO - [2022-03-18 21:48:36,331] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:36,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:48:36,433] {logging_mixin.py:104} INFO - [2022-03-18 21:48:36,433] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:48:36,472] {logging_mixin.py:104} INFO - [2022-03-18 21:48:36,472] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:48:36,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:49:07,213] {scheduler_job.py:182} INFO - Started process (PID=27669) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:07,246] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:49:07,249] {logging_mixin.py:104} INFO - [2022-03-18 21:49:07,249] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:07,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:07,378] {logging_mixin.py:104} INFO - [2022-03-18 21:49:07,377] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:49:07,432] {logging_mixin.py:104} INFO - [2022-03-18 21:49:07,431] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:49:07,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.277 seconds
[2022-03-18 21:49:38,102] {scheduler_job.py:182} INFO - Started process (PID=27701) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:38,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:49:38,111] {logging_mixin.py:104} INFO - [2022-03-18 21:49:38,110] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:38,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:49:38,216] {logging_mixin.py:104} INFO - [2022-03-18 21:49:38,215] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:49:38,260] {logging_mixin.py:104} INFO - [2022-03-18 21:49:38,259] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:49:38,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 21:50:09,110] {scheduler_job.py:182} INFO - Started process (PID=27733) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:09,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:50:09,118] {logging_mixin.py:104} INFO - [2022-03-18 21:50:09,117] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:09,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:09,228] {logging_mixin.py:104} INFO - [2022-03-18 21:50:09,227] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:50:09,274] {logging_mixin.py:104} INFO - [2022-03-18 21:50:09,274] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:50:09,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-18 21:50:39,421] {scheduler_job.py:182} INFO - Started process (PID=27758) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:39,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:50:39,430] {logging_mixin.py:104} INFO - [2022-03-18 21:50:39,429] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:39,488] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:50:39,536] {logging_mixin.py:104} INFO - [2022-03-18 21:50:39,536] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:50:39,584] {logging_mixin.py:104} INFO - [2022-03-18 21:50:39,584] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:50:39,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 21:51:10,345] {scheduler_job.py:182} INFO - Started process (PID=27783) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:10,349] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:51:10,352] {logging_mixin.py:104} INFO - [2022-03-18 21:51:10,351] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:10,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:10,458] {logging_mixin.py:104} INFO - [2022-03-18 21:51:10,457] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:51:10,502] {logging_mixin.py:104} INFO - [2022-03-18 21:51:10,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:51:10,520] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.181 seconds
[2022-03-18 21:51:40,942] {scheduler_job.py:182} INFO - Started process (PID=27815) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:40,946] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:51:40,948] {logging_mixin.py:104} INFO - [2022-03-18 21:51:40,948] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:41,004] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:51:41,046] {logging_mixin.py:104} INFO - [2022-03-18 21:51:41,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:51:41,086] {logging_mixin.py:104} INFO - [2022-03-18 21:51:41,086] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:51:41,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 21:52:11,549] {scheduler_job.py:182} INFO - Started process (PID=27847) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:11,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:52:11,557] {logging_mixin.py:104} INFO - [2022-03-18 21:52:11,557] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:11,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:11,655] {logging_mixin.py:104} INFO - [2022-03-18 21:52:11,654] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:52:11,696] {logging_mixin.py:104} INFO - [2022-03-18 21:52:11,696] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:52:11,712] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:52:42,070] {scheduler_job.py:182} INFO - Started process (PID=27879) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:42,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:52:42,077] {logging_mixin.py:104} INFO - [2022-03-18 21:52:42,077] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:42,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:52:42,172] {logging_mixin.py:104} INFO - [2022-03-18 21:52:42,171] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:52:42,210] {logging_mixin.py:104} INFO - [2022-03-18 21:52:42,209] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:52:42,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 21:53:12,584] {scheduler_job.py:182} INFO - Started process (PID=27911) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:12,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:53:12,591] {logging_mixin.py:104} INFO - [2022-03-18 21:53:12,590] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:12,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:12,686] {logging_mixin.py:104} INFO - [2022-03-18 21:53:12,686] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:53:12,726] {logging_mixin.py:104} INFO - [2022-03-18 21:53:12,726] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:53:12,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:53:43,180] {scheduler_job.py:182} INFO - Started process (PID=27943) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:43,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:53:43,187] {logging_mixin.py:104} INFO - [2022-03-18 21:53:43,187] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:43,242] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:53:43,289] {logging_mixin.py:104} INFO - [2022-03-18 21:53:43,288] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:53:43,327] {logging_mixin.py:104} INFO - [2022-03-18 21:53:43,327] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:53:43,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:54:13,764] {scheduler_job.py:182} INFO - Started process (PID=27975) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:13,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:54:13,774] {logging_mixin.py:104} INFO - [2022-03-18 21:54:13,773] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:13,825] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:13,868] {logging_mixin.py:104} INFO - [2022-03-18 21:54:13,868] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:54:13,908] {logging_mixin.py:104} INFO - [2022-03-18 21:54:13,907] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:54:13,923] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:54:44,831] {scheduler_job.py:182} INFO - Started process (PID=28006) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:44,834] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:54:44,837] {logging_mixin.py:104} INFO - [2022-03-18 21:54:44,837] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:44,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:54:44,935] {logging_mixin.py:104} INFO - [2022-03-18 21:54:44,934] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:54:44,977] {logging_mixin.py:104} INFO - [2022-03-18 21:54:44,976] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:54:44,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 21:55:15,095] {scheduler_job.py:182} INFO - Started process (PID=28032) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:15,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:55:15,102] {logging_mixin.py:104} INFO - [2022-03-18 21:55:15,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:15,150] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:15,195] {logging_mixin.py:104} INFO - [2022-03-18 21:55:15,195] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:55:15,237] {logging_mixin.py:104} INFO - [2022-03-18 21:55:15,237] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:55:15,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 21:55:45,552] {scheduler_job.py:182} INFO - Started process (PID=28057) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:45,557] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:55:45,560] {logging_mixin.py:104} INFO - [2022-03-18 21:55:45,560] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:45,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:55:45,650] {logging_mixin.py:104} INFO - [2022-03-18 21:55:45,649] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:55:45,689] {logging_mixin.py:104} INFO - [2022-03-18 21:55:45,688] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:55:45,706] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 21:56:15,998] {scheduler_job.py:182} INFO - Started process (PID=28089) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:16,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:56:16,004] {logging_mixin.py:104} INFO - [2022-03-18 21:56:16,004] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:16,054] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:16,098] {logging_mixin.py:104} INFO - [2022-03-18 21:56:16,098] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:56:16,140] {logging_mixin.py:104} INFO - [2022-03-18 21:56:16,139] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:56:16,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:56:46,500] {scheduler_job.py:182} INFO - Started process (PID=28121) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:46,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:56:46,507] {logging_mixin.py:104} INFO - [2022-03-18 21:56:46,507] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:46,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:56:46,601] {logging_mixin.py:104} INFO - [2022-03-18 21:56:46,600] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:56:46,640] {logging_mixin.py:104} INFO - [2022-03-18 21:56:46,640] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:56:46,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:57:17,034] {scheduler_job.py:182} INFO - Started process (PID=28153) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:17,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:57:17,040] {logging_mixin.py:104} INFO - [2022-03-18 21:57:17,040] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:17,097] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:17,143] {logging_mixin.py:104} INFO - [2022-03-18 21:57:17,142] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:57:17,183] {logging_mixin.py:104} INFO - [2022-03-18 21:57:17,183] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:57:17,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:57:47,619] {scheduler_job.py:182} INFO - Started process (PID=28185) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:47,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:57:47,627] {logging_mixin.py:104} INFO - [2022-03-18 21:57:47,627] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:47,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:57:47,720] {logging_mixin.py:104} INFO - [2022-03-18 21:57:47,720] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:57:47,760] {logging_mixin.py:104} INFO - [2022-03-18 21:57:47,759] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:57:47,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 21:58:18,203] {scheduler_job.py:182} INFO - Started process (PID=28217) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:18,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:58:18,211] {logging_mixin.py:104} INFO - [2022-03-18 21:58:18,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:18,263] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:18,305] {logging_mixin.py:104} INFO - [2022-03-18 21:58:18,304] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:58:18,343] {logging_mixin.py:104} INFO - [2022-03-18 21:58:18,343] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:58:18,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 21:58:48,810] {scheduler_job.py:182} INFO - Started process (PID=28249) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:48,814] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:58:48,816] {logging_mixin.py:104} INFO - [2022-03-18 21:58:48,816] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:48,868] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:58:48,911] {logging_mixin.py:104} INFO - [2022-03-18 21:58:48,910] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:58:48,951] {logging_mixin.py:104} INFO - [2022-03-18 21:58:48,950] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:58:48,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 21:59:19,608] {scheduler_job.py:182} INFO - Started process (PID=28280) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:19,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:59:19,615] {logging_mixin.py:104} INFO - [2022-03-18 21:59:19,615] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:19,666] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:19,714] {logging_mixin.py:104} INFO - [2022-03-18 21:59:19,713] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:59:19,756] {logging_mixin.py:104} INFO - [2022-03-18 21:59:19,756] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:59:19,773] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 21:59:50,116] {scheduler_job.py:182} INFO - Started process (PID=28305) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:50,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 21:59:50,123] {logging_mixin.py:104} INFO - [2022-03-18 21:59:50,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:50,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 21:59:50,224] {logging_mixin.py:104} INFO - [2022-03-18 21:59:50,224] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 21:59:50,270] {logging_mixin.py:104} INFO - [2022-03-18 21:59:50,270] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 21:59:50,287] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:00:20,595] {scheduler_job.py:182} INFO - Started process (PID=28331) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:20,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:00:20,601] {logging_mixin.py:104} INFO - [2022-03-18 22:00:20,600] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:20,654] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:20,695] {logging_mixin.py:104} INFO - [2022-03-18 22:00:20,695] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:00:20,734] {logging_mixin.py:104} INFO - [2022-03-18 22:00:20,733] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:00:20,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 22:00:51,030] {scheduler_job.py:182} INFO - Started process (PID=28363) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:51,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:00:51,038] {logging_mixin.py:104} INFO - [2022-03-18 22:00:51,037] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:51,096] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:00:51,138] {logging_mixin.py:104} INFO - [2022-03-18 22:00:51,138] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:00:51,179] {logging_mixin.py:104} INFO - [2022-03-18 22:00:51,178] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:00:51,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:01:21,388] {scheduler_job.py:182} INFO - Started process (PID=28395) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:21,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:01:21,396] {logging_mixin.py:104} INFO - [2022-03-18 22:01:21,396] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:21,453] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:21,495] {logging_mixin.py:104} INFO - [2022-03-18 22:01:21,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:01:21,536] {logging_mixin.py:104} INFO - [2022-03-18 22:01:21,536] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:01:21,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 22:01:51,795] {scheduler_job.py:182} INFO - Started process (PID=28427) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:51,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:01:51,802] {logging_mixin.py:104} INFO - [2022-03-18 22:01:51,801] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:51,855] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:01:51,898] {logging_mixin.py:104} INFO - [2022-03-18 22:01:51,897] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:01:51,937] {logging_mixin.py:104} INFO - [2022-03-18 22:01:51,936] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:01:51,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 22:02:22,401] {scheduler_job.py:182} INFO - Started process (PID=28459) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:22,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:02:22,407] {logging_mixin.py:104} INFO - [2022-03-18 22:02:22,407] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:22,455] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:22,496] {logging_mixin.py:104} INFO - [2022-03-18 22:02:22,495] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:02:22,534] {logging_mixin.py:104} INFO - [2022-03-18 22:02:22,534] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:02:22,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.156 seconds
[2022-03-18 22:02:53,081] {scheduler_job.py:182} INFO - Started process (PID=28491) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:53,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:02:53,087] {logging_mixin.py:104} INFO - [2022-03-18 22:02:53,087] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:53,139] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:02:53,182] {logging_mixin.py:104} INFO - [2022-03-18 22:02:53,181] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:02:53,221] {logging_mixin.py:104} INFO - [2022-03-18 22:02:53,221] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:02:53,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:03:24,198] {scheduler_job.py:182} INFO - Started process (PID=28523) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:24,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:03:24,205] {logging_mixin.py:104} INFO - [2022-03-18 22:03:24,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:24,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:24,298] {logging_mixin.py:104} INFO - [2022-03-18 22:03:24,298] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:03:24,342] {logging_mixin.py:104} INFO - [2022-03-18 22:03:24,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:03:24,359] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 22:03:54,499] {scheduler_job.py:182} INFO - Started process (PID=28548) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:54,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:03:54,510] {logging_mixin.py:104} INFO - [2022-03-18 22:03:54,509] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:54,569] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:03:54,618] {logging_mixin.py:104} INFO - [2022-03-18 22:03:54,617] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:03:54,663] {logging_mixin.py:104} INFO - [2022-03-18 22:03:54,662] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:03:54,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 22:04:24,964] {scheduler_job.py:182} INFO - Started process (PID=28573) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:24,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:04:24,971] {logging_mixin.py:104} INFO - [2022-03-18 22:04:24,971] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:25,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:25,065] {logging_mixin.py:104} INFO - [2022-03-18 22:04:25,064] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:04:25,111] {logging_mixin.py:104} INFO - [2022-03-18 22:04:25,111] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:04:25,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:04:55,790] {scheduler_job.py:182} INFO - Started process (PID=28605) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:55,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:04:55,797] {logging_mixin.py:104} INFO - [2022-03-18 22:04:55,797] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:55,851] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:04:55,894] {logging_mixin.py:104} INFO - [2022-03-18 22:04:55,894] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:04:55,933] {logging_mixin.py:104} INFO - [2022-03-18 22:04:55,933] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:04:55,949] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 22:05:26,617] {scheduler_job.py:182} INFO - Started process (PID=28637) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:26,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:05:26,624] {logging_mixin.py:104} INFO - [2022-03-18 22:05:26,624] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:26,676] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:26,717] {logging_mixin.py:104} INFO - [2022-03-18 22:05:26,717] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:05:26,755] {logging_mixin.py:104} INFO - [2022-03-18 22:05:26,755] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:05:26,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:05:57,336] {scheduler_job.py:182} INFO - Started process (PID=28669) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:57,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:05:57,343] {logging_mixin.py:104} INFO - [2022-03-18 22:05:57,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:57,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:05:57,448] {logging_mixin.py:104} INFO - [2022-03-18 22:05:57,447] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:05:57,494] {logging_mixin.py:104} INFO - [2022-03-18 22:05:57,493] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:05:57,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 22:06:28,156] {scheduler_job.py:182} INFO - Started process (PID=28701) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:28,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:06:28,164] {logging_mixin.py:104} INFO - [2022-03-18 22:06:28,164] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:28,213] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:28,257] {logging_mixin.py:104} INFO - [2022-03-18 22:06:28,257] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:06:28,296] {logging_mixin.py:104} INFO - [2022-03-18 22:06:28,296] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:06:28,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 22:06:59,041] {scheduler_job.py:182} INFO - Started process (PID=28733) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:59,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:06:59,050] {logging_mixin.py:104} INFO - [2022-03-18 22:06:59,049] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:59,102] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:06:59,144] {logging_mixin.py:104} INFO - [2022-03-18 22:06:59,143] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:06:59,184] {logging_mixin.py:104} INFO - [2022-03-18 22:06:59,183] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:06:59,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 22:07:29,807] {scheduler_job.py:182} INFO - Started process (PID=28765) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:07:29,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:07:29,813] {logging_mixin.py:104} INFO - [2022-03-18 22:07:29,813] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:07:29,867] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:07:29,909] {logging_mixin.py:104} INFO - [2022-03-18 22:07:29,909] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:07:29,947] {logging_mixin.py:104} INFO - [2022-03-18 22:07:29,947] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:07:29,962] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.162 seconds
[2022-03-18 22:08:00,868] {scheduler_job.py:182} INFO - Started process (PID=28797) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:00,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:08:00,875] {logging_mixin.py:104} INFO - [2022-03-18 22:08:00,875] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:00,931] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:00,984] {logging_mixin.py:104} INFO - [2022-03-18 22:08:00,984] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:08:01,033] {logging_mixin.py:104} INFO - [2022-03-18 22:08:01,032] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:08:01,050] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.189 seconds
[2022-03-18 22:08:31,693] {scheduler_job.py:182} INFO - Started process (PID=28822) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:31,697] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:08:31,700] {logging_mixin.py:104} INFO - [2022-03-18 22:08:31,700] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:31,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:08:31,801] {logging_mixin.py:104} INFO - [2022-03-18 22:08:31,801] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:08:31,850] {logging_mixin.py:104} INFO - [2022-03-18 22:08:31,849] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:08:31,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 22:09:02,581] {scheduler_job.py:182} INFO - Started process (PID=28847) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:02,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:09:02,592] {logging_mixin.py:104} INFO - [2022-03-18 22:09:02,591] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:02,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:02,695] {logging_mixin.py:104} INFO - [2022-03-18 22:09:02,695] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:09:02,737] {logging_mixin.py:104} INFO - [2022-03-18 22:09:02,736] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:09:02,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:09:33,505] {scheduler_job.py:182} INFO - Started process (PID=28879) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:33,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:09:33,513] {logging_mixin.py:104} INFO - [2022-03-18 22:09:33,512] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:33,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:09:33,614] {logging_mixin.py:104} INFO - [2022-03-18 22:09:33,614] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:09:33,655] {logging_mixin.py:104} INFO - [2022-03-18 22:09:33,655] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:09:33,672] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 22:10:04,346] {scheduler_job.py:182} INFO - Started process (PID=28911) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:04,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:10:04,354] {logging_mixin.py:104} INFO - [2022-03-18 22:10:04,354] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:04,409] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:04,458] {logging_mixin.py:104} INFO - [2022-03-18 22:10:04,457] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:10:04,501] {logging_mixin.py:104} INFO - [2022-03-18 22:10:04,501] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:10:04,517] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 22:10:35,168] {scheduler_job.py:182} INFO - Started process (PID=28943) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:35,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:10:35,175] {logging_mixin.py:104} INFO - [2022-03-18 22:10:35,175] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:35,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:10:35,282] {logging_mixin.py:104} INFO - [2022-03-18 22:10:35,282] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:10:35,324] {logging_mixin.py:104} INFO - [2022-03-18 22:10:35,323] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:10:35,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:11:05,986] {scheduler_job.py:182} INFO - Started process (PID=28975) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:05,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:11:05,995] {logging_mixin.py:104} INFO - [2022-03-18 22:11:05,994] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:06,055] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:06,104] {logging_mixin.py:104} INFO - [2022-03-18 22:11:06,104] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:11:06,146] {logging_mixin.py:104} INFO - [2022-03-18 22:11:06,146] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:11:06,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 22:11:36,801] {scheduler_job.py:182} INFO - Started process (PID=29007) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:36,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:11:36,810] {logging_mixin.py:104} INFO - [2022-03-18 22:11:36,809] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:36,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:11:36,919] {logging_mixin.py:104} INFO - [2022-03-18 22:11:36,919] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:11:36,964] {logging_mixin.py:104} INFO - [2022-03-18 22:11:36,964] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:11:36,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-18 22:12:07,649] {scheduler_job.py:182} INFO - Started process (PID=29041) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:07,656] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:12:07,660] {logging_mixin.py:104} INFO - [2022-03-18 22:12:07,659] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:07,720] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:07,769] {logging_mixin.py:104} INFO - [2022-03-18 22:12:07,769] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:12:07,813] {logging_mixin.py:104} INFO - [2022-03-18 22:12:07,812] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:12:07,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.188 seconds
[2022-03-18 22:12:39,335] {scheduler_job.py:182} INFO - Started process (PID=29070) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:39,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:12:39,343] {logging_mixin.py:104} INFO - [2022-03-18 22:12:39,343] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:39,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:12:39,452] {logging_mixin.py:104} INFO - [2022-03-18 22:12:39,452] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:12:39,500] {logging_mixin.py:104} INFO - [2022-03-18 22:12:39,500] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:12:39,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.191 seconds
[2022-03-18 22:13:10,554] {scheduler_job.py:182} INFO - Started process (PID=29096) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:10,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:13:10,561] {logging_mixin.py:104} INFO - [2022-03-18 22:13:10,561] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:10,613] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:10,663] {logging_mixin.py:104} INFO - [2022-03-18 22:13:10,662] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:13:10,708] {logging_mixin.py:104} INFO - [2022-03-18 22:13:10,708] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:13:10,725] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 22:13:40,932] {scheduler_job.py:182} INFO - Started process (PID=29123) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:40,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:13:40,939] {logging_mixin.py:104} INFO - [2022-03-18 22:13:40,939] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:41,010] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:13:41,063] {logging_mixin.py:104} INFO - [2022-03-18 22:13:41,062] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:13:41,108] {logging_mixin.py:104} INFO - [2022-03-18 22:13:41,107] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:13:41,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.201 seconds
[2022-03-18 22:14:11,860] {scheduler_job.py:182} INFO - Started process (PID=29153) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:11,866] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:14:11,869] {logging_mixin.py:104} INFO - [2022-03-18 22:14:11,868] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:11,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:11,968] {logging_mixin.py:104} INFO - [2022-03-18 22:14:11,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:14:12,011] {logging_mixin.py:104} INFO - [2022-03-18 22:14:12,010] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:14:12,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 22:14:42,715] {scheduler_job.py:182} INFO - Started process (PID=29185) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:42,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:14:42,723] {logging_mixin.py:104} INFO - [2022-03-18 22:14:42,723] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:42,780] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:14:42,832] {logging_mixin.py:104} INFO - [2022-03-18 22:14:42,832] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:14:42,880] {logging_mixin.py:104} INFO - [2022-03-18 22:14:42,880] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:14:42,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-18 22:15:13,538] {scheduler_job.py:182} INFO - Started process (PID=29217) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:13,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:15:13,546] {logging_mixin.py:104} INFO - [2022-03-18 22:15:13,545] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:13,606] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:13,655] {logging_mixin.py:104} INFO - [2022-03-18 22:15:13,654] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:15:13,699] {logging_mixin.py:104} INFO - [2022-03-18 22:15:13,699] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:15:13,717] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 22:15:44,370] {scheduler_job.py:182} INFO - Started process (PID=29249) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:44,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:15:44,380] {logging_mixin.py:104} INFO - [2022-03-18 22:15:44,380] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:44,437] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:15:44,489] {logging_mixin.py:104} INFO - [2022-03-18 22:15:44,489] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:15:44,536] {logging_mixin.py:104} INFO - [2022-03-18 22:15:44,536] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:15:44,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-18 22:16:15,225] {scheduler_job.py:182} INFO - Started process (PID=29281) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:15,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:16:15,233] {logging_mixin.py:104} INFO - [2022-03-18 22:16:15,233] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:15,284] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:15,330] {logging_mixin.py:104} INFO - [2022-03-18 22:16:15,330] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:16:15,373] {logging_mixin.py:104} INFO - [2022-03-18 22:16:15,373] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:16:15,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 22:16:45,560] {scheduler_job.py:182} INFO - Started process (PID=29313) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:45,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:16:45,569] {logging_mixin.py:104} INFO - [2022-03-18 22:16:45,568] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:45,640] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:16:45,692] {logging_mixin.py:104} INFO - [2022-03-18 22:16:45,691] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:16:45,739] {logging_mixin.py:104} INFO - [2022-03-18 22:16:45,739] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:16:45,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.203 seconds
[2022-03-18 22:17:18,990] {scheduler_job.py:182} INFO - Started process (PID=29345) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:18,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:17:18,997] {logging_mixin.py:104} INFO - [2022-03-18 22:17:18,997] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:19,051] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:19,101] {logging_mixin.py:104} INFO - [2022-03-18 22:17:19,100] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:17:19,148] {logging_mixin.py:104} INFO - [2022-03-18 22:17:19,148] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:17:19,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 22:17:49,880] {scheduler_job.py:182} INFO - Started process (PID=29370) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:49,884] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:17:49,887] {logging_mixin.py:104} INFO - [2022-03-18 22:17:49,887] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:49,943] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:17:50,001] {logging_mixin.py:104} INFO - [2022-03-18 22:17:50,001] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:17:50,047] {logging_mixin.py:104} INFO - [2022-03-18 22:17:50,046] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:17:50,066] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.194 seconds
[2022-03-18 22:18:20,334] {scheduler_job.py:182} INFO - Started process (PID=29397) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:20,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:18:20,341] {logging_mixin.py:104} INFO - [2022-03-18 22:18:20,340] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:20,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:20,440] {logging_mixin.py:104} INFO - [2022-03-18 22:18:20,440] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:18:20,485] {logging_mixin.py:104} INFO - [2022-03-18 22:18:20,485] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:18:20,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 22:18:50,755] {scheduler_job.py:182} INFO - Started process (PID=29429) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:50,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:18:50,764] {logging_mixin.py:104} INFO - [2022-03-18 22:18:50,764] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:50,814] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:18:50,861] {logging_mixin.py:104} INFO - [2022-03-18 22:18:50,860] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:18:50,904] {logging_mixin.py:104} INFO - [2022-03-18 22:18:50,904] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:18:50,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 22:19:21,020] {scheduler_job.py:182} INFO - Started process (PID=29455) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:21,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:19:21,028] {logging_mixin.py:104} INFO - [2022-03-18 22:19:21,028] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:21,083] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:21,131] {logging_mixin.py:104} INFO - [2022-03-18 22:19:21,131] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:19:21,178] {logging_mixin.py:104} INFO - [2022-03-18 22:19:21,177] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:19:21,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.187 seconds
[2022-03-18 22:19:51,837] {scheduler_job.py:182} INFO - Started process (PID=29491) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:51,841] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:19:51,844] {logging_mixin.py:104} INFO - [2022-03-18 22:19:51,843] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:51,898] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:19:51,944] {logging_mixin.py:104} INFO - [2022-03-18 22:19:51,944] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:19:51,989] {logging_mixin.py:104} INFO - [2022-03-18 22:19:51,988] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:19:52,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 22:20:22,649] {scheduler_job.py:182} INFO - Started process (PID=29523) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:22,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:20:22,658] {logging_mixin.py:104} INFO - [2022-03-18 22:20:22,657] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:22,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:22,767] {logging_mixin.py:104} INFO - [2022-03-18 22:20:22,766] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:20:22,808] {logging_mixin.py:104} INFO - [2022-03-18 22:20:22,808] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:20:22,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 22:20:53,438] {scheduler_job.py:182} INFO - Started process (PID=29555) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:53,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:20:53,445] {logging_mixin.py:104} INFO - [2022-03-18 22:20:53,445] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:53,500] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:20:53,550] {logging_mixin.py:104} INFO - [2022-03-18 22:20:53,550] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:20:53,597] {logging_mixin.py:104} INFO - [2022-03-18 22:20:53,596] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:20:53,614] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 22:21:24,258] {scheduler_job.py:182} INFO - Started process (PID=29587) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:24,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:21:24,266] {logging_mixin.py:104} INFO - [2022-03-18 22:21:24,266] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:24,322] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:24,369] {logging_mixin.py:104} INFO - [2022-03-18 22:21:24,369] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:21:24,412] {logging_mixin.py:104} INFO - [2022-03-18 22:21:24,412] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:21:24,428] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 22:21:58,095] {scheduler_job.py:182} INFO - Started process (PID=29619) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:58,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:21:58,102] {logging_mixin.py:104} INFO - [2022-03-18 22:21:58,101] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:58,155] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:21:58,215] {logging_mixin.py:104} INFO - [2022-03-18 22:21:58,215] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:21:58,265] {logging_mixin.py:104} INFO - [2022-03-18 22:21:58,264] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:21:58,288] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.200 seconds
[2022-03-18 22:22:28,407] {scheduler_job.py:182} INFO - Started process (PID=29644) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:28,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:22:28,416] {logging_mixin.py:104} INFO - [2022-03-18 22:22:28,415] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:28,468] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:28,517] {logging_mixin.py:104} INFO - [2022-03-18 22:22:28,516] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:22:28,561] {logging_mixin.py:104} INFO - [2022-03-18 22:22:28,561] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:22:28,592] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.192 seconds
[2022-03-18 22:22:58,734] {scheduler_job.py:182} INFO - Started process (PID=29669) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:58,738] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:22:58,742] {logging_mixin.py:104} INFO - [2022-03-18 22:22:58,741] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:58,798] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:22:58,845] {logging_mixin.py:104} INFO - [2022-03-18 22:22:58,845] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:22:58,885] {logging_mixin.py:104} INFO - [2022-03-18 22:22:58,885] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:22:58,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 22:23:29,656] {scheduler_job.py:182} INFO - Started process (PID=29701) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:23:29,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:23:29,664] {logging_mixin.py:104} INFO - [2022-03-18 22:23:29,664] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:23:29,717] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:23:29,763] {logging_mixin.py:104} INFO - [2022-03-18 22:23:29,763] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:23:29,805] {logging_mixin.py:104} INFO - [2022-03-18 22:23:29,805] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:23:29,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 22:24:00,028] {scheduler_job.py:182} INFO - Started process (PID=29733) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:00,038] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:24:00,041] {logging_mixin.py:104} INFO - [2022-03-18 22:24:00,041] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:00,103] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:00,151] {logging_mixin.py:104} INFO - [2022-03-18 22:24:00,150] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:24:00,198] {logging_mixin.py:104} INFO - [2022-03-18 22:24:00,197] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:24:00,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.197 seconds
[2022-03-18 22:24:30,383] {scheduler_job.py:182} INFO - Started process (PID=29763) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:30,389] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:24:30,392] {logging_mixin.py:104} INFO - [2022-03-18 22:24:30,392] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:30,450] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:24:30,510] {logging_mixin.py:104} INFO - [2022-03-18 22:24:30,510] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:24:30,564] {logging_mixin.py:104} INFO - [2022-03-18 22:24:30,564] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:24:30,584] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.208 seconds
[2022-03-18 22:25:01,473] {scheduler_job.py:182} INFO - Started process (PID=29795) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:01,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:25:01,483] {logging_mixin.py:104} INFO - [2022-03-18 22:25:01,483] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:01,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:01,584] {logging_mixin.py:104} INFO - [2022-03-18 22:25:01,584] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:25:01,632] {logging_mixin.py:104} INFO - [2022-03-18 22:25:01,632] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:25:01,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 22:25:31,859] {scheduler_job.py:182} INFO - Started process (PID=29828) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:31,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:25:31,867] {logging_mixin.py:104} INFO - [2022-03-18 22:25:31,867] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:31,926] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:25:31,980] {logging_mixin.py:104} INFO - [2022-03-18 22:25:31,979] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:25:32,051] {logging_mixin.py:104} INFO - [2022-03-18 22:25:32,050] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:25:32,069] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.218 seconds
[2022-03-18 22:26:04,555] {scheduler_job.py:182} INFO - Started process (PID=29861) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:04,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:26:04,563] {logging_mixin.py:104} INFO - [2022-03-18 22:26:04,563] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:04,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:04,693] {logging_mixin.py:104} INFO - [2022-03-18 22:26:04,693] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:26:04,740] {logging_mixin.py:104} INFO - [2022-03-18 22:26:04,739] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:26:04,758] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.210 seconds
[2022-03-18 22:26:34,872] {scheduler_job.py:182} INFO - Started process (PID=29886) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:34,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:26:34,879] {logging_mixin.py:104} INFO - [2022-03-18 22:26:34,879] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:34,933] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:26:34,981] {logging_mixin.py:104} INFO - [2022-03-18 22:26:34,981] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:26:35,028] {logging_mixin.py:104} INFO - [2022-03-18 22:26:35,028] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:26:35,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.182 seconds
[2022-03-18 22:27:05,189] {scheduler_job.py:182} INFO - Started process (PID=29911) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:05,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:27:05,197] {logging_mixin.py:104} INFO - [2022-03-18 22:27:05,197] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:05,256] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:05,300] {logging_mixin.py:104} INFO - [2022-03-18 22:27:05,300] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:27:05,342] {logging_mixin.py:104} INFO - [2022-03-18 22:27:05,342] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:27:05,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.176 seconds
[2022-03-18 22:27:36,127] {scheduler_job.py:182} INFO - Started process (PID=29943) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:36,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:27:36,138] {logging_mixin.py:104} INFO - [2022-03-18 22:27:36,137] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:36,191] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:27:36,239] {logging_mixin.py:104} INFO - [2022-03-18 22:27:36,239] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:27:36,281] {logging_mixin.py:104} INFO - [2022-03-18 22:27:36,281] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:27:36,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:28:07,085] {scheduler_job.py:182} INFO - Started process (PID=29975) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:07,091] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:28:07,095] {logging_mixin.py:104} INFO - [2022-03-18 22:28:07,094] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:07,150] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:07,197] {logging_mixin.py:104} INFO - [2022-03-18 22:28:07,196] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:28:07,240] {logging_mixin.py:104} INFO - [2022-03-18 22:28:07,239] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:28:07,257] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:28:37,984] {scheduler_job.py:182} INFO - Started process (PID=30007) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:37,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:28:37,992] {logging_mixin.py:104} INFO - [2022-03-18 22:28:37,992] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:38,048] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:28:38,095] {logging_mixin.py:104} INFO - [2022-03-18 22:28:38,094] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:28:38,137] {logging_mixin.py:104} INFO - [2022-03-18 22:28:38,137] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:28:38,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 22:29:08,837] {scheduler_job.py:182} INFO - Started process (PID=30039) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:08,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:29:08,846] {logging_mixin.py:104} INFO - [2022-03-18 22:29:08,845] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:08,897] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:08,948] {logging_mixin.py:104} INFO - [2022-03-18 22:29:08,948] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:29:08,992] {logging_mixin.py:104} INFO - [2022-03-18 22:29:08,992] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:29:09,008] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:29:39,603] {scheduler_job.py:182} INFO - Started process (PID=30071) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:39,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:29:39,612] {logging_mixin.py:104} INFO - [2022-03-18 22:29:39,611] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:39,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:29:39,715] {logging_mixin.py:104} INFO - [2022-03-18 22:29:39,715] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:29:39,759] {logging_mixin.py:104} INFO - [2022-03-18 22:29:39,758] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:29:39,776] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.179 seconds
[2022-03-18 22:30:10,355] {scheduler_job.py:182} INFO - Started process (PID=30103) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:10,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:30:10,362] {logging_mixin.py:104} INFO - [2022-03-18 22:30:10,362] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:10,419] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:10,466] {logging_mixin.py:104} INFO - [2022-03-18 22:30:10,465] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:30:10,509] {logging_mixin.py:104} INFO - [2022-03-18 22:30:10,508] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:30:10,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.177 seconds
[2022-03-18 22:30:44,231] {scheduler_job.py:182} INFO - Started process (PID=30135) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:44,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:30:44,237] {logging_mixin.py:104} INFO - [2022-03-18 22:30:44,237] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:44,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:30:44,343] {logging_mixin.py:104} INFO - [2022-03-18 22:30:44,343] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:30:44,392] {logging_mixin.py:104} INFO - [2022-03-18 22:30:44,391] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:30:44,409] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 22:31:15,454] {scheduler_job.py:182} INFO - Started process (PID=30160) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:15,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:31:15,460] {logging_mixin.py:104} INFO - [2022-03-18 22:31:15,460] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:15,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:15,554] {logging_mixin.py:104} INFO - [2022-03-18 22:31:15,553] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:31:15,602] {logging_mixin.py:104} INFO - [2022-03-18 22:31:15,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:31:15,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:31:45,708] {scheduler_job.py:182} INFO - Started process (PID=30187) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:45,712] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:31:45,715] {logging_mixin.py:104} INFO - [2022-03-18 22:31:45,714] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:45,763] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:31:45,813] {logging_mixin.py:104} INFO - [2022-03-18 22:31:45,812] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:31:45,856] {logging_mixin.py:104} INFO - [2022-03-18 22:31:45,856] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:31:45,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 22:32:16,731] {scheduler_job.py:182} INFO - Started process (PID=30217) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:16,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:32:16,739] {logging_mixin.py:104} INFO - [2022-03-18 22:32:16,739] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:16,792] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:16,836] {logging_mixin.py:104} INFO - [2022-03-18 22:32:16,836] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:32:16,875] {logging_mixin.py:104} INFO - [2022-03-18 22:32:16,874] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:32:16,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 22:32:47,538] {scheduler_job.py:182} INFO - Started process (PID=30249) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:47,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:32:47,547] {logging_mixin.py:104} INFO - [2022-03-18 22:32:47,546] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:47,596] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:32:47,638] {logging_mixin.py:104} INFO - [2022-03-18 22:32:47,637] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:32:47,676] {logging_mixin.py:104} INFO - [2022-03-18 22:32:47,676] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:32:47,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:33:18,325] {scheduler_job.py:182} INFO - Started process (PID=30281) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:18,330] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:33:18,333] {logging_mixin.py:104} INFO - [2022-03-18 22:33:18,332] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:18,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:18,430] {logging_mixin.py:104} INFO - [2022-03-18 22:33:18,430] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:33:18,469] {logging_mixin.py:104} INFO - [2022-03-18 22:33:18,468] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:33:18,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 22:33:49,165] {scheduler_job.py:182} INFO - Started process (PID=30313) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:49,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:33:49,172] {logging_mixin.py:104} INFO - [2022-03-18 22:33:49,172] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:49,228] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:33:49,274] {logging_mixin.py:104} INFO - [2022-03-18 22:33:49,273] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:33:49,312] {logging_mixin.py:104} INFO - [2022-03-18 22:33:49,312] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:33:49,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 22:34:19,924] {scheduler_job.py:182} INFO - Started process (PID=30345) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:19,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:34:19,932] {logging_mixin.py:104} INFO - [2022-03-18 22:34:19,932] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:19,995] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:20,046] {logging_mixin.py:104} INFO - [2022-03-18 22:34:20,046] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:34:20,091] {logging_mixin.py:104} INFO - [2022-03-18 22:34:20,090] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:34:20,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-18 22:34:50,644] {scheduler_job.py:182} INFO - Started process (PID=30377) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:50,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:34:50,651] {logging_mixin.py:104} INFO - [2022-03-18 22:34:50,650] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:50,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:34:50,743] {logging_mixin.py:104} INFO - [2022-03-18 22:34:50,743] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:34:50,782] {logging_mixin.py:104} INFO - [2022-03-18 22:34:50,782] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:34:50,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:35:23,019] {scheduler_job.py:182} INFO - Started process (PID=30409) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:23,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:35:23,033] {logging_mixin.py:104} INFO - [2022-03-18 22:35:23,032] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:23,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:23,146] {logging_mixin.py:104} INFO - [2022-03-18 22:35:23,146] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:35:23,189] {logging_mixin.py:104} INFO - [2022-03-18 22:35:23,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:35:23,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.196 seconds
[2022-03-18 22:35:54,178] {scheduler_job.py:182} INFO - Started process (PID=30434) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:54,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:35:54,184] {logging_mixin.py:104} INFO - [2022-03-18 22:35:54,184] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:54,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:35:54,313] {logging_mixin.py:104} INFO - [2022-03-18 22:35:54,312] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:35:54,358] {logging_mixin.py:104} INFO - [2022-03-18 22:35:54,357] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:35:54,374] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.203 seconds
[2022-03-18 22:36:24,477] {scheduler_job.py:182} INFO - Started process (PID=30461) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:24,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:36:24,484] {logging_mixin.py:104} INFO - [2022-03-18 22:36:24,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:24,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:24,575] {logging_mixin.py:104} INFO - [2022-03-18 22:36:24,575] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:36:24,614] {logging_mixin.py:104} INFO - [2022-03-18 22:36:24,614] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:36:24,629] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.159 seconds
[2022-03-18 22:36:55,296] {scheduler_job.py:182} INFO - Started process (PID=30491) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:55,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:36:55,304] {logging_mixin.py:104} INFO - [2022-03-18 22:36:55,304] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:55,355] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:36:55,397] {logging_mixin.py:104} INFO - [2022-03-18 22:36:55,396] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:36:55,435] {logging_mixin.py:104} INFO - [2022-03-18 22:36:55,434] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:36:55,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:37:26,199] {scheduler_job.py:182} INFO - Started process (PID=30523) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:26,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:37:26,206] {logging_mixin.py:104} INFO - [2022-03-18 22:37:26,205] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:26,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:26,302] {logging_mixin.py:104} INFO - [2022-03-18 22:37:26,302] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:37:26,342] {logging_mixin.py:104} INFO - [2022-03-18 22:37:26,341] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:37:26,356] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 22:37:56,981] {scheduler_job.py:182} INFO - Started process (PID=30555) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:56,985] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:37:56,988] {logging_mixin.py:104} INFO - [2022-03-18 22:37:56,988] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:57,040] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:37:57,083] {logging_mixin.py:104} INFO - [2022-03-18 22:37:57,083] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:37:57,128] {logging_mixin.py:104} INFO - [2022-03-18 22:37:57,128] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:37:57,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 22:38:27,956] {scheduler_job.py:182} INFO - Started process (PID=30587) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:27,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:38:27,963] {logging_mixin.py:104} INFO - [2022-03-18 22:38:27,962] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:28,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:28,058] {logging_mixin.py:104} INFO - [2022-03-18 22:38:28,058] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:38:28,097] {logging_mixin.py:104} INFO - [2022-03-18 22:38:28,097] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:38:28,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 22:38:58,688] {scheduler_job.py:182} INFO - Started process (PID=30619) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:58,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:38:58,696] {logging_mixin.py:104} INFO - [2022-03-18 22:38:58,695] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:58,747] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:38:58,788] {logging_mixin.py:104} INFO - [2022-03-18 22:38:58,788] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:38:58,827] {logging_mixin.py:104} INFO - [2022-03-18 22:38:58,826] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:38:58,841] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:39:29,470] {scheduler_job.py:182} INFO - Started process (PID=30651) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:39:29,474] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:39:29,477] {logging_mixin.py:104} INFO - [2022-03-18 22:39:29,476] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:39:29,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:39:29,571] {logging_mixin.py:104} INFO - [2022-03-18 22:39:29,571] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:39:29,612] {logging_mixin.py:104} INFO - [2022-03-18 22:39:29,611] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:39:29,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 22:40:02,077] {scheduler_job.py:182} INFO - Started process (PID=30683) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:02,082] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:40:02,085] {logging_mixin.py:104} INFO - [2022-03-18 22:40:02,085] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:02,139] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:02,190] {logging_mixin.py:104} INFO - [2022-03-18 22:40:02,190] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:40:02,236] {logging_mixin.py:104} INFO - [2022-03-18 22:40:02,236] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:40:02,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.183 seconds
[2022-03-18 22:40:32,427] {scheduler_job.py:182} INFO - Started process (PID=30708) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:32,431] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:40:32,434] {logging_mixin.py:104} INFO - [2022-03-18 22:40:32,434] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:32,487] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:40:32,542] {logging_mixin.py:104} INFO - [2022-03-18 22:40:32,542] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:40:32,586] {logging_mixin.py:104} INFO - [2022-03-18 22:40:32,586] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:40:32,604] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.185 seconds
[2022-03-18 22:41:02,812] {scheduler_job.py:182} INFO - Started process (PID=30733) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:02,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:41:02,818] {logging_mixin.py:104} INFO - [2022-03-18 22:41:02,818] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:02,871] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:02,914] {logging_mixin.py:104} INFO - [2022-03-18 22:41:02,913] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:41:02,952] {logging_mixin.py:104} INFO - [2022-03-18 22:41:02,952] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:41:02,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 22:41:33,758] {scheduler_job.py:182} INFO - Started process (PID=30765) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:33,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:41:33,765] {logging_mixin.py:104} INFO - [2022-03-18 22:41:33,764] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:33,819] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:41:33,861] {logging_mixin.py:104} INFO - [2022-03-18 22:41:33,861] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:41:33,902] {logging_mixin.py:104} INFO - [2022-03-18 22:41:33,901] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:41:33,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 22:42:04,722] {scheduler_job.py:182} INFO - Started process (PID=30797) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:04,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:42:04,730] {logging_mixin.py:104} INFO - [2022-03-18 22:42:04,729] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:04,781] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:04,825] {logging_mixin.py:104} INFO - [2022-03-18 22:42:04,825] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:42:04,866] {logging_mixin.py:104} INFO - [2022-03-18 22:42:04,866] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:42:04,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 22:42:35,657] {scheduler_job.py:182} INFO - Started process (PID=30829) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:35,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:42:35,664] {logging_mixin.py:104} INFO - [2022-03-18 22:42:35,663] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:35,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:42:35,759] {logging_mixin.py:104} INFO - [2022-03-18 22:42:35,758] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:42:35,801] {logging_mixin.py:104} INFO - [2022-03-18 22:42:35,801] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:42:35,816] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 22:43:06,604] {scheduler_job.py:182} INFO - Started process (PID=30861) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:06,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:43:06,610] {logging_mixin.py:104} INFO - [2022-03-18 22:43:06,610] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:06,670] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:06,714] {logging_mixin.py:104} INFO - [2022-03-18 22:43:06,713] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:43:06,753] {logging_mixin.py:104} INFO - [2022-03-18 22:43:06,752] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:43:06,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:43:37,566] {scheduler_job.py:182} INFO - Started process (PID=30893) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:37,572] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:43:37,574] {logging_mixin.py:104} INFO - [2022-03-18 22:43:37,574] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:37,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:43:37,668] {logging_mixin.py:104} INFO - [2022-03-18 22:43:37,667] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:43:37,706] {logging_mixin.py:104} INFO - [2022-03-18 22:43:37,706] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:43:37,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 22:44:08,578] {scheduler_job.py:182} INFO - Started process (PID=30925) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:08,583] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:44:08,586] {logging_mixin.py:104} INFO - [2022-03-18 22:44:08,585] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:08,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:08,678] {logging_mixin.py:104} INFO - [2022-03-18 22:44:08,678] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:44:08,717] {logging_mixin.py:104} INFO - [2022-03-18 22:44:08,716] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:44:08,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:44:41,789] {scheduler_job.py:182} INFO - Started process (PID=30957) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:41,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:44:41,797] {logging_mixin.py:104} INFO - [2022-03-18 22:44:41,795] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:41,845] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:44:41,887] {logging_mixin.py:104} INFO - [2022-03-18 22:44:41,887] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:44:41,928] {logging_mixin.py:104} INFO - [2022-03-18 22:44:41,927] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:44:41,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:45:12,760] {scheduler_job.py:182} INFO - Started process (PID=30975) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:12,766] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:45:12,769] {logging_mixin.py:104} INFO - [2022-03-18 22:45:12,768] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:12,821] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:12,868] {logging_mixin.py:104} INFO - [2022-03-18 22:45:12,868] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:45:12,914] {logging_mixin.py:104} INFO - [2022-03-18 22:45:12,914] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:45:12,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 22:45:43,171] {scheduler_job.py:182} INFO - Started process (PID=31003) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:43,176] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:45:43,178] {logging_mixin.py:104} INFO - [2022-03-18 22:45:43,178] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:43,233] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:45:43,284] {logging_mixin.py:104} INFO - [2022-03-18 22:45:43,284] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:45:43,330] {logging_mixin.py:104} INFO - [2022-03-18 22:45:43,329] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:45:43,345] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-18 22:46:13,470] {scheduler_job.py:182} INFO - Started process (PID=31035) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:13,475] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:46:13,478] {logging_mixin.py:104} INFO - [2022-03-18 22:46:13,478] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:13,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:13,582] {logging_mixin.py:104} INFO - [2022-03-18 22:46:13,582] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:46:13,622] {logging_mixin.py:104} INFO - [2022-03-18 22:46:13,621] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:46:13,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 22:46:43,871] {scheduler_job.py:182} INFO - Started process (PID=31067) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:43,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:46:43,877] {logging_mixin.py:104} INFO - [2022-03-18 22:46:43,877] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:43,926] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:46:43,969] {logging_mixin.py:104} INFO - [2022-03-18 22:46:43,968] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:46:44,008] {logging_mixin.py:104} INFO - [2022-03-18 22:46:44,008] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:46:44,023] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.158 seconds
[2022-03-18 22:47:15,204] {scheduler_job.py:182} INFO - Started process (PID=31103) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:15,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:47:15,211] {logging_mixin.py:104} INFO - [2022-03-18 22:47:15,211] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:15,265] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:15,310] {logging_mixin.py:104} INFO - [2022-03-18 22:47:15,309] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:47:15,353] {logging_mixin.py:104} INFO - [2022-03-18 22:47:15,353] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:47:15,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 22:47:46,274] {scheduler_job.py:182} INFO - Started process (PID=31135) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:46,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:47:46,281] {logging_mixin.py:104} INFO - [2022-03-18 22:47:46,280] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:46,334] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:47:46,386] {logging_mixin.py:104} INFO - [2022-03-18 22:47:46,386] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:47:46,432] {logging_mixin.py:104} INFO - [2022-03-18 22:47:46,431] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:47:46,451] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.184 seconds
[2022-03-18 22:48:17,196] {scheduler_job.py:182} INFO - Started process (PID=31167) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:17,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:48:17,204] {logging_mixin.py:104} INFO - [2022-03-18 22:48:17,204] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:17,254] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:17,296] {logging_mixin.py:104} INFO - [2022-03-18 22:48:17,296] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:48:17,334] {logging_mixin.py:104} INFO - [2022-03-18 22:48:17,334] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:48:17,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:48:47,434] {scheduler_job.py:182} INFO - Started process (PID=31197) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:47,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:48:47,441] {logging_mixin.py:104} INFO - [2022-03-18 22:48:47,441] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:47,493] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:48:47,550] {logging_mixin.py:104} INFO - [2022-03-18 22:48:47,550] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:48:47,601] {logging_mixin.py:104} INFO - [2022-03-18 22:48:47,601] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:48:47,620] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.193 seconds
[2022-03-18 22:49:20,949] {scheduler_job.py:182} INFO - Started process (PID=31231) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:20,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:49:20,955] {logging_mixin.py:104} INFO - [2022-03-18 22:49:20,955] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:21,008] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:21,057] {logging_mixin.py:104} INFO - [2022-03-18 22:49:21,056] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:49:21,100] {logging_mixin.py:104} INFO - [2022-03-18 22:49:21,100] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:49:21,116] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.174 seconds
[2022-03-18 22:49:51,555] {scheduler_job.py:182} INFO - Started process (PID=31255) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:51,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:49:51,562] {logging_mixin.py:104} INFO - [2022-03-18 22:49:51,562] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:51,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:49:51,655] {logging_mixin.py:104} INFO - [2022-03-18 22:49:51,655] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:49:51,697] {logging_mixin.py:104} INFO - [2022-03-18 22:49:51,697] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:49:51,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 22:50:22,007] {scheduler_job.py:182} INFO - Started process (PID=31283) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:22,016] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:50:22,020] {logging_mixin.py:104} INFO - [2022-03-18 22:50:22,020] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:22,083] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:22,141] {logging_mixin.py:104} INFO - [2022-03-18 22:50:22,141] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:50:22,189] {logging_mixin.py:104} INFO - [2022-03-18 22:50:22,189] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:50:22,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.207 seconds
[2022-03-18 22:50:52,265] {scheduler_job.py:182} INFO - Started process (PID=31313) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:52,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:50:52,272] {logging_mixin.py:104} INFO - [2022-03-18 22:50:52,272] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:52,327] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:50:52,375] {logging_mixin.py:104} INFO - [2022-03-18 22:50:52,374] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:50:52,417] {logging_mixin.py:104} INFO - [2022-03-18 22:50:52,417] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:50:52,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.175 seconds
[2022-03-18 22:51:23,390] {scheduler_job.py:182} INFO - Started process (PID=31345) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:23,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:51:23,397] {logging_mixin.py:104} INFO - [2022-03-18 22:51:23,397] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:23,454] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:23,505] {logging_mixin.py:104} INFO - [2022-03-18 22:51:23,504] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:51:23,546] {logging_mixin.py:104} INFO - [2022-03-18 22:51:23,545] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:51:23,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.178 seconds
[2022-03-18 22:51:54,427] {scheduler_job.py:182} INFO - Started process (PID=31377) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:54,430] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:51:54,434] {logging_mixin.py:104} INFO - [2022-03-18 22:51:54,433] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:54,486] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:51:54,528] {logging_mixin.py:104} INFO - [2022-03-18 22:51:54,528] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:51:54,567] {logging_mixin.py:104} INFO - [2022-03-18 22:51:54,567] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:51:54,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:52:25,433] {scheduler_job.py:182} INFO - Started process (PID=31409) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:25,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:52:25,440] {logging_mixin.py:104} INFO - [2022-03-18 22:52:25,440] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:25,493] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:25,540] {logging_mixin.py:104} INFO - [2022-03-18 22:52:25,540] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:52:25,581] {logging_mixin.py:104} INFO - [2022-03-18 22:52:25,581] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:52:25,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.171 seconds
[2022-03-18 22:52:56,293] {scheduler_job.py:182} INFO - Started process (PID=31441) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:56,297] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:52:56,300] {logging_mixin.py:104} INFO - [2022-03-18 22:52:56,299] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:56,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:52:56,398] {logging_mixin.py:104} INFO - [2022-03-18 22:52:56,398] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:52:56,438] {logging_mixin.py:104} INFO - [2022-03-18 22:52:56,438] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:52:56,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.168 seconds
[2022-03-18 22:53:27,368] {scheduler_job.py:182} INFO - Started process (PID=31473) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:53:27,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:53:27,375] {logging_mixin.py:104} INFO - [2022-03-18 22:53:27,375] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:53:27,428] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:53:27,470] {logging_mixin.py:104} INFO - [2022-03-18 22:53:27,470] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:53:27,512] {logging_mixin.py:104} INFO - [2022-03-18 22:53:27,512] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:53:27,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.165 seconds
[2022-03-18 22:54:00,476] {scheduler_job.py:182} INFO - Started process (PID=31505) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:00,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:54:00,484] {logging_mixin.py:104} INFO - [2022-03-18 22:54:00,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:00,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:00,578] {logging_mixin.py:104} INFO - [2022-03-18 22:54:00,578] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:54:00,624] {logging_mixin.py:104} INFO - [2022-03-18 22:54:00,623] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:54:00,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:54:31,149] {scheduler_job.py:182} INFO - Started process (PID=31529) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:31,153] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:54:31,156] {logging_mixin.py:104} INFO - [2022-03-18 22:54:31,156] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:31,207] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:54:31,252] {logging_mixin.py:104} INFO - [2022-03-18 22:54:31,252] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:54:31,297] {logging_mixin.py:104} INFO - [2022-03-18 22:54:31,297] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:54:31,314] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.172 seconds
[2022-03-18 22:55:01,371] {scheduler_job.py:182} INFO - Started process (PID=31553) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:01,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:55:01,378] {logging_mixin.py:104} INFO - [2022-03-18 22:55:01,378] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:01,430] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:01,482] {logging_mixin.py:104} INFO - [2022-03-18 22:55:01,482] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:55:01,535] {logging_mixin.py:104} INFO - [2022-03-18 22:55:01,534] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:55:01,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.186 seconds
[2022-03-18 22:55:32,422] {scheduler_job.py:182} INFO - Started process (PID=31587) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:32,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:55:32,428] {logging_mixin.py:104} INFO - [2022-03-18 22:55:32,428] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:32,480] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:55:32,523] {logging_mixin.py:104} INFO - [2022-03-18 22:55:32,523] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:55:32,562] {logging_mixin.py:104} INFO - [2022-03-18 22:55:32,562] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:55:32,578] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.163 seconds
[2022-03-18 22:56:03,285] {scheduler_job.py:182} INFO - Started process (PID=31619) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:03,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:56:03,292] {logging_mixin.py:104} INFO - [2022-03-18 22:56:03,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:03,344] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:03,386] {logging_mixin.py:104} INFO - [2022-03-18 22:56:03,385] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:56:03,425] {logging_mixin.py:104} INFO - [2022-03-18 22:56:03,424] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:56:03,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.161 seconds
[2022-03-18 22:56:34,151] {scheduler_job.py:182} INFO - Started process (PID=31651) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:34,155] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:56:34,158] {logging_mixin.py:104} INFO - [2022-03-18 22:56:34,158] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:34,211] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:56:34,255] {logging_mixin.py:104} INFO - [2022-03-18 22:56:34,254] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:56:34,296] {logging_mixin.py:104} INFO - [2022-03-18 22:56:34,296] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:56:34,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.166 seconds
[2022-03-18 22:57:05,145] {scheduler_job.py:182} INFO - Started process (PID=31683) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:05,150] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:57:05,154] {logging_mixin.py:104} INFO - [2022-03-18 22:57:05,153] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:05,206] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:05,250] {logging_mixin.py:104} INFO - [2022-03-18 22:57:05,250] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:57:05,289] {logging_mixin.py:104} INFO - [2022-03-18 22:57:05,289] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:57:05,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.167 seconds
[2022-03-18 22:57:36,090] {scheduler_job.py:182} INFO - Started process (PID=31715) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:36,094] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:57:36,097] {logging_mixin.py:104} INFO - [2022-03-18 22:57:36,097] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:36,143] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:57:36,188] {logging_mixin.py:104} INFO - [2022-03-18 22:57:36,187] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:57:36,227] {logging_mixin.py:104} INFO - [2022-03-18 22:57:36,226] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:57:36,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.160 seconds
[2022-03-18 22:58:06,938] {scheduler_job.py:182} INFO - Started process (PID=31747) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:06,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:58:06,945] {logging_mixin.py:104} INFO - [2022-03-18 22:58:06,945] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:06,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:07,042] {logging_mixin.py:104} INFO - [2022-03-18 22:58:07,041] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:58:07,084] {logging_mixin.py:104} INFO - [2022-03-18 22:58:07,083] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:58:07,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.169 seconds
[2022-03-18 22:58:39,340] {scheduler_job.py:182} INFO - Started process (PID=31779) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:39,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:58:39,347] {logging_mixin.py:104} INFO - [2022-03-18 22:58:39,346] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:39,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:58:39,445] {logging_mixin.py:104} INFO - [2022-03-18 22:58:39,445] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:58:39,489] {logging_mixin.py:104} INFO - [2022-03-18 22:58:39,489] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:58:39,506] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 22:59:10,077] {scheduler_job.py:182} INFO - Started process (PID=31803) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:10,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:59:10,083] {logging_mixin.py:104} INFO - [2022-03-18 22:59:10,083] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:10,131] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:10,175] {logging_mixin.py:104} INFO - [2022-03-18 22:59:10,174] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:59:10,218] {logging_mixin.py:104} INFO - [2022-03-18 22:59:10,217] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:59:10,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.164 seconds
[2022-03-18 22:59:40,939] {scheduler_job.py:182} INFO - Started process (PID=31829) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:40,944] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 22:59:40,946] {logging_mixin.py:104} INFO - [2022-03-18 22:59:40,946] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:41,002] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 22:59:41,046] {logging_mixin.py:104} INFO - [2022-03-18 22:59:41,045] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 22:59:41,086] {logging_mixin.py:104} INFO - [2022-03-18 22:59:41,086] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 22:59:41,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
[2022-03-18 23:00:12,308] {scheduler_job.py:182} INFO - Started process (PID=31861) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 23:00:12,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 23:00:12,316] {logging_mixin.py:104} INFO - [2022-03-18 23:00:12,315] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 23:00:12,375] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 23:00:12,420] {logging_mixin.py:104} INFO - [2022-03-18 23:00:12,420] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 23:00:12,460] {logging_mixin.py:104} INFO - [2022-03-18 23:00:12,460] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 23:00:12,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.173 seconds
[2022-03-18 23:32:33,115] {scheduler_job.py:182} INFO - Started process (PID=31879) to work on /opt/airflow/dags/spark_job.py
[2022-03-18 23:32:33,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/spark_job.py for tasks to queue
[2022-03-18 23:32:33,122] {logging_mixin.py:104} INFO - [2022-03-18 23:32:33,122] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job.py
[2022-03-18 23:32:33,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['sparkoperator_demo']) retrieved from /opt/airflow/dags/spark_job.py
[2022-03-18 23:32:33,219] {logging_mixin.py:104} INFO - [2022-03-18 23:32:33,218] {dag.py:1818} INFO - Sync 1 DAGs
[2022-03-18 23:32:33,262] {logging_mixin.py:104} INFO - [2022-03-18 23:32:33,262] {dag.py:2273} INFO - Setting next_dagrun for sparkoperator_demo to None
[2022-03-18 23:32:33,279] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/spark_job.py took 0.170 seconds
